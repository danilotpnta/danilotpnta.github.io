<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Danilo Toapanta">
<meta name="dcterms.date" content="2023-12-07">
<meta name="description" content="Description of this Post">

<title>Danilo Toapanta - Generative modelling and Deep Variational Inference</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../assets/danilo.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/material-icons-0.14.2/mi.css" rel="stylesheet">
<script>
window.MathJax = {
  tex: {
    tags: 'ams'
  }
};
</script>
<link rel="shortcut icon" href="../../../../../../../../../../../assets/danilo.ico">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../css/index-posts.css">
</head>

<body class="floating nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title"><span id="danilo_topanta_brand"> Danilo Toapanta</span> <a id="mysite" class="mysite" href="../../../../../sites/">MySites</a></span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text"><span id="home-welcome-msg">Home</span></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog/index.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects/index.html" rel="" target="">
 <span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about/index.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/danilotpnta?tab=repositories" rel="" target="_blank"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full blog-page" style="display: none;">
    <div class="quarto-title-banner page-columns page-full">
        <div class="quarto-title column-body">
            <h1 class="title">Generative modelling and Deep Variational Inference</h1>
                
            <!-- Description Block -->
                        <div>
                <div class="description">
                    Description of this Post
                </div>
            </div>
                        
            <!-- Categories Block -->
                                            <div class="quarto-categories">

                    <!-- Display Categories -->
                                            <div class="quarto-category">
                            <a href="../../blog/#category=All">
                                All
                            </a>
                        </div> 
                                            <div class="quarto-category">
                            <a href="../../blog/#category=Deep Learning">
                                Deep Learning
                            </a>
                        </div> 
                                            <div class="quarto-category">
                            <a href="../../blog/#category=TAGS">
                                TAGS
                            </a>
                        </div> 
                    
                    <!-- Display Tags if any -->
                                    </div>
                            
        </div>
    </div>


    
    <div class="quarto-title-meta">

        <div>
        <div class="quarto-title-meta-heading">Author</div>
        <div class="quarto-title-meta-contents">
                 <p><a href="https://danilotpnta.github.io/">Danilo Toapanta</a> </p>
              </div>
      </div>
        
        <div>
        <div class="quarto-title-meta-heading">Published</div>
        <div class="quarto-title-meta-contents">
          <p class="date">December 7, 2023</p>
        </div>
      </div>
      
        
      </div>
      

    
</header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">
<script>
    var currentUrl = window.location.href;
    var index_init_post = currentUrl.lastIndexOf("/20");
    var string_init_post= currentUrl.slice(index_init_post, index_init_post+3 );

    // console.log("currentUrl: " + currentUrl);
    // console.log("index: " + index_init_post);
    // console.log("string: " + string_init_post);

    // If is equal to /blog/20... then make navbar title READING MODE
    if (string_init_post === "/20"){
        let mysite = document.getElementById("mysite");
        mysite.classList.add("mysite-change");

        let navbar = document.getElementById("danilo_topanta_brand");
        navbar.classList.add("navbar-brand-change");

        // This will render a new title saying READING DANILOS BLOG
        // navbar.innerHTML = 'You are Reading Danilo\'s Blog<span style="font-size:35px; vertical-align: middle; opacity: 0.65; padding-bottom: 6px; padding-left: 14px;" class="material-icons-round"> auto_awesome </span>';
        
        const smallDevice = window.matchMedia("(min-width: 570px)");
        smallDevice.addListener(handleDeviceChange);

        function handleDeviceChange(mediaQuery) {
            if (mediaQuery.matches) {
                navbar.innerHTML = "";
                // navbar.innerHTML = "<-- You are Reading Danilo's Blog -->";
            } else  {
                navbar.innerHTML = "Danilo Toapanta";
            }
        }

        // Run it initially
        handleDeviceChange(smallDevice);

        let link = document.getElementsByClassName("navbar-brand")[0];
        link.classList.add("disablePointerEvents");

        let brand_container = document.getElementsByClassName("navbar-brand-container")[0];
        brand_container.classList.add("navbar-brand-container-new-padding");

    }
</script>


<!-- <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Running my first Marathon</h1>
                  <div>
        <div class="description">
          I will be running at the 42km TCS Amsterdam 2023, 15th October
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">News</div>
              </div>
                  </div>
  </div> -->

  <!-- ---
  coming-soon: true
  tags: [Spanish]
  --- -->








<main id="title-block-header" class="quarto-title-block default page-columns page-full" style="padding-bottom: 40px;">

    <div class="quarto-title column-body" style="margin-bottom: 1em;">
        <h1 class="title" style="padding-bottom:8px" ;="">Generative modelling and Deep Variational Inference</h1>
        
        <!-- Description Block -->
                    <div>
                <div class="description">
                    Description of this Post
                </div>
            </div>
        
        <!-- Categories Block -->
                    
                <!-- Display Categories -->
                <div class="quarto-categories">
                    <!-- <div id="tag-icon-blog" class="quarto-category tags-title">
                        <i class="fa-solid fa-hashtag" ></i> Categories:
                    </div> -->

                                            <div id="All" class="quarto-category">
                            <a href="../../blog/#category=All">
                                All
                            </a>
                        </div>
                                            <div id="Deep Learning" class="quarto-category">
                            <a href="../../blog/#category=Deep Learning">
                                Deep Learning
                            </a>
                        </div>
                                            <div id="TAGS" class="quarto-category">
                            <a href="../../blog/#category=TAGS">
                                TAGS
                            </a>
                        </div>
                                    </div>
                


                <div class="quarto-categories tag-categories">
                    
                    <!-- Tags Icon  -->
                    <!-- <div id="tag-icon-blog" class="quarto-category tags-title"> -->
                        <!-- <i class="fa-solid fa-tag" ></i> Tags: -->
                        <!-- <i class="fa-solid fa-hashtag" ></i> Tags: -->
                        <!-- <span class="material-icons-outlined" >local_offer</span> Tags: -->
                        <!-- / -->
                    <!-- </div> -->

                    <!-- Display Tags -->
                                            <div id="All-from-here" class="quarto-category tags-title" style="display: none;">
                            <a href="../../blog/#category=All">
                               <!-- <span class="hasth-tag">
                                #
                                </span> -->
                                All
                            </a>
                        </div>
                                            <div id="Deep Learning-from-here" class="quarto-category tags-title" style="display: none;">
                            <a href="../../blog/#category=Deep Learning">
                               <!-- <span class="hasth-tag">
                                #
                                </span> -->
                                Deep Learning
                            </a>
                        </div>
                                            <div id="TAGS-from-here" class="quarto-category tags-title" style="display: none;">
                            <a href="../../blog/#category=TAGS">
                               <!-- <span class="hasth-tag">
                                #
                                </span> -->
                                TAGS
                            </a>
                        </div>
                    
                    
                </div>

                    
    </div>


    
    <div class="quarto-title-meta">

        <div>
        <div class="quarto-title-meta-heading">Author</div>
        <div class="quarto-title-meta-contents">
                 <p><a href="https://danilotpnta.github.io/">Danilo Toapanta</a> </p>
              </div>
      </div>
        
        <div>
        <div class="quarto-title-meta-heading">Published</div>
        <div class="quarto-title-meta-contents">
          <p class="date">December 7, 2023</p>
        </div>
      </div>
      
        
      </div>
      

    <!-- Current link: Font-awesome, Google icons, Bootstrap icons -->
    
</main>

<!-- ## Title
<center>![Slide 1](imgs/page_1.jpeg){.w575}</center><pre></pre> -->
<!-- 
## Your feedback
<center>![Slide 2](imgs/page_2.jpeg){.w575}</center><pre></pre>



## Your feedback:
<center>![Slide 3](imgs/page_3.jpeg){.w575}</center><pre></pre>



## Your feedback
<center>![Slide 4](imgs/page_4.jpeg){.w575}</center><pre></pre>



## Your feedback
<center>![Slide 5](imgs/page_5.jpeg){.w575}</center><pre></pre>



## Your feedback
<center>![Slide 6](imgs/page_6.jpeg){.w575}</center><pre></pre> -->
<!-- 
## Title
<center>![Slide 7](imgs/page_7.jpeg){.w575}</center><pre></pre> -->
<section id="re-cap-graph-representation-for-us" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="re-cap-graph-representation-for-us"><span class="header-section-number">1</span> Re Cap Graph representation for us</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_8.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 8</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="title" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="title"><span class="header-section-number">2</span> Title</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_9.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 9</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="recap-sss-yyy" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="recap-sss-yyy"><span class="header-section-number">3</span> Recap sss yyy</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_10.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 10</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="title-1" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="title-1"><span class="header-section-number">4</span> Title</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_11.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 11</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="todays-lecture-overview" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="todays-lecture-overview"><span class="header-section-number">5</span> Today’s lecture Overview</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_12.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 12</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="what-is-generative-modelling" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="what-is-generative-modelling"><span class="header-section-number">6</span> What is generative modelling?</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_13.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 13</figcaption>
</figure>
</div>
</center>
<pre></pre>
<blockquote class="blockquote">
<p>General: - p(x) is the probability distribution of the data itself.</p>
</blockquote>
<p><strong>Discriminative model:</strong> discriminate between different kinds of data instances - you predict <span class="math inline">\(y\)</span> given <span class="math inline">\(x\)</span>, where <span class="math inline">\(y\)</span> could be the label i.e what kind of dog is in the image and <span class="math inline">\(x\)</span> is the data. - p(y|x) Its aim is to model the <strong>decision boundary</strong> (whether is A or B, the cat class or the dog class) or the relationship between input features and the output directly. - p(y|x) says get me a certain label conditional on some inputs. - Typically more effective when the primary goal is to perform a specific task, such as classification or regression.</p>
<p><strong>Generative models:</strong> can generate new data instances. - They focus on estimating the probability of observing a particular set of input features - p(x) says how probable an image is to be i.e a dog - Can be used for tasks like data generation, missing data imputation, and anomaly detection. - capture the joint probability p(X, Y), or just p(X) if there are no labels.</p>
<p><strong>The difference:</strong></p>
<p>A generative model could generate new photos of animals that look like real animals, while a discriminative model could tell a dog from a cat. GANs are just one kind of generative model.</p>
<p><strong>About probability dsitributions:</strong></p>
<p>A <em>Discriminative classifier</em> like a decision tree can label an instance without assigning a probability to that label. Such a classifier would still be a model because the distribution of all predicted labels would model the real distribution of labels in the data.</p>
<p>A <em>Generative model</em> can model a distribution by producing convincing “fake” data that looks like it’s drawn from that distribution.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Generative models are Hard, they model more
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Generative models tackle a more difficult task than analogous discriminative models. Generative models have to model more.</p>
<p>A generative model for images might capture correlations like “things that look like boats are probably going to appear near things that look like water” and “eyes are unlikely to appear on foreheads.” These are very complicated distributions.</p>
<p>In contrast, a discriminative model might learn the difference between “sailboat” or “not sailboat” by just looking for a few tell-tale patterns. It could ignore many of the correlations that the generative model must get right.</p>
<p>Discriminative models try to draw boundaries in the data space, while generative models try to model how data is placed throughout the space. For example, the following diagram shows discriminative and generative models of handwritten digits:</p>
<center>
<img src="imgs/2023-12-07-14-29-42.png" class="w550 img-fluid">
</center>
<pre></pre>
<p>The discriminative model tries to tell the difference between handwritten 0’s and 1’s by drawing a line in the data space. If it gets the line right, it can distinguish 0’s from 1’s without ever having to model exactly where the instances are placed in the data space on either side of the line.</p>
<p>In contrast, the generative model tries to produce convincing 1’s and 0’s by generating digits that fall close to their real counterparts in the data space. It has to model the distribution throughout the data space.</p>
<p>GANs offer an effective way to train such rich models to resemble a real distribution. To understand how they work we’ll need to understand the basic structure of a GAN.</p>
</div>
</div>
</div>
</section>
<section id="why-generative-modelling" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="why-generative-modelling"><span class="header-section-number">7</span> Why generative modelling?</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_14.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 14</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="why-generative-modelling-more-reasons" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="why-generative-modelling-more-reasons"><span class="header-section-number">8</span> Why generative modelling? More reasons</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_15.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 15</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="bayes-rule-if-we-have-generative-models-we-have-it-all" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="bayes-rule-if-we-have-generative-models-we-have-it-all"><span class="header-section-number">9</span> Bayes rule: if we have generative models: we have it all</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_16.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 16</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>p(y|x) was all ConvNets, the transformers and all models before.</p>
<p>p(x) is parametrize with theta</p>
</section>
<section id="a-map-of-generative-models" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="a-map-of-generative-models"><span class="header-section-number">10</span> A map of generative models</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_17.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 17</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Here with GANs you can sample images but you cannot say how likely a given image is</p>
<p><strong>Types of Generative models</strong></p>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lilianweng.github.io/posts/2018-10-13-flow-models/three-generative-models.png" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Lil’s <a href="https://lilianweng.github.io/posts/2018-10-13-flow-models/#types-of-generative-models">Blog</a></figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="title-2" class="level2" data-number="11">
<h2 data-number="11" class="anchored" data-anchor-id="title-2"><span class="header-section-number">11</span> Title</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_18.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 18</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="autoencoders-shape" class="level2" data-number="12">
<h2 data-number="12" class="anchored" data-anchor-id="autoencoders-shape"><span class="header-section-number">12</span> Autoencoders: shape</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_19.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 19</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>It is called Autoencoder because the ouput has the same size as the input</p>
<p>Because of the bottle neck it will only learn what is important to reconstruct the input back, which could be for instance noise</p>
</section>
<section id="autoencoders-structure" class="level2" data-number="13">
<h2 data-number="13" class="anchored" data-anchor-id="autoencoders-structure"><span class="header-section-number">13</span> Autoencoders: structure</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_20.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 20</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>For instance CNN because it is important for us to have in every layer the proper dimensions</p>
</section>
<section id="learning-autoencoders" class="level2" data-number="14">
<h2 data-number="14" class="anchored" data-anchor-id="learning-autoencoders"><span class="header-section-number">14</span> Learning Autoencoders</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_21.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 21</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Here is an unsupervised loss, because we do not use any labels</p>
</section>
<section id="autoencoders-why-though" class="level2" data-number="15">
<h2 data-number="15" class="anchored" data-anchor-id="autoencoders-why-though"><span class="header-section-number">15</span> Autoencoders: why though?</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_22.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 22</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>The encoder learns to compress the input but compress it just enougth such that the decoder can reconstructed again</p>
</section>
<section id="autoencoders-for-representation-learning-ie-use-the-encoder-afterwards" class="level2" data-number="16">
<h2 data-number="16" class="anchored" data-anchor-id="autoencoders-for-representation-learning-ie-use-the-encoder-afterwards"><span class="header-section-number">16</span> Autoencoders for representation learning (ie use the encoder afterwards)</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_23.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 23</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>The loss does not have any dependency on labels, no prior knowledge</p>
</section>
<section id="autoencoders-for-representation-learning" class="level2" data-number="17">
<h2 data-number="17" class="anchored" data-anchor-id="autoencoders-for-representation-learning"><span class="header-section-number">17</span> Autoencoders for representation learning</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_24.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 24</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Compared to PCA approach the colors are better separated, both use same data. Except that the autoencoder uses a NN</p>
</section>
<section id="autoencoders-for-representation-learning-13years-later-bigbigan" class="level2" data-number="18">
<h2 data-number="18" class="anchored" data-anchor-id="autoencoders-for-representation-learning-13years-later-bigbigan"><span class="header-section-number">18</span> “Autoencoders” for representation learning (13years later): BigBiGAN</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_25.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 25</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="dimensionality-of-latent-space" class="level2" data-number="19">
<h2 data-number="19" class="anchored" data-anchor-id="dimensionality-of-latent-space"><span class="header-section-number">19</span> Dimensionality of latent space</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_26.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 26</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>If the dimensionality of the latent is too low then you cannot reconstruct all the details, because there is so much information that you can compress in a 2D space</p>
</section>
<section id="quiz" class="level2" data-number="20">
<h2 data-number="20" class="anchored" data-anchor-id="quiz"><span class="header-section-number">20</span> Quiz:</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_27.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 27</figcaption>
</figure>
</div>
</center>
<pre></pre>
<ol start="4" type="1">
<li>True: because PCA minimizes the L2 norm so it has the same problems as Least Square fitting. So L2 looks like a quadratic function depending how far are you from the thing that you are trying to fit. So all the stuff that is further away gets quadratically exaggerated.</li>
<li>Not quite True: PCA gives you linear combinations of features that could be interpretable but mostly they are not because for example you want to estimate the price of a house, then what you end up is you have 5 times the size of the house - 0.2 the location of the house, which then you get a feature with positive and negative coefficients which is not interpretable</li>
</ol>
</section>
<section id="pca-refresher" class="level2" data-number="21">
<h2 data-number="21" class="anchored" data-anchor-id="pca-refresher"><span class="header-section-number">21</span> PCA Refresher</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/2023-12-07-15-36-28.png" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 28</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Continue this explanation <a href="h>ps://stats.stackexchange.com/quest ions/2691/making-sense-of-principal- component-analysis-eigenvectors- eigenvalues">here</a></p>
</section>
<section id="autoencoder-applications" class="level2" data-number="22">
<h2 data-number="22" class="anchored" data-anchor-id="autoencoder-applications"><span class="header-section-number">22</span> Autoencoder applications</h2>
<center>
<img src="imgs/2023-12-07-15-41-03.png" class="w250 img-fluid">
</center>
<pre></pre>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_29.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 29</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Autoencoder do not need prior knowledge abour invariances, or augmentations.</p>
</section>
<section id="why-can-they-not-generate-new-data-points" class="level2" data-number="23">
<h2 data-number="23" class="anchored" data-anchor-id="why-can-they-not-generate-new-data-points"><span class="header-section-number">23</span> Why can they not generate new data points?</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_30.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 30</figcaption>
</figure>
</div>
</center>
<pre></pre>
<ul>
<li>They can reconstruct the input: encoder</li>
<li>They cannot generate new data: decoder</li>
</ul>
<p>We cannot generate new data because the latent representation can be extremely “entagled”. For instance there is no way to know if i.e the 1st dimension is ranging from,…. So we don’t know how the dimensions are related.</p>
<p>That means we do not know how we would sample a new datapoint from this latent space because the NN has been trained to reconstruct the input. It has not been given any instruction that if I take a different input in this latent space that it should still reconstruct something.</p>
</section>
<section id="what-we-will-arrive-at-in-this-lecture" class="level2" data-number="24">
<h2 data-number="24" class="anchored" data-anchor-id="what-we-will-arrive-at-in-this-lecture"><span class="header-section-number">24</span> What we will arrive at in this lecture</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_31.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 31</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Now we parametrized the latent z with <span class="math inline">\(\mu, \sigma\)</span>, those are the variables that will be coming from a Gaussian and with these variables we are parametrize a latent distribution over the latent p(z)</p>
<p>With this p(z) data distribution we can sample a sample ‘z’, push it trough the decoder and then we can get an ouput out.</p>
<p>VAE sample from the data and get a probability for a particular image</p>
</section>
<section id="recent-vae-use-cases" class="level2" data-number="25">
<h2 data-number="25" class="anchored" data-anchor-id="recent-vae-use-cases"><span class="header-section-number">25</span> Recent VAE use cases</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_32.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 32</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="for-vaes-we-need-to-understand-latent-variable-models" class="level2" data-number="26">
<h2 data-number="26" class="anchored" data-anchor-id="for-vaes-we-need-to-understand-latent-variable-models"><span class="header-section-number">26</span> For VAEs we need to understand latent variable models</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_33.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 33</figcaption>
</figure>
</div>
</center>
<pre></pre>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Notes on this slide
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>You first sample z and that generates with a different distribution generates your observed data x</p>
<p><strong>Goal</strong> is to compute:</p>
<ul>
<li><span class="math inline">\(p(x)\)</span> likelihood</li>
<li><span class="math inline">\(p(z|x)\)</span> posterior distribution</li>
</ul>
</div>
</div>
</div>
<ul>
<li><span class="math inline">\(p_{\theta}(z)\)</span>: Prior, distribution for the latent variable</li>
<li><span class="math inline">\(p_{\theta}(x|z)\)</span>: Likelihood, connects the latent variable wot the observation</li>
<li><span class="math inline">\(p_{\theta}(z|x)\)</span>: Posterior</li>
</ul>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lilianweng.github.io/posts/2018-08-12-vae/VAE-graphical-model.png" class="w375 img-fluid figure-img"></p>
<figcaption class="figure-caption">Source at Lil’s <a href="https://lilianweng.github.io/posts/2018-08-12-vae/">Blog</a></figcaption>
</figure>
</div>
</center>
<pre></pre>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.danilotpnta.com/blog/2023-10-07_latent-variable-models-&amp;-k-means-clustering/2023-10-10-23-15-02.png" class="w475 img-fluid figure-img"></p>
<figcaption class="figure-caption">Source in my blog about: <a href="https://www.danilotpnta.com/blog/2023-10-07_latent-variable-models-&amp;-k-means-clustering/2023-10-10-23-15-02.png">Latent models</a></figcaption>
</figure>
</div>
</center>
<pre></pre>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Summary of VAE
</div>
</div>
<div class="callout-body-container callout-body">
<p>Variational Autoencoders (VAEs) are a type of generative model that learn to represent data in a lower-dimensional latent space and can generate new data that resemble the input data. Here’s an overview of the formulas involved, the known and unknown distributions, what corresponds to each part of the VAE architecture, and what needs to be computed, trained, or optimized.</p>
<section id="known-distributions" class="level3" data-number="26.1">
<h3 data-number="26.1" class="anchored" data-anchor-id="known-distributions"><span class="header-section-number">26.1</span> Known Distributions:</h3>
<ol type="1">
<li><strong>Prior Distribution of Latent Variables (p(z))</strong>:
<ul>
<li>Typically assumed to be a standard normal distribution: <span class="math inline">\(p(z) = \mathcal{N}(z; 0, I)\)</span>.</li>
<li>This is a design choice and is known a priori.</li>
</ul></li>
<li><strong>Likelihood of Data Given Latent Variables (p(x|z))</strong>:
<ul>
<li>This is modeled by the decoder network, usually parameterized as a normal distribution <span class="math inline">\(\mathcal{N}(x; \mu_{\theta}(z), \sigma^2_{\theta}(z)I)\)</span> where <span class="math inline">\(\mu_{\theta}(z)\)</span> and <span class="math inline">\(\sigma^2_{\theta}(z)\)</span> are the outputs of the decoder.</li>
<li>The parameters <span class="math inline">\(\theta\)</span> of the decoder network that determine this distribution are unknown and need to be learned.</li>
</ul></li>
</ol>
</section>
<section id="unknown-distributions" class="level3" data-number="26.2">
<h3 data-number="26.2" class="anchored" data-anchor-id="unknown-distributions"><span class="header-section-number">26.2</span> Unknown Distributions:</h3>
<ol type="1">
<li><strong>Posterior Distribution of Latent Variables Given Data (p(z|x))</strong>:
<ul>
<li>This is the true but intractable distribution we want to approximate.</li>
<li>It cannot be computed directly in most cases.</li>
</ul></li>
</ol>
</section>
<section id="approximate-distribution" class="level3" data-number="26.3">
<h3 data-number="26.3" class="anchored" data-anchor-id="approximate-distribution"><span class="header-section-number">26.3</span> Approximate Distribution:</h3>
<ol type="1">
<li><strong>Variational Approximation to the Posterior (q(z|x))</strong>:
<ul>
<li>This is approximated by the encoder network, usually parameterized as a normal distribution <span class="math inline">\(q(z|x) = \mathcal{N}(z; \mu_{\phi}(x), \sigma^2_{\phi}(x)I)\)</span> where <span class="math inline">\(\mu_{\phi}(x)\)</span> and <span class="math inline">\(\sigma^2_{\phi}(x)\)</span> are the outputs of the encoder.</li>
<li>The parameters <span class="math inline">\(\phi\)</span> of the encoder network that determine this distribution are unknown and need to be learned.</li>
</ul></li>
</ol>
</section>
<section id="objective-function" class="level3" data-number="26.4">
<h3 data-number="26.4" class="anchored" data-anchor-id="objective-function"><span class="header-section-number">26.4</span> Objective Function:</h3>
<ol type="1">
<li><strong>Evidence Lower Bound (ELBO)</strong>:
<ul>
<li>The ELBO is the objective function that VAEs maximize. It is a lower bound on the logarithm of the marginal likelihood of the data <span class="math inline">\(p(x)\)</span>.</li>
<li>The ELBO is given by: <span class="math inline">\(\text{ELBO} = \mathbb{E}_{q(z|x)}[\log p(x|z)] - \text{KL}[q(z|x) || p(z)]\)</span></li>
<li>The first term is the expected log likelihood of the data given the latent variables, which encourages the decoder to reconstruct the data well.</li>
<li>The second term is the Kullback-Leibler divergence between the approximate posterior and the prior, which encourages the approximate posterior to be similar to the prior.</li>
</ul></li>
</ol>
</section>
<section id="example" class="level3" data-number="26.5">
<h3 data-number="26.5" class="anchored" data-anchor-id="example"><span class="header-section-number">26.5</span> Example:</h3>
<ul>
<li>Let’s say we have a dataset of images and we want to model the distribution of these images using a VAE.</li>
<li><strong>Encoder (Approximate Posterior q(z|x))</strong>: An image <span class="math inline">\(x\)</span> is input into the encoder, which outputs parameters <span class="math inline">\(\mu_{\phi}(x)\)</span> and <span class="math inline">\(\sigma^2_{\phi}(x)\)</span> of a normal distribution representing the distribution of the latent variables for this image.</li>
<li><strong>Decoder (Likelihood p(x|z))</strong>: A latent variable <span class="math inline">\(z\)</span> is sampled from the approximate posterior and input into the decoder, which outputs parameters of a distribution over images. For simplicity, assume this is also a normal distribution with mean <span class="math inline">\(\mu_{\theta}(z)\)</span> and fixed variance.</li>
</ul>
</section>
<section id="what-we-compute-and-optimize" class="level3" data-number="26.6">
<h3 data-number="26.6" class="anchored" data-anchor-id="what-we-compute-and-optimize"><span class="header-section-number">26.6</span> What We Compute and Optimize:</h3>
<ul>
<li><strong>Compute</strong>: We can compute the ELBO for given parameters <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\theta\)</span>.</li>
<li><strong>Optimize</strong>: We use stochastic gradient descent or a variant to optimize the parameters <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\theta\)</span> to maximize the ELBO.</li>
<li><strong>Train</strong>: We train the encoder and decoder networks by using backpropagation based on gradients computed from the ELBO.</li>
</ul>
</section>
<section id="what-we-cannot-compute-directly" class="level3" data-number="26.7">
<h3 data-number="26.7" class="anchored" data-anchor-id="what-we-cannot-compute-directly"><span class="header-section-number">26.7</span> What We Cannot Compute Directly:</h3>
<ul>
<li><strong>Posterior p(z|x)</strong>: We cannot compute this directly; it’s typically intractable due to the integral over all possible values of <span class="math inline">\(z\)</span>.</li>
<li><strong>Marginal Likelihood p(x)</strong>: We also cannot compute this directly; it involves an integral over all latent variables which is typically intractable.</li>
</ul>
<p>VAEs aim to learn the parameters of the encoder and decoder networks such that the latent space effectively captures the variations in the data, and new data can be generated that resemble the input data. We optimize the ELBO because the true posterior <span class="math inline">\(p(z|x)\)</span> and the marginal likelihood <span class="math inline">\(p(x)\)</span> are intractable to compute directly</p>
</section>
</div>
</div>
</section>
<section id="latent-variable-models" class="level2" data-number="27">
<h2 data-number="27" class="anchored" data-anchor-id="latent-variable-models"><span class="header-section-number">27</span> Latent variable models</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_34.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 34</figcaption>
</figure>
</div>
</center>
<pre></pre>
<ul>
<li>First we sample z, so from the distribution p(z)</li>
<li>Second we sample x from p(x|z)</li>
<li>Third we do “statistical Inference” where is defined as the process of going from the observations to the latent variable z, so we want to know the factors that generate the data. So we want to calculate the posterior p(z|x)</li>
</ul>
</section>
<section id="reminder-notes-from-ml1" class="level2" data-number="28">
<h2 data-number="28" class="anchored" data-anchor-id="reminder-notes-from-ml1"><span class="header-section-number">28</span> Reminder: notes from ML1</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_35.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 35</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="inference" class="level2" data-number="29">
<h2 data-number="29" class="anchored" data-anchor-id="inference"><span class="header-section-number">29</span> Inference</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_36.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 36</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>When we want to do inference, so compute the posterior p(z|x) we see that this involves the join (numerator) and the marginal likelihood p(x) (denominator). To compute the marginal p(x) we use the integration over the join, but this is expensive computationally.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Why is expensive?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<center>
<img src="imgs/2023-12-07-21-17-15.png" class="w550 img-fluid">
</center>
<pre></pre>
</div>
</div>
</div>
</section>
<section id="inference-1" class="level2" data-number="30">
<h2 data-number="30" class="anchored" data-anchor-id="inference-1"><span class="header-section-number">30</span> Inference</h2>
<p>We will talk how to solve computing p(x), which is in the denominator for calculating the posterior aka doing inference. Inference is going from the generated observation to the latent variable z</p>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_37.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 37</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>If we can generate data using the latent variable so from z -&gt; x. We can do the inverse and that would be inference</p>
<p>So we can have our data where x is generated from p(x) and then given this distribution (so given p(x)) we can derive p(z|x). That is expressed in the last line with formulas. That means that we arrive to p(x,z) the join which is a step to calculate the inference step aka posterior.</p>
<p>This we can do because we have have a dataset x which has been sample from the world and now we want to get a z out of the observations. The join distribution that we will be modelling is always the same because of bayes rule</p>
</section>
<section id="why-shall-we-do-inference" class="level2" data-number="31">
<h2 data-number="31" class="anchored" data-anchor-id="why-shall-we-do-inference"><span class="header-section-number">31</span> Why shall we do inference?</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_38.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 38</figcaption>
</figure>
</div>
</center>
<pre></pre>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_36.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 36</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>We want to do inference, so computing the posterioir p(z|x), because then we can explain the observation. See the bulletpoints</p>
</section>
<section id="inference-via-maximum-likelihood" class="level2" data-number="32">
<h2 data-number="32" class="anchored" data-anchor-id="inference-via-maximum-likelihood"><span class="header-section-number">32</span> Inference via maximum likelihood</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_39.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 39</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>MLE is all about finding the <span class="math inline">\(\theta\)</span> that maximizes modelling the distribution that represents the data <span class="math inline">\(p_{\theta}(x)\)</span></p>
<p>For laten variable models there is no closed-form solution. It is not like you can derive with regards to theta (set it to zero and solve for theta) no you cannot.</p>
<p>Here we are also assuming that all datapoints are independent see next slide</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Why are we talking about p(x)?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We do it because it is in the denominator when we want to do inference. Remember inference was the posterior</p>
<center>
<img src="imgs/2023-12-07-21-39-19.png" class="w250 img-fluid">
</center>
<pre></pre>
<p>And recall we want to do inference because it was one of the 3 steps. Also recall that doing Inference is like going back because inference is defined as the process of going from the observations to the latent variable z</p>
</div>
</div>
</div>
</section>
<section id="reminder-why-the-sum-of-logarithms" class="level2" data-number="33">
<h2 data-number="33" class="anchored" data-anchor-id="reminder-why-the-sum-of-logarithms"><span class="header-section-number">33</span> Reminder: Why the sum of logarithms?</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_40.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 40</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="the-gradient-of-max-likelihood" class="level2" data-number="34">
<h2 data-number="34" class="anchored" data-anchor-id="the-gradient-of-max-likelihood"><span class="header-section-number">34</span> The gradient of max likelihood</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_41.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 41</figcaption>
</figure>
</div>
</center>
<pre></pre>
<center>
<img src="imgs/2023-12-07-22-01-03.png" class="w300 img-fluid">
</center>
<pre></pre>
<p>Because computing the <span class="math inline">\(\theta\)</span> that maximizes <span class="math inline">\(p_{\theta}(x)\)</span> has not closed form solution, we can do SGD. Thus why in this slide we explain how to calculate the derivative of <span class="math inline">\(log p_{\theta}(x)\)</span>.</p>
<ul>
<li>First line, second equal p(x) we just make it into a joint distribution, where we add z and integrate over the whole z.</li>
<li>Second line, we can change the integral and the gradient. This is because the gradient does not depend on thetha but dz (so the integral depends on z). Here we also use the same identiy but with p(x,z)</li>
<li>Third line, we see that to compute the gradient of the marginal we need to compute the posterior <span class="math inline">\(p(z|x)\)</span>. Which as we saw before is very expensive</li>
</ul>
</section>
<section id="but-exact-inference-is-hard" class="level2" data-number="35">
<h2 data-number="35" class="anchored" data-anchor-id="but-exact-inference-is-hard"><span class="header-section-number">35</span> But: Exact inference is hard</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_42.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 42</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>So as we see in the last slide from third line and second as well, computing the prior is very expensive we see an example that if we have an image with 20 dimensions then we will end up summing over 1M latents (because of integral or summation). Thus is very expensive.</p>
<p>So this approach of modelling the probabilities, so the latent distribution p(z) is not feseable because we would have to do inference in this way and we cannot solve this integral even not with brute force</p>
</section>
<section id="lets-take-a-breath.-where-are-we-me" class="level2" data-number="36">
<h2 data-number="36" class="anchored" data-anchor-id="lets-take-a-breath.-where-are-we-me"><span class="header-section-number">36</span> Let’s take a breath. Where are we? me</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_43.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 43</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Here in the last bullet point by normalize we mean we want to sum/integram across all data but this is intractable</p>
</section>
<section id="variational-inference" class="level2" data-number="37">
<h2 data-number="37" class="anchored" data-anchor-id="variational-inference"><span class="header-section-number">37</span> Variational Inference</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_44.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 44</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>So because we this is intractable we will aproximate the integrals, which means we go from statistical inference to optimization.</p>
<p>So basically have a NN for the inference process for us</p>
</section>
<section id="approximate-inference" class="level2" data-number="38">
<h2 data-number="38" class="anchored" data-anchor-id="approximate-inference"><span class="header-section-number">38</span> Approximate inference</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_45.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 45</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>With Variational inference, we say we do not know the posterior p(z|x) but we can model it, we just say is a Gaussian distribution which makes everything super easy. So instead of computing the full posterior we want to approximate it for example as we said by saying is a Gaussian distribution and then we want a NN to then learn the parameters wrt to the distribution and thus now the untractable problem becomes an optimization problem</p>
<p>This method however, will make it into a single forward pass which means we cannot trade computation for accuracy. Whereas in markov chain monte carlo we just know we keep running it for long and then we will get more and more accurate but this is not an option for NNs</p>
</section>
<section id="revisit-kullbackleibler-divergence" class="level2" data-number="39">
<h2 data-number="39" class="anchored" data-anchor-id="revisit-kullbackleibler-divergence"><span class="header-section-number">39</span> Revisit: Kullback—Leibler divergence</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_46.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 46</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>KL is not symetric.</p>
<p>The Kullback-Leibler divergence is a measure of how much one probability distribution differs from another.</p>
<p>KL:0 refers to the Kullback-Leibler divergence between two probability distributions when they are equal.</p>
<p>KL:1 refers to the Kullback-Leibler divergence between two probability distributions when they are maximally different.</p>
<p>That means if you have q fix and you optimize p.&nbsp;This will give you a different result if you write it like this instead of the other way. This is because you will have the mode seeking behavior of this process. That means in one case it will learn q and you observing data p(x), it will try to fit both of these peaks. While if you use the reverse KL that will just collapse into one of the modes and model a peak instead of both</p>
</section>
<section id="tool-1-jensens-inequality" class="level2" data-number="40">
<h2 data-number="40" class="anchored" data-anchor-id="tool-1-jensens-inequality"><span class="header-section-number">40</span> Tool 1: Jensen’s inequality</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_47.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 47</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>It says that the logarithm is monotonic. Monotonic refers tgat:</p>
<ul>
<li>a&lt;b -&gt; log(a) &lt; log(b). So it conserves the order</li>
</ul>
<p>So here the Jensens is defined for log and it just says that a line connecting two points will always be below the function</p>
</section>
<section id="tool-2-monte-carlo-methods" class="level2" data-number="41">
<h2 data-number="41" class="anchored" data-anchor-id="tool-2-monte-carlo-methods"><span class="header-section-number">41</span> Tool 2: Monte Carlo methods</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_48.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 48</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Here we would be doing one-sample montecarlo</p>
</section>
<section id="tool-2-monte-carlo-methods-1" class="level2" data-number="42">
<h2 data-number="42" class="anchored" data-anchor-id="tool-2-monte-carlo-methods-1"><span class="header-section-number">42</span> Tool 2: Monte Carlo methods</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_49.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 49</figcaption>
</figure>
</div>
</center>
<pre></pre>
<ul>
<li>p(x) is a probability distribution</li>
</ul>
<p>This integral, you cannot just find a close form solution. Because we cannot do this we will use solve it numerically and we use Montecarlo then we do an estimation fo sampling points ‘x’ from this distribution p(x) and then just plug in it, and summing then up. That is how you get an estimate of this integral So Montecarlo here just samples from p(x). The longer you do this sampling the more the samples will have been approximated by probabilities distributions and the more accurate of the integral would be.</p>
<p>If n goes to infinity you will have the exact same solution</p>
</section>
<section id="variational-inference-1" class="level2" data-number="43">
<h2 data-number="43" class="anchored" data-anchor-id="variational-inference-1"><span class="header-section-number">43</span> Variational inference</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_50.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 50</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>This changes the task of finding the posterior distribution into an optimization problem. So now we approximate:</p>
<ul>
<li>The posterior with a <strong>variational posterior</strong></li>
</ul>
<p>The parameters phi they do not need to be NNs later on they will be NN parameters, but in general variational inference is not the case</p>
</section>
<section id="variational-inference-2" class="level2" data-number="44">
<h2 data-number="44" class="anchored" data-anchor-id="variational-inference-2"><span class="header-section-number">44</span> Variational inference</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_51.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 51</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="training-with-variational-inference" class="level2" data-number="45">
<h2 data-number="45" class="anchored" data-anchor-id="training-with-variational-inference"><span class="header-section-number">45</span> Training with variational inference</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_52.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 52</figcaption>
</figure>
</div>
</center>
<pre></pre>
<center>
<img src="2023-12-08-22-00-24.png" class="w500 img-fluid">
</center>
<pre></pre>
<p>We want to go up for the log likelihood p(x), if we learn a lower bound that means if we keep increasing the low bound we will actually be maximizing the log likelihood p(x).</p>
<p>Here we will be training the model with Variational inference by maximizing the <strong>variational lower bound</strong></p>
</section>
<section id="important-how-to-arrive-at-the-variational-lower-bound" class="level2" data-number="46">
<h2 data-number="46" class="anchored" data-anchor-id="important-how-to-arrive-at-the-variational-lower-bound"><span class="header-section-number">46</span> Important: How to arrive at the variational lower bound</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_53.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 53</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Now we can express it as an expectation over the sample of q. We multiply everything with q, so we may as well sampling it instead. This is the montecarlo estimate of this difficult integral.</p>
<p>This expectation is in theory infinite samples but we just take a few of this</p>
</section>
<section id="variational-lower-bound" class="level2" data-number="47">
<h2 data-number="47" class="anchored" data-anchor-id="variational-lower-bound"><span class="header-section-number">47</span> Variational lower bound</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_54.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 54</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Now we can have a loss function because we got the variational lower bound.</p>
<p>We can now maximize this L instead of the untractable log p(x)</p>
</section>
<section id="variational-lower-bound-1" class="level2" data-number="48">
<h2 data-number="48" class="anchored" data-anchor-id="variational-lower-bound-1"><span class="header-section-number">48</span> Variational lower bound</h2>
<p>Here note we are designing a variational posterior q(z|x) not q(z) as we have before. And we do it as simple as possible i.e Normal dist.</p>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_55.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 55</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>This function is called the <strong>Evidence Lower Bound</strong>. It is called evidence (another term for describing the data we see)</p>
</section>
<section id="derive-elbo-in-a-different-way" class="level2" data-number="49">
<h2 data-number="49" class="anchored" data-anchor-id="derive-elbo-in-a-different-way"><span class="header-section-number">49</span> Derive ELBO in a different way</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_56.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 56</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="entropy-regularization" class="level2" data-number="50">
<h2 data-number="50" class="anchored" data-anchor-id="entropy-regularization"><span class="header-section-number">50</span> Entropy regularization</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_57.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 57</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>We want high entropy which means we carry more information</p>
</section>
<section id="variational-gap" class="level2" data-number="51">
<h2 data-number="51" class="anchored" data-anchor-id="variational-gap"><span class="header-section-number">51</span> Variational gap</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_58.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 58</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>There is a gap between the lower bound, So between ELBO =second line and p(x). It turns out the gap is the second term of the third line</p>
<p>So this is the difference between the real likelihood and the lowe bound ELBO</p>
</section>
<section id="variational-gap-1" class="level2" data-number="52">
<h2 data-number="52" class="anchored" data-anchor-id="variational-gap-1"><span class="header-section-number">52</span> Variational gap</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_59.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 59</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="fitting-the-variational-posterior" class="level2" data-number="53">
<h2 data-number="53" class="anchored" data-anchor-id="fitting-the-variational-posterior"><span class="header-section-number">53</span> Fitting the variational posterior</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_60.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 60</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>The error loss is on the RHS of the red equation, we CAN optimize. These two things are untractable:</p>
<ol type="1">
<li>p(x) expensive to compute the integral</li>
<li>p(z|x) we dont know</li>
</ol>
See the picture:
<center>
<img src="2023-12-09-00-44-29.png" class="w150 img-fluid">
</center>
<pre></pre>
<p>But two things that are untractable can be tractable</p>
</section>
<section id="training-the-model" class="level2" data-number="54">
<h2 data-number="54" class="anchored" data-anchor-id="training-the-model"><span class="header-section-number">54</span> Training the model</h2>
<center>
<img src="https://lilianweng.github.io/posts/2018-08-12-vae/VAE-graphical-model.png" class="w375 img-fluid">
</center>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_61.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 61</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>First we want to optimize the model parameters:</p>
<ul>
<li>We want to update the model parameters thetha to increase the ELBO. This belongs to the model parameters</li>
<li>By optimizing the thetha:
<ul>
<li>increase log p(x) prob</li>
<li>decrease the varational gap</li>
</ul></li>
</ul>
<p>For this we should use the most expressive psoterior that we can such that we are as closs as possible to modelling the actual distribution. Now the question is how do we choose the variational posterior q</p>
</section>
<section id="where-are-we" class="level2" data-number="55">
<h2 data-number="55" class="anchored" data-anchor-id="where-are-we"><span class="header-section-number">55</span> Where are we?</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_62.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 62</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>The last point refers to how to choose variational posterior q that is expresive enough so that is close to the actual distribution</p>
</section>
<section id="choosing-the-form-of-the-variational-posterior" class="level2" data-number="56">
<h2 data-number="56" class="anchored" data-anchor-id="choosing-the-form-of-the-variational-posterior"><span class="header-section-number">56</span> Choosing the form of the variational posterior</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_63.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 63</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>The simples way is to fully factorize the distribution, where we say the full distribution of z is the multiplication of all different z_i distributions. That means they are very simply related all of these points are identically distributed so idd</p>
<p>In clasic Variational inference, the <strong>idd</strong> is also know as mean field approximation.</p>
<p>Here we model the high-level latent factors that can cature independent factors such as camera, angle, lighthening, etc such that forgetting the main latent representation you just multiply all these together</p>
<p>The treadoff: in practice for VAE the <strong>mean field</strong> approximation is used. Where we have gaussian distributions, so every z so every latent dimension is independent of each other</p>
</section>
<section id="amortized-variational-inference" class="level2" data-number="57">
<h2 data-number="57" class="anchored" data-anchor-id="amortized-variational-inference"><span class="header-section-number">57</span> Amortized variational inference</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_64.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 64</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Here you have your observation x and now you have a complicated procedure back and forth to gradually arrive at your variational parameters phi. Now because we say q would be Gaussians then <span class="math inline">\(\phi\)</span> represents <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> which are the parameters of a Gaussian distribution</p>
<p>Now because p(z|x) is different for each observation x, we would do something more efficient called <em>amortized inference</em>, where amortized just means we will reuse things and therefore we do not have to do this iterative for each data sample</p>
</section>
<section id="amortized-variational-inference-the-deep-learners-inference" class="level2" data-number="58">
<h2 data-number="58" class="anchored" data-anchor-id="amortized-variational-inference-the-deep-learners-inference"><span class="header-section-number">58</span> Amortized variational inference: the Deep Learner’s inference</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_65.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 65</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Instead of optimizing a set of free paramaters, we use a NN that accepts an observation an input and ouputs these <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> directly.</p>
<p>So instead of having this blackbox, for every single sample that gradually learns <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> which is done tipically in statistics, we just have a NN to approximate this behavior</p>
<p>It is amortized because across all the samples in the dataset we are using the same NN to do this, thus we are amortizing this process</p>
</section>
<section id="amortized-variational-inference-1" class="level2" data-number="59">
<h2 data-number="59" class="anchored" data-anchor-id="amortized-variational-inference-1"><span class="header-section-number">59</span> Amortized variational inference</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_66.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 66</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>So because now <span class="math inline">\(\phi\)</span> represents the weights of our NN, and we can train jointly with the model using the ELBO loss</p>
</section>
<section id="benefits-of-using-amortization" class="level2" data-number="60">
<h2 data-number="60" class="anchored" data-anchor-id="benefits-of-using-amortization"><span class="header-section-number">60</span> Benefits of using amortization</h2>
<center>
<img src="https://lilianweng.github.io/posts/2018-08-12-vae/VAE-graphical-model.png" class="w375 img-fluid">
</center>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_67.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 67</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>It is fast, for every new observation all we need to do is one single forward pass and then we have all the approximate posterior <span class="math inline">\(q_{\phi}(z|x)\)</span> distribution parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. With the paramaters then we have the approximate posterior distribution as well because we are saying is a Gaussian distribution</p>
</section>
<section id="maximizing-the-elbo" class="level2" data-number="61">
<h2 data-number="61" class="anchored" data-anchor-id="maximizing-the-elbo"><span class="header-section-number">61</span> Maximizing the ELBO</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_68.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 68</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Because to maximize the ELBO is a non-convex optimization we need to estimate the gradients. We will now estimating the gradient because you still have this expectations over this distribution, we will be estimating the gradients using Montecarlo sampling</p>
<!-- ## Take 3 min and discuss with your neighbor the following points
<center>![Slide 69](imgs/page_69.jpeg){.w575}</center><pre></pre> -->
</section>
<section id="gradient-w.r.t.-the-model-parameters" class="level2" data-number="62">
<h2 data-number="62" class="anchored" data-anchor-id="gradient-w.r.t.-the-model-parameters"><span class="header-section-number">62</span> Gradient w.r.t. the model parameters</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_70.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 70</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Instead of taking computing the whole expectation (which the formula for expectations involves an integral) we just take <span class="math inline">\(k\)</span> samples to approximate it. This is a Montecarlo approach. Thus by taking k samples we get a rough estimate of the gradient. So instead of sampling the whole thing we do the simplest montecarlo estimate that is possible</p>
</section>
<section id="gradient-w.r.t.-variational-parameters" class="level2" data-number="63">
<h2 data-number="63" class="anchored" data-anchor-id="gradient-w.r.t.-variational-parameters"><span class="header-section-number">63</span> Gradient w.r.t. variational parameters</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_71.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 71</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>It is not obvious how to take the derivative of a distribution from where we are sampling</p>
</section>
<section id="gradients-of-expectations" class="level2" data-number="64">
<h2 data-number="64" class="anchored" data-anchor-id="gradients-of-expectations"><span class="header-section-number">64</span> Gradients of expectations</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_72.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 72</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="reparameterization-trick" class="level2" data-number="65">
<h2 data-number="65" class="anchored" data-anchor-id="reparameterization-trick"><span class="header-section-number">65</span> Reparameterization trick</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_73.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 73</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>First we sample <span class="math inline">\(z\)</span> form the approximated posterior distribution <span class="math inline">\(q(\textbf{z}_n | \textbf{x}_n)\)</span></p>
<p>Then express the random variable <span class="math inline">\(z\)</span> as a deterministic variable <span class="math inline">\(z=g(\epsilon, \phi)\)</span>, where <span class="math inline">\(\epsilon\)</span> is an auxiliary independent random variable, and the transformation function <span class="math inline">\(g(.)\)</span> parameterized by <span class="math inline">\(\phi\)</span> converts <span class="math inline">\(\epsilon\)</span> to <span class="math inline">\(z\)</span>.</p>
<p>The problem that we have before is that the get the gradient of the expectation over <span class="math inline">\(q(\textbf{z}_n | \textbf{x}_n)\)</span> was not feasible, as this requires us to sample infinietly, so now instead we do reparametrization which instead of sampling <span class="math inline">\(z\)</span> we will be sampling from the this parametrized function <span class="math inline">\(g(\epsilon, \phi)\)</span></p>
<p>This <span class="math inline">\(\epsilon\)</span> will form a distribution which in practice in a Normal dsitr.</p>
<p>So the crucial bit is that with reparametrization we shift in the expectation from which distribution to sample in this case from <span class="math inline">\(p(\epsilon)\)</span>. So now we can take the gradient and now the gradient can go inside because the sampling is not done by anithing that depends on the parameters <span class="math inline">\(\phi\)</span>. So then we end up with the last line of equation above by taking the Chain Rule.</p>
</section>
<section id="reparameterization-trick-1" class="level2" data-number="66">
<h2 data-number="66" class="anchored" data-anchor-id="reparameterization-trick-1"><span class="header-section-number">66</span> Reparameterization trick</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_74.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 74</figcaption>
</figure>
</div>
</center>
<pre></pre>
<center>
<img src="https://lilianweng.github.io/posts/2018-08-12-vae/reparameterization-trick.png" class="w375 img-fluid">
</center>
<pre></pre>
<p>We want to learn <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> so the last line represent the reparametrization where now we can sample from <span class="math inline">\(\epsilon\)</span>.</p>
<p>Even though we add stotastichs because we sample from epsilon, this make it differentiable which was a problem before by just taking the gradient of the expectation</p>
</section>
<section id="reparameterization-trick-visualised" class="level2" data-number="67">
<h2 data-number="67" class="anchored" data-anchor-id="reparameterization-trick-visualised"><span class="header-section-number">67</span> Reparameterization trick visualised</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_75.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 75</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>If sample as in the left you cannot take gradients because there is no way how you could do that. However, if you add the reparametrization you get a noisy sample and then you multiply by <span class="math inline">\(\sigma\)</span> and add <span class="math inline">\(\mu\)</span> and that is differentiable.</p>
<p>Here in the most right we have a vector because we have a mean for every latent dimension i.e this could be 120 dimensions and then we have a standard deviation for every latent dimension that is being ouputed. So now you have our parameters <span class="math inline">\(\sigma\)</span> and <span class="math inline">\(\mu\)</span> so then we can get p(z|x). You also get your <span class="math inline">\(z =\mu + \sigma circ \epsilon\)</span> because we did the reparametrization trick. Now you put this sample <span class="math inline">\(z\)</span> into the decoder network to deconstruct it.</p>
</section>
<section id="where-are-we-1" class="level2" data-number="68">
<h2 data-number="68" class="anchored" data-anchor-id="where-are-we-1"><span class="header-section-number">68</span> Where are we?:</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_76.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 76</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>So we can choose any simple approximation for our posterior q but when we want to optimizie this then we get into the trouble of not knowing how to get the gradient of a expectation which we need to samply from this distribution. This gradient of the expectation involves the variational parameters that we wish to take take the derivative from.</p>
<p>So instead we reparametrized this to have have a generic stochastic epsilon that we could map us back to our z whihc before was difficult to compute.</p>
<p>A sampling procedure is like you have an image and then you are taking the crop, so then you cannot take the gradients with regards to the cropping procedure. You can fake it by doing the reparametrization because you are saying okay you take the sample but then you shift it and you scale it by exaclty the same thing. Note, for images is different because we do not have just a gaussian distribution.</p>
<p>What we say is that all latent dimensions are idenpendent so basically your covariance matrix your sigma has only entries on the diagonal matrix, technically this does not need to be the case. It will just mean that this network will ouput a lot more standard deviations. But genreally Gaussians are simple, they stay gaussian even if you take the derivative</p>
</section>
<section id="variational-autoencoders-summary" class="level2" data-number="69">
<h2 data-number="69" class="anchored" data-anchor-id="variational-autoencoders-summary"><span class="header-section-number">69</span> Variational autoencoders summary</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_77.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 77</figcaption>
</figure>
</div>
</center>
<pre></pre>
<center>
<img src="https://lilianweng.github.io/posts/2018-08-12-vae/vae-gaussian.png" class="w575 img-fluid">
</center>
<pre></pre>
<ul>
<li>VAE are generative models with continous latent variables. We do not chunk them into zeros or ones</li>
<li>The likelihood p(x) and the variational posterioir <span class="math inline">\(q_\theta\)</span> are NNs</li>
<li>The last point refers that the noise comes from the epsilon</li>
</ul>
</section>
<section id="variational-autoencoders-elbo" class="level2" data-number="70">
<h2 data-number="70" class="anchored" data-anchor-id="variational-autoencoders-elbo"><span class="header-section-number">70</span> Variational autoencoders ELBO</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_78.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 78</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="encoder-decoder" class="level2" data-number="71">
<h2 data-number="71" class="anchored" data-anchor-id="encoder-decoder"><span class="header-section-number">71</span> Encoder &amp; Decoder</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_79.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 79</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>With your input data you get your <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> and then you get <span class="math inline">\(z\)</span>. And then given this <span class="math inline">\(z\)</span> you can reconstruct the input. In between these steeps there is a reparametrization step when you do the training</p>
</section>
<section id="generating-data" class="level2" data-number="72">
<h2 data-number="72" class="anchored" data-anchor-id="generating-data"><span class="header-section-number">72</span> Generating Data</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_80.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 80</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>When you generate new data, you can now simply sample <span class="math inline">\(z\)</span> from this Gaussian distrivution with mean zero and std <span class="math inline">\(I\)</span>. And then for example if your Gaussian distribution is 2D then you can sample a point from the top left all the way to the bottom right and each time you sample <span class="math inline">\(z\)</span> through the decoder network you can vizualise it based on where it cames from for instance if it comes from the left corner or top corner or so on.</p>
<ul>
<li>We sample first from from p(z) to then obtain the values of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span></li>
<li>With those now we sample from <span class="math inline">\(p(x|z)\)</span> that comes from this new Gaussian distribution with the parameters we found in the prev step.</li>
</ul>
</section>
<section id="dimensionality-of-latent-space-1" class="level2" data-number="73">
<h2 data-number="73" class="anchored" data-anchor-id="dimensionality-of-latent-space-1"><span class="header-section-number">73</span> Dimensionality of latent space</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_81.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 81</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Once we have more dimensions we get more noisy data. This is because it start to fit the noise which is not particualrly usefull</p>
<p>If you go to higuer dimensionalities, then you will start to have optimizations issues.</p>
</section>
<section id="face-generation" class="level2" data-number="74">
<h2 data-number="74" class="anchored" data-anchor-id="face-generation"><span class="header-section-number">74</span> Face generation</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_82.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 82</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>It is not blurry is noisy because now we have more dimensions</p>
</section>
<section id="inference-suboptimality" class="level2" data-number="75">
<h2 data-number="75" class="anchored" data-anchor-id="inference-suboptimality"><span class="header-section-number">75</span> Inference suboptimality</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_83.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 83</figcaption>
</figure>
</div>
</center>
<pre></pre>
<ul>
<li><strong>Variational posterior:</strong> <span class="math inline">\(q_{\phi}(\textbf{z}_n | \textbf{x}_n)\)</span> match to the true posterior <span class="math inline">\(p_{\theta}(\textbf{z}_n)\)</span></li>
</ul>
<p>In terms ob observations: - The divergence from the true posterioir is often imperfect mostly due to the amortized inference network rather that the limmiting capacity or complexity of the approximating distribution</p>
</section>
<section id="inference-gaps" class="level2" data-number="76">
<h2 data-number="76" class="anchored" data-anchor-id="inference-gaps"><span class="header-section-number">76</span> Inference Gaps</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_84.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 84</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Here the approximation gap is the same as Variational gap</p>
<ul>
<li><p>Variational gap: if this is small then you can make it samll by having an expressive variational distribution</p></li>
<li><p>Amortization Gap: you can make this small by having a stronger bigger NN</p></li>
</ul>
</section>
<section id="vae-variants" class="level2" data-number="77">
<h2 data-number="77" class="anchored" data-anchor-id="vae-variants"><span class="header-section-number">77</span> VAE variants</h2>
<!-- <center>![Slide 85](imgs/page_85.jpeg){.w575}</center><pre></pre> -->
</section>
<section id="conditional-vaes" class="level2" data-number="78">
<h2 data-number="78" class="anchored" data-anchor-id="conditional-vaes"><span class="header-section-number">78</span> Conditional VAEs</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_86.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 86</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="conditional-vaes-1" class="level2" data-number="79">
<h2 data-number="79" class="anchored" data-anchor-id="conditional-vaes-1"><span class="header-section-number">79</span> Conditional VAEs</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_87.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 87</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="conditional-vaes-2" class="level2" data-number="80">
<h2 data-number="80" class="anchored" data-anchor-id="conditional-vaes-2"><span class="header-section-number">80</span> Conditional VAEs</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_88.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 88</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="beta-vae" class="level2" data-number="81">
<h2 data-number="81" class="anchored" data-anchor-id="beta-vae"><span class="header-section-number">81</span> Beta-VAE</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_89.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 89</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="beta-vae-1" class="level2" data-number="82">
<h2 data-number="82" class="anchored" data-anchor-id="beta-vae-1"><span class="header-section-number">82</span> Beta-VAE</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_90.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 90</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="vq-vae-and-vq-vae2" class="level2" data-number="83">
<h2 data-number="83" class="anchored" data-anchor-id="vq-vae-and-vq-vae2"><span class="header-section-number">83</span> VQ-VAE and VQ-VAE2</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_91.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 91</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="further-reading" class="level2" data-number="84">
<h2 data-number="84" class="anchored" data-anchor-id="further-reading"><span class="header-section-number">84</span> Further reading</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_92.jpeg" class="w575 img-fluid figure-img"></p>
<figcaption class="figure-caption">Slide 92</figcaption>
</figure>
</div>
</center>
<pre></pre>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../about/index.html"><span class="footerDaniloToapanta">Mantained by Danilo Toapanta</span></a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../coming-soon.html">Newsletter</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../docs/sitemap.xml">RSS</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>

    let navbar = document.getElementsByClassName("navbar-nav")[0]    

    let li2 = document.createElement("li");
    li2.className = "nav-item compact";

    let a2 = document.createElement("a");
    a2.className = "nav-link quarto-color-scheme-toggle";
    a2.style.cursor = "pointer"
    li2.appendChild(a2)

    let i2 = document.createElement("i");
    i2.className = "bi bi-moon"
    a2.append(i2)

    navbar.appendChild(li2);

    i2.onclick = function() {
        window.quartoToggleColorScheme(); return false;
    }
    // <a href="http://localhost:4200/about/" class="quarto-color-scheme-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>

    let li = document.createElement("li");
    li.className = "nav-item compact";

    let a = document.createElement("a");
    a.className = "nav-link";
    a.style.cursor = "pointer"
    li.appendChild(a)

    let i = document.createElement("i");
    i.className = "bi bi-search"
    a.append(i)

    // let span = document.createElement("span");
    // span.className = "menu-text"
    // a.append(span)

    navbar.appendChild(li);

    a.onclick = function() {
        window.quartoOpenSearch()
    }


</script>





</body></html>