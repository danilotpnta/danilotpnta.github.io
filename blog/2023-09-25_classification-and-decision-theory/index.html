<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Danilo Toapanta">
<meta name="dcterms.date" content="2023-09-25">
<meta name="description" content="Formulas for the course at UvA: Machine Learning 1">

<title>Danilo Toapanta - Classification and Decision Theory</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../assets/danilo.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/material-icons-0.14.2/mi.css" rel="stylesheet">
<script>
window.MathJax = {
  tex: {
    tags: 'ams'
  }
};
</script>
<link rel="shortcut icon" href="../../../../../../../../../../../assets/danilo.ico">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../css/index-posts.css">
</head>

<body class="floating nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title"><span id="danilo_topanta_brand"> Danilo Toapanta</span> <a id="mysite" class="mysite" href="../../../../../sites/">MySites</a></span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text"><span id="home-welcome-msg">Home</span></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog/index.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects/index.html" rel="" target="">
 <span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about/index.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/danilotpnta?tab=repositories" rel="" target="_blank"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full blog-page" style="display: none;">
    <div class="quarto-title-banner page-columns page-full">
        <div class="quarto-title column-body">
            <h1 class="title">Classification and Decision Theory</h1>
                
            <!-- Description Block -->
                        <div>
                <div class="description">
                    Formulas for the course at UvA: Machine Learning 1
                </div>
            </div>
                        
            <!-- Categories Block -->
                                            <div class="quarto-categories">

                    <!-- Display Categories -->
                                            <div class="quarto-category">
                            <a href="../../blog/#category=All">
                                All
                            </a>
                        </div> 
                                            <div class="quarto-category">
                            <a href="../../blog/#category=Education">
                                Education
                            </a>
                        </div> 
                                            <div class="quarto-category">
                            <a href="../../blog/#category=Machine Learning">
                                Machine Learning
                            </a>
                        </div> 
                                            <div class="quarto-category">
                            <a href="../../blog/#category=TAGS">
                                TAGS
                            </a>
                        </div> 
                                            <div class="quarto-category">
                            <a href="../../blog/#category=Classification">
                                Classification
                            </a>
                        </div> 
                    
                    <!-- Display Tags if any -->
                                    </div>
                            
        </div>
    </div>


    
    <div class="quarto-title-meta">

        <div>
        <div class="quarto-title-meta-heading">Author</div>
        <div class="quarto-title-meta-contents">
                 <p><a href="https://danilotpnta.github.io/">Danilo Toapanta</a> </p>
              </div>
      </div>
        
        <div>
        <div class="quarto-title-meta-heading">Published</div>
        <div class="quarto-title-meta-contents">
          <p class="date">September 25, 2023</p>
        </div>
      </div>
      
        
      </div>
      

    
</header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">
<script>
    var currentUrl = window.location.href;
    var index_init_post = currentUrl.lastIndexOf("/20");
    var string_init_post= currentUrl.slice(index_init_post, index_init_post+3 );

    // console.log("currentUrl: " + currentUrl);
    // console.log("index: " + index_init_post);
    // console.log("string: " + string_init_post);

    // If is equal to /blog/20... then make navbar title READING MODE
    if (string_init_post === "/20"){
        let mysite = document.getElementById("mysite");
        mysite.classList.add("mysite-change");

        let navbar = document.getElementById("danilo_topanta_brand");
        navbar.classList.add("navbar-brand-change");

        // This will render a new title saying READING DANILOS BLOG
        // navbar.innerHTML = 'You are Reading Danilo\'s Blog<span style="font-size:35px; vertical-align: middle; opacity: 0.65; padding-bottom: 6px; padding-left: 14px;" class="material-icons-round"> auto_awesome </span>';
        
        const smallDevice = window.matchMedia("(min-width: 570px)");
        smallDevice.addListener(handleDeviceChange);

        function handleDeviceChange(mediaQuery) {
            if (mediaQuery.matches) {
                navbar.innerHTML = "";
                // navbar.innerHTML = "<-- You are Reading Danilo's Blog -->";
            } else  {
                navbar.innerHTML = "Danilo Toapanta";
            }
        }

        // Run it initially
        handleDeviceChange(smallDevice);

        let link = document.getElementsByClassName("navbar-brand")[0];
        link.classList.add("disablePointerEvents");

        let brand_container = document.getElementsByClassName("navbar-brand-container")[0];
        brand_container.classList.add("navbar-brand-container-new-padding");

    }
</script>


<!-- <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Running my first Marathon</h1>
                  <div>
        <div class="description">
          I will be running at the 42km TCS Amsterdam 2023, 15th October
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">News</div>
              </div>
                  </div>
  </div> -->

  <!-- ---
  coming-soon: true
  tags: [Spanish]
  --- -->








<main id="title-block-header" class="quarto-title-block default page-columns page-full" style="padding-bottom: 40px;">

    <div class="quarto-title column-body" style="margin-bottom: 1em;">
        <h1 class="title" style="padding-bottom:8px" ;="">Classification and Decision Theory</h1>
        
        <!-- Description Block -->
                    <div>
                <div class="description">
                    Formulas for the course at UvA: Machine Learning 1
                </div>
            </div>
        
        <!-- Categories Block -->
                    
                <!-- Display Categories -->
                <div class="quarto-categories">
                    <!-- <div id="tag-icon-blog" class="quarto-category tags-title">
                        <i class="fa-solid fa-hashtag" ></i> Categories:
                    </div> -->

                                            <div id="All" class="quarto-category">
                            <a href="../../blog/#category=All">
                                All
                            </a>
                        </div>
                                            <div id="Education" class="quarto-category">
                            <a href="../../blog/#category=Education">
                                Education
                            </a>
                        </div>
                                            <div id="Machine Learning" class="quarto-category">
                            <a href="../../blog/#category=Machine Learning">
                                Machine Learning
                            </a>
                        </div>
                                            <div id="TAGS" class="quarto-category">
                            <a href="../../blog/#category=TAGS">
                                TAGS
                            </a>
                        </div>
                                            <div id="Classification" class="quarto-category">
                            <a href="../../blog/#category=Classification">
                                Classification
                            </a>
                        </div>
                                    </div>
                


                <div class="quarto-categories tag-categories">
                    
                    <!-- Tags Icon  -->
                    <!-- <div id="tag-icon-blog" class="quarto-category tags-title"> -->
                        <!-- <i class="fa-solid fa-tag" ></i> Tags: -->
                        <!-- <i class="fa-solid fa-hashtag" ></i> Tags: -->
                        <!-- <span class="material-icons-outlined" >local_offer</span> Tags: -->
                        <!-- / -->
                    <!-- </div> -->

                    <!-- Display Tags -->
                                            <div id="All-from-here" class="quarto-category tags-title" style="display: none;">
                            <a href="../../blog/#category=All">
                               <!-- <span class="hasth-tag">
                                #
                                </span> -->
                                All
                            </a>
                        </div>
                                            <div id="Education-from-here" class="quarto-category tags-title" style="display: none;">
                            <a href="../../blog/#category=Education">
                               <!-- <span class="hasth-tag">
                                #
                                </span> -->
                                Education
                            </a>
                        </div>
                                            <div id="Machine Learning-from-here" class="quarto-category tags-title" style="display: none;">
                            <a href="../../blog/#category=Machine Learning">
                               <!-- <span class="hasth-tag">
                                #
                                </span> -->
                                Machine Learning
                            </a>
                        </div>
                                            <div id="TAGS-from-here" class="quarto-category tags-title" style="display: none;">
                            <a href="../../blog/#category=TAGS">
                               <!-- <span class="hasth-tag">
                                #
                                </span> -->
                                TAGS
                            </a>
                        </div>
                                            <div id="Classification-from-here" class="quarto-category tags-title" style="display: none;">
                            <a href="../../blog/#category=Classification">
                               <!-- <span class="hasth-tag">
                                #
                                </span> -->
                                Classification
                            </a>
                        </div>
                    
                    
                </div>

                    
    </div>


    
    <div class="quarto-title-meta">

        <div>
        <div class="quarto-title-meta-heading">Author</div>
        <div class="quarto-title-meta-contents">
                 <p><a href="https://danilotpnta.github.io/">Danilo Toapanta</a> </p>
              </div>
      </div>
        
        <div>
        <div class="quarto-title-meta-heading">Published</div>
        <div class="quarto-title-meta-contents">
          <p class="date">September 25, 2023</p>
        </div>
      </div>
      
        
      </div>
      

    <!-- Current link: Font-awesome, Google icons, Bootstrap icons -->
    
</main>

<h1>
Classification
</h1>
<p>This section focus on third week of the course. For Regression continue to this <a href="../2023-09-05_equation-for-ml1/">post</a>.</p>
<section id="classification-through-decision-regions" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="classification-through-decision-regions"><span class="header-section-number">1</span> Classification through decision regions</h2>
<ul>
<li>Here the targets can take only discrete values. In Linear Regression the targets were continuous</li>
</ul>
<p><span class="math display">\[
\begin{align}
\underline{x} &amp;\in \mathbb{R}^{Dx1}, \text{ $D$ Dimensional Space}\\
&amp;= [x_1, .., x_D]^T \nonumber
\end{align}
\]</span></p>
<ul>
<li><p>For instance when <span class="math inline">\(D=2\)</span> we can think of <span class="math inline">\(x_1\)</span> as the amount of black pixels in the image, and <span class="math inline">\(x_2\)</span> as the white pixels. Then I can clasify one image into this 2-D dimensional space. So in the xy-plane one image has <span class="math inline">\((x1,x2)\)</span> coordinates</p></li>
<li><p>We dive <span class="math inline">\(\underline{x}\)</span> into <span class="math inline">\(K\)</span> Decision Regions <span class="math inline">\(R_k\)</span>.</p></li>
<li><p>For each Decision Region <span class="math inline">\(R_k\)</span> we assign it to a class <span class="math inline">\(C_k\)</span>.</p></li>
<li><p>The target <span class="math inline">\(\underline{t} \in \{C_1,...,C_k\}\)</span> meaning the target can be classified either <span class="math inline">\(C_1\)</span> or the target can be classified as <span class="math inline">\(C_2\)</span></p></li>
</ul>
</section>
<section id="linear-classification" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="linear-classification"><span class="header-section-number">2</span> Linear Classification</h2>
<blockquote class="blockquote">
<p>Note: do not confuse <span class="math inline">\(D\)</span> the amount of data points with this new <span class="math inline">\(D\)</span> where we talk about the dimensionality of how each data point is represented (the coordinates)</p>
</blockquote>
<ul>
<li>The classification is done by only linear decision boundaries</li>
</ul>
<p>For <span class="math inline">\(D\)</span>-dimensional input space: <span class="math inline">\(\underline{x}\in\mathbb{R}^{D}\)</span>. The decision surface is a <span class="math inline">\(D-1\)</span> dimensional hyperplane. For instance:</p>
<ul>
<li>The decision boundaries can take a form of a line, i.e when <span class="math inline">\(\underline{x}\in\mathbb{R}^{D=2x1}\)</span> meaning the dots are drawn in the <span class="math inline">\(x,y\)</span> coordinates</li>
<li>The decision boundaries can take a form of a plane, i.e when <span class="math inline">\(\underline{x}\in\mathbb{R}^{D=3x1}\)</span> meaning the dots are drawn in the <span class="math inline">\(x,y,z\)</span> coordinates</li>
</ul>
<p>Linear Classifiers have however some constraints: one-versus-one, or one-vs-rest cannot classified in one specific region when majority vote its applied. There is class of decisions</p>
</section>
<section id="decision-theory" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="decision-theory"><span class="header-section-number">3</span> Decision Theory</h2>
<p>Here we talked about when we consider a classifier (a model) a good classifier.</p>
<ul>
<li>We talk about the Bayes Error Rate</li>
<li>How to minimize the misclassification rate</li>
</ul>
<p>Model that you start with:</p>
<ul>
<li>Class-conditional densities: <span class="math inline">\(p(\underline{x}|C_k)\)</span> <em>aka</em> (<strong>Likelihood</strong>)</li>
<li><strong>Prior</strong> class probabilities: <span class="math inline">\(p(C_k)\)</span></li>
</ul>
<p>From these two you can derive:</p>
<ol type="1">
<li>The Joint distribution <span class="math inline">\(p(\underline{x}, C_k)\)</span></li>
</ol>
<p><span class="math display">\[
\begin{align}
p(\underline{x}, C_k)=p(\underline{x}|C_k)p(C_k)
\end{align}
\]</span></p>
<ol start="2" type="1">
<li>The <strong>Posterior</strong> <span class="math inline">\(p(C_k|\underline{x})\)</span>.</li>
</ol>
<p><span class="math display">\[
\begin{align}
p(C_k|\underline{x}) = \frac{p(\underline{x}| C_k)p(C_k)}{p(\underline{x})}
\end{align}
\]</span></p>
<ul>
<li>Decision Theory tell us that the best prediction for input <span class="math inline">\(\underline{x}\)</span> is to choose the class with highest joint <span class="math inline">\(p(\underline{x}, C_k)\)</span></li>
<li>Or equivalently: choose class with the highest posterior <span class="math inline">\(p(C_k|\underline{x})\)</span></li>
<li>Decision boundary between <span class="math inline">\(C_k\)</span> and <span class="math inline">\(C_j\)</span> are at <span class="math inline">\(p(C_k | \underline{x})=p(C_j | \underline{x})\)</span></li>
</ul>
</section>
<section id="from-bayes-rule-to-bayes-classifiers" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="from-bayes-rule-to-bayes-classifiers"><span class="header-section-number">4</span> From Bayes Rule to Bayes Classifiers</h2>
<p><span class="math display">\[
\begin{align}
p(C|X) = \frac{P(X|C)P(C)}{P(X)} \\
\end{align}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(P(C|X)\)</span> is the <strong>Posterior</strong> (Given the data what is the prob of being class C_k)</li>
<li><span class="math inline">\(P(X|C)\)</span> is the <strong>Likelihood</strong> (How the data is distributed given C)</li>
<li><span class="math inline">\(P(C)\)</span> is the <strong>Prior</strong></li>
<li><span class="math inline">\(P(X)\)</span> is the <strong>Evidence</strong>/ Marginal likelihood</li>
</ul>
<p>The evidence <span class="math inline">\(P(X)\)</span> can also be decomposed in:</p>
<p><span class="math display">\[
\begin{align}
P(X) &amp;= \sum_{j}{}P(X,C_j)\\
     &amp;= \sum_{j}{}P(X|C_j)P(C_j) \\
\end{align}
\]</span></p>
<p>Unlike regression, I will have one likelihood per each class, mainly:</p>
<p><span class="math display">\[
\begin{align}
p(X|C_0) \quad \text{and} \quad p(X|C_1) \\
\end{align}
\]</span></p>
<p>For instance for <span class="math inline">\(K=2\)</span> two classes. This means per each class we are going to have our own model</p>
<p>The decicion boundary then becomes equal when both likelihoods are equal:</p>
<p><span class="math display">\[
\begin{align}
p(C_0|X) &amp;= p(C_1|X) \quad \text{Decision Boundary}\\
% P(X, C_0) &amp;= p(X, C_1) \nonumber
\end{align}
\]</span></p>
<p>Here:</p>
<ul>
<li><span class="math inline">\(P(C_0|X)\)</span> is the <strong>Posterior</strong> probability</li>
</ul>
</section>
<section id="types-of-classification" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="types-of-classification"><span class="header-section-number">5</span> Types of Classification</h2>
<ul>
<li>Decision Trees</li>
<li>Logistic Regressions</li>
<li>Bayes Classifiers (Generative): first fit P(x|C) and then use Bayes Rule to flip it and tell which type of class correspond <span class="math inline">\(x\)</span>
<ul>
<li>Naive Bayes: you put an x and it gives you to which class <span class="math inline">\(K\)</span> correponds</li>
<li>Gaussian Likelihood: here <span class="math inline">\(p(x|C_k) = N(\mu_k, \Sigma_k)\)</span><br>
QDA: Quadratic discriminant analysis
<ul>
<li>Shared Parameters<br>
LDA: Linear Discriminant Analysis</li>
</ul></li>
</ul></li>
</ul>
<section id="gaussian-generative-classifiers" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="gaussian-generative-classifiers"><span class="header-section-number">5.1</span> Gaussian Generative Classifiers</h3>
<p>Here we assume arbitrary covariance matrices for each class</p>
<p><span class="math display">\[
\begin{align}
p(x|C_k) = N(\mu_k, \Sigma_k)
\end{align}
\]</span></p>
<ul>
<li>Each class <span class="math inline">\(K\)</span> is going to have its normal distribution. And each of these distributions would be completely different from the others.</li>
</ul>
<section id="quadratic-discriminant-analysis" class="level4 unnumbered unlisted">
<h4 class="unnumbered unlisted anchored" data-anchor-id="quadratic-discriminant-analysis">Quadratic Discriminant Analysis</h4>
<p>Here the decision boundary would be quadratic.</p>
<p>Here the covariances would different for each class, like so:</p>
<p><span class="math display">\[
\begin{align}
1&amp;=\frac{p(x, C_2)}{p(x, C_1)} \\
&amp;=\frac{p(x| C_2)p(C_2)}{p(x| C_1)p(C_1)} \nonumber
\end{align}
\]</span></p>
<p>Taking the log at both sides</p>
<p><span class="math display">\[
\begin{align}
0 &amp;= log N(\mu_2, \Sigma_2) - log N(\mu_1, \Sigma_1) + log \frac{p(C_2)}{p(C_1)}
\end{align}
\]</span></p>
<p>If you solve the equation above then you end up with quadratic terms.</p>
<p>This tell us that now we can handle non-linear separate cases now the data can needs to be quadratic separable.</p>
</section>
<section id="shared-parameters" class="level4" data-number="5.1.1">
<h4 data-number="5.1.1" class="anchored" data-anchor-id="shared-parameters"><span class="header-section-number">5.1.1</span> Shared Parameters</h4>
</section>
<section id="linear-discriminant-analysis" class="level4 unnumbered unlisted">
<h4 class="unnumbered unlisted anchored" data-anchor-id="linear-discriminant-analysis">Linear Discriminant Analysis</h4>
<p>Here the decision boundary would be linear.</p>
<p>Here the covariances would be the same: 1 covariance matrix like so:</p>
<p><span class="math display">\[
\begin{align}
0 &amp;= log N(\mu_2, \Sigma) - log N(\mu_1, \Sigma) + log \frac{p(C_2)}{p(C_1)}
\end{align}
\]</span></p>
<p>Here we do not impose <span class="math inline">\(diag\{\Sigma_k\}\)</span>, we can have Naive Bayes approach here. The latter meaning we can indeeed if we want have the covariance matrices to be <span class="math inline">\(diag\{\Sigma_k\}\)</span>. In this called we called. <em>Naive Bayes applied to LDA</em>.</p>
<ul>
<li>Naive Bayes applied to LDA: same/shared parameters for <span class="math inline">\(\Sigma_k\)</span> and <span class="math inline">\(diag\{\Sigma_k\}\)</span></li>
</ul>
</section>
</section>
<section id="understanding-covariance-and-variance" class="level3 unlisted unnumbered">
<h3 class="unlisted unnumbered anchored" data-anchor-id="understanding-covariance-and-variance">Understanding Covariance and Variance</h3>
<div class="cell" data-freeze="true" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> multivariate_normal</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.colorbar <span class="im">as</span> cbar</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the mean and covariance matrix for the original case</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>covariance_matrix <span class="op">=</span> [[<span class="dv">2</span>, <span class="dv">1</span>], [<span class="dv">1</span>, <span class="dv">2</span>]]  <span class="co"># Example covariance matrix</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a grid of points</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>x, y <span class="op">=</span> np.meshgrid(np.linspace(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">100</span>), np.linspace(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">100</span>))</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>pos <span class="op">=</span> np.dstack((x, y))</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a multivariate Gaussian distribution for the original case</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>rv <span class="op">=</span> multivariate_normal(mean, covariance_matrix)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the probability density at each point in the grid for the original case</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>pdf <span class="op">=</span> rv.pdf(pos)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate eigenvalues and eigenvectors for the original case</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>eigenvalues, eigenvectors <span class="op">=</span> np.linalg.eig(covariance_matrix)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the scale factor for the arrows</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>scale_factor <span class="op">=</span> <span class="fl">2.0</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the first subplot for the original case</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>plt.contourf(x, y, pdf, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    plt.arrow(</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        mean[<span class="dv">0</span>],</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        mean[<span class="dv">1</span>],</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        eigenvectors[i, <span class="dv">0</span>] <span class="op">*</span> np.sqrt(eigenvalues[i]) <span class="op">*</span> scale_factor,</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        eigenvectors[i, <span class="dv">1</span>] <span class="op">*</span> np.sqrt(eigenvalues[i]) <span class="op">*</span> scale_factor,</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>        head_width<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>        head_length<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>        fc<span class="op">=</span><span class="st">'r'</span>,</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>        ec<span class="op">=</span><span class="st">'r'</span>,</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>plt.annotate(<span class="ss">f'Var(X) = </span><span class="sc">{</span>eigenvalues[<span class="dv">0</span>]<span class="sc">:.2f}</span><span class="ss">'</span>, xy<span class="op">=</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>), color<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>plt.annotate(<span class="ss">f'Var(Y) = </span><span class="sc">{</span>eigenvalues[<span class="dv">1</span>]<span class="sc">:.2f}</span><span class="ss">'</span>, xy<span class="op">=</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">2</span>), color<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>plt.annotate(<span class="ss">f'Cov(X, Y) = </span><span class="sc">{</span>covariance_matrix[<span class="dv">0</span>][<span class="dv">1</span>]<span class="sc">:.2f}</span><span class="ss">'</span>, xy<span class="op">=</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">1</span>), color<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Original Case (Covariance ≠ 0)'</span>)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the mean and covariance matrix for the equal variance case</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>equal_variance_cov_matrix <span class="op">=</span> np.diag([<span class="dv">2</span>, <span class="dv">2</span>])  <span class="co"># Equal variance along both dimensions</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a multivariate Gaussian distribution for the equal variance case</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>rv_equal_variance <span class="op">=</span> multivariate_normal(mean, equal_variance_cov_matrix)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the probability density at each point in the grid for the equal variance case</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>pdf_equal_variance <span class="op">=</span> rv_equal_variance.pdf(pos)</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the second subplot for the equal variance case</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>plt.contourf(x, y, pdf_equal_variance, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>plt.annotate(<span class="ss">f'Var(X) = </span><span class="sc">{</span>equal_variance_cov_matrix[<span class="dv">0</span>, <span class="dv">0</span>]<span class="sc">:.2f}</span><span class="ss">'</span>, xy<span class="op">=</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>), color<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>plt.annotate(<span class="ss">f'Var(Y) = </span><span class="sc">{</span>equal_variance_cov_matrix[<span class="dv">1</span>, <span class="dv">1</span>]<span class="sc">:.2f}</span><span class="ss">'</span>, xy<span class="op">=</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">2</span>), color<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Equal Variance Case (Covariance = 0)'</span>)</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Set common labels</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> plt.gcf().axes:</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'X'</span>)</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'Y'</span>)</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure equal aspect ratio for both subplots</span></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> plt.gcf().axes:</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>    ax.set_aspect(<span class="st">'equal'</span>, adjustable<span class="op">=</span><span class="st">'box'</span>)</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a new axes for the legend with adjusted width</span></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>cax <span class="op">=</span> plt.gcf().add_axes([<span class="fl">0.96</span>, <span class="fl">0.3</span>, <span class="fl">0.02</span>, <span class="fl">0.4</span>])  <span class="co"># Adjust the width and position as needed</span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot vertical colorbar for the legend</span></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>cbar.ColorbarBase(cax, cmap<span class="op">=</span><span class="st">'viridis'</span>, orientation<span class="op">=</span><span class="st">'vertical'</span>, label<span class="op">=</span><span class="st">'Probability Density'</span>)</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust the overall layout</span></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(wspace<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-2-output-1.png" width="690" height="306"></p>
</div>
</div>
<p>This plot visually illustrates how variance represents the spread along each dimension, and the arrows depict how the covariance matrix encodes the relationships between the dimensions in a Gaussian distribution.</p>
<ol type="1">
<li><strong>Original Case (Covariance ≠ 0):</strong></li>
</ol>
<ul>
<li>In the first plot (Original Case), the color yellow represents regions where the probability density is higher. In a Gaussian distribution, the probability density is highest at the mean (center) of the distribution and decreases as you move away from the mean. The color yellow typically corresponds to higher probability values in this context.</li>
</ul>
<ol start="2" type="1">
<li><strong>Equal Variance Case (Covariance = 0):</strong></li>
</ol>
<ul>
<li>In the second plot (Equal Variance Case), the color yellow also represents regions of higher probability density. Even though the covariance is zero, meaning there is no linear relationship between the X and Y dimensions, the multivariate Gaussian distribution still has a peak at the mean (center) in each dimension. The color yellow again corresponds to higher probability values in this context.</li>
</ul>
<center>
<img class="img-fluid" width="450px" src="img_m.jpeg">
</center>
<ol type="1">
<li><p><strong>QDA:</strong> they have separate Covariances</p></li>
<li><p><strong>LDA:</strong> they share a non-zero covariance</p></li>
<li><p>Here the shared variances mean for example 3 in the y-direction and 1 in the x-direction, they however contain a non-zero covariance</p></li>
<li><p>Here the shared variances mean for example 1 in the y-direction and 1 in the x-direction, they however contain a zero covariance.</p></li>
</ol>
</section>
</section>
<section id="probabilistic-generative-models-k2" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="probabilistic-generative-models-k2"><span class="header-section-number">6</span> Probabilistic Generative Models <span class="math inline">\(K=2\)</span></h2>
<p><span class="math display">\[
\begin{align}
P(C_1|x) &amp;= \frac{p(x|C_1)p(C_1)}{p(x|C_1)p(C_1)p(x|C_2)p(C_2)}\\
&amp;= \frac{1}{1+e^-a}\nonumber\\
\end{align}
\]</span></p>
<p>Where <span class="math inline">\(a\)</span> is the log odds:</p>
<p><span class="math display">\[
\begin{align}
a &amp;= \ln\frac{p(x|C_1)p(C_1)}{p(x|C_2)p(C_2)}\label{log_odds}\\
\end{align}
\]</span></p>
<p>This can be expressed as the Sigmoid Function:</p>
<p><span class="math display">\[
\begin{align}
\sigma &amp;= \frac{1}{1+e^{(-a)}}\\
\end{align}
\]</span></p>
<ul>
<li>When the log odds its possitive in the sigmud function it will converge to 1. This means I am certain it will be class <span class="math inline">\(C_1\)</span></li>
<li>If the log odds is equal meaning not clue which class to assign. The probability of classifing the target to either class is 0.5.
<ul>
<li>For <span class="math inline">\(a\)</span> to be equal to zero. I need <span class="math inline">\(a=\ln(1)\)</span>. This 1 means <span class="math inline">\(p(x|C_1)p(C_1)=p(x|C_2)p(C_2)\)</span></li>
</ul></li>
<li>When the log odds its negative, the sigmoid function will go to zero. This means I am certain it will be class <span class="math inline">\(C_2\)</span></li>
</ul>
</section>
<section id="probabilistic-generative-models-generalk" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="probabilistic-generative-models-generalk"><span class="header-section-number">7</span> Probabilistic Generative Models, general:<span class="math inline">\(K\)</span></h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Remember
</div>
</div>
<div class="callout-body-container callout-body">
<p>You are given:</p>
<ul>
<li>Class-conditional densities: <span class="math inline">\(p(x|C_k)\)</span> <em>aka</em> <strong>Likelihood</strong></li>
<li><strong>Prior</strong> class probabilities: <span class="math inline">\(p(Ck)\)</span></li>
</ul>
<p>With these two guys you can get:</p>
<ul>
<li>Joint Distribution: <span class="math inline">\(p(x,C_k) = p(x|C_k)p(C_k)\)</span> the <em>numerator</em></li>
<li>The <strong>Posterior</strong> <span class="math inline">\(p(C_k|x)=\frac{p(x|C_k)p(C_k)}{p(x)}\)</span></li>
</ul>
<p>Goal:</p>
<ul>
<li>Find <span class="math inline">\(p(C_k|x)\)</span> so that you can determine the class of <span class="math inline">\(x\)</span> by knowing the Decision boundaries<br>
</li>
</ul>
</div>
</div>
<p><span class="math display">\[
\begin{align}
P(C_k|x) &amp;= \frac{p(x|C_k)p(C_k)}{\sum_{j=1}^{K}p(x|C_j)p(C_j)}\\
&amp;= \frac{e^{a_k}}{\sum_{j=1}^{K}e^{a_j}}\label{softmax}\\
a_k &amp;= \ln(p(x|C_k)p(C_k)) \nonumber
\end{align}
\]</span></p>
<p>Where <span class="math inline">\(\ref{softmax}\)</span> is called the <strong>Softmax</strong>:</p>
<ul>
<li>if <span class="math inline">\(a_k&gt;&gt;a_j\)</span> for all <span class="math inline">\(j \neq k\)</span> then <span class="math inline">\(p(C_k|x)=1\)</span> and <span class="math inline">\(p(C_j|x)=0\)</span></li>
<li>The <strong>Softmax</strong> reduces to the <strong>Simoid</strong> function when <span class="math inline">\(K=2\)</span></li>
</ul>
<section id="how-to-parametrize-class-conditional-densities-aka-the-likelihood" class="level4" data-number="7.0.1">
<h4 data-number="7.0.1" class="anchored" data-anchor-id="how-to-parametrize-class-conditional-densities-aka-the-likelihood"><span class="header-section-number">7.0.1</span> How to parametrize Class Conditional Densities (<em>aka</em> The Likelihood)?</h4>
<p>With Gaussians!</p>
<p><span class="math display">\[
\begin{align}
p(x|C_k)&amp;=\mathcal{N}(x|\mu_k , \Sigma_k ) \\
        &amp;= \frac{1}{(2 \pi)^{D/2}} \frac{1}{|\Sigma_k|^{1/2}} \exp^{\{-\frac{1}{2}(x-\mu_k)^T \Sigma_k^-1 (x-\mu_k)\}} \label{gaussian_lda}\\
\end{align}
\]</span></p>
<ul>
<li>Where the Gaussian is going to be multivariate and it will be <span class="math inline">\(D\)</span>-dimensional due to the input being <span class="math inline">\(x \in \mathbb{R}^{D}\)</span>
<ul>
<li>This means for each <span class="math inline">\(\mu_k\)</span> and <span class="math inline">\(\Sigma_k\)</span> I would have a different Gaussian distribution</li>
</ul></li>
<li><span class="math inline">\(\Sigma_k\)</span> determines the shape of my distribution. Like in the python plot above in the left graph</li>
</ul>
<p>When we assume each of these Gaussian share the same the Covariance matrix: <span class="math inline">\(\Sigma_k\)</span> then we are talking about LDA</p>
<p>To determine the decision boundary we have that:</p>
<p><span class="math display">\[
\begin{align}
p(C_1|X) &amp;= \frac{1}{1+e^(-a)} = \sigma(a)\\
\end{align}
\]</span></p>
<p>Where <span class="math inline">\(a\)</span> is defined was defined as the log odds. So replacing <span class="math inline">\(p(x|C_k)\)</span> so replacing <span class="math inline">\(\ref{gaussian_lda}\)</span> (the Gaussians) in the log odds <span class="math inline">\(\ref{log_odds}\)</span> give us The Generalized Linear Model:</p>
<p><span class="math display">\[
\begin{align}
p(C_1|x) &amp;= \sigma(\underline{w}^T\underline{x}+w_o)\\
\end{align}
\]</span></p>
<p>And now recall that the decision boundary happens when <span class="math inline">\(p(C_1|x) = p(C_2|x)\)</span>.</p>
<ul>
<li>This all means if we want to make decisions based on the posterior distributions, then <span class="math inline">\(a=0\)</span> meaning the prob/prob is 1 or the <span class="math inline">\(\sigma(a) = \frac{1}{2}\)</span></li>
</ul>
</section>
</section>
<section id="lda-maximum-likelihood-for-k2" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="lda-maximum-likelihood-for-k2"><span class="header-section-number">8</span> LDA: Maximum Likelihood for K=2</h2>
<blockquote class="blockquote">
<p><strong>Goal:</strong> recover the Gaussian distributions (the join distribution = p(X, C_k)) that have generated the data. To accomplished that we need to take the MLE over the the Gaussian conditional densities aka the likelihood and solve for <span class="math inline">\(u_k\)</span>, <span class="math inline">\(\Sigma\)</span> and priors <span class="math inline">\(p(C_k)\)</span></p>
</blockquote>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Isometric Covariance definition
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>It is a special case of a covariance matrix where all off-diagonal elements are zero, and the diagonal elements are equal, representing a constant variance or dispersion in all dimensions.</p>
<p>Mathematically, an isometric covariance matrix Σ can be represented as:</p>
<ul>
<li>Σ = σ² * I</li>
</ul>
<p>Where:</p>
<ul>
<li>Σ is the covariance matrix.</li>
<li>σ² is the common variance or dispersion parameter.</li>
<li>I is the identity matrix, which has ones on the diagonal and zeros elsewhere.</li>
</ul>
<p>In this form, each element along the diagonal of the covariance matrix Σ is equal to σ², and all off-diagonal elements are zero. This implies that the variables in a multivariate distribution with an isometric covariance matrix have equal variances and are uncorrelated with each other.</p>
</div>
</div>
</div>
<p>Given:</p>
<ol type="1">
<li>Gaussian conditional densities aka <strong>Likelihoods</strong>:</li>
</ol>
<p><span class="math display">\[
\begin{align}
p(x|C_k) = \frac{1}{(2 \pi)^{D/2}} \frac{1}{|\Sigma_k|^{1/2}} \exp^{\{-\frac{1}{2}(x-\mu_k)^T \Sigma_k^-1 (x-\mu_k)\}} \nonumber\\
\end{align}
\]</span></p>
<ol start="2" type="1">
<li>Prior <span class="math inline">\(p(C_k)\)</span><br>
Because we have <span class="math inline">\(k=2\)</span> then we can assign <span class="math inline">\(p(C_1) = q\)</span> and <span class="math inline">\(p(C_2) = 1-q\)</span></li>
</ol>
<p>With 1. and 2. we can solve for the Joint distributions:</p>
<p>For <span class="math inline">\(x_n\)</span> with <span class="math inline">\(t_n =1\)</span>: <span class="math display">\[
\begin{align}
p(x_n, C_1) &amp;= p(x_n|C_1)p(C_1) = q \, N(x_n|\mu_1,\Sigma) \\
\end{align}
\]</span></p>
<p>For <span class="math inline">\(x_n\)</span> with <span class="math inline">\(t_n =0\)</span>: <span class="math display">\[
\begin{align}
p(x_n, C_2) &amp;= p(x_n|C_2)p(C_2) = (1-q) \, N(x_n|\mu_2, \Sigma)\\
\end{align}
\]</span></p>
<ul>
<li><span class="math inline">\(t_n\)</span> is binary if I do <span class="math inline">\(\sum t_n\)</span> here I am counting the number of times <span class="math inline">\(t_n\)</span> is equals to 1.</li>
</ul>
<section id="deriving-q_ml" class="level3" data-number="8.1">
<h3 data-number="8.1" class="anchored" data-anchor-id="deriving-q_ml"><span class="header-section-number">8.1</span> Deriving <span class="math inline">\(q_{ML}\)</span></h3>
<p><span class="math display">\[
\begin{align}
q_{ML} &amp;= \frac{1}{N} \sum_{n=1}^{N} t_n = \frac{N_1}{N}\\
\end{align}
\]</span></p>
<ul>
<li><span class="math inline">\(q\)</span> is the prior probability of observing class <span class="math inline">\(K=1\)</span>. The result above means the total number of observations that I have observed <span class="math inline">\(t_n=1\)</span></li>
</ul>
</section>
<section id="deriving-muml" class="level3" data-number="8.2">
<h3 data-number="8.2" class="anchored" data-anchor-id="deriving-muml"><span class="header-section-number">8.2</span> Deriving <span class="math inline">\(\mu{ML}\)</span></h3>
<p><span class="math display">\[
\begin{align}
\mu_{1,ML} &amp;= \frac{1}{N_1} \sum_{n=1}^{N} t_n \, x_n\\
\end{align}
\]</span></p>
<ul>
<li><span class="math inline">\(\mu_{1,Ml}\)</span> is the sample mean of all my observations where <span class="math inline">\(x_n\)</span> belongs to class <span class="math inline">\(K=1\)</span>. Here $t_n =1 $ when the class is 1.</li>
</ul>
<p><span class="math display">\[
\begin{align}
\mu_{2,ML} &amp;= \frac{1}{N_2} \sum_{n=1}^{N} (1-t_n) \, x_n\\
\end{align}
\]</span></p>
<ul>
<li><span class="math inline">\(\mu_{2,Ml}\)</span> is the sample mean of all my observations where <span class="math inline">\(x_n\)</span> belongs to class <span class="math inline">\(K=2\)</span></li>
</ul>
</section>
<section id="covariance-for-discrete-random-variables" class="level3" data-number="8.3">
<h3 data-number="8.3" class="anchored" data-anchor-id="covariance-for-discrete-random-variables"><span class="header-section-number">8.3</span> Covariance for discrete Random Variables</h3>
<p>For class <span class="math inline">\(i\)</span> the covariance matrix can be calculated as: <span class="math display">\[
\begin{align}
\Sigma_i &amp;= \frac{1}{N_i}\sum_{n=1}^{N_i}(x_n-\mu_i)(x_n-\mu_i)^T \\
\end{align}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(N_i\)</span> ​is the number of data points in class <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(x_n\)</span> is a data point in class <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(\mu_i\)</span> is the mean vector of class <span class="math inline">\(i\)</span></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
How to classify a new data point?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p><strong>Gaussian Classifier:</strong> Once you have the covariance matrices for each class, you can use them to build a Gaussian classifier. The Gaussian classifier estimates the likelihood of a given data point belonging to each class based on the probability density function of a multivariate Gaussian distribution with the class’s mean and covariance matrix.</p></li>
<li><p><strong>Classification:</strong> When you receive a new data point, you calculate the likelihood of it belonging to each class using the Gaussian distribution parameters (mean and covariance matrix) for each class. You can then assign the data point to the class with the highest likelihood.</p></li>
</ol>
</div>
</div>
</div>
<p>The whole point of LDA was explained at: <a href="https://youtu.be/R6yNZ4diIQo?si=53KJbtvIB71V8Yad&amp;t=1436">here</a></p>
</section>
<section id="disadvantages-of-lda" class="level3" data-number="8.4">
<h3 data-number="8.4" class="anchored" data-anchor-id="disadvantages-of-lda"><span class="header-section-number">8.4</span> Disadvantages of LDA</h3>
<ul>
<li>Sensitive to outliers. Meaning if I have a point really far from <span class="math inline">\(\mu_1\)</span> then it induces a large shift to the actual <span class="math inline">\(\mu_1\)</span></li>
<li>Relies in handcrafted features, if I go to high dimensional spaces I need to make choices and complicates things</li>
<li>The same as regression, here in clarification with LDA the MLE MAximum Likelihood are prone to overfilling. The latter because any regularization has been applied</li>
</ul>
<p>So far:</p>
</section>
</section>
<section id="parametrizing-the-class-conditional-desnsitiy-with-other-distributions" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="parametrizing-the-class-conditional-desnsitiy-with-other-distributions"><span class="header-section-number">9</span> Parametrizing the class-conditional desnsitiy with other distributions</h2>
<ul>
<li><p>So far we parametrize the Class conditional distributions with Gaussians. We can use however different ones. This is necessary when ie. the data it is not continuous and for instance its discrete.</p></li>
<li><p>In the Continuous space the number of parameters does not scales as much as in the discrete where then we have for i.e a binary classification to <span class="math inline">\(2^D\)</span> parameters. The reasons is that we cannot fit anymore a Gaussains distribution to the discrete variables</p></li>
</ul>
<p>To contrast the huge num. of parameters then we are going to make a model assumption that is:</p>
<ul>
<li>Naive Bayes assumption: feature value are treated as independent when conditioned on class <span class="math inline">\(C_k\)</span>. That means:</li>
</ul>
<p>Given:</p>
<ul>
<li>Class-conditional probabilities: <span class="math display">\[
\begin{align}
p(x|C_k) &amp;= \prod_{i=1}^{D} \, p(x_i|C_k) \\
&amp;= \prod_{i=1}^{D} \,  \pi_{k_i}^{x_i}(1- \pi_{k_i}^{x_i})^{1-x_i} \nonumber
\end{align}
\]</span></li>
</ul>
<p>Here:</p>
<ul>
<li><span class="math inline">\(x_i\)</span> takes the value <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span> given my class <span class="math inline">\(C_k\)</span></li>
</ul>
<p>The above equation was modeled using the bernoulli equation</p>
<ul>
<li><span class="math inline">\(\pi_{k_i}=p(x_i=1|C_k)\)</span><br>
</li>
<li>Now the number of parameters per class is <span class="math inline">\(D\)</span></li>
</ul>
<p>With this parametrization we can calculate the posterior probability: <span class="math inline">\(p(C_k|x)\)</span> where we can compute it with our recently parametrized-bernouli like class density aka the likelihood. Here modeling the prior follows the same as how we did it with the class-density akak Likelihood, With these two we can get the joint aka the evidence evidence.</p>
<p>Remember the evidence is the marginalization (sumation) over the joint (<span class="math inline">\(p(x,C_k)\)</span>).</p>
<p><span class="math display">\[
\begin{align}
p(x) = \sum_{k=1}^{K}p(x,C_k) = \sum_{k=1}^{K}p(x|C_k)p(C_k)
\end{align}
\]</span></p>
</section>
<section id="discriminative-linear-models" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="discriminative-linear-models"><span class="header-section-number">10</span> Discriminative Linear Models</h2>
<p>We go away momentarily from the prob view and try model the discriminant function without describing first a prob model.</p>
<p>We will do the following. Given input <span class="math inline">\(x \in \mathbb{R}^{Dx1}\)</span> and targets <span class="math inline">\(t \in {C1, C2}={-1,1}\)</span></p>
<p><span class="math display">\[
\begin{align}
y(x,\overline{w})&amp;=f(\overline{w}^t \boldsymbol{\phi}) \\
\boldsymbol{\phi} &amp;= (\phi_{0}(x),\phi_{1}(x),...,\phi_{M-1}(x))^T
\end{align}
\]</span></p>
<p>This model is linear with respect to <span class="math inline">\(w\)</span></p>
</section>
<section id="least-squares-for-classification" class="level2" data-number="11">
<h2 data-number="11" class="anchored" data-anchor-id="least-squares-for-classification"><span class="header-section-number">11</span> Least Squares for Classification</h2>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../about/index.html"><span class="footerDaniloToapanta">Mantained by Danilo Toapanta</span></a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../coming-soon.html">Newsletter</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../docs/sitemap.xml">RSS</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>

    let navbar = document.getElementsByClassName("navbar-nav")[0]    

    let li2 = document.createElement("li");
    li2.className = "nav-item compact";

    let a2 = document.createElement("a");
    a2.className = "nav-link quarto-color-scheme-toggle";
    a2.style.cursor = "pointer"
    li2.appendChild(a2)

    let i2 = document.createElement("i");
    i2.className = "bi bi-moon"
    a2.append(i2)

    navbar.appendChild(li2);

    i2.onclick = function() {
        window.quartoToggleColorScheme(); return false;
    }
    // <a href="http://localhost:4200/about/" class="quarto-color-scheme-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>

    let li = document.createElement("li");
    li.className = "nav-item compact";

    let a = document.createElement("a");
    a.className = "nav-link";
    a.style.cursor = "pointer"
    li.appendChild(a)

    let i = document.createElement("i");
    i.className = "bi bi-search"
    a.append(i)

    // let span = document.createElement("span");
    // span.className = "menu-text"
    // a.append(span)

    navbar.appendChild(li);

    a.onclick = function() {
        window.quartoOpenSearch()
    }


</script>



</body></html>