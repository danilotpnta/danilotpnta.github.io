<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.53">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Danilo Toapanta">
<meta name="dcterms.date" content="2023-11-22">
<meta name="description" content="Description of this Post">

<title>Lexical semantics and word embeddings – Danilo Toapanta</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../assets/danilo.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<!-- <link href="../../site_libs/quarto-contrib/material-icons-0.14.2/mi.css" rel="stylesheet"> -->
<script>
window.MathJax = {
  tex: {
    tags: 'ams'
  }
};
</script>


<link rel="stylesheet" href="../css/index-posts.css">
</head>

<body class="floating nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <div id="quarto-announcement" data-announcement-id="af66dd50c39dd2ed9de488e10a192054" class="alert alert-primary hidden"><i class="bi bi-info-circle quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p><strong>Let op</strong> - This website is undergoing scheduled maintenance</p>
</div></div>
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title"><span id="danilo_topanta_brand"> Danilo Toapanta</span> <a id="mysite" class="mysite" href="../../site-ver-hist/">v1.2</a></span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text"><span id="home-welcome-msg">Home</span></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects/index.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about/index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/danilotpnta?tab=repositories" target="_blank"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full blog-page" style="display: none !important;">
    <div class="quarto-title-banner page-columns page-full">
        <div class="quarto-title column-body">
            <h1 class="title">Lexical semantics and word embeddings</h1>
                
            <!-- Description Block -->
                        <div>
                <div class="description">
                    Description of this Post
                </div>
            </div>
                        
            <!-- Categories Block -->
                                            <div class="quarto-categories">

                    <!-- Display Categories -->
                                            <div class="quarto-category">
                            <a href="../../blog/#category=All">
                                All
                            </a>
                        </div> 
                                            <div class="quarto-category">
                            <a href="../../blog/#category=NLP">
                                NLP
                            </a>
                        </div> 
                                            <div class="quarto-category">
                            <a href="../../blog/#category=TAGS">
                                TAGS
                            </a>
                        </div> 
                    
                    <!-- Display Tags if any -->
                                    </div>
                            
        </div>
    </div>


    
    <div class="quarto-title-meta">

        <div>
        <div class="quarto-title-meta-heading">Author</div>
        <div class="quarto-title-meta-contents">
                 <p><a href="https://danilotpnta.github.io/">Danilo Toapanta</a> </p>
              </div>
      </div>
        
        <div>
        <div class="quarto-title-meta-heading">Published</div>
        <div class="quarto-title-meta-contents">
          <p class="date">November 22, 2023</p>
        </div>
      </div>
      
        
      </div>
      

    
</header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">
<script>
    var currentUrl = window.location.href;
    var index_init_post = currentUrl.lastIndexOf("/20");
    var string_init_post= currentUrl.slice(index_init_post, index_init_post+3 );

    // console.log("currentUrl: " + currentUrl);
    // console.log("index: " + index_init_post);
    // console.log("string: " + string_init_post);

    // If is equal to /blog/20... then make navbar title READING MODE
    if (string_init_post === "/20"){
        let mysite = document.getElementById("mysite");
        mysite.classList.add("mysite-change");

        let navbar = document.getElementById("danilo_topanta_brand");
        navbar.classList.add("navbar-brand-change");

        // This will render a new title saying READING DANILOS BLOG
        // navbar.innerHTML = 'You are Reading Danilo\'s Blog<span style="font-size:35px; vertical-align: middle; opacity: 0.65; padding-bottom: 6px; padding-left: 14px;" class="material-icons-round"> auto_awesome </span>';
        
        const smallDevice = window.matchMedia("(min-width: 570px)");
        smallDevice.addListener(handleDeviceChange);

        function handleDeviceChange(mediaQuery) {
            if (mediaQuery.matches) {
                navbar.innerHTML = "";
                // navbar.innerHTML = "<-- You are Reading Danilo's Blog -->";
            } else  {
                navbar.innerHTML = "Danilo Toapanta";
            }
        }

        // Run it initially
        handleDeviceChange(smallDevice);

        let link = document.getElementsByClassName("navbar-brand")[0];
        link.classList.add("disablePointerEvents");

        let brand_container = document.getElementsByClassName("navbar-brand-container")[0];
        brand_container.classList.add("navbar-brand-container-new-padding");

    }
</script>


<!-- <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Running my first Marathon</h1>
                  <div>
        <div class="description">
          I will be running at the 42km TCS Amsterdam 2023, 15th October
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">News</div>
              </div>
                  </div>
  </div> -->

  <!-- ---
  coming-soon: true
  tags: [Spanish]
  --- -->








<main id="title-block-header" class="quarto-title-block default page-columns page-full" style="padding-bottom: 40px;">

    <div class="quarto-title column-body" style="margin-bottom: 1em;">
        <h1 class="title" style="padding-bottom:8px" ;="">Lexical semantics and word embeddings</h1>
        
        <!-- Description Block -->
                    <div>
                <div class="description">
                    Description of this Post
                </div>
            </div>
        
        <!-- Categories Block -->
                    
                <!-- Display Categories -->
                <div class="quarto-categories">
                    <!-- <div id="tag-icon-blog" class="quarto-category tags-title">
                        <i class="fa-solid fa-hashtag" ></i> Categories:
                    </div> -->

                                            <div id="All" class="quarto-category">
                            <a href="../../blog/#category=All">
                                All
                            </a>
                        </div>
                                            <div id="NLP" class="quarto-category">
                            <a href="../../blog/#category=NLP">
                                NLP
                            </a>
                        </div>
                                            <div id="TAGS" class="quarto-category">
                            <a href="../../blog/#category=TAGS">
                                TAGS
                            </a>
                        </div>
                                    </div>
                


                <div class="quarto-categories tag-categories">
                    
                    <!-- Tags Icon  -->
                    <!-- <div id="tag-icon-blog" class="quarto-category tags-title"> -->
                        <!-- <i class="fa-solid fa-tag" ></i> Tags: -->
                        <!-- <i class="fa-solid fa-hashtag" ></i> Tags: -->
                        <!-- <span class="material-icons-outlined" >local_offer</span> Tags: -->
                        <!-- / -->
                    <!-- </div> -->

                    <!-- Display Tags -->
                                            <div id="All-from-here" class="quarto-category tags-title" style="display: none;">
                            <a href="../../blog/#category=All">
                               <!-- <span class="hasth-tag">
                                #
                                </span> -->
                                All
                            </a>
                        </div>
                                            <div id="NLP-from-here" class="quarto-category tags-title" style="display: none;">
                            <a href="../../blog/#category=NLP">
                               <!-- <span class="hasth-tag">
                                #
                                </span> -->
                                NLP
                            </a>
                        </div>
                                            <div id="TAGS-from-here" class="quarto-category tags-title" style="display: none;">
                            <a href="../../blog/#category=TAGS">
                               <!-- <span class="hasth-tag">
                                #
                                </span> -->
                                TAGS
                            </a>
                        </div>
                    
                    
                </div>

                    
    </div>


    
    <div class="quarto-title-meta">

        <div>
        <div class="quarto-title-meta-heading">Author</div>
        <div class="quarto-title-meta-contents">
                 <p><a href="https://danilotpnta.github.io/">Danilo Toapanta</a> </p>
              </div>
      </div>
        
        <div>
        <div class="quarto-title-meta-heading">Published</div>
        <div class="quarto-title-meta-contents">
          <p class="date">November 22, 2023</p>
        </div>
      </div>
      
        
      </div>
      

    <!-- Current link: Font-awesome, Google icons, Bootstrap icons -->
    
</main>


<!-- ## Title
<center>![Slide 1](imgs/page_1.png){.w575}<center><pre></pre> -->
<section id="outline." class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="outline."><span class="header-section-number">1</span> Outline.</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_2.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 2</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="semantics" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="semantics"><span class="header-section-number">2</span> Semantics</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_3.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 3</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Semantics is concerned with modelling meaning</p>
<ul>
<li><p>Compositional semantics: meaning of phrases</p></li>
<li><p>Lexical semantics: meaning of individuals words</p></li>
</ul>
</section>
<section id="what-is-lexical-meaning" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="what-is-lexical-meaning"><span class="header-section-number">3</span> What is lexical meaning?</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_4.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 4</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="how-to-approach-lexical-meaning" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="how-to-approach-lexical-meaning"><span class="header-section-number">4</span> How to approach lexical meaning?</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_5.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 5</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>In formal semantics: The meaning of words are represented as sets</p>
<p>i.e <strong>Bachelors</strong> -&gt; if is a man and also unmmaried</p>
</section>
<section id="how-to-approach-lexical-meaning-1" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="how-to-approach-lexical-meaning-1"><span class="header-section-number">5</span> How to approach lexical meaning?</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_6.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 6</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="prototype-theory" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="prototype-theory"><span class="header-section-number">6</span> Prototype theory</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_7.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 7</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Prototype theory: concepts are represents as a graded category, it is like a human categorization</p>
<ul>
<li>not all members needs to share a property</li>
</ul>
<p>i.e <strong>furniture</strong> -&gt; <em>chair</em> is more central (prototypical) than <em>stool</em> or a <em>couch</em></p>
</section>
<section id="semantic-relations" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="semantic-relations"><span class="header-section-number">7</span> Semantic relations</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_8.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 8</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Taxonomy refers to the science of classification, specifically the classification of living organisms into various categories based on shared characteristics</p>
</section>
<section id="other-semantic-relations" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="other-semantic-relations"><span class="header-section-number">8</span> Other semantic relations</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_9.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 9</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="polysemy-and-word-senses" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="polysemy-and-word-senses"><span class="header-section-number">9</span> Polysemy and word senses</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_10.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Polysemy is the ability of a word to have multiple meanings</p>
<p>A word can mean different things in a different context</p>
</section>
<section id="polysemy" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="polysemy"><span class="header-section-number">10</span> Polysemy</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_11.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="outline.-1" class="level2" data-number="11">
<h2 data-number="11" class="anchored" data-anchor-id="outline.-1"><span class="header-section-number">11</span> Outline.</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_12.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>This a modeling framework</p>
</section>
<section id="distributional-hypothesis" class="level2" data-number="12">
<h2 data-number="12" class="anchored" data-anchor-id="distributional-hypothesis"><span class="header-section-number">12</span> Distributional hypothesis</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_13.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>We can analysis the word depending of how it is used in a large corpus</p>
<p>A corpus (plural: corpora) refers to a large and structured set of texts,</p>
</section>
<section id="distributional-hypothesis-1" class="level2" data-number="13">
<h2 data-number="13" class="anchored" data-anchor-id="distributional-hypothesis-1"><span class="header-section-number">13</span> Distributional hypothesis</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_14.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 14</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="distributional-hypothesis-2" class="level2" data-number="14">
<h2 data-number="14" class="anchored" data-anchor-id="distributional-hypothesis-2"><span class="header-section-number">14</span> Distributional hypothesis</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_15.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 15</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="distributional-hypothesis-3" class="level2" data-number="15">
<h2 data-number="15" class="anchored" data-anchor-id="distributional-hypothesis-3"><span class="header-section-number">15</span> Distributional hypothesis</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_16.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 16</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="distributional-hypothesis-4" class="level2" data-number="16">
<h2 data-number="16" class="anchored" data-anchor-id="distributional-hypothesis-4"><span class="header-section-number">16</span> Distributional hypothesis</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_17.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 17</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="scrumpy" class="level2" data-number="17">
<h2 data-number="17" class="anchored" data-anchor-id="scrumpy"><span class="header-section-number">17</span> Scrumpy</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_18.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 18</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="distributional-hypothesis-5" class="level2" data-number="18">
<h2 data-number="18" class="anchored" data-anchor-id="distributional-hypothesis-5"><span class="header-section-number">18</span> Distributional hypothesis</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_19.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 19</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>The context about a word provides the information about its meaning</p>
<p>Meaning similarity, could be then be the vector that is also similar to another where each element of the vector is a context, so the more similar context the closer the meaning</p>
</section>
<section id="the-general-intuition" class="level2" data-number="19">
<h2 data-number="19" class="anchored" data-anchor-id="the-general-intuition"><span class="header-section-number">19</span> The general intuition</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_20.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 20</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>each word is a point: a row</p>
<p>Dimensions: are all possible contexts in our dataset</p>
<p>the values are the frequencies that ocurred in that context</p>
</section>
<section id="vectors" class="level2" data-number="20">
<h2 data-number="20" class="anchored" data-anchor-id="vectors"><span class="header-section-number">20</span> Vectors</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_21.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 21</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="the-notion-of-context" class="level2" data-number="21">
<h2 data-number="21" class="anchored" data-anchor-id="the-notion-of-context"><span class="header-section-number">21</span> The notion of context</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_22.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 22</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="context" class="level2" data-number="22">
<h2 data-number="22" class="anchored" data-anchor-id="context"><span class="header-section-number">22</span> Context</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_23.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 23</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Here we delte words that are frequent</p>
<p>Here the window stays the same</p>
</section>
<section id="context-1" class="level2" data-number="23">
<h2 data-number="23" class="anchored" data-anchor-id="context-1"><span class="header-section-number">23</span> Context</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_24.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 24</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Now we just take the stem of each word and then we do a count on this stem words; here acknowledged -&gt; acknowledge</p>
<p>This is handy if your corpus is not very large, because then your vectors would be very sparce meaning we would have zero entries because of the different variants of a word, so instead you want to aggregate context that mean the same so then we fix sparse vectors</p>
</section>
<section id="context-2" class="level2" data-number="24">
<h2 data-number="24" class="anchored" data-anchor-id="context-2"><span class="header-section-number">24</span> Context</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_25.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 25</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Instead of word window, we can use syntatic relations. That is we can extract syntactic context even for those words that are further way but have some relation with the wording that we are looking.</p>
</section>
<section id="context-weighting" class="level2" data-number="25">
<h2 data-number="25" class="anchored" data-anchor-id="context-weighting"><span class="header-section-number">25</span> Context weighting</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_26.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 26</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>The first decision: how to model</p>
<p>The second: how to weight the context, so which metric we wil use</p>
</section>
<section id="characteristic-model" class="level2" data-number="26">
<h2 data-number="26" class="anchored" data-anchor-id="characteristic-model"><span class="header-section-number">26</span> Characteristic model</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_27.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 27</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Here we are saying that there are some words that are more characteristic of a context. For i.e ‘floffy’ can be refered to dogs or cats, or toys but not so much of ‘computer’, ‘screwdriver’</p>
<p>It measures the joint probability of the word and the context (numerator) and the probability of them occurring together if they were independent (denominator)</p>
<p>P(c|w): how likely it is the context given that we are seeing this word.</p>
<p>So we want to compute the probability of the word occurance in the corpus to their probability of occurrence independently</p>
</section>
<section id="what-semantic-space" class="level2" data-number="27">
<h2 data-number="27" class="anchored" data-anchor-id="what-semantic-space"><span class="header-section-number">27</span> What semantic space?</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_28.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 28</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>The first decision: how to model</p>
<p>The second: how to weight the context, so which metric we wil use</p>
<p>Third design decision: what kind of semantic space to use? aka how many context to include</p>
<ul>
<li>We can use entire vocabulary<br>
A CON is that it will be very sparse if we use the whole vocab</li>
</ul>
</section>
<section id="word-frequency-zipfian-distribution" class="level2" data-number="28">
<h2 data-number="28" class="anchored" data-anchor-id="word-frequency-zipfian-distribution"><span class="header-section-number">28</span> Word frequency: Zipfian distribution</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_29.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 29</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="what-semantic-space-1" class="level2" data-number="29">
<h2 data-number="29" class="anchored" data-anchor-id="what-semantic-space-1"><span class="header-section-number">29</span> What semantic space?</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_30.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 30</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Dimensionality reduction is to benefit from approach 1 and 2</p>
</section>
<section id="an-example-noun" class="level2" data-number="30">
<h2 data-number="30" class="anchored" data-anchor-id="an-example-noun"><span class="header-section-number">30</span> An example noun</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_31.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 31</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>the values here are PMI values</p>
</section>
<section id="an-example-adjective" class="level2" data-number="31">
<h2 data-number="31" class="anchored" data-anchor-id="an-example-adjective"><span class="header-section-number">31</span> An example adjective</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_32.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 32</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Decathlon is strange to see in the first place</p>
<p>PMI property: no matter which data you apply to is that you would get unreseanable PMI values for rare events.</p>
<p>So Decathlon is rare, and if it appears with academic once, then it will have a high PMI, because has a low prior probability</p>
</section>
<section id="polysemy-1" class="level2" data-number="32">
<h2 data-number="32" class="anchored" data-anchor-id="polysemy-1"><span class="header-section-number">32</span> Polysemy</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_33.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 33</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Polysemy is the ability of a word to have multiple meanings</p>
<p>All these senses are encoded and collapse toguether within a single distribution. Basically you have different context that correspond to different meanings and</p>
</section>
<section id="calculating-similarity-in-a-distributional-space" class="level2" data-number="33">
<h2 data-number="33" class="anchored" data-anchor-id="calculating-similarity-in-a-distributional-space"><span class="header-section-number">33</span> Calculating similarity in a distributional space</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_34.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 34</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="measuring-similarity" class="level2" data-number="34">
<h2 data-number="34" class="anchored" data-anchor-id="measuring-similarity"><span class="header-section-number">34</span> Measuring similarity</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_35.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 35</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>The dot product of the two vectors that is normalized by the vector lenght</p>
<p>The Euclidean distance considers the length of the vectors:</p>
<center>
<img src="imgs/2023-11-22-20-43-40.png" class="w250 img-fluid">
</center>
<pre></pre>
<p>The euclidean distance would be quite large, so that is why we need to normalize</p>
</section>
<section id="the-scale-of-similarity-some-examples" class="level2" data-number="35">
<h2 data-number="35" class="anchored" data-anchor-id="the-scale-of-similarity-some-examples"><span class="header-section-number">35</span> The scale of similarity: some examples</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_36.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 36</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="words-most-similar-to-cat" class="level2" data-number="36">
<h2 data-number="36" class="anchored" data-anchor-id="words-most-similar-to-cat"><span class="header-section-number">36</span> Words most similar to cat</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_37.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 37</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="but-what-is-similarity" class="level2" data-number="37">
<h2 data-number="37" class="anchored" data-anchor-id="but-what-is-similarity"><span class="header-section-number">37</span> But what is similarity?</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_38.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 38</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="distributional-methods-are-a-usage-representation" class="level2" data-number="38">
<h2 data-number="38" class="anchored" data-anchor-id="distributional-methods-are-a-usage-representation"><span class="header-section-number">38</span> Distributional methods are a usage representation</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_39.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 39</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="distribution-for-policeman" class="level2" data-number="39">
<h2 data-number="39" class="anchored" data-anchor-id="distribution-for-policeman"><span class="header-section-number">39</span> Distribution for policeman</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_40.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 40</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="distribution-for-cop" class="level2" data-number="40">
<h2 data-number="40" class="anchored" data-anchor-id="distribution-for-cop"><span class="header-section-number">40</span> Distribution for cop</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_41.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 41</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Cop and policeman, even though the words seems to be the same, there is cultural associations with cop that is highly negative.</p>
<p>This means that words have relative meanings to the culture and thus if compared this terms between cultures their meanings could be totally different which then evaluating a similarity metric will yield that they are not similar.</p>
<p>Tha being, we take two words from the same corpus but because of cultural use of words they may have different distributions (cognotations). Unquestionable, this is a property of the data.</p>
<p>1set carriage bike vehicle train truck lorry coach taxi – official officer inspector journalist detective constable policeman reporter – sister daughter parent relative lover cousin friend wife mother husband brother father</p>
<p>2set car engine petrol road driver wheel trip steering seat fo, highway sign speed - concert singer stage light music show audience performance ticket - experiment research scientist paper result publication laboratory finding</p>
</section>
<section id="clustering-nouns" class="level2" data-number="41">
<h2 data-number="41" class="anchored" data-anchor-id="clustering-nouns"><span class="header-section-number">41</span> Clustering nouns</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_42.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 42</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="clustering-nouns-1" class="level2" data-number="42">
<h2 data-number="42" class="anchored" data-anchor-id="clustering-nouns-1"><span class="header-section-number">42</span> Clustering nouns</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_43.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 43</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="outline.-2" class="level2" data-number="43">
<h2 data-number="43" class="anchored" data-anchor-id="outline.-2"><span class="header-section-number">43</span> Outline.</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_44.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 44</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="distributional-semantic-models" class="level2" data-number="44">
<h2 data-number="44" class="anchored" data-anchor-id="distributional-semantic-models"><span class="header-section-number">44</span> Distributional semantic models</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_45.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 45</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Dense vectors or word embeddings</p>
<p>Count-based models we can see clearly</p>
<p>Here we train the model to predict what makes a good context for a word.</p>
<p>Dense in the sense that the dimensionals are used and there are fewer dimensions, the model learns some interactions between them. However the dimensions are latent so if the model has a strange behaviour is very hard to know why.</p>
</section>
<section id="sparse-vs.-dense-vectors" class="level2" data-number="45">
<h2 data-number="45" class="anchored" data-anchor-id="sparse-vs.-dense-vectors"><span class="header-section-number">45</span> Sparse vs.&nbsp;dense vectors</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_46.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 46</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>In traditional distribution models we can have tends of thousands of contexts in a large corpus</p>
<p>they generalize better, by having those latent dimensions that are trained in the prediction task, the model learns to map similar context toguether to the same dimensions.</p>
<p>If in a traditional distribution model you would have distints concepts for car and automobile, there is no way for the model to know that they provide the same information, whereas in a dense vector we can agregate over similar context, you can map them to the same dimension and you can reduce the redundancy in the data but also end up with a model that is more generalizable</p>
</section>
<section id="prediction-based-distributional-models" class="level2" data-number="46">
<h2 data-number="46" class="anchored" data-anchor-id="prediction-based-distributional-models"><span class="header-section-number">46</span> Prediction-based distributional models</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_47.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 47</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>The most popular model of word embedding of prediction base is the Skip-gram model</p>
<p>Probabilistic language models, such as n-gram models where our goal is given a sequence of words we want to predict the next word that comes next</p>
<p>Here, the task is the same exceot that we use a NN to perform this prediction.</p>
<p>The idea is that we can learn word representations in the process</p>
</section>
<section id="skip-gram" class="level2" data-number="47">
<h2 data-number="47" class="anchored" data-anchor-id="skip-gram"><span class="header-section-number">47</span> Skip-gram</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_48.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 48</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>in Skip-gram we do not care about the sequence, but rather we want to take individual words as input, and we want to output the words that it can occur in the data i.e.&nbsp;if we take a 5-word window, basically we want to train the model to predict the valid context for thee word and then we lear the world representation in the process (in the projection layer)</p>
</section>
<section id="skip-gram-1" class="level2" data-number="48">
<h2 data-number="48" class="anchored" data-anchor-id="skip-gram-1"><span class="header-section-number">48</span> Skip-gram</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_49.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 49</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Words that occur toguether in the data should have some similarity in meaning. This is different from i.e we compare context towards the current and the relation in their similar meaning but rather a word should be similar in meaning to its neighbors.</p>
<p>Essentially we want to compare the vectors of the word and their neighbors</p>
<p>Given word at time t</p>
<p>Goal: predict all its neighboring words within a window. For instance we use a 5-word windows then these are the words to predict</p>
</section>
<section id="skip-gram-parameter-matrices" class="level2" data-number="49">
<h2 data-number="49" class="anchored" data-anchor-id="skip-gram-parameter-matrices"><span class="header-section-number">49</span> Skip-gram: Parameter matrices</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_50.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 50</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>For each word skip gram learns 2 parameter vectors:</p>
<p>For each word it learns two vectors:</p>
<ol type="1">
<li><p>The word vector, that is the <strong>word embedding</strong> v, in word matrix W<br>
This is the vector that represents the meaning of that word</p></li>
<li><p>A <strong>context vector</strong> that is the vector that represents its behavior as context for other words</p></li>
</ol>
<p>In a sense each word can have two rows: it can act as a word from which we are learning the word meaning AND it can also act as context for other words</p>
<p><strong>W:</strong> is the matrix of word embeddings</p>
<p><strong>C:</strong> the matrix of context embeddings</p>
<p>and so then we choose the dimensionality of our embeddings to have, for instance between 50 and 500 dimensions</p>
<p>Here for a whole Vocabulary we have a vector for every word, so the dimensionality here is the size of our vocabulary, so the columns are the word embeddings for all of our words</p>
<p>Again:</p>
<p><strong>W:</strong></p>
<p>So in the columns we have the vector oer word so we go from 1..Vw</p>
<p>The rows represent the dimensionality of the vector</p>
<p><strong>C:</strong></p>
<p>The columns are the dimensions</p>
<p>The rows we have the size of our vocabulary so we have a word, so the number of rows are the number of word in the vocabulary</p>
<p>In practice, these are the same, so we say we use individual words as context, so all words will learn embeddings, and each word can acts as a context. However there is no requirement to be the same, in fact the context vocabulary can be different and we can use any definition of context as we discuss in distributional models</p>
</section>
<section id="skip-gram-setup" class="level2" data-number="50">
<h2 data-number="50" class="anchored" data-anchor-id="skip-gram-setup"><span class="header-section-number">50</span> Skip-gram: Setup</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_51.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 51</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>we go word by word extracting its context.</p>
<p>This may look like Bigram prob but is not, and is not because position does not matter. So basically we consider each context in isolation like a set, so the context that the word might have and we operate over context pairs, the order does not matter in the sequence. So word and each context in isolation. And which context are possible we define based on the word window for any other criteria like we explain before like:</p>
<ul>
<li>Context window unfilter</li>
<li>Context window filtered</li>
<li>Context window lexeme filtered</li>
<li>Connected by a grammatical relation</li>
</ul>
<p>So the position of the context does not matter once we have extracted the context but of course it does matter in the process of extracting it, so it has to be whithin the word window</p>
<p><strong>Intuition</strong> of skip-gram: to compute that probability we need to compute the similarity between w_j and w_k</p>
</section>
<section id="skip-gram-computing-similarity" class="level2" data-number="51">
<h2 data-number="51" class="anchored" data-anchor-id="skip-gram-computing-similarity"><span class="header-section-number">51</span> Skip-gram: Computing similarity</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_52.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 52</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="skip-gram-similarity-as-dot-product" class="level2" data-number="52">
<h2 data-number="52" class="anchored" data-anchor-id="skip-gram-similarity-as-dot-product"><span class="header-section-number">52</span> Skip-gram: Similarity as dot product</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_53.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 53</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Why do we use dot product to compute the similarity. Again we use cosine, here we used it because it does not matter about the mangnitude but if they are pointing in the same direction then they are considered similar.</p>
<p>So vectors that are similar in this case w_j (current word) and w_k (word to predict) will be similar if they have a high dot product</p>
</section>
<section id="skip-gram-compute-probabilities" class="level2" data-number="53">
<h2 data-number="53" class="anchored" data-anchor-id="skip-gram-compute-probabilities"><span class="header-section-number">53</span> Skip-gram: Compute probabilities</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_54.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 54</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>case w_j (current word) and w_k (word to predict) v_j (current word) and c_k (word to predict)</p>
<p>So here P(w_k|w_j) we want to predict how likely is that this context is predicted.</p>
<p>We end up with having a vector of dot products, so we are comparing the word with all of the context vectors, that gives a vector of products over the whole vocabulary and then we normalize it using softmax</p>
<p>At the end we use softmax to make probabilities summ up to one</p>
</section>
<section id="skip-gram-learning" class="level2" data-number="54">
<h2 data-number="54" class="anchored" data-anchor-id="skip-gram-learning"><span class="header-section-number">54</span> Skip-gram: Learning</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_55.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 55</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>we iterative update the embeddings to make the embeddings of our words more similar to the real seen context words and less similar to the embeddings of everything else (other context words)</p>
</section>
<section id="skip-gram-objective" class="level2" data-number="55">
<h2 data-number="55" class="anchored" data-anchor-id="skip-gram-objective"><span class="header-section-number">55</span> Skip-gram: Objective</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_56.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 56</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>So we want to maximize the overall corpus probability, that is the probability of the real seen context.</p>
<p>Here we assume that the context is independent of each other, so the whole sequence does not matter. We assume that the probabilities are independent of each other and so basically the objective becomes to maximize the product of the probabilities of the real seen context pairs</p>
<p>Where:</p>
<ul>
<li>c_k is the vector representation of the context word w_k</li>
<li>v_j is the vector representation of the word w_j</li>
</ul>
</section>
<section id="visualising-skip-gram-as-a-network" class="level2" data-number="56">
<h2 data-number="56" class="anchored" data-anchor-id="visualising-skip-gram-as-a-network"><span class="header-section-number">56</span> Visualising skip-gram as a network</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_57.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 57</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>our input here is the vector representation of the word</p>
<p>The last layer tell us all the possible contexts.</p>
<p>So we are predicting a context word at a time. For ie. here w_t is a vector and we predict all the probabilities of context words</p>
</section>
<section id="one-hot-vectors" class="level2" data-number="57">
<h2 data-number="57" class="anchored" data-anchor-id="one-hot-vectors"><span class="header-section-number">57</span> One hot vectors</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_58.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 58</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="visualising-skip-gram-as-a-network-1" class="level2" data-number="58">
<h2 data-number="58" class="anchored" data-anchor-id="visualising-skip-gram-as-a-network-1"><span class="header-section-number">58</span> Visualising skip-gram as a network</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_59.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 59</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>The problem arises at computing softmax. If our corpus is large then the denominator will go over this large text thus being computationally expensive. So basically we have to iterate over all the vocabulary to perform the update</p>
</section>
<section id="skip-gram-with-negative-sampling" class="level2" data-number="59">
<h2 data-number="59" class="anchored" data-anchor-id="skip-gram-with-negative-sampling"><span class="header-section-number">59</span> Skip-gram with negative sampling</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_60.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 60</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>Instead of iterating over the whole vocabulary, for each word and positive context pair we will now sum over noise or negative samples i.e words that are not context to that word. In the above formula this translates in suming ‘i’ number of negative or noisy samples in the denominator therefore reducing the amount of computations.</p>
</section>
<section id="skip-gram-with-negative-sampling-1" class="level2" data-number="60">
<h2 data-number="60" class="anchored" data-anchor-id="skip-gram-with-negative-sampling-1"><span class="header-section-number">60</span> Skip-gram with negative sampling</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_61.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 61</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>For each word of the window: so for word pair (‘tablespppon’, ‘apricot’), we are gonna randomly sample some negative examples, so sampling other possible contexts. You can decide how many you want to have per possitve context i.e 2 or 10. Say we are going to choose randomly two noise examples i.e ‘cement’ and ‘iddle’, those are words that have nothing to do with ‘apricot’ so those are the negative examples.</p>
<p>How to choose negative examples? it is just random and it is done over the whole vocabulary but you could be more especific and i.e pick from their unigram probability with more frequent words</p>
<p>So here if we take 2 negative examples per positive we will have 8 different pairs because our windows is 4</p>
</section>
<section id="skip-gram-with-negative-sampling-training-examples" class="level2" data-number="61">
<h2 data-number="61" class="anchored" data-anchor-id="skip-gram-with-negative-sampling-training-examples"><span class="header-section-number">61</span> Skip-gram with negative sampling: Training examples</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_62.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 62</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>So basically we will convert our dataset into word pairs</p>
</section>
<section id="skip-gram-with-negative-sampling-2" class="level2" data-number="62">
<h2 data-number="62" class="anchored" data-anchor-id="skip-gram-with-negative-sampling-2"><span class="header-section-number">62</span> Skip-gram with negative sampling</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_63.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 63</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>So now for a given pair we are going to predict if it is a negative or positive example, basically we converted into a binary clarification problem</p>
<p>So basically we will have a probability that a pair (w_j: context, w_k: example) is a positive example and then the probability that is a negative example.</p>
<!-- ## Skip-gram with negative sampling
<center>![Slide 64](imgs/page_64.png){.w575}</center><pre></pre> -->
</section>
<section id="skip-gram-with-negative-sampling-3" class="level2" data-number="63">
<h2 data-number="63" class="anchored" data-anchor-id="skip-gram-with-negative-sampling-3"><span class="header-section-number">63</span> Skip-gram with negative sampling</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_65.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 65</figcaption>
</figure>
</div>
</center>
<pre></pre>
<!-- 
## Skip-gram with negative sampling: Objective
<center>![Slide 66](imgs/page_66.png){.w575}</center><pre></pre>



## Skip-gram with negative sampling: Objective
<center>![Slide 67](imgs/page_67.png){.w575}</center><pre></pre> -->
</section>
<section id="skip-gram-with-negative-sampling-objective" class="level2" data-number="64">
<h2 data-number="64" class="anchored" data-anchor-id="skip-gram-with-negative-sampling-objective"><span class="header-section-number">64</span> Skip-gram with negative sampling: Objective</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_68.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 68</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>So now the intuition is that we want to make the word vector like the context vector and unlike the context vector of the negative examples.</p>
<p>So here we want to maximize the probability of positive examples being positive and maximize the probability of negative examples being negative</p>
<section id="savings-from-negative-skip-gram.-softmax-sigmoid" class="level3" data-number="64.1">
<h3 data-number="64.1" class="anchored" data-anchor-id="savings-from-negative-skip-gram.-softmax-sigmoid"><span class="header-section-number">64.1</span> Savings from negative Skip-gram. Softmax –&gt; Sigmoid</h3>
<center>
<img src="imgs/2023-11-23-12-57-34.png" class="w550 img-fluid">
</center>
<pre></pre>
<p>Edit:</p>
<p>To sum up we see from the last equation that instead of iterating over the whole vocabulary, now we will maximize over the positive and negative sets which their size is a design choice that as explained during the lectures is more computational efficient (less dot products to compute) as iterating over the whole vocabulary as it was the case with Softamx.</p>
</section>
</section>
<section id="properties-of-embeddings" class="level2" data-number="65">
<h2 data-number="65" class="anchored" data-anchor-id="properties-of-embeddings"><span class="header-section-number">65</span> Properties of embeddings</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_69.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 69</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>The number below France is the ranking of most similar words. The interesting thing is that if you do not use lexematitation, it also captures more find grained aspects of meaning. For instance in ‘Reddish’ we do not get other colors but we also get a red-like similar words is not about ish words because we also get silvery. This show us that the model cna capture fine grained aspects, which is what we want.</p>
<!-- ## Properties of embeddings
<center>![Slide 70](imgs/page_70.png){.w575}</center><pre></pre> -->
</section>
<section id="properties-of-embeddings-1" class="level2" data-number="66">
<h2 data-number="66" class="anchored" data-anchor-id="properties-of-embeddings-1"><span class="header-section-number">66</span> Properties of embeddings</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_71.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 71</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>We compare two pairs of words in terms of their relation</p>
<ol type="1">
<li>here in apples in the plural relation</li>
<li>here in man and woman there is a gender relation</li>
</ol>
<p>So the model needs to complete the analogy given a is b and then given c is to what?</p>
</section>
<section id="properties-of-embeddings-2" class="level2" data-number="67">
<h2 data-number="67" class="anchored" data-anchor-id="properties-of-embeddings-2"><span class="header-section-number">67</span> Properties of embeddings</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_72.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 72</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="properties-of-embeddings-3" class="level2" data-number="68">
<h2 data-number="68" class="anchored" data-anchor-id="properties-of-embeddings-3"><span class="header-section-number">68</span> Properties of embeddings</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_73.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 73</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="word-embeddings-in-practice" class="level2" data-number="69">
<h2 data-number="69" class="anchored" data-anchor-id="word-embeddings-in-practice"><span class="header-section-number">69</span> Word embeddings in practice</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_74.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 74</figcaption>
</figure>
</div>
</center>
<pre></pre>
<p>In your NN the first layer are going to be the word embeddings which are some representations of the word in a sequence</p>
</section>
<section id="count-based-models-vs.-skip-gram-word-embeddings" class="level2" data-number="70">
<h2 data-number="70" class="anchored" data-anchor-id="count-based-models-vs.-skip-gram-word-embeddings"><span class="header-section-number">70</span> Count-based models vs.&nbsp;skip-gram word embeddings</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_75.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 75</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="count-based-models-vs.-skip-gram-word-embeddings-1" class="level2" data-number="71">
<h2 data-number="71" class="anchored" data-anchor-id="count-based-models-vs.-skip-gram-word-embeddings-1"><span class="header-section-number">71</span> Count-based models vs.&nbsp;skip-gram word embeddings</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_76.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 76</figcaption>
</figure>
</div>
</center>
<pre></pre>
</section>
<section id="acknowledgement" class="level2" data-number="72">
<h2 data-number="72" class="anchored" data-anchor-id="acknowledgement"><span class="header-section-number">72</span> Acknowledgement</h2>
<center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/page_77.png" class="w575 img-fluid figure-img"></p>
<figcaption>Slide 77</figcaption>
</figure>
</div>
</center>
<pre></pre>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/www\.danilotpnta\.com");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../about/index.html">
<p><span class="footerDaniloToapanta">© 2024 Danilo Toapanta</span></p>
</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../privacy/index.html">
<p>Privacy</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../contact/index.html">
<p>Contact</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../license/index.html">
<p>License</p>
</a>
  </li>  
</ul>
    <div class="toc-actions"><ul><li><a href="https://github.com/danilotpnta/danilotpnta.github.io/blob/main/blog/2023-11-22_lexical-semantics-and-word-embeddings/index.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/danilotpnta/danilotpnta.github.io/edit/main/blog/2023-11-22_lexical-semantics-and-word-embeddings/index.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/danilotpnta/danilotpnta.github.io/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="../../docs/sitemap.xml">
      <i class="bi bi-rss-fill" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>
<script>

    let navbar = document.getElementsByClassName("navbar-nav")[0]    

    let li2 = document.createElement("li");
    li2.className = "nav-item compact";

    let a2 = document.createElement("a");
    a2.className = "nav-link quarto-color-scheme-toggle";
    a2.style.cursor = "pointer"
    li2.appendChild(a2)

    let i2 = document.createElement("i");
    i2.className = "bi bi-moon"
    a2.append(i2)

    navbar.appendChild(li2);

    i2.onclick = function() {
        window.quartoToggleColorScheme(); return false;
    }
    // <a href="http://localhost:4200/about/" class="quarto-color-scheme-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>

    let li = document.createElement("li");
    li.className = "nav-item compact";

    let a = document.createElement("a");
    a.className = "nav-link";
    a.style.cursor = "pointer"
    li.appendChild(a)

    let i = document.createElement("i");
    i.className = "bi bi-search"
    a.append(i)

    // let span = document.createElement("span");
    // span.className = "menu-text"
    // a.append(span)

    navbar.appendChild(li);

    a.onclick = function() {
        window.quartoOpenSearch()
    }


</script>






</body></html>