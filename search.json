[
  {
    "objectID": "dev/index.html",
    "href": "dev/index.html",
    "title": "Danilo Toapanta",
    "section": "",
    "text": "In this section I have recompiled the sources, links and all the material that were more helpfull during the creation of this website."
  },
  {
    "objectID": "notes/2023-09-03_commands-terminal/index.html",
    "href": "notes/2023-09-03_commands-terminal/index.html",
    "title": "Commands Terminal",
    "section": "",
    "text": "Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 3, 2023"
  },
  {
    "objectID": "notes/2023-09-03_commands-terminal/index.html#terminal",
    "href": "notes/2023-09-03_commands-terminal/index.html#terminal",
    "title": "Commands Terminal",
    "section": "1 Terminal",
    "text": "1 Terminal\ncd -    # one folder back\ncd ..   # one up\ncd ../  # two up\ncd      # home directory \ncd /    # root directory\npwd         # print working directory\nopen &lt;PATH&gt;\nopen .     # open current folder you're in\ntouch &lt;file.txt&gt; # to create a file"
  },
  {
    "objectID": "notes/2023-09-03_commands-terminal/index.html#git-hub",
    "href": "notes/2023-09-03_commands-terminal/index.html#git-hub",
    "title": "Commands Terminal",
    "section": "2 Git Hub",
    "text": "2 Git Hub\ngit clone &lt;HTTPS&gt;    # copy repo from the HTTPS of the GitHub repository \ngit status                      # to check whether the tree line has been updated\ngit add .                       # add all new folders and files to git repo\ngit add &lt;name&gt;       # add specific folder for the git repo\n                                         # this is only to tell git taht there has been changes, we still need to commit\ngit commit -m \"&lt;message&gt;\"   # this save the files to git repo\ngit commit -m \"&lt;message&gt;\" -m \"&lt;message for the description box&gt;\"   # this save the files to git repo\nSo the way it works\n\nYou change the code\nYou need to save to the git file –&gt; git add .\nYou need to commit –&gt; git commit - m “message”\nYou push it to the repo –&gt; git push main\n\n\n2.1 Working with branches\n\nhttps://youtu.be/QV0kVNvkMxc\n\n\n\n2.2 Key Generation\nssh-keygen -t rsa -b 4096 -C \"danilotpnta@gmail.com\"   # to generate a key SSH\nls | grep git-key   # to check the keys available\n                    # key.pub pub stands for public \ncat &lt;example_key.pub&gt;                     # to print the key\n\n\n2.3 Generating a new SSH key\nssh-keygen -t ed25519 -C \"danilotpnta@gmail.com\" \n\n\n2.4 Adding your SSH key to the ssh-agent\neval \"$(ssh-agent -s)\"\nopen ~/.ssh/config\nvim ~/.ssh/config\nssh-add ~/.ssh/id_ed25519   # to add the key with name \"id_ed25519\"\ncat ~/.ssh/id_ed25519.pub   # to print the key that we created"
  },
  {
    "objectID": "notes/2023-09-03_commands-terminal/index.html#vim",
    "href": "notes/2023-09-03_commands-terminal/index.html#vim",
    "title": "Commands Terminal",
    "section": "3 Vim",
    "text": "3 Vim\n:wq     # to write/save and quit\nESC     # to scape from __INSERT__\n\n3.1 Prompt Message\nhe Bash command prompt looks like this by default:\n[USERNAME]@[HOSTNAME]:[PATH][SYMBOL]\n\n[USERNAME] is the username of the currently operating user. normally this is your user, but when you run sudo su or similar commands, you get a “root shell”, that means the user is “root”.\n[HOSTNAME] is your hostname. It’s the name of your computer. You had to enter that during the system installation.\n[PATH] is your current working directory, the directory you’re currently operating on. When you open a new terminal, the default directory is your current user’s home directory. A synonym for /home/YOURUSERNAME is ~.\n[SYMBOL] is usually either $ if you’re operating as any normal user, or # if you’re operating as “root” user.\n\nSo your Bash prompt looks like this:\nganesh@ganesh:~$\nThat means you’re logged in as user ganesh on a computer called ganesh as well, currently operating in your own home directory (~). Of course you’re not “root”, therefore the $."
  },
  {
    "objectID": "notes/2023-09-11_how-to-create-conda-environment-using-yml-file/index.html",
    "href": "notes/2023-09-11_how-to-create-conda-environment-using-yml-file/index.html",
    "title": "How to create Conda environment using YML file?",
    "section": "",
    "text": "Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Environment\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Conda\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Environment\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Conda\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 11, 2023"
  },
  {
    "objectID": "notes/2023-09-11_how-to-create-conda-environment-using-yml-file/index.html#define-yml-requirements",
    "href": "notes/2023-09-11_how-to-create-conda-environment-using-yml-file/index.html#define-yml-requirements",
    "title": "How to create Conda environment using YML file?",
    "section": "1 Define YML requirements",
    "text": "1 Define YML requirements\nFor instance the following file: environment.yml\nname: cv1\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  - python=3.7\n  - pip=21.3.1\n  - pip:\n    - numpy==1.19.5\n    - opencv-contrib-python==3.4.2.17\n    - matplotlib==3.3.4\n    - jupyter==1.0.0\n    - scikit-learn==0.23.0\n    - scipy==1.5.4"
  },
  {
    "objectID": "notes/2023-09-11_how-to-create-conda-environment-using-yml-file/index.html#create-conda-env-from-terminal",
    "href": "notes/2023-09-11_how-to-create-conda-environment-using-yml-file/index.html#create-conda-env-from-terminal",
    "title": "How to create Conda environment using YML file?",
    "section": "2 Create Conda ENV from terminal",
    "text": "2 Create Conda ENV from terminal\nconda env create -f path/to/environment.yml"
  },
  {
    "objectID": "notes/2023-08-22_command_for_environments/index.html",
    "href": "notes/2023-08-22_command_for_environments/index.html",
    "title": "Command Environments",
    "section": "",
    "text": "A useful list of conda commands\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Environments\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Conda\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Environments\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Conda\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 22, 2023"
  },
  {
    "objectID": "notes/2023-08-22_command_for_environments/index.html#conda",
    "href": "notes/2023-08-22_command_for_environments/index.html#conda",
    "title": "Command Environments",
    "section": "Conda",
    "text": "Conda\n\nA conda environment is a directory that contains a specific collection of conda packages that you have installed. For example, you may have one environment with NumPy 1.7 and its dependencies, and another environment with NumPy 1.6 for legacy testing."
  },
  {
    "objectID": "notes/2023-08-22_command_for_environments/index.html#anaconda",
    "href": "notes/2023-08-22_command_for_environments/index.html#anaconda",
    "title": "Command Environments",
    "section": "Anaconda",
    "text": "Anaconda\n\nIt gives you all the standard packages used in scientific computing in a convenient package without having to worry about installing them all individually with their dependencies."
  },
  {
    "objectID": "notes/2023-08-22_command_for_environments/index.html#in-short-conda-anaconda",
    "href": "notes/2023-08-22_command_for_environments/index.html#in-short-conda-anaconda",
    "title": "Command Environments",
    "section": "In short Conda + Anaconda",
    "text": "In short Conda + Anaconda\nConda is a package manager. It helps you take care of your different packages by handling installing, updating and removing them. Anaconda contains all of the most common packages (tools) a data scientist needs and can be considered the hardware store of data science tools.\nconda install anaconda"
  },
  {
    "objectID": "notes/2023-08-22_command_for_environments/index.html#how-to-erase-an-environment",
    "href": "notes/2023-08-22_command_for_environments/index.html#how-to-erase-an-environment",
    "title": "Command Environments",
    "section": "How to erase an environment",
    "text": "How to erase an environment\nconda remove --name ml1labs --all"
  },
  {
    "objectID": "notes/2023-08-22_command_for_environments/index.html#echo-path",
    "href": "notes/2023-08-22_command_for_environments/index.html#echo-path",
    "title": "Command Environments",
    "section": "echo $PATH",
    "text": "echo $PATH\n\n$PATH (or the search path) is the list of directories that will be searched for anything that you type on the command line\nWe use sometimes ls or pwd or echo this is because there is a $PATH where this was. This list of pre-designated directories is stored in a special variable called “PATH”\nThis is a colon-delimited list of all the directories the command line looks in by default for programs on the particular computer.\nExample\n$ (progLab) datoapanta@Danilos-MacBook-Pro ~ % echo $PATH\n/Users/datoapanta/opt/anaconda3/envs/progLab/bin:/Users/datoapanta/opt/anaconda3/condabin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/usr/local/share/dotnet:~/.dotnet/tools:/Library/Frameworks/Mono.framework/Versions/Current/Commands:/Users/datoapanta/.local/bin:/Users/datoapanta/.local/bin\necho $PATH | tr \":\" \"\\n\"\n/Users/datoapanta/opt/anaconda3/envs/progLab/bin /Users/datoapanta/opt/anaconda3/condabin /usr/local/bin /usr/bin /bin /usr/sbin /sbin /Library/TeX/texbin /usr/local/share/dotnet ~/.dotnet/tools /Library/Frameworks/Mono.framework/Versions/Current/Commands /Users/datoapanta/.local/bin /Users/datoapanta/.local/bin\n\nWe can now more clearly see this is a list of directories. All of these places, stored in the variable called “PATH”, are searched whenever we are typing a command in the terminal window.\nIf the command we are trying to use is present in any of the directories listed in our PATH, we don’t need to point at its specific location in full (its path, lowercase) when we are trying to use it – which is of course nice for things we use often."
  },
  {
    "objectID": "notes/2023-09-04_how-to-create-a-jupyther-kernel/index.html",
    "href": "notes/2023-09-04_how-to-create-a-jupyther-kernel/index.html",
    "title": "How to Create a Jupyther Kernel",
    "section": "",
    "text": "How to Create a Jupyther Kernel\n        \n        \n                    \n                \n                    Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 4, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\npython3 -m pip install tensorflow\nconda install -c anaconda ipykernel\npython -m ipykernel install --user --name=firstEnv"
  },
  {
    "objectID": "notes/2023-08-22_commands-for-jupyter/index.html",
    "href": "notes/2023-08-22_commands-for-jupyter/index.html",
    "title": "Commands Jupyter",
    "section": "",
    "text": "Commands Jupyter\n        \n        \n                    \n                \n                    Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 22, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\njupyter kernelspec list              \npython -m ipykernel install --user --name=git-pages"
  },
  {
    "objectID": "notes/2023-08-22_commands-for-github/index.html",
    "href": "notes/2023-08-22_commands-for-github/index.html",
    "title": "Commands GitHub",
    "section": "",
    "text": "Commands GitHub\n        \n        \n                    \n                \n                    A useful list of Github commands\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                GitHub\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                GitHub\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 22, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\n\nGithub\ngh repo create\ngit add . && git commit - 'update'\ngit push origin master \n\nmkdir repo-name\ncd repo-name\ntouch file.js\ngit init\ngit add . && git commit -m 'update'\ngh repo create &gt; existing\n\ngit push origin master\n\ngit pull origin master\n\n# To remove files from terminal\ngit rm -r fil\n\n# To change of branch\n\n\ngh\ngh repo delete name-repo\ngh repo create\ngh browse         # Open the repo in a browser Tab\n\n# To update changes to the website\ncd danilotpnta.github.io/\ngit checkout main   # Make sure you are in main branch \nquarto publish gh-pages"
  },
  {
    "objectID": "notes/index.html",
    "href": "notes/index.html",
    "title": "\nPython\n",
    "section": "",
    "text": "Showing All Notes\n\n \n\nShow All Notes \n\n\n\n\n\n\n\nBlog\n\n\n\n\n\n\n\n\n\n #   published: \n\n\nPython\n\n\n\n\n\n\n\n\n\n     \n    \n        \n        \n        \n            \n        \n        \n        \n            \n        \n        \n        \n            \n        \n        \n            \n            1\n        \n            \n                \n                1\n        \n        \n        \n            \n        \n        \n        \n            \n        \n        \n        \n            \n        \n        \n        \n            \n        \n        \n        \n            \n        \n        \n        \n            \n        \n        \n            \n            2\n            \n            3\n        \n            \n                \n                2\n                \n                3\n        \n        \n            \n            4\n        \n            \n        \n        \n        \n            \n                \n                4\n        \n        \n            \n            5\n        \n            \n                \n                5\n        \n        \n            \n            6\n        \n            \n\nNotes\n    \n    \n                    \n                            \n                                \n                                    Oct 11\n                                \n                                \n                                \n                            \n                            \n                                \n                                \n                                    \n                                            Basic Terminal Commands in Windows NEW\n                                    \n                                \n                                \n                            \n                            \n                                \n                                \n                                \n                                        \n                                        \n                                                \n                                                    All\n                                                \n                                                                            \n                                \n                            \n                            \n                                \n                                \n                                \n                                \n                                    Oct 11\n                            \n                    \n                    \n                            \n                                \n                                    Oct 09\n                                \n                                \n                                \n                            \n                            \n                                \n                                \n                                    \n                                            Numpy Arrays\n                                    \n                                \n                                \n                            \n                            \n                                \n                                \n                                \n                                        \n                                        \n                                                \n                                                    All\n                                                \n                                                                            \n                                \n                            \n                            \n                                \n                                \n                                \n                                \n                                    Oct 09\n                            \n                    \n                    \n                            \n                                \n                                    Oct 06\n                                \n                                \n                                \n                            \n                            \n                                \n                                \n                                    \n                                            How to embed ML application?\n                                    \n                                \n                                \n                            \n                            \n                                \n                                \n                                \n                                        \n                                        \n                                                \n                                                    All\n                                                \n                                                                            \n                                \n                            \n                            \n                                \n                                \n                                \n                                \n                                    Oct 06\n                            \n                    \n                    \n                            \n                                \n                                    Sep 11\n                                \n                                \n                                \n                            \n                            \n                                \n                                \n                                    \n                                            How to create Conda environment using YML file?\n                                    \n                                \n                                \n                            \n                            \n                                \n                                \n                                \n                                        \n                                        \n                                                \n                                                    All\n                                                \n                                                                            \n                                \n                            \n                            \n                                \n                                \n                                \n                                \n                                    Sep 11\n                            \n                    \n                    \n                            \n                                \n                                    Sep 04\n                                \n                                \n                                \n                            \n                            \n                                \n                                \n                                    \n                                            How to Create a Jupyther Kernel\n                                    \n                                \n                                \n                            \n                            \n                                \n                                \n                                \n                                        \n                                        \n                                                \n                                                    All\n                                                \n                                                                            \n                                \n                            \n                            \n                                \n                                \n                                \n                                \n                                    Sep 04\n                            \n                    \n                    \n                            \n                                \n                                    Sep 03\n                                \n                                \n                                \n                            \n                            \n                                \n                                \n                                    \n                                            Create Website using Local\n                                    \n                                \n                                \n                            \n                            \n                                \n                                \n                                \n                                        \n                                        \n                                                \n                                                    All\n                                                \n                                                                            \n                                \n                            \n                            \n                                \n                                \n                                \n                                \n                                    Sep 03\n                            \n                    \n                    \n                            \n                                \n                                    Sep 03\n                                \n                                \n                                \n                            \n                            \n                                \n                                \n                                    \n                                            Commands Terminal\n                                    \n                                \n                                \n                            \n                            \n                                \n                                \n                                \n                                        \n                                        \n                                                \n                                                    All\n                                                \n                                                                            \n                                \n                            \n                            \n                                \n                                \n                                \n                                \n                                    Sep 03\n                            \n                    \n                    \n                            \n                                \n                                    Aug 27\n                                \n                                \n                                \n                            \n                            \n                                \n                                \n                                    \n                                            Changes to Vanilla Quarto\n                                    \n                                \n                                \n                            \n                            \n                                \n                                \n                                \n                                        \n                                        \n                                                \n                                                    All\n                                                \n                                                                            \n                                \n                            \n                            \n                                \n                                \n                                \n                                \n                                    Aug 27\n                            \n                    \n                    \n                            \n                                \n                                    Aug 27\n                                \n                                \n                                \n                            \n                            \n                                \n                                \n                                    \n                                            Features, tools & improvements website\n                                    \n                                \n                                \n                            \n                            \n                                \n                                \n                                \n                                        \n                                        \n                                                \n                                                    All\n                                                \n                                                                            \n                                \n                            \n                            \n                                \n                                \n                                \n                                \n                                    Aug 27\n                            \n                    \n                    \n                            \n                                \n                                    Aug 26\n                                \n                                \n                                \n                            \n                            \n                                \n                                \n                                    \n                                            How to highlight lines of code in Github\n                                    \n                                \n                                \n                            \n                            \n                                \n                                \n                                \n                                        \n                                        \n                                                \n                                                    All\n                                                \n                                                                            \n                                \n                            \n                            \n                                \n                                \n                                \n                                \n                                    Aug 26\n                            \n                    \n                    \n                            \n                                \n                                    Aug 22\n                                \n                                \n                                \n                            \n                            \n                                \n                                \n                                    \n                                            Commands Shells\n                                    \n                                \n                                \n                            \n                            \n                                \n                                \n                                \n                                        \n                                        \n                                                \n                                                    All\n                                                \n                                                                            \n                                \n                            \n                            \n                                \n                                \n                                \n                                \n                                    Aug 22\n                            \n                    \n                    \n                            \n                                \n                                    Aug 22\n                                \n                                \n                                \n                            \n                            \n                                \n                                \n                                    \n                                            Commands GitHub\n                                    \n                                \n                                \n                            \n                            \n                                \n                                \n                                \n                                        \n                                        \n                                                \n                                                    All\n                                                \n                                                                            \n                                \n                            \n                            \n                                \n                                \n                                \n                                \n                                    Aug 22\n                            \n                    \n                    \n                            \n                                \n                                    Aug 22\n                                \n                                \n                                \n                            \n                            \n                                \n                                \n                                    \n                                            Commands Jupyter\n                                    \n                                \n                                \n                            \n                            \n                                \n                                \n                                \n                                        \n                                        \n                                                \n                                                    All\n                                                \n                                                                            \n                                \n                            \n                            \n                                \n                                \n                                \n                                \n                                    Aug 22\n                            \n                    \n                    \n                            \n                                \n                                    Aug 22\n                                \n                                \n                                \n                            \n                            \n                                \n                                \n                                    \n                                            Command Environments\n                                    \n                                \n                                \n                            \n                            \n                                \n                                \n                                \n                                        \n                                        \n                                                \n                                                    All\n                                                \n                                                                            \n                                \n                            \n                            \n                                \n                                \n                                \n                                \n                                    Aug 22\n                            \n                    \n                    \n                            \n                                \n                                    Aug 22\n                                \n                                \n                                \n                            \n                            \n                                \n                                \n                                    \n                                            Commands Quarto\n                                    \n                                \n                                \n                            \n                            \n                                \n                                \n                                \n                                        \n                                        \n                                                \n                                                    All\n                                                \n                                                                            \n                                \n                            \n                            \n                                \n                                \n                                \n                                \n                                    Aug 22\n                            \n                    \n    \n\n\n         \n            Environment\n        \n         \n            Shells\n        \n         \n            Scripting\n        \n         \n            GitHub\n        \n         \n            Environments\n        \n         \n            Quarto\n        \n         \n            Conda\n        \n         \n            Bash\n        \n         \n            Zsh\n        \n         \n            Python\n        \n         \n            Conda\n        \n         \n            Notes-table\n        \n\n\nNo matching items\n\n\n\n\n\n  \n  \n    \n    CATEGORIES\n      \n    \n      \n  \n  \n  \n    \n      TAGS"
  },
  {
    "objectID": "notes/2023-08-22_commands-for-shells/index.html",
    "href": "notes/2023-08-22_commands-for-shells/index.html",
    "title": "Commands Shells",
    "section": "",
    "text": "Commands Shells\n        \n        \n                    \n                \n                    A useful list of Shell commands\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Shells\n                            \n                        \n                                            \n                            \n                                Scripting\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Bash\n                            \n                        \n                                            \n                            \n                                Zsh\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Shells\n                            \n                        \n                                            \n                            \n                               \n                                Scripting\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Bash\n                            \n                        \n                                            \n                            \n                               \n                                Zsh\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 22, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\n\nBash\n# Creates an alias function that can be called from terminal\nfunction(){\n    \n    # $1 first argument passed from terminal\n    FOLDER=$(python create_dir.py $1 $2) \n\n    # To print a variable\n    echo $FOLDER\n\n    # Use var inside another var uses ${}\n    BACKUPDIR=$(ls -td ${FOLDER}/*/ | head -1)\n\n}\n\n\nZsh\n\n# Eliminate the last line of history\ncd\ncode .zsh_history\nreload_shell\n\n# Makes reload the page\nreload_shell(){\n  cd \n  source .zshrc   \n}\n\n# Folder for plugin's\nopen ~/.oh-my-zsh/plugins\n\n# Show all including empty files\nls -a            \n\n\nSyntax\n# Valid naming\n_ALI\nTOKEN_A\n\n# Invalid naming\n2_VAR\n-VARIABLE\nVAR1-VAR2"
  },
  {
    "objectID": "notes/2023-10-11_basic-terminal-commands-in-windows/index.html",
    "href": "notes/2023-10-11_basic-terminal-commands-in-windows/index.html",
    "title": "Basic Terminal Commands in Windows",
    "section": "",
    "text": "Basic Terminal Commands in Windows\n        \n        \n                    \n                \n                    Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          October 11, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\n# Windows                   # MacOS\ndir                         # ls \necho.&gt; environment.yml      # touch\nstart .                     # open .\nnotepad environment.yml     # open env w/ app"
  },
  {
    "objectID": "notes/2023-08-26_how-to-highlight-lines-of-code-in-github/index.html",
    "href": "notes/2023-08-26_how-to-highlight-lines-of-code-in-github/index.html",
    "title": "How to highlight lines of code in Github",
    "section": "",
    "text": "How to highlight lines of code in Github\n        \n        \n                    \n                \n                    Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 26, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\nYou use at the end of an html:\n#L5-L6\n\n[Demo](https://github.com/danilotpnta/hammerspoon-config/blob/master/init.lua#L5-L6)\nDemo"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html",
    "title": "Deep Feedforward Networks",
    "section": "",
    "text": "Notes for course DL1 at University of Amsterdam 3 Nov 2023\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Deep Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Deep Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          November 5, 2023"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#from-linear-functions-to-nonlinear-from-shallow-to-deep",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#from-linear-functions-to-nonlinear-from-shallow-to-deep",
    "title": "Deep Feedforward Networks",
    "section": "1 From linear functions to nonlinear = from shallow to deep",
    "text": "1 From linear functions to nonlinear = from shallow to deep\n\n\n\n\nHere to apply first a Relu and the output of that another Relu: \\(\\sigma(B\\sigma(A\\textbf{x}))\\)"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#deep-feedforward-networks",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#deep-feedforward-networks",
    "title": "Deep Feedforward Networks",
    "section": "2 Deep feedforward networks",
    "text": "2 Deep feedforward networks\n\n\n\n\nMLP is just a combination of multiple linear perceptrons, in each layer there would be parameters ie \\(A\\) is \\(\\theta_1\\), \\(B\\) is \\(\\theta_2\\)"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#neural-networks-in-blocks",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#neural-networks-in-blocks",
    "title": "Deep Feedforward Networks",
    "section": "3 Neural networks in blocks",
    "text": "3 Neural networks in blocks"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#non-linear-feature-learning-perspective",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#non-linear-feature-learning-perspective",
    "title": "Deep Feedforward Networks",
    "section": "4 Non-linear feature learning perspective",
    "text": "4 Non-linear feature learning perspective\n\n\n\n\nHere we are saying that at the end we have just have a linear function \\(C\\) “the linear model” ie.\n\\[\nC(\\sigma(B\\sigma(A\\textbf{x})))\n\\]\nto a transformed input \\(\\varphi(x\\textbf{x})\\) = \\(\\sigma(B\\sigma(A\\textbf{x}))\\)"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#how-to-get-w-gradiend-based-learning",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#how-to-get-w-gradiend-based-learning",
    "title": "Deep Feedforward Networks",
    "section": "5 How to get w? gradiend-based learning",
    "text": "5 How to get w? gradiend-based learning\n\nDue to nonlinearity our loss function would be nonconvex\nWe use then SGD\nNo guarantee of convergence, and sensitive to initialization of the parameters"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#cost-function",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#cost-function",
    "title": "Deep Feedforward Networks",
    "section": "6 Cost Function",
    "text": "6 Cost Function\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere saturated means that the function becomes very flat so then the gradient of this is very minimal so then we cannot compute optimize because all the derivatives would look like very similar"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#activation-functions",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#activation-functions",
    "title": "Deep Feedforward Networks",
    "section": "7 Activation Functions",
    "text": "7 Activation Functions\n\n\n\n\n\nDefined how the weighted sum of the input is transformed into an output from a node or nodes in a layer of the network.\nIf output range limited, then called a “squashing function.”\nThe choice of activation function has a large impact on the capability and performance of the neural network.\nDifferent activation functions may be combined, but rare\nAll hidden layers typically use the same activation function\nNeed to be differentiable at most points"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#linear-units-fully-connected-layer",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#linear-units-fully-connected-layer",
    "title": "Deep Feedforward Networks",
    "section": "8 Linear Units/ “Fully connected layer”",
    "text": "8 Linear Units/ “Fully connected layer”"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#advantages-of-relu",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#advantages-of-relu",
    "title": "Deep Feedforward Networks",
    "section": "9 Advantages of ReLU",
    "text": "9 Advantages of ReLU\n\n\n\nReLu is better for propagation because if i.e take a sin as activation function when we derive close to zero the gradient would be very small, we keep doing this over multiple layers and essentially multiplying small times smalls at the end the result would be close to \\(0\\)."
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#disadvantages-of-relu",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#disadvantages-of-relu",
    "title": "Deep Feedforward Networks",
    "section": "10 Disadvantages of ReLU",
    "text": "10 Disadvantages of ReLU"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#leaky-relu",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#leaky-relu",
    "title": "Deep Feedforward Networks",
    "section": "11 Leaky ReLU",
    "text": "11 Leaky ReLU"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#exponential-linear-unit-elu",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#exponential-linear-unit-elu",
    "title": "Deep Feedforward Networks",
    "section": "12 Exponential Linear Unit (ELU)",
    "text": "12 Exponential Linear Unit (ELU)\n\n\n\nUsed in Language models like BERT"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#gaussian-error-linear-unit",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#gaussian-error-linear-unit",
    "title": "Deep Feedforward Networks",
    "section": "13 Gaussian Error Linear Unit",
    "text": "13 Gaussian Error Linear Unit\n\n\n\n\nWe are not bounded by the computation power but by memory to be loaded in the computation units of the GPUs on Snellius"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#sigmoid-and-tanh",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#sigmoid-and-tanh",
    "title": "Deep Feedforward Networks",
    "section": "14 Sigmoid and Tanh",
    "text": "14 Sigmoid and Tanh"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#softmax",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#softmax",
    "title": "Deep Feedforward Networks",
    "section": "15 Softmax",
    "text": "15 Softmax\n\n\n\n\nIt outputs a probability distribution because it depends on the denominator which means all the variables would be taken into account. For instance this can be the last activation function to output probabilities of predicting a cat, a dog, a bird and so on.\nIf we now introduce a term \\(\\tau\\) in Softmax (by dividing the \\(e^{\\frac{x_i}{\\tau}}\\) in the numerator and denominator) then we have the following:\n\n\n\n\n\n\nSoftamx and \\(\\tau\\)\n\n\n\nIf τ is introduced, it can be used to control the temperature or the “sharpness” of the softmax distribution.\nWhen τ is set to a value greater than 1, it has the effect of “softening” the probabilities, making the distribution more uniform. In other words, it makes the probability of all categories more similar to each other. This can be useful in scenarios where you want to explore a wider range of possibilities or reduce the impact of extreme values in the input vector.\nConversely, when τ is set to a value less than 1, it has the effect of “sharpening” the probabilities, making the distribution more peaky, and emphasizing the largest values in the input vector. This can be useful when you want to make more distinct predictions and reduce uncertainty."
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#how-to-choose-and-activation-function",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#how-to-choose-and-activation-function",
    "title": "Deep Feedforward Networks",
    "section": "16 How to Choose and Activation Function",
    "text": "16 How to Choose and Activation Function\n\n\n\nHere inference is testing or predicting\n\n16.1 Difference between Multiclass classification vs Multilabel calssification\n\nMulticlass Classification:\n\nIn multiclass classification, the task is to assign an input data point to one and only one class or category from a set of multiple mutually exclusive classes.\nEach data point belongs to exactly one class, and the goal is to determine which class that data point most likely belongs to.\nExamples of multiclass classification problems:\n\nHandwritten digit recognition: Given an image of a handwritten digit (0-9), determine which digit it represents.\nSpecies classification: Given a photo of an animal, classify it into one of several species (e.g., dog, cat, bird, etc.).\n\n\nExample: Suppose you have a multiclass classification problem where you want to classify fruits into three categories: apples, oranges, and bananas. If you input an image of an apple, the model should predict that it belongs to the “apples” class.\nMultilabel Classification:\n\nIn multilabel classification, each data point can be associated with one or more classes or labels. It’s not limited to assigning a single class per data point.\nThis is used when a data point can have multiple attributes or characteristics simultaneously, and you want to predict all relevant labels.\nExamples of multilabel classification problems:\n\nDocument categorization: Tagging a document with multiple topics or subjects that are present in it.\nImage tagging: Assigning tags to an image to describe its content, where an image may contain multiple objects or scenes.\n\n\nExample: Consider an image tagging problem. You have an image containing a beach scene with a dog and a sunset. In a multilabel classification scenario, the model might predict the following labels: “beach,” “dog,” and “sunset,” because all three labels are relevant to the image.\n\n\n\n\n\n\n\nHow to use Softmax in a Multiclass Classification problem?\n\n\n\n\n\nIn a multiclass classification problem, the softmax function is commonly used to convert the raw output scores of a model into a probability distribution over multiple classes. This probability distribution allows you to determine the likelihood of each class for a given input data point. Here’s how you use the softmax function in a multiclass classification problem:\n\nModel Output:\n\nAfter training your multiclass classification model, you will typically have a final layer in your neural network or a scoring function that produces raw scores (logits) for each class. These scores are not yet probabilities but represent the model’s confidence in each class.\nLet’s say you have N classes, and the model’s output for a particular input is a vector of raw scores \\(z\\) with N elements, one for each class.\n\nApply Softmax Function:\n\nTo convert the raw scores into probabilities, apply the softmax function to the \\(z\\) vector. The softmax function transforms the scores into a probability distribution where the sum of the probabilities for all classes equals 1.\nThe softmax function for class \\(i\\) is given by: \\(\\text{softmax}(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^N e^{z_j}}\\)\nCalculate the softmax value for each class \\(i\\) in the \\(z\\) vector to obtain a probability distribution.\n\nPredict the Class:\n\nThe class with the highest probability in the softmax distribution is typically chosen as the predicted class for the input data point. In other words, the class with the highest \\(\\text{softmax}(z)_i\\) value is the model’s prediction for that input.\n\n\nHere’s a step-by-step example of using softmax for multiclass classification:\nSuppose you have a multiclass classification problem with three classes: “cat,” “dog,” and “bird.” After processing an input image, your model produces the following raw scores:\n\\(z = [2.1, 0.9, 1.5]\\)\n\nApply the softmax function:\n\nCalculate the softmax values for each class:\n\\(\\text{softmax}(z)_1 = \\frac{e^{2.1}}{e^{2.1} + e^{0.9} + e^{1.5}}\\)\n\\(\\text{softmax}(z)_2 = \\frac{e^{0.9}}{e^{2.1} + e^{0.9} + e^{1.5}}\\)\n\\(\\text{softmax}(z)_3 = \\frac{e^{1.5}}{e^{2.1} + e^{0.9} + e^{1.5}}\\)\n\nPredict the class:\n\nThe class with the highest softmax probability is the predicted class. In this case, if \\(\\text{softmax}(z)_1\\) is the highest probability, the model predicts “cat.”\n\n\nUsing the softmax function in multiclass classification allows you to obtain a probability distribution over classes and select the most likely class as the model’s prediction."
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#width-and-depth",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#width-and-depth",
    "title": "Deep Feedforward Networks",
    "section": "17 Width and Depth",
    "text": "17 Width and Depth\n\n\n\n\nIf we have a single big hidden layer (so a lot of parameters) can approximate any functions but in practice this infeasible.\n\nWidth is how many neurons in a single layer\nDepth is the number of layers\n\nThis also does not tell you how many hidden units you would need. The theorem just says to approx any function you need infinitely.\n\n\n\n\nHere we are saying that Deeper models reduce the loss functions (reduce the generalization error) because they generalize better meaning do not overfit. So do not need one single layer with a lot of neurons but instead multiple layers with fewer neurons.\n\n17.1 Convolution Neural Networks vsFully Connected Neural Networks\n\n\n\n\nConvolutional needs lees parameters as their inputs are not fully connected to every neuron see pic above\n\n\n\n\n\n3 Convolutional is worse than 11 Convolutional, because the latter is more deeper"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#neural-network-architectures-jungle",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#neural-network-architectures-jungle",
    "title": "Deep Feedforward Networks",
    "section": "18 Neural Network architectures (jungle)",
    "text": "18 Neural Network architectures (jungle)"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#computational-graph",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#computational-graph",
    "title": "Deep Feedforward Networks",
    "section": "19 Computational graph",
    "text": "19 Computational graph\n\n\n\n\n\n19.1 Example\n\n\n\n\nProblem with activation function ReLU"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#chain-rule-of-calculus",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#chain-rule-of-calculus",
    "title": "Deep Feedforward Networks",
    "section": "20 Chain Rule of Calculus",
    "text": "20 Chain Rule of Calculus"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#the-jacobian",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#the-jacobian",
    "title": "Deep Feedforward Networks",
    "section": "21 The Jacobian",
    "text": "21 The Jacobian\n\n\n\n\n\n\n\n\n\nThe Jacobian measures how a change in the input changes the output\nThe shape of the Jacobian is ouputs x inputs"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#computing-gradients-in-complex-functions-chain-rule",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#computing-gradients-in-complex-functions-chain-rule",
    "title": "Deep Feedforward Networks",
    "section": "22 Computing gradients in complex functions: Chain rule",
    "text": "22 Computing gradients in complex functions: Chain rule"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#chain-rule-and-tensors-intuitively",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#chain-rule-and-tensors-intuitively",
    "title": "Deep Feedforward Networks",
    "section": "23 Chain rule and tensors, intuitively",
    "text": "23 Chain rule and tensors, intuitively"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#example-1",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#example-1",
    "title": "Deep Feedforward Networks",
    "section": "24 Example",
    "text": "24 Example"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#backpropagation-chain-rule",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#backpropagation-chain-rule",
    "title": "Deep Feedforward Networks",
    "section": "25 Backpropagation Chain Rule",
    "text": "25 Backpropagation Chain Rule\n\n\n\n\n\n\n\n\n\n\n\n25.1 Backpropagation in summary\n\n\n\n\n\n\n\n\nNote: in the figure above, we know what is \\(h_0\\), \\(h_1\\), \\(h_2\\) and \\(L\\) because we have initialized our \\(w_1\\) and \\(w_2\\) and we also know how the sigmoid function works:\n\n\n\n\n\n\nThat means all these values are known so that when we calculate the derivatives below everything is know and then we can use SGD to update the weights\nThen the derivatives wrt. \\(w\\) are:\n\n\n\n\n\n\nThese last equations is what we need to do SGD\n\nBackprogation allows us to generally reduce the amount of space we need in order to compute all the gradients for all the layers, because storing the Jacobian takes a lot of space."
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#chain-rule-visualized",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#chain-rule-visualized",
    "title": "Deep Feedforward Networks",
    "section": "26 Chain rule visualized",
    "text": "26 Chain rule visualized\n\n\n\n\n\nBut now if the ouput is an scalar, we get in the ouput a vector:\n\n\n\n\n\n\nNow from the back to front you are only multiplying vector times matrices instead of large matrices with large matrices"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#but-we-still-need-the-jacobian",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#but-we-still-need-the-jacobian",
    "title": "Deep Feedforward Networks",
    "section": "27 But we still need the Jacobian",
    "text": "27 But we still need the Jacobian"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#computational-graphs-forward-graph",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#computational-graphs-forward-graph",
    "title": "Deep Feedforward Networks",
    "section": "28 Computational graphs: Forward graph",
    "text": "28 Computational graphs: Forward graph"
  },
  {
    "objectID": "blog/2023-11-05_deep-feedforward-networks/index.html#computational-graphs-forward-graph-1",
    "href": "blog/2023-11-05_deep-feedforward-networks/index.html#computational-graphs-forward-graph-1",
    "title": "Deep Feedforward Networks",
    "section": "29 Computational graphs: Forward graph",
    "text": "29 Computational graphs: Forward graph"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html",
    "title": "Deep Learning Optimizations I",
    "section": "",
    "text": "Description of this Post\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Deep Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Deep Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          November 8, 2023"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#optimizing-neural-networks",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#optimizing-neural-networks",
    "title": "Deep Learning Optimizations I",
    "section": "1 Optimizing neural networks",
    "text": "1 Optimizing neural networks\n\n\n\n\nSlide 2"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#lecture-overview",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#lecture-overview",
    "title": "Deep Learning Optimizations I",
    "section": "2 Lecture overview",
    "text": "2 Lecture overview\n\n\n\n\nSlide 3"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#optimization-us.-learning",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#optimization-us.-learning",
    "title": "Deep Learning Optimizations I",
    "section": "3 Optimization US. Learning",
    "text": "3 Optimization US. Learning\n\n\n\n\nSlide 4"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#risk-minimization",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#risk-minimization",
    "title": "Deep Learning Optimizations I",
    "section": "4 Risk minimization",
    "text": "4 Risk minimization\n\n\n\n\nSlide 5\n\n\n\n\nOmega is a regularization factor\nY_hat is the prediction, each module i.e h1 comes with a set of parameters\nThe expectation is taken over the true data distribution which is not available. Then how do we put this into practice ## Minimizing the empirical risk, –&gt; minimise “loss”\n\n\n\n\nSlide 6\n\n\n\n\n\nWe give up to find the real minimum of the data because we have not access to all the data in the world\nWe take a look at what we have: training data aka empirical data distribution.\n\nThe loss is for a single sample and the empirical risk is the loss over the whole data set. We are not optimizing the real risk but we are optimizing the empirical risk which is an estimate for the real risk. If you take that for a a sample, then a sample, or a batch, we call it loss.\nWe take an step in the direction of minimizing the loss that is in the negative gradient of the loss\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define a simple quadratic loss function\ndef loss_function(x):\n    return x**2\n\n# Define the derivative of the loss function (gradient)\ndef gradient(x):\n    return 2 * x\n\n# Generate x values\nx_values = np.linspace(-5, 5, 100)\n\n# Compute corresponding y values for the loss function\ny_values = loss_function(x_values)\n\nplt.figure(figsize=(4, 3))\n\n# Plot the loss function\nplt.plot(x_values, y_values, label='Loss Function')\n\n# Choose a point on the curve\nx_point = 3\ny_point = loss_function(x_point)\n\n# Plot the point on the curve\nplt.scatter(x_point, y_point, color='red', label='Current Point')\n\n# Compute the gradient at the chosen point\ngrad_at_point = gradient(x_point)\n\n# Plot the gradient vector as an arrow\narrow_start = (x_point, y_point)\narrow_end = (x_point - grad_at_point, y_point - grad_at_point**2)\nplt.arrow(*arrow_start, *(np.array(arrow_end) - np.array(arrow_start)),\n          color='green', width=0.1, head_width=0.5, head_length=0.5, length_includes_head=True, label='Gradient')\n\n# Add labels and legend\nplt.xlabel('Model Parameter')\nplt.ylabel('Loss')\nplt.title('Gradient Direction in Steepest Ascent')\nplt.grid(alpha=0.1)\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n\n\n\nIn the context of optimization and gradient descent:\n\nSteepest Ascent: The gradient of the loss function at a particular point indicates the direction in which the function increases the most rapidly. If you were to take a step in the direction of the gradient, you would be moving uphill along the loss function. This is why it’s often referred to as the direction of “steepest ascent” because the function value increases most quickly in that direction.\nSteepest Descent: Conversely, to minimize the loss function, we move in the opposite direction of the gradient. This is called the direction of “steepest descent” because it leads us downhill along the loss function, toward lower values.\n\n“Loss increases the fastest,” means that if you move in the direction of the gradient, you are moving in the direction where the loss function grows most rapidly, or where the function value increases the fastest so moving uphill. However, during optimization, we take steps in the opposite direction to decrease the loss and reach a minimum."
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#minimizing-the-empirical-risk-minimise-loss",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#minimizing-the-empirical-risk-minimise-loss",
    "title": "Deep Learning Optimizations I",
    "section": "5 Minimizing the empirical risk, –> minimise “loss”",
    "text": "5 Minimizing the empirical risk, –&gt; minimise “loss”\n\n\n\n\nSlide 6\n\n\n\n\n\nWe give up to find the real minimum of the data because we have not access to all the data in the world\nWe take a look at what we have: training data aka empirical data distribution.\n\nThe loss is for a single sample and the empirical risk is the loss over the whole data set. We are not optimizing the real risk but we are optimizing the empirical risk which is an estimate for the real risk. If you take that for a a sample, then a sample, or a batch, we call it loss.\nWe take an step in the direction of minimizing the loss that is in the negative gradient of the loss\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define a simple quadratic loss function\ndef loss_function(x):\n    return x**2\n\n# Define the derivative of the loss function (gradient)\ndef gradient(x):\n    return 2 * x\n\n# Generate x values\nx_values = np.linspace(-5, 5, 100)\n\n# Compute corresponding y values for the loss function\ny_values = loss_function(x_values)\n\nplt.figure(figsize=(4, 3))\n\n# Plot the loss function\nplt.plot(x_values, y_values, label='Loss Function')\n\n# Choose a point on the curve\nx_point = 3\ny_point = loss_function(x_point)\n\n# Plot the point on the curve\nplt.scatter(x_point, y_point, color='red', label='Current Point')\n\n# Compute the gradient at the chosen point\ngrad_at_point = gradient(x_point)\n\n# Plot the gradient vector as an arrow\narrow_start = (x_point, y_point)\narrow_end = (x_point - grad_at_point, y_point - grad_at_point**2)\nplt.arrow(*arrow_start, *(np.array(arrow_end) - np.array(arrow_start)),\n          color='green', width=0.1, head_width=0.5, head_length=0.5, length_includes_head=True, label='Gradient')\n\n# Add labels and legend\nplt.xlabel('Model Parameter')\nplt.ylabel('Loss')\nplt.title('Gradient Direction in Steepest Ascent')\nplt.grid(alpha=0.1)\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n\n\n\nIn the context of optimization and gradient descent:\n\nSteepest Ascent: The gradient of the loss function at a particular point indicates the direction in which the function increases the most rapidly. If you were to take a step in the direction of the gradient, you would be moving uphill along the loss function. This is why it’s often referred to as the direction of “steepest ascent” because the function value increases most quickly in that direction.\nSteepest Descent: Conversely, to minimize the loss function, we move in the opposite direction of the gradient. This is called the direction of “steepest descent” because it leads us downhill along the loss function, toward lower values.\n\n“Loss increases the fastest,” means that if you move in the direction of the gradient, you are moving in the direction where the loss function grows most rapidly, or where the function value increases the fastest so moving uphill. However, during optimization, we take steps in the opposite direction to decrease the loss and reach a minimum."
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#gradient-descent",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#gradient-descent",
    "title": "Deep Learning Optimizations I",
    "section": "5 Gradient descent",
    "text": "5 Gradient descent\n\n\n\n\nSlide 7\n\n\n\n\nSGD: for mini-batch, in textbooks they say is for only one sample, but in practice you do SGD in a mini-batch, here the samples you picked they are random thus stochastic gradient descent"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#batch-gradient-descent-for-neuralynets",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#batch-gradient-descent-for-neuralynets",
    "title": "Deep Learning Optimizations I",
    "section": "7 Batch gradient descent for neuralynets’",
    "text": "7 Batch gradient descent for neuralynets’\n\n\n\n\nSlide 8"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#httpslosslandscape.comexplorer",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#httpslosslandscape.comexplorer",
    "title": "Deep Learning Optimizations I",
    "section": "7 https://losslandscape.com/explorer",
    "text": "7 https://losslandscape.com/explorer\n\n\n\n\nSlide 9"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#gradient-descent-vs.-stochastic-gradient-descent",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#gradient-descent-vs.-stochastic-gradient-descent",
    "title": "Deep Learning Optimizations I",
    "section": "8 Gradient descent vs. Stochastic Gradient Descent",
    "text": "8 Gradient descent vs. Stochastic Gradient Descent\n\n\n\n\nSlide 10\n\n\n\n\nWhy dont we use the whole dataset to compute gradient descent?\nUsing the entire dataset to compute the gradient at each step of the optimization process can be computationally expensive, especially when dealing with large datasets. Also, in many cases, using the entire dataset in every iteration introduces redundancy because the information contained in the dataset might already be captured in the gradient computed from a smaller subset.\nFor NNs, using SGD are NOT guaranteed to find the global minimum"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#sgd-properties",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#sgd-properties",
    "title": "Deep Learning Optimizations I",
    "section": "9 SGD properties",
    "text": "9 SGD properties\n\n\n\n\nSlide 11\n\n\n\n\nSGD estimates the gradient. And if you do any estimation, you can calculate the estandard error, as the std deviation \\(\\sigma\\) divided by the sqrt of the batch size\nFor ie, if you want to get an estimate of the gradient which is twice as good we need 4 times more data"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#quiz",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#quiz",
    "title": "Deep Learning Optimizations I",
    "section": "10 Quiz",
    "text": "10 Quiz\n\n\n\n\nSlide 12\n\n\n\n\n\nThe fact that videos are correlated i.e in 30fps it does have any to do with the batch size, it actually require higuer batch size because you have a lot less happening so that means all of your data samples are highly correlated. If you data samples are highly correlated that means you are actually very bias i.e. if you are training with a sampled dataset from those biased data then your gradient would be much more worse than if you sample randomly from all classes\nThis is True, it depends on the GPU. For instance for videos, a single sample may contain 30 frames so that means for a batch size not the individual number of pixels but the number of datasamples, and if you datasample its two seconds long and each second contains 30frames so 30 images, then you are basically reducing the batch size by 60 already. Another thing that lead to be GPU not able to handled is because to process videos the architecture takes more to compute, so there is a lot more computation happening.\nVideo in DL are currently handled by using small resolution i.e 100x100. Images are usually 224x224 or if you do object detection then images can go up to 1000x1000 pixels. So that means videos are lower resolutions\n\nYou can compute the variance in terms of low level statistics, like RGB but that does not mean anything about the variance within the NN, and if you need to do a whole forward pass before doing a backward pass then it becomes slow."
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#sgd-properties-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#sgd-properties-1",
    "title": "Deep Learning Optimizations I",
    "section": "11 SGD properties",
    "text": "11 SGD properties\n\n\n\n\nSlide 13\n\n\n\n\nyou can keep suffleing after every epoch, as one epoch is defined as you go through the training set once completely\nRandomness leads to randomness in the class and the data. That means this help us not just optimizing for one or two classes and then in the next batch optimize for one or two classes and then leads you to jump around but instead lead to decreased a good estimate for the wholedataset"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#batch-size",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#batch-size",
    "title": "Deep Learning Optimizations I",
    "section": "12 Batch size",
    "text": "12 Batch size\n\n\n\n\nSlide 14\n\n\n\n\nIt is more efficient than in multiple linear passes because it is more efficient to do it in one fully connected linear layer.\nSo one big data multiplication is faster than doing two small matrix multiplications\nSmall batches usually add more noise to the learning process, therefore can get stuck less in local minimas and sometimes can lead to better performance but this is not supper common.\nWith the increase of batch size the effective gradient would be less strong because is a better estimation across all samples so to make the model still train as quickly is we need to increase th learning rate"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#why-does-mini-batch-sgd-work",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#why-does-mini-batch-sgd-work",
    "title": "Deep Learning Optimizations I",
    "section": "13 Why does mini-batch SGD work?",
    "text": "13 Why does mini-batch SGD work?\n\n\n\n\nSlide 15\n\n\n\n\nREducing the sample size does not imply reduced gradient wuality that is because the training samples could be noisy, or have biases or outliers (recall in every dataset you have lots of mislabel classes) so these noisy data allows you not to get stuck in local minimas while the real gradient may do this.\nFor i.e if the real gradient points in one direction and you are stuck in a local minima thne it wont help you because the the gradient descent for the whole set only have points in one direction at a certain location and if it happens to be a place where you get stuck htne you are stuck. This is contrary to stochastic where you keep taking random samples, yeah you can be stuck for the next 20 steps where you pick random samples but then you pick something that migh hav some outlier and now suddenly the gradient is pretty large and you end up scapping this local minima."
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#stochastic-gradient-based-optimization",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#stochastic-gradient-based-optimization",
    "title": "Deep Learning Optimizations I",
    "section": "14 Stochastic gradient-based optimization",
    "text": "14 Stochastic gradient-based optimization\n\n\n\n\nSlide 16"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#stochastic-gradient-based-optimization-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#stochastic-gradient-based-optimization-1",
    "title": "Deep Learning Optimizations I",
    "section": "15 Stochastic gradient-based optimization",
    "text": "15 Stochastic gradient-based optimization\n\n\n\n\nSlide 17"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#stochastic-gradient-based-optimization-2",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#stochastic-gradient-based-optimization-2",
    "title": "Deep Learning Optimizations I",
    "section": "16 Stochastic gradient-based optimization",
    "text": "16 Stochastic gradient-based optimization\n\n\n\n\nSlide 18"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#stochastic-gradient-based-optimization-3",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#stochastic-gradient-based-optimization-3",
    "title": "Deep Learning Optimizations I",
    "section": "17 Stochastic gradient-based optimization",
    "text": "17 Stochastic gradient-based optimization\n\n\n\n\nSlide 19"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#stochastic-gradient-based-optimization-4",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#stochastic-gradient-based-optimization-4",
    "title": "Deep Learning Optimizations I",
    "section": "18 Stochastic gradient-based optimization",
    "text": "18 Stochastic gradient-based optimization\n\n\n\n\nSlide 20"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#gradient-descent-vs.-stochastic-gradient-descent-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#gradient-descent-vs.-stochastic-gradient-descent-1",
    "title": "Deep Learning Optimizations I",
    "section": "19 Gradient descent vs. stochastic gradient descent",
    "text": "19 Gradient descent vs. stochastic gradient descent\n\n\n\n\nSlide 21"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#gradient-descent-vs.-stochastic-gradient-descent-2",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#gradient-descent-vs.-stochastic-gradient-descent-2",
    "title": "Deep Learning Optimizations I",
    "section": "20 Gradient descent vs. stochastic gradient descent",
    "text": "20 Gradient descent vs. stochastic gradient descent\n\n\n\n\nSlide 22"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#in-a-nutshell",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#in-a-nutshell",
    "title": "Deep Learning Optimizations I",
    "section": "21 In a nutshell",
    "text": "21 In a nutshell\n\n\n\n\nSlide 23"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#lets-see-this-in-practice",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#lets-see-this-in-practice",
    "title": "Deep Learning Optimizations I",
    "section": "22 Let’s see this in practice",
    "text": "22 Let’s see this in practice\n\n\n\n\nSlide 24"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#httpsplayground.tensorflow.or",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#httpsplayground.tensorflow.or",
    "title": "Deep Learning Optimizations I",
    "section": "23 https://playground.tensorflow.or",
    "text": "23 https://playground.tensorflow.or\n\n\n\n\nSlide 25"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#challenges-in-optimization",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#challenges-in-optimization",
    "title": "Deep Learning Optimizations I",
    "section": "24 Challenges in optimization",
    "text": "24 Challenges in optimization\n\n\n\n\nSlide 26\n\n\n\n\nNN training is non-covex optimization, these functions have lots of local optima, but we do not care about the global minimum because we care how it will perform in real life data. We care something that is optimum and that generalizes well."
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#why-are-nn-losses-not-convex",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#why-are-nn-losses-not-convex",
    "title": "Deep Learning Optimizations I",
    "section": "25 Why are NN losses not convex?",
    "text": "25 Why are NN losses not convex?\n\n\n\n\nSlide 27"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#challenges-in-optimization-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#challenges-in-optimization-1",
    "title": "Deep Learning Optimizations I",
    "section": "26 Challenges in optimization",
    "text": "26 Challenges in optimization\n\n\n\n\nSlide 28"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#ill-conditioning",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#ill-conditioning",
    "title": "Deep Learning Optimizations I",
    "section": "27 1. Ill-conditioning",
    "text": "27 1. Ill-conditioning\n\n\n\n\nSlide 29\n\n\n\n\nThe Hessian at a particular point in the function measures how well you can fit a quadratic function to this point.\nThe Jacobian measure how well you can fit a plane trough that point."
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#ill-conditioning-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#ill-conditioning-1",
    "title": "Deep Learning Optimizations I",
    "section": "28 1. Ill-conditioning",
    "text": "28 1. Ill-conditioning\n\n\n\n\nSlide 30\n\n\n\n\nSo curvature is determine by the second derivative so its determined by the Hessian\nBottom Left plot:\n\nIf you have a negative curvature that means the cost function decreases faster than the gradient predicts.\n\nBottom Right plot:\n\nIf you have a positive curvature that means the cost function decreases slower than expected and eventually starts to increase"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#ill-conditioning-2",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#ill-conditioning-2",
    "title": "Deep Learning Optimizations I",
    "section": "29 1. Ill-conditioning",
    "text": "29 1. Ill-conditioning\n\n\n\n\nSlide 31\n\n\n\n\nCritical points are where, the gradient is zero and you can define with the Hessian what kind of critical points they are, you have a local minimum, a local maximum and saddle point\nMost points in high dimensions are saddle points, this is beccause it becomes expontially (\\(2^n\\) combinations of th signs) to have at least one positive and at least one negative. So this is more likely."
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#linear-algebra-recap",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#linear-algebra-recap",
    "title": "Deep Learning Optimizations I",
    "section": "30 Linear Algebra Recap:",
    "text": "30 Linear Algebra Recap:\n\n\n\n\nSlide 32"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#ill-conditioning-3",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#ill-conditioning-3",
    "title": "Deep Learning Optimizations I",
    "section": "31 1. Ill-conditioning",
    "text": "31 1. Ill-conditioning\n\n\n\n\nSlide 33\n\n\n\n\n\n\n\n\n\n\nCondition number\n\n\n\n\n\nThe condition number of a matrix is a measure of how sensitive the matrix is to changes in its input. A high condition number indicates that the matrix is ill-conditioned, which can lead to numerical instability. In the context of optimization problems like gradient descent, ill-conditioned matrices can slow down convergence and make the optimization process more sensitive to small changes in the input.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define a quadratic loss function\ndef loss_function(x):\n    return x**2\n\n# Define the derivative of the loss function (gradient)\ndef gradient(x):\n    return 2 * x\n\n# Define the second derivative of the loss function (Hessian)\ndef hessian(x):\n    return 2 * np.ones_like(x)\n\n# Generate x values\nx_values = np.linspace(-5, 5, 100)\n\n# Set up subplots\nfig, axes = plt.subplots(1, 2, figsize=(7, 3))\n\n# Plot the loss function and its gradient for different condition numbers\nfor i, condition_number in enumerate([1, 10]):\n    hessian_values = condition_number * hessian(x_values)\n\n    # Compute the gradient at the chosen point\n    x_point = 3\n    grad_at_point = gradient(x_point)\n\n    # Compute the change in x\n    delta_x = np.linspace(-1, 1, 100)\n\n    # Compute the change in y based on the quadratic loss function\n    delta_y = 0.5 * hessian_values[x_point] * delta_x**2\n\n    # Plot the loss function\n    axes[i].plot(x_values, loss_function(x_values), label='Loss Function')\n\n    # Plot the gradient vector as an arrow\n    axes[i].arrow(x_point, loss_function(x_point), -grad_at_point, 0,\n                  color='green', width=0.1, head_width=0.5, head_length=0.5, length_includes_head=True, label='Gradient')\n\n    # Plot the change in x and corresponding change in y\n    axes[i].plot(x_point + delta_x, loss_function(x_point) + delta_y, '--', label='Approximation')\n\n    axes[i].set_xlabel('Model Parameter')\n    axes[i].set_ylabel('Loss')\n    axes[i].set_title(f'Condition Number = {condition_number}')\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nAn ill-conditioned problem, system, or matrix refers to a situation where small changes or perturbations in the input data or parameters can lead to large changes in the output or solution. In the context of linear algebra and optimization, the condition number is a measure of how sensitive a mathematical problem is to changes in its input.\nMathematically, the condition number of a matrix \\(A\\) is defined as the product of the matrix norm and the norm of its inverse. It is denoted as \\(\\text{cond}(A) = \\|A\\| \\cdot \\|A^{-1}\\|\\).\n\nIf \\(\\text{cond}(A)\\) is close to 1, the matrix is well-conditioned.\nIf \\(\\text{cond}(A)\\) is much greater than 1, the matrix is ill-conditioned.\n\nAn ill-conditioned matrix is problematic for several reasons:\n\nSensitivity to Input Perturbations: Small changes in the input data or parameters can result in large changes in the solution, making the problem numerically unstable.\nNumerical Instability: In numerical computations, ill-conditioning can lead to loss of precision, rounding errors, and difficulties in obtaining accurate solutions.\nSlow Convergence: In optimization problems, ill-conditioning can slow down the convergence of iterative optimization algorithms like gradient descent.\nNumerical Issues: When solving linear systems or performing matrix inversion, ill-conditioned matrices can lead to numerical instability and inaccurate results.\n\nIn the context of optimization problems, the Hessian matrix (second derivative of the loss function) plays a crucial role. If the Hessian matrix is ill-conditioned, it can make optimization algorithms more sensitive to the choice of step size and direction, potentially leading to slow convergence or convergence to suboptimal solutions.\nAddressing ill-conditioning often involves using regularization techniques, preconditioning, or carefully selecting optimization algorithms that can handle such numerical challenges.\n\n\n\nYou can think of how much the matrix distort the space.\nWhy is now a large condition number bad? - In the case of a small condition number, going to the local minimum is quite straight forward, but in the case of a very bad conditioned number you know where to go because the gradient tells you this but you do not know the right step size. You can keep oscillating, which slows the convergence of the algorithm.\nWith a large condition number, Gradient Descent performs poorly because it is difficult to make a good step size.\nSo it is like optimizing one direction at the time if you are luckily but the ill-conditioning to the point that you will overshoot"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#ill-conditioning-4",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#ill-conditioning-4",
    "title": "Deep Learning Optimizations I",
    "section": "32 1. Ill-conditioning",
    "text": "32 1. Ill-conditioning\n\n\n\n\nSlide 34\n\n\n\n\nif in the tailor expansion we see that the curvature term is higher than the linear component of the Tailor function then, taking a small step size (updating w) it will increase the loss instead of decreasing it. So we end up with a higher loss."
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#local-minima",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#local-minima",
    "title": "Deep Learning Optimizations I",
    "section": "33 2. Local minima",
    "text": "33 2. Local minima\n\n\n\n\nSlide 35\n\n\n\n\nModel identifiability deals with the ability to uniquely determine the values of model parameters based on the available data. In other words, a model is identifiable if the true values of its parameters can be uniquely recovered or estimated from observed data.\nIf you have a network that is equivalent between different sets of parameters you can switch them around."
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#local-minima-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#local-minima-1",
    "title": "Deep Learning Optimizations I",
    "section": "34 2. Local minima",
    "text": "34 2. Local minima\n\n\n\n\nSlide 36\n\n\n\n\nThese are the one we would have trouble (bottom left)\nyou reach some place and you are stuck in this place but there is a much better solution in the loss surface. That is why noisy SGD works better"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#local-minima-tricky-thing-about-blindness",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#local-minima-tricky-thing-about-blindness",
    "title": "Deep Learning Optimizations I",
    "section": "35 2. Local minima: tricky thing about “blindness”",
    "text": "35 2. Local minima: tricky thing about “blindness”\n\n\n\n\nSlide 37"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#ravines",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#ravines",
    "title": "Deep Learning Optimizations I",
    "section": "36 3. Ravines",
    "text": "36 3. Ravines\n\n\n\n\nSlide 38"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#plateausflat-areas",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#plateausflat-areas",
    "title": "Deep Learning Optimizations I",
    "section": "37 3. Plateaus/Flat areas",
    "text": "37 3. Plateaus/Flat areas\n\n\n\n\nSlide 39\n\n\n\n\nIn these surfaces you have zero gradients, no updates, no learning. If you have converged and that minimum tends to be flat those tend to be the ones that generalized better to new data"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#oni7",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#oni7",
    "title": "Deep Learning Optimizations I",
    "section": "74 Oni7",
    "text": "74 Oni7\n\n\n\n\nSlide 76"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#why-are-flat-minima-preferred",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#why-are-flat-minima-preferred",
    "title": "Deep Learning Optimizations I",
    "section": "39 Why are “flat” minima preferred?",
    "text": "39 Why are “flat” minima preferred?\n\n\n\n\nSlide 41\n\n\n\n\nWhy are they less likely to be the result of overfilling to train distribution?\nsmall batches tend to converge to flat minimizers that have small eigenvalues of the Hessian"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#flat-areas-steep-minima",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#flat-areas-steep-minima",
    "title": "Deep Learning Optimizations I",
    "section": "40 4. Flat areas, steep minima",
    "text": "40 4. Flat areas, steep minima\n\n\n\n\nSlide 42\n\n\n\n\nIf you have lots of flat areas with very steep minima, for example when you have logits that are scaled by a very very small number that means these numbers tend to be extremelly higuer, so they are almost on-hot like and at that point you are not getting much of the gradients from the other classes anymore.\nTherefore by changing the temperature you can change how wide these locals deeps are."
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#cliffs-and-exploding-gradients",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#cliffs-and-exploding-gradients",
    "title": "Deep Learning Optimizations I",
    "section": "41 4. Cliffs and Exploding Gradients",
    "text": "41 4. Cliffs and Exploding Gradients\n\n\n\n\nSlide 43\n\n\n\n\nWe clip it meaning we set the gradient of this eta to a treshold, you still are going in the same direction but now witch a scaled version. Escentially you reduce the size of the gradient"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#long-term-dependencies",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#long-term-dependencies",
    "title": "Deep Learning Optimizations I",
    "section": "42 5. Long term dependencies",
    "text": "42 5. Long term dependencies\n\n\n\n\nSlide 44\n\n\n\n\nThis is related to Recurrent NNs where you apply a matrix W^t over and over again, so you apply it to the input multiple times. Then you can decompose the matrix, in this case t stands for the power of t and you can see that if you apply this eigen value decomposition is simple the eigenvalues are taken to the power of t. So if you have eigenvalues larger than one then they will get insanely high, but if they are small then these eigenvalues will plummed to zero, almost vanishing.\nAs a product we would have a training-trajectory dependency which would be hard to recover from a bad start, IF you keep applying the same weights\nExample, in time series you use Recurrent NNs and for example your prediction at time 30 depends on predition at time zero. These are the long term dependencies are.\n\n\n\n\nSlide 45"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#title",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#title",
    "title": "Deep Learning Optimizations I",
    "section": "75 Title",
    "text": "75 Title\n\n\n\n\nSlide 78"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#revisit-of-gradient-descent",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#revisit-of-gradient-descent",
    "title": "Deep Learning Optimizations I",
    "section": "43 Revisit of gradient descent",
    "text": "43 Revisit of gradient descent\n\n\n\n\nSlide 46"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#setting-the-learning-rate-yn",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#setting-the-learning-rate-yn",
    "title": "Deep Learning Optimizations I",
    "section": "46 Setting the learning rate yN",
    "text": "46 Setting the learning rate yN\n\n\n\n\nSlide 47"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#advanced-optimizers",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#advanced-optimizers",
    "title": "Deep Learning Optimizations I",
    "section": "45 Advanced optimizers",
    "text": "45 Advanced optimizers\n\n\n\n\nSlide 48"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#momentum.",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#momentum.",
    "title": "Deep Learning Optimizations I",
    "section": "46 Momentum.",
    "text": "46 Momentum.\n\n\n\n\nSlide 49"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#momentum-designed-to-accelerate-learning-especially-when-loss-is-high-curvature",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#momentum-designed-to-accelerate-learning-especially-when-loss-is-high-curvature",
    "title": "Deep Learning Optimizations I",
    "section": "47 Momentum: designed to accelerate learning, especially when loss is high curvature",
    "text": "47 Momentum: designed to accelerate learning, especially when loss is high curvature\n\n\n\n\nSlide 50\n\n\n\n\nTo mimic the momentum we need to recall the exponentially weighted moving averages are: - You have your noisy data and you want to approximate some smooth average of this"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#momentum",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#momentum",
    "title": "Deep Learning Optimizations I",
    "section": "48 Momentum",
    "text": "48 Momentum\n\n\n\n\nSlide 51\n\n\n\n\nIt is easy to compute it recursively: Take your previous point * Beta + (1-Beta)*current_observation.\nYou can compute this from left to right so that you dont keep track of the points.\nHere the momentum is of your previous gradient\nHere we notice that if you have 1. Large beta then it is more smoother so it tends to have more momentum so it is basically tends to be the values that you have seen 2. Smaller beta so less smooth, which means that it reacts more to the current observation\nBecause we set V_0 = 0 then it will always be baised towards V_0, but you can correct for thi using the formulas above"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#momentum-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#momentum-1",
    "title": "Deep Learning Optimizations I",
    "section": "49 Momentum",
    "text": "49 Momentum\n\n\n\n\nSlide 52\n\n\n\n\nWhat moving average tends to, it basically removes the effect of stuff that is way in the past. For example if you have beta=0.9 if you do 0.9^10 then you already end up at 0.35. So even if you have a high Beta like 0.98 after 50 steps it basically decays so it onluy has the effect of dividing 1/e"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#sgd-with-momentum",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#sgd-with-momentum",
    "title": "Deep Learning Optimizations I",
    "section": "50 SGD with momentum",
    "text": "50 SGD with momentum\n\n\n\n\nSlide 53\n\n\n\n\nYou do not want be switching directions all the time, this is what happens in the half pipe, you want to mantain the momentum from previous updates, so now you will see that\nNow we have in addition the gamma*v_t, this is imply the gradient from the last steps. You can see how much gradients from the last step is taken\nFor isntance if gamma is 0.9 and then we say v_0 = 0. Then the first v1, so the first step is just the normal update.\nFor v2, now we take the gradient at update 2 plus the term 0.9*gradient_1 which is from the previous step.\nFor v3 we take more into account the current gradient3 but also the previous gradients. It is only changing the direction of where we are going so now we do not only consider the current gradient at tha point but also the previous gradients causing momentum"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#sgd-with-momentum-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#sgd-with-momentum-1",
    "title": "Deep Learning Optimizations I",
    "section": "51 SGD with Momentum",
    "text": "51 SGD with Momentum\n\n\n\n\nSlide 54\n\n\n\n\nHere rho = gamma, give us the friction of how much we can change direction. It is friction because where if we have it as 0 then we are only calculating one sample so no velocity, if we let it to be o.9 then we have more velocity.\nThis cancels out oscillating gradients. And it gives more weight to the recent updates, this leads to much faster convergence"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#sgd-with-momentum-2",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#sgd-with-momentum-2",
    "title": "Deep Learning Optimizations I",
    "section": "52 SGD with momentum",
    "text": "52 SGD with momentum\n\n\n\n\nSlide 55"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#sgd-with-momentum-3",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#sgd-with-momentum-3",
    "title": "Deep Learning Optimizations I",
    "section": "53 SGD with momentum",
    "text": "53 SGD with momentum\n\n\n\n\nSlide 56\n\n\n\n\nFor the parameter update:\n\nThe momentum term increases for dimensions where the gradients points in the same direction. One way that we have extracted away from this formulas is that this formulas is that the gradient is multidimensional for every parameter. So it means if your gradient for one particular weight keeps going left and right, left and right it averages out to not taking a step in this direction, but if it keep going left left and left, then it will stay that way and take more steps in this direction.\n\nSo in this case, it will keep going left and right but it will always in the one direction will keep up going down and this will gradually build up and go downwards.\nAll optimizers use momentum, clipping is less common, momentum nothing is done without it. Clipping is when for some instance your gradients explode for some reason."
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#nesterov-momentum",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#nesterov-momentum",
    "title": "Deep Learning Optimizations I",
    "section": "54 Nesterov momentum",
    "text": "54 Nesterov momentum\n\n\n\n\nSlide 57\n\n\n\n\nThis is an extension to momemntum, so in the case for nesterov momentum, we use the future gradient instead of the current gradient\nAnother approach is first take the step that momentum tell us and at this point calculate the gradient, and then add this together So now the gradient is not computed at the current location but at the current location + the step we go according to the momentum\nThis should gives a better approximation of to the gradient, because we are going in that direction anyways so how about we first apply the momentum and then calculate the gradient\nThis results in better responsiveness and better guarantees"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#nesterov-momentum-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#nesterov-momentum-1",
    "title": "Deep Learning Optimizations I",
    "section": "55 Nesterov momentum",
    "text": "55 Nesterov momentum\n\n\n\n\nSlide 58\n\n\n\n\nBlue would be what normal gradient descent does with standard momentum. You can think of Nesterov as a correction that you do to. the typically momentum, So you take momentum and you take the gradient that you have at that location.\nIn practice not use too often"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#sgd-with-adaptive-step-sizes",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#sgd-with-adaptive-step-sizes",
    "title": "Deep Learning Optimizations I",
    "section": "56 SGD with adaptive step sizes",
    "text": "56 SGD with adaptive step sizes\n\n\n\n\nSlide 59\n\n\n\n\nWhat is in practice very common is SGD with adaptive step sizes\n\nLearning rates directly affect the step size\n\nIn NNs for clasifying dogs, the lower layers classify rgbs pixels the upper classify whether is a dog, so instead of having equal learning rates for all modules why not having learning rates per parameter. We can use this by using the following: Adagrad … see next slides"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#adagrad",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#adagrad",
    "title": "Deep Learning Optimizations I",
    "section": "57 Adagrad",
    "text": "57 Adagrad\n\n\n\n\nSlide 60\n\n\n\n\nHere we adapt the learning rate per component, so for every paramter it adapts the learning rate to incorporate the knowledge of the past observations\nHere the dot in a circle represent the element wise product, r is the gradient for this parameter summed up over time, so if summed overtime it keeps getting bigger. So that means the gradient according with time just keeps getting lower.\nSo the parameters that have large gradients quickly decrease in effective learning rate because r would be very big so the term in from of the gradient would be very small, because we have eta/r. and we saw that r was big, so eta/r would be small\n\nRapid decrease in learning rate for parameters with large partial derivatives\n\nSo the parameters that have large gradients will not be updated anymore because we will have the learning rate eta/r to be close to zero like 0.00001..\n\nSmaller decrease in learning rate for parameters with small partial derivatives"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#adagrad-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#adagrad-1",
    "title": "Deep Learning Optimizations I",
    "section": "58 Adagrad",
    "text": "58 Adagrad\n\n\n\n\nSlide 61\n\n\n\n\nso here with Adadelta:\n\nThere is another extension to this which seeks to reduce its aggressive, monotonically decreasing learning rate. This could be somewhat problematic because if you do not finish by \\(x\\) number of steps then all of your learning rates will be zero so Adadelta simply makes a sliding winwdow instead to use past gradients. It does so by restricting the window of acummulated past gradients to some fixed size instead of acummulating all past squared gradients.\nWe do not need to set a default learning rate. as it has been eliminated from the updated rule"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#rmsprop",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#rmsprop",
    "title": "Deep Learning Optimizations I",
    "section": "59 RMSprop",
    "text": "59 RMSprop\n\n\n\n\nSlide 62\n\n\n\n\n\nIt is just a modification of Adagrad, and it simply uses the exponentially weighted average to accumulate gradients\n\nSo before r was jus the sum of square gradients, now we take the exponentially weighed average. we can also use standard momentum and Nesterov momentum and so on."
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#rmsprop-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#rmsprop-1",
    "title": "Deep Learning Optimizations I",
    "section": "60 RMSprop",
    "text": "60 RMSprop\n\n\n\n\nSlide 63\n\n\n\n\n\nLarge gradients here the updates are are detained, tammed, interrumped,\nSmall gradients here the updates are are exacerbated, more aggresive"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#adam",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#adam",
    "title": "Deep Learning Optimizations I",
    "section": "61 Adam",
    "text": "61 Adam\n\n\n\n\nSlide 64\n\n\n\n\n\ncoombines RMSProp and momentum\nuses adaptive learning rate for each parameter (higher memory)\nIt keeps an exponentially decaying average of past gradient like momentum\nIt introduces bias correction terms i.e if we have smoothing average, it tends to have some dependency for the first v_0, but at the beginning you dont have a really first value so we need to set it to zero which is a bias, but we can have a formula that compensates for this.\nit is more popular specially for transformers architecture\nso popular that is not even cited"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#adam-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#adam-1",
    "title": "Deep Learning Optimizations I",
    "section": "62 Adam",
    "text": "62 Adam\n\n\n\n\nSlide 65\n\n\n\nMomentum —&gt; Adagrad —&gt; RMSprop\n\n  \n\n\nWe have the exponentiall average of gradients so the \\(\\sqrt{v_t}\\), the square is use to rescale again one learning rate at the beginning and then automatic learning rates per parameter and then the moving average of gradient is use for the update itself.\nWhat is new is the combination fo the two."
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#notice-something",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#notice-something",
    "title": "Deep Learning Optimizations I",
    "section": "63 Notice something?",
    "text": "63 Notice something?\n\n\n\n\nSlide 66"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#visual-overview",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#visual-overview",
    "title": "Deep Learning Optimizations I",
    "section": "64 Visual overview",
    "text": "64 Visual overview\n\n\n\n\nSlide 67\n\n\n\n\nAdam is a heavy ball with a lot of friction and all the other, like the yellow one tends to overshoot a lot and adam introduces this friction term to the optimizer"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#which-optimizer-to-use",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#which-optimizer-to-use",
    "title": "Deep Learning Optimizations I",
    "section": "65 Which optimizer to use?",
    "text": "65 Which optimizer to use?\n\n\n\n\nSlide 68\n\n\n\n\n\nTypically SGD + momentum often works best\nAdam is often the easy choice but it tends to not perform best.\nAdam + weigth decay is standard for optimizing transformers\nEven in optimizers like Adam we do learning rate decay"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#approximate-second-order-methods",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#approximate-second-order-methods",
    "title": "Deep Learning Optimizations I",
    "section": "66 Approximate Second-Order Methods",
    "text": "66 Approximate Second-Order Methods\n\n\n\n\nSlide 69\n\n\n\n\nThis is another whole level of optimizers, these are of second order:\nThis does not look only at the gradeitn but try to see how is the gradient changing at this location. It is trying to get some approximations to the Hessian just to haver a feeling of where to go.\nWe will only talk about Newtons Method"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#newtons-method",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#newtons-method",
    "title": "Deep Learning Optimizations I",
    "section": "67 Newton’s method",
    "text": "67 Newton’s method\n\n\n\n\nSlide 70\n\n\n\n\nWe approximate the gradient at some point with Taylor expansion - Now if we want to solve for the critical point, which means the gradient is zero, then we get the second eq as an update formula. - If the function is like quadratic becuase we are learning a quadratic approximation to the function Newton method will only need one step directly to get to the solution - If is convex but not quadratic, we keep on iterating and it will get us to the minimum"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#newtons-method-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#newtons-method-1",
    "title": "Deep Learning Optimizations I",
    "section": "68 Newton’s method",
    "text": "68 Newton’s method\n\n\n\n\nSlide 71\n\n\n\n\n\nOnly works if Hessian is positive definite, if near saddle point, the Hessian are not all positive. So it does not work.\nThe solution for this is to add an identity matrix times this expression and then solve for the update\nStill computationally expensive"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#quasi-newton-methods",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#quasi-newton-methods",
    "title": "Deep Learning Optimizations I",
    "section": "69 Quasi-Newton methods",
    "text": "69 Quasi-Newton methods\n\n\n\n\nSlide 72\n\n\n\n\nBecause it is very computational expensive people have came with Quasi-Newton methods which trie to reduce the expensive computations of the inversion of the Hessian in the previous method\n\nThey approx these matrices by lower rank matrices, then less storage and complexity\n\nBut not really used"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#interactive-session",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#interactive-session",
    "title": "Deep Learning Optimizations I",
    "section": "70 Interactive session",
    "text": "70 Interactive session\n\n\n\n\nSlide 73"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#reading-materials",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#reading-materials",
    "title": "Deep Learning Optimizations I",
    "section": "71 Reading materials",
    "text": "71 Reading materials\n\n\n\n\nSlide 74"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#how-research-ets-done-art-il-marie-curie.",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#how-research-ets-done-art-il-marie-curie.",
    "title": "Deep Learning Optimizations I",
    "section": "74 How research ets done art Il Marie Curie.",
    "text": "74 How research ets done art Il Marie Curie.\n“Nothing in life is to be"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#oni7-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#oni7-1",
    "title": "Deep Learning Optimizations I",
    "section": "75 Oni7",
    "text": "75 Oni7\n\n\n\n\nSlide 76"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#re-constant-init-see-tutorial",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#re-constant-init-see-tutorial",
    "title": "Deep Learning Optimizations I",
    "section": "74 Re: constant init: see Tutorial",
    "text": "74 Re: constant init: see Tutorial\n\n\n\n\nSlide 77"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#title-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#title-1",
    "title": "Deep Learning Optimizations I",
    "section": "77 Title",
    "text": "77 Title\n\n\n\n\nSlide 78"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#weight-initialization",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#weight-initialization",
    "title": "Deep Learning Optimizations I",
    "section": "76 Weight initialization",
    "text": "76 Weight initialization\n\n\n\n\nSlide 79\n\n\n\n\n\n\n\n\n\n\nWhy init weights to zero is bad?\n\n\n\n\n\nThe use of random values for weight initialization in neural networks is a common practice and serves several important purposes in the training process. Here are some reasons why random initialization is preferred:\n\nBreaking Symmetry: If all the weights in a neural network are initialized to the same value, each neuron in a given layer would receive the same input and learn the same features during training. This symmetry problem makes it difficult for neurons to learn diverse and meaningful features. Random initialization breaks this symmetry by providing each neuron with a unique starting point.\nAvoiding Zero Gradients: If all weights are initialized to zero, the gradients with respect to each weight will be the same during backpropagation. This means that all weights will be updated by the same amount in each iteration, leading to symmetrical weight updates and slow convergence. Random initialization ensures that each weight starts with a different value, preventing this issue.\nEncouraging Exploration: Random initialization introduces diversity in the initial state of the neural network, promoting exploration in the weight space. This is particularly important when using optimization algorithms like gradient descent, as it helps the algorithm escape local minima and find better solutions.\nDealing with Dead Neurons: If weights are initialized to zero, neurons in a network with certain activation functions (e.g., ReLU) may become “dead” and stay inactive (always outputting zero) for all inputs. Random initialization helps mitigate this issue, ensuring that neurons have a chance to receive different inputs and learn meaningful features.\nImproving Generalization: Random initialization contributes to the generalization ability of the neural network. Different initializations allow the network to learn diverse representations of the input data, which can lead to better performance on unseen data.\n\nWhat about biases set to zero?\nWhile it’s common to initialize weights with random values, the initialization of biases is often done differently. Setting biases to zero is a common and reasonable practice, and it generally does not lead to the same issues as initializing weights to zero"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#random-yes.-but-how",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#random-yes.-but-how",
    "title": "Deep Learning Optimizations I",
    "section": "77 Random: yes. But how?",
    "text": "77 Random: yes. But how?\n\n\n\n\nSlide 80\n\n\n\n\nBy controlling the spread of initial weights (variance), we aim to avoid extreme values that could hinder the training process.\n\n\n\n\n\n\nWhy do we even want to preserve the variance of the activations?\n\n\n\n\n\nConserving the variance of activations during the training of neural networks is an important consideration for several reasons:\n\nPreventing Vanishing Gradients:\n\nIf the variance of activations becomes too small as the information passes through the layers during forward propagation, it may lead to vanishing gradients during backpropagation.\nVanishing gradients make it challenging for the optimization algorithm to update the weights effectively, hindering the learning process.\n\nPreventing Exploding Gradients:\n\nConversely, if the variance of activations becomes too large, it may lead to exploding gradients during backpropagation.\nExploding gradients can cause the weights to be updated by very large values, leading to numerical instability and making it difficult for the model to converge to a solution.\n\nFacilitating Learning Across Layers:\n\nConserving the variance helps in maintaining a suitable range of activations throughout the layers of the network.\nA consistent variance allows each layer to make meaningful contributions to the learning process, preventing issues where some layers become overly dominant or inactive.\n\nSmoothing the Optimization Landscape:\n\nA stable and consistent variance in activations contributes to a smoother optimization landscape.\nA smoother landscape makes it easier for optimization algorithms to navigate and converge, leading to more stable and efficient training.\n\nEncouraging Exploration and Learning:\n\nA controlled variance ensures that the network can effectively explore the solution space during training.\nThe ability to explore different configurations and update weights based on meaningful gradients helps the model to learn representative features from the data.\n\nBetter Generalization:\n\nMaintaining a reasonable variance helps in producing more robust models that generalize well to unseen data.\nOverly small or large activations may result in a model that is sensitive to minor variations in the training data, leading to poor generalization.\n\nMitigating Sensitivity to Weight Initialization:\n\nA consistent variance makes the training process less sensitive to the specific choice of weight initialization.\nWhen the variance is carefully controlled, the network is more likely to exhibit stable behavior during training, irrespective of the initial weights.\n\n\n\n\n\n\n\n\n\n\n\nWhy do we even mean by variance of the weights?\n\n\n\n\n\nWhen we refer to “variance” in the context of neural networks and weight initialization, we are typically talking about the spread or dispersion of values. Specifically, it refers to the spread of the weights’ initial values. The term “variance” in this context does not directly relate to statistical variance, but rather it’s used in a more general sense to describe the range of values.\nHere’s a breakdown of the concept:\n\nWeight Variance:\n\nEach weight in a neural network has an associated value.\nThe “variance” in weight initialization refers to how spread out or varied these initial weight values are across the neurons in a layer.\n\nConsistent Spread Across Layers:\n\nWhen initializing weights, especially in deep neural networks, it’s desirable to have a consistent spread of initial values across layers.\nThe goal is to avoid situations where the weights in some layers are much larger or smaller than in others.\n\nAvoiding Extreme Values:\n\nExtreme weight values can lead to numerical instability during training, causing issues like exploding or vanishing gradients.\nBy controlling the spread of initial weights (variance), we aim to avoid extreme values that could hinder the training process.\n\nMaintaining Activation Variance:\n\nThe idea is to set the initial weights in a way that the variance of activations (outputs of neurons after applying weights and activation functions) remains reasonably constant across layers.\nThis helps prevent issues like vanishing or exploding gradients, as mentioned earlier."
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#bad-initialization-can-cause-problems",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#bad-initialization-can-cause-problems",
    "title": "Deep Learning Optimizations I",
    "section": "78 Bad initialization can cause problems",
    "text": "78 Bad initialization can cause problems\n\n\n\n\nSlide 81\n\n\n\n\nLow variance = high peak\nHigh variance = smooth out bell\nIn the upper row, if we initialize every length with weigths that have same constant variance then in further layers we dimished the variance, so it tends to smooth out –&gt; diminsh variance\nIn the opposite if every layer has an increase variance, then we end up with a very spiky peak because we can can explode the variance in activations"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#initializing-weights-by-preserving-variance",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#initializing-weights-by-preserving-variance",
    "title": "Deep Learning Optimizations I",
    "section": "79 Initializing weights by preserving variance",
    "text": "79 Initializing weights by preserving variance\n\n\n\n\nSlide 82"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#initializing-weights-by-preserving-variance-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#initializing-weights-by-preserving-variance-1",
    "title": "Deep Learning Optimizations I",
    "section": "80 Initializing weights by preserving variance",
    "text": "80 Initializing weights by preserving variance\n\n\n\n\nSlide 83\n\n\n\n\nHere then we are saying that our weight to preserve the variance we will be draw from a Gaussian with mean = 0 and variance = 1/d, where d is the number of input variables to the layer."
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#initialization-for-relus",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#initialization-for-relus",
    "title": "Deep Learning Optimizations I",
    "section": "81 Initialization for ReLUs",
    "text": "81 Initialization for ReLUs\n\n\n\n\nSlide 84\n\n\n\n\nFor Relu or variants we use Kaiming\nThe Kaiming initialization sets the initial weights with a variance of 2/n, where n is the number of input units. This choice helps prevent issues like vanishing or exploding gradients, particularly in deep neural networks."
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#xavier-initialization",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#xavier-initialization",
    "title": "Deep Learning Optimizations I",
    "section": "82 Xavier initialization",
    "text": "82 Xavier initialization\n\n\n\n\nSlide 85"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#interesting-results-with-randomly-initialized-networks",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#interesting-results-with-randomly-initialized-networks",
    "title": "Deep Learning Optimizations I",
    "section": "83 Interesting results with randomly initialized networks",
    "text": "83 Interesting results with randomly initialized networks\n\n\n\n\nSlide 86"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#reading-materials-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#reading-materials-1",
    "title": "Deep Learning Optimizations I",
    "section": "84 Reading materials",
    "text": "84 Reading materials\n\n\n\n\nSlide 87"
  },
  {
    "objectID": "blog/2023-05-29_markdown-structure/index.html",
    "href": "blog/2023-05-29_markdown-structure/index.html",
    "title": "Markdown structure, titles and CSS",
    "section": "",
    "text": "Showing how titles and sections will be displayed in all posts\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Markdown\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Testing\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Markdown\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Testing\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          May 29, 2023"
  },
  {
    "objectID": "blog/2023-05-29_markdown-structure/index.html#posts",
    "href": "blog/2023-05-29_markdown-structure/index.html#posts",
    "title": "Markdown structure, titles and CSS",
    "section": "1. Posts",
    "text": "1. Posts\ndate-modified: last-modified\n\n# Bootstrap Icons\ncategories: [ &lt;i class='bi bi-archive'&gt;&lt;/i&gt; DevOps, TAGS, Python]                    \n\n# Material Icons\ncategories: [ \"&lt;i class='material-icons'&gt;account_circle&lt;/i&gt;\",  DevOps, TAGS, Python] \n\n# Hides post\ncoming-soon: true\n\n# Make numbered the sections\nnumber-sections: true\n\n# Until what numebr to show in TOC\ntoc-depth: 4"
  },
  {
    "objectID": "blog/2023-05-29_markdown-structure/index.html#notebook",
    "href": "blog/2023-05-29_markdown-structure/index.html#notebook",
    "title": "Markdown structure, titles and CSS",
    "section": "2. Notebook",
    "text": "2. Notebook\n# Uses Bootstrap icons\nlinks:\n  - icon: download\n    name: Code\n    href: index.out.ipynb\n  - icon: file-earmark-pdf\n    name: See Article \n    url: https://www.researchgate.net/\n  - icon: file-slides-fill\n    name: Slides\n    url: https://www.google.com/\n  - icon: play-btn-fill\n    name: Video\n    url: https://www.google.com/\n\n# Creates downloadable icon below TOC\nformat:\n  ipynb: default"
  },
  {
    "objectID": "blog/2023-05-29_markdown-structure/index.html#this-is-an-h2-title",
    "href": "blog/2023-05-29_markdown-structure/index.html#this-is-an-h2-title",
    "title": "Markdown structure, titles and CSS",
    "section": "1.1 This is an H2 title",
    "text": "1.1 This is an H2 title\n\n1.1.1 This is an H3 title\n\n1.1.1.1 This is an H4 title\nAbove we use the left option to specify items for the left side of the navigation bar. You can also use the right option to specify items for the right side.\nThe text for navigation bar items will be taken from the underlying target document’s title. Note that in the above example we provide a custom text: “Home” value for index.qmd.\nYou can also create a navigation bar menu by including a menu (which is a list of items much like left and right). For example:\nleft: - text: “More” menu: - talks.qmd - about.qmd\nHere are all of the options available for top navigation:\nOption Description title Navbar title (uses the site: title if none is specified). Use title: false to suppress the display of the title on the navbar. logo Logo image to be displayed left of the title. logo-alt Alternate text for the logo image. logo-href Target href from navbar logo / title. By default, the logo and title link to the root page of the site (/index.html). background Background color (“primary”, “secondary”, “success”, “danger”, “warning”, “info”, “light”, “dark”, or hex color) foreground Foreground color (“primary”, “secondary”, “success”, “danger”, “warning”, “info”, “light”, “dark”, or hex color). The foreground color will be used to color navigation elements, text and links that appear in the navbar. search Include a search box (true or false) tools List of navbar tools (e.g. link to github or twitter, etc.). See Navbar Tools for details. left / right Lists of navigation items for left and right side of navbar pinned Always show the navbar (true or false). Defaults to false, and uses headroom.js to automatically show the navbar when the user scrolls up on the page. collapse Collapse the navbar items into a hamburger menu when the display gets narrow (defaults to true) collapse-below Responsive breakpoint at which to collapse navbar items to a hamburger menu (“sm”, “md”, “lg”, “xl”, or “xxl”, defaults to “lg”) Here are the options available for individual navigation items:\nOption Description href Link to file contained with the project or external URL. text Text to display for navigation item (defaults to the document title if not provided). icon Name of one of the standard Bootstrap 5 icons (e.g. “github”, “twitter”, “share”, etc.). aria-label Accessible label for the navigation item. rel Value for rel attribute. Multiple space-separated values are permitted. menu List of navigation items to populate a drop-down menu.\n\n\n\n1.1.2 This is a title\nAbove we use the left option to specify items for the left side of the navigation bar. You can also use the right option to specify items for the right side.\nThe text for navigation bar items will be taken from the underlying target document’s title. Note that in the above example we provide a custom text: “Home” value for index.qmd.\nYou can also create a navigation bar menu by including a menu (which is a list of items much like left and right). For example:\nleft: - text: “More” menu:\n- talks.qmd\n\n- about.qmd\n\n1.1.2.1 This is a title\nHere are all of the options available for top navigation:\nOption Description\ntitle Navbar title (uses the site: title if none is specified). Use title: false to suppress the display of the title on the navbar. logo Logo image to be displayed left of the title. logo-alt Alternate text for the logo image. logo-href Target href from navbar logo / title. By default, the logo and title link to the root page of the site (/index.html). background Background color (“primary”, “secondary”, “success”, “danger”, “warning”, “info”, “light”, “dark”, or hex color) foreground Foreground color (“primary”, “secondary”, “success”, “danger”, “warning”, “info”, “light”, “dark”, or hex color). The foreground color will be used to color navigation elements, text and links that appear in the navbar. search Include a search box (true or false) tools List of navbar tools (e.g. link to github or twitter, etc.). See Navbar Tools for details. left / right Lists of navigation items for left and right side of navbar pinned Always show the navbar (true or false). Defaults to false, and uses headroom.js to automatically show the navbar when the user scrolls up on the page. collapse Collapse the navbar items into a hamburger menu when the display gets narrow (defaults to true) collapse-below Responsive breakpoint at which to collapse navbar items to a hamburger menu (“sm”, “md”, “lg”, “xl”, or “xxl”, defaults to “lg”) Here are the options available for individual navigation items:\nOption Description href Link to file contained with the project or external URL. text Text to display for navigation item (defaults to the document title if not provided). icon Name of one of the standard Bootstrap 5 icons (e.g. “github”, “twitter”, “share”, etc.). aria-label Accessible label for the navigation item. rel Value for rel attribute. Multiple space-separated values are permitted. menu List of navigation items to populate a drop-down menu."
  },
  {
    "objectID": "blog/2023-05-29_markdown-structure/index.html#this-is-a-title-2",
    "href": "blog/2023-05-29_markdown-structure/index.html#this-is-a-title-2",
    "title": "Markdown structure, titles and CSS",
    "section": "1.2 This is a title",
    "text": "1.2 This is a title\nOption Description title Navbar title (uses the site: title if none is specified). Use title: false to suppress the display of the title on the navbar. logo Logo image to be displayed left of the title. logo-alt Alternate text for the logo image. logo-href Target href from navbar logo / title. By default, the logo and title link to the root page of the site (/index.html). background Background color (“primary”, “secondary”, “success”, “danger”, “warning”, “info”, “light”, “dark”, or hex color) foreground Foreground color (“primary”, “secondary”, “success”, “danger”, “warning”, “info”, “light”, “dark”, or hex color). The foreground color will be used to color navigation elements, text and links that appear in the navbar. search Include a search box (true or false) tools List of navbar tools (e.g. link to github or twitter, etc.). See Navbar Tools for details. left / right Lists of navigation items for left and right side of navbar pinned Always show the navbar (true or false). Defaults to false, and uses headroom.js to automatically show the navbar when the user scrolls up on the page. collapse Collapse the navbar items into a hamburger menu when the display gets narrow (defaults to true) collapse-below Responsive breakpoint at which to collapse navbar items to a hamburger menu (“sm”, “md”, “lg”, “xl”, or “xxl”, defaults to “lg”) Here are the options available for individual navigation items:\nOption Description href Link to file contained with the project or external URL. text Text to display for navigation item (defaults to the document title if not provided). icon Name of one of the standard Bootstrap 5 icons (e.g. “github”, “twitter”, “share”, etc.). aria-label Accessible label for the navigation item. rel Value for rel attribute. Multiple space-separated values are permitted. menu List of navigation items to populate a drop-down menu."
  },
  {
    "objectID": "blog/2023-05-29_markdown-structure/index.html#this-is-a-title-5",
    "href": "blog/2023-05-29_markdown-structure/index.html#this-is-a-title-5",
    "title": "Markdown structure, titles and CSS",
    "section": "2.1 This is a title",
    "text": "2.1 This is a title\nAbove we use the left option to specify items for the left side of the navigation bar. You can also use the right option to specify items for the right side.\nThe text for navigation bar items will be taken from the underlying target document’s title. Note that in the above example we provide a custom text: “Home” value for index.qmd.\nYou can also create a navigation bar menu by including a menu (which is a list of items much like left and right). For example:\nleft: - text: “More” menu: - talks.qmd - about.qmd\nHere are all of the options available for top navigation:"
  },
  {
    "objectID": "blog/2023-05-29_markdown-structure/index.html#this-is-a-title-6",
    "href": "blog/2023-05-29_markdown-structure/index.html#this-is-a-title-6",
    "title": "Markdown structure, titles and CSS",
    "section": "2.2 This is a title",
    "text": "2.2 This is a title\n\n2.2.1 This is a title\nOption Description title Navbar title (uses the site: title if none is specified). Use title: false to suppress the display of the title on the navbar. logo Logo image to be displayed left of the title. logo-alt Alternate text for the logo image. logo-href Target href from navbar logo / title. By default, the logo and title link to the root page of the site (/index.html). background Background color (“primary”, “secondary”, “success”, “danger”, “warning”, “info”, “light”, “dark”, or hex color) foreground Foreground color (“primary”, “secondary”, “success”, “danger”, “warning”, “info”, “light”, “dark”, or hex color). The foreground color will be used to color navigation elements, text and links that appear in the navbar. search Include a search box (true or false) tools List of navbar tools (e.g. link to github or twitter, etc.). See Navbar Tools for details. left / right Lists of navigation items for left and right side of navbar pinned Always show the navbar (true or false). Defaults to false, and uses headroom.js to automatically show the navbar when the user scrolls up on the page. collapse Collapse the navbar items into a hamburger menu when the display gets narrow (defaults to true) collapse-below Responsive breakpoint at which to collapse navbar items to a hamburger menu (“sm”, “md”, “lg”, “xl”, or “xxl”, defaults to “lg”) Here are the options available for individual navigation items:"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html",
    "href": "blog/2023-10-04_logistic-regression/index.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "Lecture Notes UvA on 25-9-2023\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          October 4, 2023\nThe downside with the Perceptron is that there is no probabilistic interpretation. We want to link the linear model to class conditional probabilities\ni.e we would like to say there is 50% that this belongs to class K \\[\n\\begin{align}\np(C|x)\n\\end{align}\n\\]\nNow, lets talk about Logistic Regression"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#plotting-pc_kx-2nd-plot",
    "href": "blog/2023-10-04_logistic-regression/index.html#plotting-pc_kx-2nd-plot",
    "title": "Logistic Regression",
    "section": "1 Plotting \\(p(C_k|x)\\) (2nd plot)",
    "text": "1 Plotting \\(p(C_k|x)\\) (2nd plot)\n\n\nCode\n# Generate a grid of x and y coordinates\nx_range = np.linspace(-10, 10, 400)\ny_range = np.linspace(-10, 10, 400)\nxx, yy = np.meshgrid(x_range, y_range)\n\n# Calculate p(C_A | x) and p(C_B | x) for each point on the grid\n# Note: This is a simplified approach and doesn't use the actual Naive Bayes model\np_C_A_given_x = norm.pdf(np.linalg.norm([xx - np.cos(theta) * (2 * theta + np.pi), yy - np.sin(theta) * (2 * theta + np.pi)], axis=0))\np_C_B_given_x = norm.pdf(np.linalg.norm([xx - np.cos(theta) * (-2 * theta - np.pi), yy - np.sin(theta) * (-2 * theta - np.pi)], axis=0))\n\n# Plot the contour plots\nplt.figure(figsize=(7, 3))\nplt.subplot(121)\nplt.contourf(xx, yy, p_C_A_given_x, cmap='Blues', levels=20)\nplt.title('p(C_A | x)')\nplt.colorbar()\n\nplt.subplot(122)\nplt.contourf(xx, yy, p_C_B_given_x, cmap='Oranges', levels=20)\nplt.title('p(C_B | x)')\nplt.colorbar()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nThe contour plots show the probability values over the grid of x and y coordinates, with color indicating probability levels. The higher the probability, the darker the color.\nSince the data is not generated according to a real statistical model, the visualized distributions are more conceptual than precise.\nIn a real Naive Bayes model, you would estimate p(C_k | x) using the actual data and the independence assumption. The visualization would depend on the data, features, and model parameters."
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#concentric-circles-distribution",
    "href": "blog/2023-10-04_logistic-regression/index.html#concentric-circles-distribution",
    "title": "Logistic Regression",
    "section": "2 Concentric circles Distribution",
    "text": "2 Concentric circles Distribution\n\n\nCode\nfrom sklearn.datasets import make_circles\n\nX, y = make_circles(n_samples=1000, random_state=123, \n                    noise=0.1, factor=0.2)\n\nplt.figure(figsize=(8,6))\n\nplt.scatter(X[y==0, 0], X[y==0, 1], color='red', alpha=0.5)\nplt.scatter(X[y==1, 0], X[y==1, 1], color='blue', alpha=0.5)\nplt.title('Concentric circles')\nplt.ylabel('y coordinate')\nplt.xlabel('x coordinate')\nplt.show()"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#deriving-logistic-regression",
    "href": "blog/2023-10-04_logistic-regression/index.html#deriving-logistic-regression",
    "title": "Logistic Regression",
    "section": "3 Deriving Logistic Regression",
    "text": "3 Deriving Logistic Regression\n\nNote: We would be talking about Binary Classification\n\nHere the want to link linear model to probabilities to get Logistic Regression\n\nWhen we set up Bayes Classifiers, We look at the ratio of probabilities.\n\n\n\n\nHere we are saying that this ratio would not work because i.e if we would predict a negative value for this ratio that would mean that either the denominator or denominator would be negative. But negative probables cannot happen.\nThe solution, make compute the \\(\\ln\\)\n\n\n\nNote that at the decision boundary meaning when \\(p(C_1|x)=p(C_2|x)\\) we would have that the ratio is zero.\nNow, rearranging the expression above:\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Sigmoid"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#logistic-regression-making-predictions",
    "href": "blog/2023-10-04_logistic-regression/index.html#logistic-regression-making-predictions",
    "title": "Logistic Regression",
    "section": "4 Logistic Regression: Making Predictions",
    "text": "4 Logistic Regression: Making Predictions"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#counting-parameters",
    "href": "blog/2023-10-04_logistic-regression/index.html#counting-parameters",
    "title": "Logistic Regression",
    "section": "5 Counting Parameters",
    "text": "5 Counting Parameters\nHow much more parameter efficient is logistic regression vs a Gaussian classifier? (assume the feature vector has D dimensions)\nLogistic regression\n\nNum of parameters: \\(D+1\\) one weight for each feature value and then you have the bias weight.\n\nLinear Discriminant Analysis\n\nHere we defined the Gaussian likelihoods\n\n\nNum of parameters: \\((2D)+[D(D - 1)2 + D]\\)\n\n\nHow many parameters do the means of these gaussian likelihood have?\n\\(2D\\): because D dimensions per each mean and we have 2 likelihoods because we are doing binary classifier\nHow many parameters the covariance matrix have? Assume we are doing LDA, so the covariance matrix are shared.\n\\(D^2\\) Naively but in this case, the covariance matrix has this symmetry structure so \\(D*D - D/2\\) is the off diagonal matrix and we add \\(D\\) more for the diagonal\nThe last term, we have means, we have covariances. We need the bias because maybe we can have unbalance data so we also want this to balance the data.\nIn a bayes classifier we fixed our unbalance data with the prior. So we have one parameter for the prior\n\nTo understand more: link\nThat means for the LDA we need around \\(D^2\\) as compared to Logistic Regression \\(D+1\\) to get a classification example."
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#learning-via-log-likelihood",
    "href": "blog/2023-10-04_logistic-regression/index.html#learning-via-log-likelihood",
    "title": "Logistic Regression",
    "section": "6 Learning via Log-Likelihood",
    "text": "6 Learning via Log-Likelihood\nWe talked about our Logistic Regression model, now lets see how do we fit into our data."
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#learning-via-log-likelihood-1",
    "href": "blog/2023-10-04_logistic-regression/index.html#learning-via-log-likelihood-1",
    "title": "Logistic Regression",
    "section": "7 Learning via Log-likelihood",
    "text": "7 Learning via Log-likelihood\nWe assume our data are ID.\nNow that we have our labels which are binary we could use a Bernouli distribution to model this.\n\n\n\nWhere, \\(\\pi\\) represents the probability of sucess and \\(t\\) represents our possible outcomes. In this case our outcomes would be to belong to class \\(0\\) if \\(C_0\\) or \\(1\\) if \\(C_1\\)\n\n\n\nWhere, \\(\\sigma(\\textbf{w}^T\\textbf{x}_n)^{t_n}\\) is equal to \\(p(C1|x)\\). See the graph of the sigmoid Figure 1\nNow lets take the log of this Likelihood\n\n\n\nTo compute the Error we have:\n\n\n\nThis is equation is also called cross-entropy loss\nif the label \\(t_n=1\\) then second term will go away. Because we want to have the error to go to zero, then we need to make the log to go to zero. This happens when \\(log(1)\\) thus the \\(\\sigma(\\textbf{w}^T\\textbf{x}_n)\\) needs to equal one. This will only happen when the value of \\(\\textbf{w}^T\\textbf{x}_n\\) is large enough so that the \\(\\sigma()\\) computes it to one, meaning that \\(p(C_1|x)=1\\) which means we have predicted the correct label. Recall \\(t_n=1\\).\nThe other way around, the truth label is \\(t_n=1\\) but the output of \\(\\sigma(\\textbf{w}^T\\textbf{x}_n)~0\\) so close to zero which means the \\(\\ln(0.00001)=-11\\) would be negative which then recall we have a \\(-\\) minus sign which means we would be making a big error of \\(11\\).\n\\(E(w)\\) is convex in \\(\\textbf{w}\\) but unlike linear regression there is no analytical solution [1]. Which means if we take the derivative and solve for \\(w\\) we would get stuck.\n\nWhat is convex decision boundaries?\n\n\n\n\nif you take any two points within the boundary, the line segment connecting those points lies entirely within the boundary as well"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#class-entropy-loss",
    "href": "blog/2023-10-04_logistic-regression/index.html#class-entropy-loss",
    "title": "Logistic Regression",
    "section": "8 Class-Entropy Loss",
    "text": "8 Class-Entropy Loss\n\n\n\n\n8.1 Comparing Logistic Regression and Square Regression\n\n\n\nLogistic Regression is on the green line, Least Square Regression the purple.\n\nIf you have outliers, LEast Square changes its boundary so its sensible to outliers\nLogistic Regression is not, it kept the original boundary"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#gradient-descent-variants",
    "href": "blog/2023-10-04_logistic-regression/index.html#gradient-descent-variants",
    "title": "Logistic Regression",
    "section": "9 Gradient Descent: Variants",
    "text": "9 Gradient Descent: Variants\n\nNote, because we saw that the Error of the Log-likelihood of Logistic Regression cannot be solved analytically then we turn into gradient descent\n\n\n\n\n\nBecause the above summation is expensive then we got variants.\n\nBatch: Use all N data points\nStochastic: Use one data point to approximate sum\nHere we pick a random point \\(i\\) and we multiply by \\(N\\) to replicate the magnitude of learning rate. This is to keep same scale as the full gradient descent formula we see above. In other words this is just to conserve the magnitude of the \\(\\eta\\) value\n\n\n\n\n\nMini-Batch: Use B data points where 1 &lt; B &lt; N. Usually B much less than N (B &lt;&lt; N)\n\n\n\n\n\n9.1 Gradient Descent: Variants Performance"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#gradient-calculation",
    "href": "blog/2023-10-04_logistic-regression/index.html#gradient-calculation",
    "title": "Logistic Regression",
    "section": "10 Gradient Calculation",
    "text": "10 Gradient Calculation\n\n\n\n\n\n\n\n\n\n\n\n\nThe answer look identical to the one proposed for the perceptron in our prev post\n\n\n\n\nThe difference with the perceptron its that the update for the weights its softer.\nThe Gradient descent with logistic regresion will keep updating until \\(t_i-\\sigma(\\textbf{w}_t^T\\textbf{x}_i)\\) is close to zero, whereas the perceptron because of this \\(f(w^T\\phi)&gt;0\\) condition will be: \\(t_i-\\sigma(\\textbf{w}_t^T\\textbf{x}_i)\\) this is close enough (review the inequality post) to zero then we do not update the weight."
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#stochastic-gradient-descent",
    "href": "blog/2023-10-04_logistic-regression/index.html#stochastic-gradient-descent",
    "title": "Logistic Regression",
    "section": "11 Stochastic Gradient Descent",
    "text": "11 Stochastic Gradient Descent\nHere the perceptron choose only misclassified, here in Stochastic Gradient Descent we would pick any point randomly. Even if it’s well classified already.\n\n\n\nNow the question is: how do I set this parameter \\(\\eta\\) the learning rate. The answer to that is a method that help us find that. It’s called Newton-Raphson"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#setting-learning-rate",
    "href": "blog/2023-10-04_logistic-regression/index.html#setting-learning-rate",
    "title": "Logistic Regression",
    "section": "12 Setting learning rate",
    "text": "12 Setting learning rate\nIt is a difficult task:\n\ntoo small —&gt; long time to reach minimum\ntoo big —&gt; bounce around and never converge"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#idea-use-2nd-derivative",
    "href": "blog/2023-10-04_logistic-regression/index.html#idea-use-2nd-derivative",
    "title": "Logistic Regression",
    "section": "13 Idea: Use 2nd Derivative",
    "text": "13 Idea: Use 2nd Derivative\nThe second derivative corresponds to the curvature of the loss function, thus\nThis captures the notion of curvature\n\n\n\n\nSmall second derivative –&gt; large learning rate\nSo if these two purple arrows are pointing in the same direction it means there their second derivative is small because there is no much change which then means we can increase the learning rate because there is still a curvature meaning we have not reach to global minimum\nLarge second derivative –&gt; small learning rate\nIn the second case with the green arrows, this time the second derivative is large because there is a substantial change from pointing down to now pointing in almost horizontal direction. Then that means that we are getting closer to a deep and this we want to make the learning rate small\n\n\n13.1 Computing 2nd Derivative (for scalar)\n\n\n\nHere the second derivative \\(\\frac{\\partial^2}{\\partial w_t^2}\\) represents the curvature of the loss function so the answer that we will show below is just the graph of how this curvature would look like.\n\n\n\n\nThe error curvature would be maximized when the model is uncertain. The intuition is that if you have a lot of points next to the decision boundary then\nIt is small when the model is certain.\n\n\n\n\nWhere we have introduce the normalization term"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#steepest-descent-vs-newton-raphson",
    "href": "blog/2023-10-04_logistic-regression/index.html#steepest-descent-vs-newton-raphson",
    "title": "Logistic Regression",
    "section": "14 Steepest DEscent vs Newton-Raphson",
    "text": "14 Steepest DEscent vs Newton-Raphson\n\n\n\n\nThus, we see tha the Newton-Raphson takes a more direct path because it considers the curvature of the error loss.\n\n\n\n\n\n\nDerivative of vector^T with respect to vector\n\n\n\n\n\nThe notation \\(\\partial (x^T) / \\partial x\\) represents the derivative of a row vector \\(x^T\\) with respect to a column vector \\(x\\). In this context, the derivative is a Jacobian matrix.\nIf \\(x\\) is an \\(n\\)-dimensional column vector and \\(x^T\\) is the corresponding \\(n\\)-dimensional row vector, then the derivative \\(\\partial (x^T) / \\partial x\\) is a \\(n \\times n\\) Jacobian matrix.\nEach element \\((\\partial (x^T)_i / \\partial x_j)\\) of this Jacobian matrix is the partial derivative of the \\(i\\)-th element of \\(x^T\\) with respect to the \\(j\\)-th element of \\(x\\). Since each element of \\(x^T\\) is just a scalar, this derivative is straightforward to calculate:\n\\((\\partial (x^T)_i / \\partial x_j) = \\delta_{ij}\\)\nwhere \\(\\delta_{ij}\\) is the Kronecker delta, which is equal to 1 when \\(i = j\\) and 0 otherwise.\nTherefore, the Jacobian matrix \\(\\partial (x^T) / \\partial x\\) is a diagonal matrix with 1s on the diagonal and 0s off the diagonal. It’s an identity matrix of size \\(n \\times n\\)."
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#newton-raphson-iterative-optimization",
    "href": "blog/2023-10-04_logistic-regression/index.html#newton-raphson-iterative-optimization",
    "title": "Logistic Regression",
    "section": "15 Newton-Raphson Iterative Optimization",
    "text": "15 Newton-Raphson Iterative Optimization\n\n\n\n\n\n\n\n15.1 What is the H?\n\n\n\n\nThe blue highlighted section means that we have taken the second derivative over the error of the log-likelihood which has a minus hence why the blue hihglited parts vary in order."
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#newton-rpahson-iterative-optimization",
    "href": "blog/2023-10-04_logistic-regression/index.html#newton-rpahson-iterative-optimization",
    "title": "Logistic Regression",
    "section": "16 Newton-Rpahson Iterative Optimization",
    "text": "16 Newton-Rpahson Iterative Optimization"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#faq",
    "href": "blog/2023-10-04_logistic-regression/index.html#faq",
    "title": "Logistic Regression",
    "section": "17 FAQ",
    "text": "17 FAQ\n\n\n\n\n\n\nWhat are linear features in binary classification?\n\n\n\n\n\nIn binary classification, linear features refer to features that can be effectively separated by a straight line (or a hyperplane in higher dimensions) when plotting them on a graph. These features are sometimes called linearly separable features because you can draw a line that cleanly separates the two classes, making it easy for a linear classifier like logistic regression or a linear support vector machine (SVM) to classify the data accurately.\nHere’s an example to illustrate linear features in binary classification:\nSuppose you are working on a binary classification problem to predict whether an email is spam (class 1) or not spam (class 0) based on two features: the number of words in the email and the number of times the word “free” appears in the email.\nYou collect data on various emails, and when you plot this data on a graph with the number of words on the x-axis and the frequency of the word “free” on the y-axis, you notice that spam emails tend to have fewer words and a higher frequency of the word “free,” while non-spam emails tend to have more words and a lower frequency of the word “free.”\nHere’s a simplified example:\n\nSpam Email A: 10 words, “free” appears 8 times\nSpam Email B: 12 words, “free” appears 10 times\nNon-Spam Email X: 20 words, “free” appears 2 times\nNon-Spam Email Y: 18 words, “free” appears 1 time\n\nIf you plot these data points on a graph, you might observe that you can draw a straight line that effectively separates the spam emails (class 1) from the non-spam emails (class 0). In this case, the number of words and the frequency of the word “free” are linear features, as they allow for a linear separation of the two classes.\nHere’s what the separation might look like (though in reality, the data might be more complex):\n\n\nCode\nimport matplotlib.pyplot as plt\n\n# Data points\nspam_emails = [(10, 8), (12, 10)]\nnon_spam_emails = [(20, 2), (18, 1)]\n\n# Unpack the data into separate lists\nspam_x, spam_y = zip(*spam_emails)\nnon_spam_x, non_spam_y = zip(*non_spam_emails)\n\n# Create the scatter plot\nplt.scatter(spam_x, spam_y, label='Spam Emails', marker='*')\nplt.scatter(non_spam_x, non_spam_y, label='Non-Spam Emails', marker='o')\n\n# Add labels and legend\nplt.xlabel('Number of Words')\nplt.ylabel('Frequency of \"free\"')\nplt.legend()\n\n# Add a straight line for separation (in this case, manually defined)\nplt.plot([15, 15], [0, 12], linestyle='--', color='gray')\n\n# Set plot limits and display\nplt.xlim(0, 25)\nplt.ylim(0, 12)\nplt.title('Linearly Separable Data for Binary Classification')\nplt.grid(True)\nplt.show()\n\n\n\n\n\nIn this example, you can see that a straight line can be drawn to separate the two classes, making the features (number of words and frequency of “free”) linear features for this binary classification problem."
  },
  {
    "objectID": "blog/2022-11-05_welcome/index.html",
    "href": "blog/2022-11-05_welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Welcome To My Blog\n        \n        \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                News\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                News\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          November 5, 2022\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\nThis is the first post in my blog. Welcome!"
  },
  {
    "objectID": "blog/2023-09-03_when-you-get-older/index.html",
    "href": "blog/2023-09-03_when-you-get-older/index.html",
    "title": "When you get older",
    "section": "",
    "text": "When you get older\n        \n        \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Poems\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Spanish\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Poems\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Spanish\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 3, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\nby Danilo Toapanta \n\nBlog  &gt; Poems\n\n\nWhen you get older my son\nYour hands start to become like raisins\nYour heart beats like one of those boats\nbut not like those new ones.\n\nWhen you get older son\nYour memories start to fade\nAs with your energy every day\nYou wonder son, how are my children doing\nAnd in a cozy chair your find yourself\nlost navigating in your memories\nthose years where your hands were not raisins.\n\nFor that reason my son\nif you see me agitated\nfragile like a leaf of autumn\nremember son\nyour father is just\nlike a brand new boat\nbut not like those new ones\nit is just a boat,\na boat that continues navigating\nwith more wisdom and firm pace.\n\nOh son, do not panic. If one day this boat\nhas decided to take its last ship\nThat day my son you will know this ship\nhas found the most valuable and precious secret\nAnd that day my son\nI will pass on you\nbefore my wood sinks and\nmy sails float in the sea of life.\n\nBe certain son,\nthat day you will then be armoured for a war\nand from the depth seas\nI will command you and guide your way\nexactly like my father did it\na couple of decades ago.\n\nWith love to Marcelo and Valerio Saico"
  },
  {
    "objectID": "blog/2023-08-18_how_to_use_widgets_in_jupyter_notebooks/index.html",
    "href": "blog/2023-08-18_how_to_use_widgets_in_jupyter_notebooks/index.html",
    "title": "How to use widgets in jupyter notebooks",
    "section": "",
    "text": "How to use widgets in jupyter notebooks\n                \n            \n                        \n                \n                    Description of this Notebook\n                \n            \n                        \n            \n                                            \n\n                    \n                                            \n                            \n                                All\n                            \n                         \n                                            \n                            \n                                TAGS\n                            \n                         \n                                            \n                            \n                                Python\n                            \n                         \n                    \n                    \n                                    \n                            \n        \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 18, 2023\n        \n      \n      \n        \n      \n      \n\n        \n                 Code\n            \n    \n\n\n\n\n\n\n    \n        How to use widgets in jupyter notebooks\n        \n        \n                    \n                \n                    Description of this Notebook\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 18, 2023\n        \n      \n      \n        \n      \n      \n\n    \n        Quick Links\n    \n         Quick Links:\n                                    \n                 Code"
  },
  {
    "objectID": "blog/2023-01-29_displaying-jupyter-notebooks/index.html",
    "href": "blog/2023-01-29_displaying-jupyter-notebooks/index.html",
    "title": "Displaying jupyter notebooks",
    "section": "",
    "text": "Example of a simple blog post using Jupyter Notebooks\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Analysis\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Testing\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Analysis\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Testing\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          January 29, 2023"
  },
  {
    "objectID": "blog/2023-01-29_displaying-jupyter-notebooks/index.html#polar-demo",
    "href": "blog/2023-01-29_displaying-jupyter-notebooks/index.html#polar-demo",
    "title": "Displaying jupyter notebooks",
    "section": "Polar Demo",
    "text": "Polar Demo\nFor a demonstration of a line plot on a polar axis, see Figure 1.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 1 * np.pi * r\nfig, ax = plt.subplots(\n    subplot_kw = {'projection': 'polar'}\n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\nFigure 1: A line plot on a polar axis\n\n\n\n\n\nHow to transform into a plot\n\nplt.figure(figsize=(4, 2))\n_ = plt.plot([3, 4, 2, 5])\n\n\n\n\n\nThis is gonna be a normal plot. The figure above\nWhen people think about using artificial intelligence (AI) for writing, they immediately jump to 1500-word articles and lengthy social media posts. And yes, these are use cases that AI writing assistants can help with.\nBut it’s only a fraction of what this technology can do.\nA high-quality paragraph generator transforms everyone on your team into a robust and well-rounded writer. Now anyone can create informative, engaging, and persuasive content one paragraph at a time – whether responding to a lead via email or creating a thought leadership piece to go viral.\nThat’s why, in a moment, we’ll show you how to use Cop.aiI’s paragraph generator to build any text-based asset you need.\nBefore diving in, though, let’s cover the basics and answer the following: what’s a paragraph generator, how do they work, and why would you want to use one?\n\n\n\nAnother Big boy\nWhen people think about using artificial intelligence (AI) for writing, they immediately jump to 1500-word articles and lengthy social media posts. And yes, these are use cases that AI writing assistants can help with.\nBut it’s only a fraction of what this technology can do.\nA high-quality paragraph generator transforms everyone on your team into a robust and well-rounded writer. Now anyone can create informative, engaging, and persuasive content one paragraph at a time – whether responding to a lead via email or creating a thought leadership piece to go viral.\nThat’s why, in a moment, we’ll show you how to use Cop.aiI’s paragraph generator to build any text-based asset you need.\nBefore diving in, though, let’s cover the basics and answer the following: what’s a paragraph generator, how do they work, and why would you want to use one?\n\n\n2.1 My template for you"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html",
    "href": "blog/2023-10-04_neural-networks/index.html",
    "title": "Neural networks",
    "section": "",
    "text": "Lecture Notes UvA on 26-9-2023\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          October 4, 2023\nThe only difference between the normal perceptron and the logistic regression its how we compute the activation function the f(x)\nThe perceptron cannot solve the XOR problem also the logistic regression. To get around this problem, we stack perceptron like in a layer fashion model. This is called Multilayer Perceptron\nBut because people start to use the logistic regression instead of the actual hardcore perceptron output (so \\(+1\\) or \\(-1\\)) then we now call it. Multilayer Logistic Regression\nSo instead of that we are gonna have different activation functions\nWe also talked about QDA this is a non linear model classifier\nWe call the computation from going to the input to the ouput as forward propagation\nThe number of parameters for Logistic Regression is \\(D+1\\) vs Gaussian Classifier contains \\(D^2\\). all these computation.\nSo when you get scared about the number of layers then you just remember the previous layers they were just a type of basis funtions and the last layer is a linear model like so:\nThe difference between linear models with adaptive basis is that the Neural Networks learn the basis functions.\nWith Neural Networks we do not have to have heuristics for this basis functions but they learn by themselves.\nWe see that to separate our data from above we can use one hidden layer with tree units:\nRecall from the previous lecture that with our Logistic Regression we neede to have some radial functions, the difference here its that we can now gotten learnt this basis functions with our Neural Network.\nNN start with low level features and keeps increasing until it calculates the features it find relevant to take a decision.\nIt is spacial invariant because you are moving your kernel along all dimensions."
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#universal-approximators",
    "href": "blog/2023-10-04_neural-networks/index.html#universal-approximators",
    "title": "Neural networks",
    "section": "1 Universal Approximators",
    "text": "1 Universal Approximators\nWe can find a number M and for the weights \\(\\textbf{w}^(2)\\) so the weights in the second layer. Here \\(M\\) represents the units aka the circles in a layer. See the green highlighted circles below\n\n\n\n\nIf we want the error to be to zero then we want the value of \\(M\\) to be larger and larger. This is because we fixed our NN to have only 2 layers so the only thing that can grow its the widht so \\(M\\) so the number of neurons (units). So with M its hard if you compute plenty of them because then you need a lot of GPUs.\nThe summary of the Universal Approximator is that width \\(M\\) is the one that matter. It is just one hidden layer and if you can make it big enough, so if you can increase \\(M\\) enough then you can fit approximate almost anything\n\n\n\n\nHere \\(\\textbf{w}^2 \\in \\mathbb{R}^{Mx1}\\) because if we want to compute only one single value at the end of the NN we need the dimensions of the vector to align see figure above"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#deep-neural-nets-and-shallow-neural-nets",
    "href": "blog/2023-10-04_neural-networks/index.html#deep-neural-nets-and-shallow-neural-nets",
    "title": "Neural networks",
    "section": "2 Deep Neural Nets and Shallow Neural Nets",
    "text": "2 Deep Neural Nets and Shallow Neural Nets\n\n\n\nHere we are saying that if we want to conserve the error lower as much as a Deep Neural Net, so that we can have a Shallow Neural Net then we need to increase the number of \\(M\\) or number of weights. But by doing so this scales exponentially.\nTo growth complexity you have to increase the width, but instead of this you can do it in the depth. As we will see in the slide below, Depth gives you more complexity so its preferable to increase depth instead of width\n\nWidth: \\(M\\) number of weights\nIf you want the error small then increase this number. However if you go this route the number \\(M(\\varepsilon)\\) grows exponentially\nDepth: \\(l\\) number of hidden layers.\nHere it gives you more complexity, so its recommended, End result have deeper NNs.\n\n\nThe point of the image above is to show that with the same model (3 hidden units and 1 linesr ouput unit) which is the Neural Network we can approximate these 4 functions."
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#expressive-power-relu-networks",
    "href": "blog/2023-10-04_neural-networks/index.html#expressive-power-relu-networks",
    "title": "Neural networks",
    "section": "3 Expressive power ReLU networks",
    "text": "3 Expressive power ReLU networks"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#network-training-regression",
    "href": "blog/2023-10-04_neural-networks/index.html#network-training-regression",
    "title": "Neural networks",
    "section": "4 Network Training: Regression",
    "text": "4 Network Training: Regression\nRemember computing the Maximum Likelihood is the same as the minimum of the negative log likelihood, that is why there is a minus on front the \\(\\ln p(\\textbf{t}|\\textbf{W},\\textbf{w})\\)"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#network-training",
    "href": "blog/2023-10-04_neural-networks/index.html#network-training",
    "title": "Neural networks",
    "section": "5 Network Training",
    "text": "5 Network Training\n\n5.1 Regression: Network Training\n\n\n\n\n\n5.2 Binary Classification: Network Training\n\n\n\n5.3 Classification with K classes: Network Training\n\n\n\nFor further explanation in class distribution take a look at here"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#losses-overview",
    "href": "blog/2023-10-04_neural-networks/index.html#losses-overview",
    "title": "Neural networks",
    "section": "6 Losses overview",
    "text": "6 Losses overview"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#training-neural-networks",
    "href": "blog/2023-10-04_neural-networks/index.html#training-neural-networks",
    "title": "Neural networks",
    "section": "7 Training Neural Networks",
    "text": "7 Training Neural Networks\nBecause we cannot find easily the mathematically solutions for training the NN, we use Gradient Descent\n\n\n\n\nResult of forward propagation. Depends on all the NN weights —&gt; Lots of local minima! It results in lots of local minima because we are updating simultaneously all the weights\nThat means that the loss function depends on all the parameters (all the weights in the NN) thus we have a lot of parameters to update.\n\n\n\n\nHere for instance we have 2 local minima and one unique global minima"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#neural-network-optimization-surface",
    "href": "blog/2023-10-04_neural-networks/index.html#neural-network-optimization-surface",
    "title": "Neural networks",
    "section": "8 Neural Network Optimization Surface",
    "text": "8 Neural Network Optimization Surface\n\n\n\n\nDespite these crazy optimization landscapes, gradient descent works amazingly well!\nFor large networks, many of the critical points are saddle-points, not local minima.\n\nAs our dimensionality increases, the saddle points will grow with respect to the minimum, but the minimam will also grow\n\n\n\nBecause of all these variation we want to always report uncertainties on performance. This uncertainties comes from randomness in initialization and Stochastic Gradient Descend SGD.\nThe idea is to report error by averaging over all these models in the same column.\nNow, we talked about making the learning rate higher at start and then slowly decreased it at training. This what we talk in the next topic:"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#cyclic-learning-rates",
    "href": "blog/2023-10-04_neural-networks/index.html#cyclic-learning-rates",
    "title": "Neural networks",
    "section": "9 Cyclic Learning Rates",
    "text": "9 Cyclic Learning Rates\nIt may seem crazy making the learning rate cyclic, so increase it again then lower it then increase it again. But this results in exploration so that you don’t end up in a local minima.\n\n\n\n\n\n\nWith cyclic learning rate we could explore three local minima\n\nNote: We used to compute Logistic Regression with Gradient Descent, here its the same with NN. More mathematically we cannot compute a closed form of the weights hence we use GD."
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#chain-rule-through-layers",
    "href": "blog/2023-10-04_neural-networks/index.html#chain-rule-through-layers",
    "title": "Neural networks",
    "section": "10 Chain Rule through Layers",
    "text": "10 Chain Rule through Layers\n\nForward Propagation: is to evaluate the full network from inputs to ouputs\nBackward Propagation: is to send error signals back though the network\n\n\n\n\nRemember \\(h_l = \\sigma(a)\\). Meaning the ouput of the sigmoid is the new \\(h_l\\). With this in mind because we want to tune the parameters aka weights we send the error back to the inputs, this as we said before it’s called backpropagation.\nNow, because we want to send the error back so that we can reduce it, we would compute the derivative. Here is the same, we will compute the derivatives and because the NN its like a chain of multiplication due to the chain rule, here we can make use of optimization techniques. That is:\n\nBackpropagation is simply the chain rule implemented with cached values of intermediate computations.\nWe have the tradeoff between computational complexity for memory. In other words we have saved in computation complexity (carry out many derivatives) because we have cached these \\(h_{l,j}\\) which is exactly the result of computing the derivatives to reduce the error and thus carry out backpropagation.\n\nIn summary when we do backprogation due to the symmetry of the hidden layers, we can save in computing all the times the derivatives and instead trade it for memory to cache these \\(h_{l,j}\\)\nThe above is what distinguishes the chain rule from backpropagation. Backpropagation uses the notion of reusing information."
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#downside-numerical-issues",
    "href": "blog/2023-10-04_neural-networks/index.html#downside-numerical-issues",
    "title": "Neural networks",
    "section": "11 Downside: Numerical Issues",
    "text": "11 Downside: Numerical Issues\n\n\n\nTwo things can go wrong with this approach:\n\nExploding gradients:\n\nProblem: The multiplication of an intermediate derivate value could be large so then wehn you continue multiplying with the rest of the layers then it will become a huge number.\n\nSolution: can usually be handled by ‘clipping’ values or regularizing weights to be small.\n\nVanishing gradients:\n\nProblem: When the ouput of the sigmoid is close to \\(1\\) or \\(0\\) we would have that the derivative \\(h_{l,j}*(1-h_{l,j})\\) where recall that \\(\\textbf{h}_l=\\sigma(\\textbf{a})\\) meaning when sigmoid evaluates to this extremes then the derivative would become zero. In other words, if zero because \\(h_{l,j}\\) can be \\(1\\) or \\(0\\) then all derivatives to earlier layers will be zero. See figure below:\n\n\n\n\nThe figure above then means that if one derivative becomes zero then learning cannot happen.\n\nPossible Solution1: there is no proper solution because if you say you want to clip this derivative not to yield \\(1\\) or \\(0\\) then your next question its to how much close to these extremes I should set the derivative. (In practice however the sigmoid will not evaluate to perfect \\(1\\) or \\(0\\) but it will be small enough to make the multiplication of the other derivatives in the chain rule significantly deleterious to proceed training).\n\nPossible Solution2: In the neural networks we add a line that connect the current output layer \\(h_l\\) with the previous outout layer \\(h_{l-1}\\)"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#scalar-neural-network",
    "href": "blog/2023-10-04_neural-networks/index.html#scalar-neural-network",
    "title": "Neural networks",
    "section": "12 Scalar Neural Network",
    "text": "12 Scalar Neural Network\n\n\n\n\nRecall that when we do linear regression we do not need to have an activation function \\(f\\) like softmax or logistic, we just have the identity which means \\(f(w_2 \\cdot h)\\) becomes just \\(w_2 \\cdot h\\).\n\n\n\n\n\n12.1 Computing the Error loss on \\(w_1\\)\n\n\n\nIf we would compute the error but now with activation function \\(a\\) equals Relu\n\n\n\nThis could be a bad idea because if \\(w_1 \\cdot x\\) is lower than \\(0\\) then the whole error loss would be evaluated to zero and thus cannot train the network because you keep getting derivatives of zero. This is called the Dead Relu problem. In practice people initialize the input to a positive value. Also people use Leaky Relu depicted below"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#vector-neural-network",
    "href": "blog/2023-10-04_neural-networks/index.html#vector-neural-network",
    "title": "Neural networks",
    "section": "13 Vector Neural Network",
    "text": "13 Vector Neural Network\n\nWe will have a scalar input and scalar ouput but with hidden layers as vectors.\n\n\n\n\n\n\n\nNote\n\n\n\n\nDerivative is a row vector: \\[\n\\begin{align}\n\\frac{\\partial f}{\\partial \\textbf{x}} = \\left[\\frac{\\partial f}{\\partial x_1},...,\\frac{\\partial f}{\\partial x_D} \\right]\n\\end{align}\n\\]\nGradient is the transpose of the Derivative vector: \\[\n\\begin{align}\n\\nabla_{w_1}f = \\left[\\frac{\\partial f}{\\partial \\textbf{w}_1} \\right]^T\n\\end{align}\n\\] We do the transpose because we are tryng to get the same shape as our paramter \\(\\textbf{W}\\). So in this case if \\(W\\) would have been a two-row vector then with the transpose we ensure that."
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#computations-in-2d",
    "href": "blog/2023-10-04_neural-networks/index.html#computations-in-2d",
    "title": "Neural networks",
    "section": "14 Computations in 2D",
    "text": "14 Computations in 2D\n\n\n\nA rule of thumb is:\n\nOutput linear operator Rows\nThe model parameters as Columns"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#two-modes-forward-and-reverse",
    "href": "blog/2023-10-04_neural-networks/index.html#two-modes-forward-and-reverse",
    "title": "Neural networks",
    "section": "15 Two Modes: Forward and Reverse",
    "text": "15 Two Modes: Forward and Reverse\nIn Pytorch, you can compute the forward or reverse computation we saw before. The only difference is which direction you cache from.\n\nForward mode: you start with the partial derivatives at the beginning of the NN. For instance in the image below, from dh1/dw1 (the first layer) to df/dh2 (the last layer).\n\nBetter when ouput dim &gt;&gt; input dim\n\n\n\n\n\n\nReverse mode: you start from the ouput to the input.\n\nBetter when ouput dim &lt;&lt; input dim\n\n\n\n\n\n\nThis is telling us that i.e to be more efficient in an image classifier then you would prefer the Reverse mode because you have that your input would be a huge array of numbers whereas your ouput would be a few classes. So here it applies: dim ouput &lt;&lt; dim input.\nThe reason for ie in forward mode is that you would compute small derivatives because your input is small so then you delay to compute much more multiplication to the end\nAnother examples why is more efficient, say your outputs &gt;&gt; inputs, then if you start by computing the ouput derivatives then you are going to accumulate and carry all those dimensions due to the large ouput derivatives. Then you carry all these computations to the input layer that has fewer computations but you already have a hug baggage and its not efficient. Summary: you want to do the large multiplication until the end so that you do not carry unnecessary derivation."
  },
  {
    "objectID": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html",
    "href": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html",
    "title": "Maximum Likelihood vs Maximum a Posteriori Estimation",
    "section": "",
    "text": "MLE vs MAP in the context of parameter estimation\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 26, 2023"
  },
  {
    "objectID": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#definition",
    "href": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#definition",
    "title": "Maximum Likelihood vs Maximum a Posteriori Estimation",
    "section": "Definition",
    "text": "Definition\nMaximum Likelihood Estimation (MLE) and Maximum A Posteriori Estimation (MAP) are two common statistical methods used for parameter estimation in various fields, including machine learning and statistics. They are often used in the context of estimating parameters of a statistical model or distribution. Here are the key differences between MLE and MAP:"
  },
  {
    "objectID": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#objective",
    "href": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#objective",
    "title": "Maximum Likelihood vs Maximum a Posteriori Estimation",
    "section": "Objective:",
    "text": "Objective:\n\nMLE (Maximum Likelihood Estimation): MLE aims to find the parameter values that maximize the likelihood function, which measures how well the observed data fits the model. In other words, it seeks the parameter values that make the observed data most probable under the assumed model.\nBasically, I have prob density ie a Gaussian. I take its log and then compute the derivate of it w/ rspect to some variable of interest i.e \\(\\mu\\), or \\(\\underline{w}\\)\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generate random data from a Gaussian distribution\nmean = 0  # Mean of the Gaussian distribution\nstd_dev = 1  # Standard deviation of the Gaussian distribution\nsample_size = 10000  # Number of data points\n\ndata = np.random.normal(mean, std_dev, sample_size)\n\n# Create a figure with two subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3))\n\n# Plot the Gaussian distribution on the left subplot\nax1.hist(data, bins=50, density=True, color='blue', alpha=0.7, label='Gaussian Data')\nax1.set_xlabel('x')\nax1.set_ylabel('PDF')\nax1.set_title('Gaussian Distribution')\nax1.grid(True)\n\n# Calculate the PDF of the Gaussian distribution for plotting\nx = np.linspace(mean - 4 * std_dev, mean + 4 * std_dev, 1000)\npdf = norm.pdf(x, mean, std_dev)\n\n# Plot the log PDF on the right subplot\nlog_pdf = np.log(pdf)\nax2.plot(x, log_pdf, 'r-', label='Log PDF of Gaussian')\nax2.set_xlabel('x')\nax2.set_ylabel('Log PDF')\nax2.set_title('Log PDF of Gaussian Distribution')\nax2.grid(True)\n\n# Show legends\nax1.legend()\nax2.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nMAP (Maximum A Posteriori Estimation): MAP, on the other hand, incorporates prior information about the parameters into the estimation process. It seeks the parameter values that maximize the posterior probability, which combines the likelihood of the data and the prior probability of the parameters.\n\n\n\n\n\n\n\nWant to know more?\n\n\n\n\n\n\nIncorporation of Prior Information:\nMLE: MLE does not consider any prior information or beliefs about the parameters. It solely relies on the likelihood of the observed data. MAP: MAP explicitly incorporates prior beliefs or information about the parameters through the prior probability distribution. This makes MAP especially useful when you have some prior knowledge about the parameters.\n\n\nFormulation:\nMLE: The MLE estimate for a parameter is obtained by maximizing the likelihood function, typically by taking the derivative of the likelihood function with respect to the parameter and setting it to zero. MAP: The MAP estimate for a parameter is obtained by maximizing the posterior probability, which is proportional to the product of the likelihood and the prior probability. Mathematically, it involves finding the mode of the posterior distribution.\n\n\nRobustness to Small Sample Sizes:\nMLE: MLE can be sensitive to small sample sizes because it tends to overfit the data when the sample size is small. MAP: MAP can provide more stable estimates in situations with limited data because it incorporates prior information, which can act as regularization.\n\n\nInterpretability:\nMLE: MLE estimates tend to be more data-driven and may not incorporate external knowledge. They are often considered more objective. MAP: MAP estimates can be influenced by prior information, which can introduce subjectivity into the estimation process. The choice of the prior distribution can significantly impact the MAP estimates.\nIn summary, the main difference between MLE and MAP is the incorporation of prior information. MLE seeks the parameter values that maximize the likelihood of the data, while MAP combines the likelihood with prior information to find parameter values that maximize the posterior probability. The choice between MLE and MAP depends on the specific problem and the availability of prior knowledge about the parameters."
  },
  {
    "objectID": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#incorporation-of-prior-information",
    "href": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#incorporation-of-prior-information",
    "title": "Maximum Likelihood vs Maximum a Posteriori Estimation",
    "section": "Incorporation of Prior Information:",
    "text": "Incorporation of Prior Information:\nMLE: MLE does not consider any prior information or beliefs about the parameters. It solely relies on the likelihood of the observed data. MAP: MAP explicitly incorporates prior beliefs or information about the parameters through the prior probability distribution. This makes MAP especially useful when you have some prior knowledge about the parameters."
  },
  {
    "objectID": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#formulation",
    "href": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#formulation",
    "title": "Maximum Likelihood vs Maximum a Posteriori Estimation",
    "section": "Formulation:",
    "text": "Formulation:\nMLE: The MLE estimate for a parameter is obtained by maximizing the likelihood function, typically by taking the derivative of the likelihood function with respect to the parameter and setting it to zero. MAP: The MAP estimate for a parameter is obtained by maximizing the posterior probability, which is proportional to the product of the likelihood and the prior probability. Mathematically, it involves finding the mode of the posterior distribution."
  },
  {
    "objectID": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#robustness-to-small-sample-sizes",
    "href": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#robustness-to-small-sample-sizes",
    "title": "Maximum Likelihood vs Maximum a Posteriori Estimation",
    "section": "Robustness to Small Sample Sizes:",
    "text": "Robustness to Small Sample Sizes:\nMLE: MLE can be sensitive to small sample sizes because it tends to overfit the data when the sample size is small. MAP: MAP can provide more stable estimates in situations with limited data because it incorporates prior information, which can act as regularization."
  },
  {
    "objectID": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#interpretability",
    "href": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#interpretability",
    "title": "Maximum Likelihood vs Maximum a Posteriori Estimation",
    "section": "Interpretability:",
    "text": "Interpretability:\nMLE: MLE estimates tend to be more data-driven and may not incorporate external knowledge. They are often considered more objective. MAP: MAP estimates can be influenced by prior information, which can introduce subjectivity into the estimation process. The choice of the prior distribution can significantly impact the MAP estimates.\nIn summary, the main difference between MLE and MAP is the incorporation of prior information. MLE seeks the parameter values that maximize the likelihood of the data, while MAP combines the likelihood with prior information to find parameter values that maximize the posterior probability. The choice between MLE and MAP depends on the specific problem and the availability of prior knowledge about the parameters."
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html",
    "href": "blog/2023-11-13_sequence-labelling/index.html",
    "title": "Sequence Labelling",
    "section": "",
    "text": "Description of this Post\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                NLP\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                NLP\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          November 13, 2023"
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#representing-and-estimating-categorical-distributions-the-logistic-case",
    "href": "blog/2023-11-13_sequence-labelling/index.html#representing-and-estimating-categorical-distributions-the-logistic-case",
    "title": "Sequence Labelling",
    "section": "1 Representing and estimating Categorical distributions: the logistic case",
    "text": "1 Representing and estimating Categorical distributions: the logistic case\n\n\n\n\nW is condition on the Random variable H, which can be a history\n\nf = is a function of the history \\(h\\) and has some parameters \\(\\theta\\)\nf is not a real value but a collection of probability values\nW = word\nIt can take on \\(V\\) categories, so W can take on \\(V\\) possible assignments\nV = vocabulary size\nH = history h the history can take as many values as possible i.e (BOS, a), (BOS, an), (BOS, some)\n\nIf you take a single row then all these values would add up to 1\nA Tabular representation is table look up operation. The yellow row represents then one \\(\\textbf{f}=\\theta_{row=h}^{col=1...V}\\)\nThen we need to think the function\n\\[\n\\textbf{f}(h; \\theta)\n\\]\nas a mechanism to predict vectors from the conditional information"
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#logistic-representation-of-categorical-cpds",
    "href": "blog/2023-11-13_sequence-labelling/index.html#logistic-representation-of-categorical-cpds",
    "title": "Sequence Labelling",
    "section": "2 Logistic Representation of Categorical CPDs",
    "text": "2 Logistic Representation of Categorical CPDs\nCPDs= Conditional Probability Distribution\nWhat we are predicting with this Categorical distribution is the probabilities per each W under the condition of an \\(h\\) so on a row. Essentially we are predicting every single entry in the tabular representation. I am interest then to map these to\n\n\n\n\nafter each conditional information has been mapped to a point, I will map those points to a different space. I want a vecgor with \\(V\\) probabilities in it, one per each possible outcomes of the random variable \\(W\\).\n\n\n\n\nHere we have \\(\\phi\\)(small,birs) \\(\\in \\mathbb{R}^{2}\\) so in 2D that means I need my \\(W_1\\) also to be in 2D so when I multiply with \\(\\phi\\)(small,birs), I get an scalar value. \\(b_1\\) is just an scalar.\nThese last row \\(\\textbf{S}\\) is called vector of ‘Logits’ these can be large or negative to turn this into a vector inside the probability simplex we can use Softmax. Note we go from the dimensional space to logits throught a lienar model. And then from logits to probabilities with a Softmax function\nThe \\(n\\)-dimensional probability simplex, denoted as \\(\\Delta^n\\), is defined as:\n\\[\n\\Delta^n = \\left\\{ (p_1, p_2, \\ldots, p_n) \\mid p_i \\geq 0, \\sum_{i=1}^n p_i = 1 \\right\\}\n\\]\nHere, \\(p_i\\) represents the probability of event \\(i\\), and the conditions \\(p_i \\geq 0\\) and \\(\\sum_{i=1}^n p_i = 1\\) ensure that the vector lies within the simplex.\n\n\n\n\nThe model can turn the h into a vector of \\(V\\) probabilities. so the \\(\\textbf{f}_1(h,\\theta), \\textbf{f}_2(h,\\theta)...\\)\n\n2.1 Why is this a great idea?\n\n\n\n\n\nThe model size is a function of how many \\(w\\)s we have. So the model is very compact, because it does not depend on how many instances of h, because we have this basis function \\(\\phi\\) that maps it to the proper dimensions so that we can multiply it with \\(W^T\\)\nHistories are conditional information are no longer treated as unrelated to one another, now in fact are related to each other trhough their features. Because of these relatedness linear models work, because they find patterns that we can code in a tabular reprsentation\n\n\nSuppose you condition on a sentence to draw a prob of a label/class.\nImagine you have 5 labels/classes, the thing that you condition can be represented by a feature function that gives you D-dimensional features so we are talking about \\(\\phi(h) \\in \\mathbb{R}^D\\). For each of those dimensions you would weight them towards a class, for instance if you have \\(K\\)-classes, so \\(KD\\). Note \\(K=V\\)\nEach feature gets a relevance an importance score towards a class and each class get a bias \\(b\\). You can think of \\(b\\) of how usefull this class is, or how generally present it is in the data regardless of context.\nSo per feature, per class you have a real number \\(KD\\) + \\(K\\) (from the bias) for each of the possible classes in my hypothetical example"
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#estimation-example",
    "href": "blog/2023-11-13_sequence-labelling/index.html#estimation-example",
    "title": "Sequence Labelling",
    "section": "3 Estimation example",
    "text": "3 Estimation example\nHow do we estimate the W_s and the b_s\n\nWe get data as pair, where we have \\(h_n\\) as a conditional variable & \\(w_n\\) an assigment of the outcome variable\nOur model would be log-linear it will map from the history through a feature function it will map histories to a vector of probability values of the correct dimensionality\n\\(s\\) = W\\(\\theta\\) + b is called the parametric function. Through this \\(s\\) our model predicts from any history h a complete categorical mass function with \\(V\\) values\n\nTo learn the parameters we initialize it, and then we compute the log likelihood of the parameters \\(\\theta\\) give our data \\(D\\). This can be solve due to the idd assumption.\n\n\n\n\nWhen we solve for the grad wrt. \\(\\theta\\) we do not get a closed-form solution like we get in the tabular representation. Thus we use an iterative procedure aka SGD.\nMatmul is the same as doing dot product but for matrices take a look at this link\nExample:\n\n\n\n\ncode at Colab"
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#start-of-lecture",
    "href": "blog/2023-11-13_sequence-labelling/index.html#start-of-lecture",
    "title": "Sequence Labelling",
    "section": "4 Start of Lecture",
    "text": "4 Start of Lecture\n\n\n\n\nSlide 2\n\n\n\n\n\n\n\n\n\n\nSlide 5\n\n\n\n\n\n\n\n\nSlide 6"
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#why-do-we-want-to-classify-words-in-classescategories",
    "href": "blog/2023-11-13_sequence-labelling/index.html#why-do-we-want-to-classify-words-in-classescategories",
    "title": "Sequence Labelling",
    "section": "5 Why do we want to classify words in classes/categories",
    "text": "5 Why do we want to classify words in classes/categories\n\n\n\n\nSlide 7\n\n\n\n\nReduce the number of dimensions like in bigrams only consider the nouns and adjectives and that is to measure the sentiment of a review. So here we refer to feature as the \\(\\phi(h)\\) so if we reduce this feature vector say \\(D\\) to a less than \\(D\\) i.e in bigrams \\(D=2\\) then we save memory and reduce the dimensions\n\n\n\n\n\nSlide 9\n\n\n\n\nIn out tabular CPDs we are force to treat each words as if they are unrelated to each other, but that is not trueth because as we sa before we can have relatedness i.e adjectives preceed nouns.\nSo to capture relatedness the categorization of words can capture that.\n\nFor example how to classify them:\n\n\n\n\n\nSlide 10\n\n\n\n\n\n\n\n\nSlide 11\n\n\n\n\nOnce we have categorized we can even not use the words because we know already its categories and we know that we this categorization a sentences would be like noun + adjective, so then we dont need the actual word but rather just its category.\n\nCalled the above a mapping. Note this could not be good enough in some instances. A reason why to do this is so that we reduce the dimensionality space.\n\n\n\n\n\nSlide 12\n\n\n\n\nHere an example of how people classify unambiguously\n\n\n\n\nSlide 13\n\n\n\n\n\n\n\n\nSlide 14"
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#how-to-annotate-words-with-part-of-speech-pos-using-peen-style",
    "href": "blog/2023-11-13_sequence-labelling/index.html#how-to-annotate-words-with-part-of-speech-pos-using-peen-style",
    "title": "Sequence Labelling",
    "section": "6 How to annotate words with Part Of Speech (POS) using Peen Style",
    "text": "6 How to annotate words with Part Of Speech (POS) using Peen Style\n\n\n\n\nSlide 15\n\n\n\n\n\n\n\n\n\nSlide 17\n\n\n\n\nThis is a join distribution\n\n\n\n\n\n\n\n\nSlide 18\n\n\n\n\nRecall we model text as a join distribution over all available tokens\nNow we model POS_tagged text: joint distribution over text and their POS tags\n\nOur goal is to assigned probabilities to the sequence paits \\((w_{1:l}, c_{1:l})\\)\n\n\n\n\n\nSlide 19\n\n\n\n\n\nRecall \n\n\n\n\n\nSlide 20\n\n\n\n\n\nW Words is a random variable for us, are tokens in Caligraphic_W (a vocabulary of symbols) that I know. The size of the vocabulary is V\nw is an specific word\nC is for Category and is a random variable, that are in Caligraphic_C (the tagset). The size of the tagset is K\nc is an specific tag\nX is a random sequence (our token sequence from lst week), from words from one until the lenght L in order\n\\(w_{1:l}\\) is a sequence of l words from the Caligraphic_W w/ vocabulary size V\nY is a random sequence\n\\(c_{1:l}\\) is a sequence of l tags from the Caligraphic_C w/ tagset size K\n\n\n\n\n\nSlide 21\n\n\n\n\nNow we want a distribution over the cross product of all Text and all Tags sequence: \\(w_{1:l}, c_{1:l}\\). This is an enormous space\n\n\n\n\nSlide 22\n\n\n\n\nYou can do two things with this:\n\nFor instance, I give you the ‘little cat’ and you want to know what is the prob sequence under the model. You can compute the possible probability sequence given that you give me a certain token sequence and then I could look for what maximizes this probability\nAnother we can do a language model, a language model was a mechanism to assign probabilities to strings without any tags, BUT if you get a distribution over two variables, token sequences and class sequences and you marginalized out one of the variables. ie you marginalized my choice for the first class, for the second class, all the way to the last class. If I sum the probabilities of all possible tag sequences that pair with these word sequence then I get a marginal probability. So in the above equation, the left part:\n\n\n\n\n\nSo that is the probability of a sentence so \\(P_X(w_{1:l})\\) this is a language model.\nSo once you design a model that can assign join probabilities to labeled sequences of words then you can use it to either:\n\ntag news sequences of words with their respective categories or\nassign prob to a sequence of words, regardless of which classes they have been annotated\n\nRemember NB classifier you can do:\n\nyou can annotate what is the most probable class of a document\nassign prob to a document regardless of their class (is the denominator of the NB model). Note the den of Bayes rule is the marginal\n\nThis second step is common to all generative model. Every time you have\n\n\n\n\nC1..C3 is the class tha sits at position 1..3\n\n\n\n\nSlide 23\n\n\n\n\nLast time we created a distribution and we created a new one, by chopping out sequences and working with probabilities for words given a short history, now we will do something similar but this time we are gonna built a distribution with pairs of sequences\n\n\n\n\nSlide 24\n\n\n\n\nSteps: a way of describing the generation of a tag sequence pair. And wathever we call step that is the unit we are gonna sign probabilities to.\n\n\n\n\n\n\n\n\n\n\n\n\nMarkov Model Assumption\n\n\n\n\nHere is this image we have assume Markov assumption\nAt the tag level it looks like a bigram model and not somethingelse, we have made the assumption that when we have generated certain variable I can forget a lot of the precedding context all the classes that ocurred before except for the last one and even all the words that were generated before so this conditional independence is a markov assumption.\n\nWhy is hidden? originally it was decided so that you do not get to see which class is for each on every position, these are latent variable. Latent variables are the variables you pretend there is there but you dont observe its value. We do this because it makes modelling easier or more usefull for a certain purpose. Here we are observing both, the token sequence and the tag sequence but if you would not see the tag sequence yet pretend that it exists a modeling desing choice and it will be hidden for you.\n\n\n\nAt the class level this looks like a bigram because when we genreate a symbol. For instance when you generates a symbol for isntance when you generate ‘is’ (when VERB is generated) we can use the fact that you have just generated a NOUN this is like a bigram. To generate one word you can condition on the previous one but this time we are not generating words but are generating tag sequences\nThis model starts with the tag sequence not from the text , isnt that weird? Not really the NB started from class not from the text you generate the class and given the class you generate the words in the text with a conditional independence\nSo at the tag level we are doing bigrams language modelling, the orange stuff exits even without the blue stuff, so the orange stuff is never conditioning on the words. But the words comes from somewhere, from their ‘categories’. I.e if I would generate a verb and I know is a verb, isnt it easier to assign lower probabilities to nouns, I already know is a verb so maybe that in its own is gonna lead to conditional distributions that are much more compact because the set of verbs are more compact than the set of all words\n\nIt is not because of the factorization starts with classes and then generates words, that can be the other way around, we can observe a word sequence and ask: what is the most probable tag sequence.\nWhat is a factorization? It is a decomposition of products see next slide. So I decomposed the enttire sequence pair (the orange sequence and the blue sequence) into the probabilities of the number of circles with an arrow pointing to them.\n\nThe trick again you add the BoS and EoS, why do I do that? because I know that for every class I am generating there is something before to condition before (except in the first class that is why BoS fixes that) and the second reason is that I give to every single symbol a chance to be part of the conditional context that is what EoS is helpful for. In the img above it translates to also given teh punctuation a chance to assign the probability of a sequence ending\n\n\nLets imagine the following, lets take the words away just leave the categories? Now if we were an HHM so a model, then the question is give me a VERB. Then the answer is tha there is no way I would get the same verb twice. Some poeple reply: jump other: run so there is a ot of variation.\nBecause our model is not that advanced our model can: - describe statistical patterns of pair of classes that ocurr in a relative order, - it can explain the distribution of our words given the categories\nIn more concrete notes: the model can lear for instance that 80% of the time VERBS appear after right after NOUNS but it cannot sample the noun and the verb, the actual words together. You can get book is or book are, there is no agreement there which verb it will be.\nIs there a trap where it goes NOUN VERB NOUN VERB … but this is very unlikely if we do MLE it is very unlikely to fall in this trap because you would not see this traps in the data. It is unlikely if you do MLE, but if you start fideling with smoothing things get really weird.\nEvery time that a history h is given, this corresping 1:1 to a factorization, which we can get it whit the chain rule as follows:"
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#hidden-markov-model",
    "href": "blog/2023-11-13_sequence-labelling/index.html#hidden-markov-model",
    "title": "Sequence Labelling",
    "section": "7 Hidden Markov Model",
    "text": "7 Hidden Markov Model\n\n\n\n\nSlide 26\n\n\n\n\nIn the slide above we forgot in the same qual to write above ‘idd’ assumption.\nThe \\(w_i\\) here is the word that is emitted for that particular class. We call that an emission probability"
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#generative-history",
    "href": "blog/2023-11-13_sequence-labelling/index.html#generative-history",
    "title": "Sequence Labelling",
    "section": "8 Generative History",
    "text": "8 Generative History\n\n\n\n\nSlide 27\n\n\n\n\nWe can sample from an HMM by following the history.\n\nstart two sequence the token sequence (the words) and the label sequence (c_0 = BOS)\nCondition on the previous class so that is c_0 so condition on BOS, and extend Y with BOS. Whatever class you get extend your sequence to Y and move on. Here we use the transition distribution. Here the P(c_i|c_i-1) would be the transition distribution\n\n^ Here we draw a c_i and that we use for the next step\n\nCondition on current class c_i and draw a word w_i with probability P_w|c(w_i_i). So when we say random we meant np.random.choice([vector], weights=P_w|c(w_i_i)). Whatever word you get extend your sequence to X and move on\nFor instance you can get a Determiner, so do P_w|c(w_i)) and draw a word from it. Here we use the emission distribution.\n\nIf your sequence is too long then stop. And this would be the factorization of the HMM\n\n\n\n\nHere in the picture you start with BoS, then you fo to DET and then to the and then to NOUN and book and so on..\nWhich tasks is this model use for? in 2023 none.\n\n\n\n\nSlide 28\n\n\n\n\nIn the trasition distribution we would go from the prev class called ‘\\(r\\)’. Once you know it you can retrieve \\(K\\) probabilities one for each of the tags that you may trasition to. For instance \\(K=10\\) so NOUN, VERBS, ADJ, … so given one of them which we call it i.e ‘\\(r=DETERMINER\\)’ then I can retrieve \\(K\\) numbers which I called them \\(\\lambda_1, \\lambda_2 ... \\lambda_K\\) And these are the probability values for the conditional probability of drawing a NOUN given a DETERMINER, a VERB given a DETERMINER, a ADJECTIVE given a DETERMINER, ….\nNow for the Emission distribution or W|C, we need to specify:\n\nWhat are you emitting from, which class ie. a VERB, that is the little ‘\\(c\\)’. Once you know what are you emitting from, then you can retrieve a collection of \\(V\\) numbers which are \\(\\theta_1,\\theta_2,.. \\theta_V\\). These are the probability from which you draw a certain word in the vocabulary of known words given that you are emitting from little ‘\\(c\\)’ category.\n\nOnce you have all these tabels all the tabular representation, now you can assign a probability to any sequence pair by taking the product of the relevant number. So go to the entry (row) of the table that conditions on the previous tag and find the probability (per each column) of the current tag. Or go to the table of emissions find the row that corresponds to the current class and multiply the probability of generating the current word given that class so multiply it with the (emission distribution). You will find values from each of the tables and you will multiply them together"
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#example",
    "href": "blog/2023-11-13_sequence-labelling/index.html#example",
    "title": "Sequence Labelling",
    "section": "9 Example",
    "text": "9 Example\n\n\n\n\nSlide 29\n\n\n\n\n\n\n\n\nWhat is the difference between this and what was done last time?\nAt an abstract level we have two sets of outcomes, we have a token sequence and a class sequence and there is also some difference in the parametrisation like what condition independences we make but the two are familiar and the tables are also familiar\nWhich then leads to the following question:"
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#r-rightarrow-c",
    "href": "blog/2023-11-13_sequence-labelling/index.html#r-rightarrow-c",
    "title": "Sequence Labelling",
    "section": "10 \\(r \\rightarrow c\\)",
    "text": "10 \\(r \\rightarrow c\\)\n\nNow I give you data and I want to estimate the values of our parameters and I choose MLE, I give you data, meaning I give you word sequences (aka sentences i.e ‘A nice dog’) for which you know the type sequences (so their PoS: DETERMINANT, ADJECTIVE&lt; NOUN).\n\nThe question is then what is the probability of transition from a tag r –&gt; to a tag c i.e r=DETERMINANT, and c=NOUN. What is the probability?\n\nWe do not need Bayes RUle, we would need it if my query is not a parameter, for i.e if I ask what is the prob of the prev tag given that I know the current, then that is reversive the model so that is what you use Bayes Rule for.\nOur case is different we are asking a query that is a parameter of the model, the probability of given a class generating the next.\n\n10.1 The question:\n\n\nWhat is the probability of transition from a tag r –&gt; to a tag c i.e r=DETERMINANT, and c=NOUN. What is the probability?\n\n\n\n\n\n10.2 The answer:\n\n\n\n\nSlide 32\n\n\n\n\nSo how many times I have seen a DETERMINANT that was follow by a NOUN divided by the how many times you have count DETERMINANT follwed by anything\nThis is the solution for MLE: count(condition_on=DETERMINANT, the_outcome=NOUN)/sum_k count(DETERMINANT,k). The later means the DETERMINANT pair with any other tag from the tag set\nWhere k is any possible outcome in the set of things that you know"
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#c-rightarrow-w",
    "href": "blog/2023-11-13_sequence-labelling/index.html#c-rightarrow-w",
    "title": "Sequence Labelling",
    "section": "11 \\(c \\rightarrow w\\)",
    "text": "11 \\(c \\rightarrow w\\)\n\n11.1 The question:\n\n\nWhat is the probability of generating w given c?\n\n\nThe model choice is an HMM the dataset is the ‘A nice dog’, the algorithm of choice is MLE.\n\n\n11.2 The answer:\nThe expression to compute the mission probability. So what is the probaility of emission of w given that have just generated class c.\n\n\n\n\nSlide 34\n\n\n\n\nNote: here in the denominator is the same, sum over all V with c, being fixed\n\n\n\n\nSlide 35\n\n\n\n\nThis approach still suffers from Data Sparcity, so the data contains plenty of zeros. For instance unseen word-tag pairs or unseen tag-tag pairs that are not too frequent and that we have not seen but this could happen. This can also happen as you tag set grows really large and maybe the tag set for a language like Arabic, Turkish, etc, i.e for these languages the tag set is really large so then maybe the transition probabilities aren’t easy to estimate. On the other hand, emission probabilities can be really sparce in the sense that i.e a language like Czeck or Portuguess where you have many word forms that are slight variation of the same thing and all have the same category so you would need a lot of data before you have seen every noun pop up or every verb.\nThis is less sparce compared to NGram LM where you have more data sparcity i.e because you need to memorize long phrases so is easy to find phrases that you have never seen thus creating sparcity.\n\nIn this sense, HMM are more compact than Ngram LM, but what is the limitation with this?\n\nLimitation\n\nWhen we generate a word all we know is a class, is hard to believe that if I sample from this model I would get nice sentences. I will get words that, if I extract from what they are and think only about the categories, then the trnasition from class to class would make sense, but when we look at the semantics (so the words then make no sense) i.e An furious bottle. The tags (A determinant then an adjective and then a noun) are okay but the semantics do not make sense\n\n\n\n\n\n\n\nPoS: DET, Prenomial ADJ Examples\n\n\n\n\n\n\n12 Examples of determinats can be:\n\nDeterminers (DET):\n\na: I saw a cat in the garden.\nan: She has an apple in her hand.\nthe: The sun is shining brightly.\nthis: I would like this book, please.\nsome: Can I have some water?\n\n\n\n\n13 Examples of Prenomial adjectives:\nPrenomial adjectives are adjectives that come before the noun they modify. Here are some examples of prenomial adjectives:\n\nThe red apple\n\n“red” is a prenomial adjective modifying the noun “apple.”\n\nA beautiful sunset\n\n“beautiful” is a prenomial adjective describing the noun “sunset.”\n\nThree large elephants\n\n“large” is a prenomial adjective indicating the size of the noun “elephants.”\n\nAn old book\n\n“old” is a prenomial adjective modifying the noun “book.”\n\nThe happy child\n\n“happy” is a prenomial adjective describing the noun “child.”\n\nSeveral interesting movies\n\n“interesting” is a prenomial adjective modifying the noun “movies.”\n\n\nThese examples illustrate how adjectives are positioned before the nouns they modify in a sentence.\n\n\n\n\n\n\nSyntactics\n\n\nWhen something is syntactically correct, it means that it adheres to the grammatical rules of a given language\n\n\nSyntax are the rules that dictate the order of words in a sentence and how they are structured to convey meaning.\nSemantic content of a sentence refers to the meaning or information conveyed by the arrangement of words and the relationships between them.\nGrammar\n\n\nGrammar rules refer to the set of structural and syntactic principles that govern how words are combined to form meaningful sentences and phrases in a language. These rules define the relationships between different elements of a language, such as nouns, verbs, adjectives, adverbs, and other parts of speech\n\nThis model main caveat is therefore if I abstract the words to which Category they belong, then they almost look like correct words i.e NOUN, VERB, ADVERB. But when we look at the semantic content it makes no sense\nAnother example you have a singular NOUN with a plural VERB\nHMM then are not able to make sentences but its able to cluster the words according to some vague distribution\n\n\n\n\n\n\nSlide 39\n\n\n\n\nThere is two things you can do with an HMM:\n\nObtain a tag sequence when you dont know it. So you know the word sequence and you ask: Give me the most probable tag sequence\nYou can use it as a Language Model\n\n\n\n\n\nSlide 40\n\n\n\n\nUnder this model, it spits out a tag sequence that is most probable. How do we evaluate this task sequence? you compare it to the tag sequence that is annotated in the dataset for you because PoS tag is almost unambiguous. For instance we will all agree of a tag sequence of english. So you compute the performance of the model as if you would in a classifier but instead of classifying once you have many classifications steps. You have one per step of the sequence so you compute accuracy. So then the performance is evaluate as accuracy across tag set."
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#examples-of-determinats-can-be",
    "href": "blog/2023-11-13_sequence-labelling/index.html#examples-of-determinats-can-be",
    "title": "Sequence Labelling",
    "section": "12 Examples of determinats can be:",
    "text": "12 Examples of determinats can be:\n\nDeterminers (DET):\n\na: I saw a cat in the garden.\nan: She has an apple in her hand.\nthe: The sun is shining brightly.\nthis: I would like this book, please.\nsome: Can I have some water?"
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#examples-of-prenomial-adjectives",
    "href": "blog/2023-11-13_sequence-labelling/index.html#examples-of-prenomial-adjectives",
    "title": "Sequence Labelling",
    "section": "13 Examples of Prenomial adjectives:",
    "text": "13 Examples of Prenomial adjectives:\nPrenomial adjectives are adjectives that come before the noun they modify. Here are some examples of prenomial adjectives:\n\nThe red apple\n\n“red” is a prenomial adjective modifying the noun “apple.”\n\nA beautiful sunset\n\n“beautiful” is a prenomial adjective describing the noun “sunset.”\n\nThree large elephants\n\n“large” is a prenomial adjective indicating the size of the noun “elephants.”\n\nAn old book\n\n“old” is a prenomial adjective modifying the noun “book.”\n\nThe happy child\n\n“happy” is a prenomial adjective describing the noun “child.”\n\nSeveral interesting movies\n\n“interesting” is a prenomial adjective modifying the noun “movies.”\n\n\nThese examples illustrate how adjectives are positioned before the nouns they modify in a sentence."
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#example-with-3-positions",
    "href": "blog/2023-11-13_sequence-labelling/index.html#example-with-3-positions",
    "title": "Sequence Labelling",
    "section": "14 Example with 3 positions",
    "text": "14 Example with 3 positions\n\n\n\n\n\nMy task: what is the task for the first word, for the second word and for third word - We have a 3-word sentence and I need to know the most probable tag sequence for that sentence - Assume that the tag set contains two tags\n\n\nYou are asked what is the most probable tag sequence, the only way to know is to assign prob to each and every one of the options that has been numerated so every row. More concrete you need to assing a prob to the first row to the second and so on. Assigning prob to this is relatively easy, once the table of parameters exist I just go through my sequence (per each row) and collect the relevant probabilities (so multiply all the parameters in one row)\nSuppose we already did that So the table is filled with numerical values, meaning I will have one join prbability value for each one of the options. So now we could sort the list and pick the best\n\n\n\n\n\nSlide 43\n\n\n\n\n\nSo the size of this computation would be K_1position, K_2position, K_3position, K_Lposition so K^L\n\nBecause this is exponential is expensive to compute\n\n\n\n\nSlide 44\n\n\n\n\nDynamic programing is when you program such that it solves smaller problems whose algorithm for solving repeats itsleve and it is not generally available meaning to every programm can be dinamyc, you need to design your model with careful choices such that a dynamic program can be used. HMM can fit into a Dynamic programm. The key to the dynamic program is to look closely to my screenshots (the img above) and realized that most probabilities are the same anyway. So each row is the join probability of assing to one of the tag sequences and all the numbers are same basically everywhere so there is a lot of structure that repeats itself, the idea is to split into subproblems solve the subproblems and combine their solutions\nIn the following video we see how to do that:\n\n\n\n\n\n\n\n\nSlide 45\n\n\n\n\nThe key is: pretend there is a table alpha(i, j) which tells you if I were tagging the ith position with the jth tag i.e so the 10th position I will make it a NOUN, then I can solve this problem by combining the solutions to the previous one: the 9th position and I can do that if I know the 8th position and so on, so this becomes recursion. You can solve this if you have solve the ones before and by structuring this in a recursive call\nIn the \\({\\) the one above is the transition emission pair for that position. You do not need recusion to implement this you can also do for-loop\nRecall: the 2. thing can be done with an HMM is to marginalized out the tag sequences.\n\n14.1 The concept of marginalization out\nImagine there is two variables, a person and a route to the university. Each path to the univerisy will cost an amount of time. If you ask the question how does does it take you on average to get to work and you have no knowledge of the path that was taken then you reason all paths could have done then you sum all the cost of all the paths and averga them out\n\n\n14.2 What is marginalization\nSo if you have two or more variables, marginalization menas fix some of them and for whathever is left enumerate all hte possible outcomes and sum their probabilities.\n\n\n\n\nSlide 46\n\n\n\n\nWe have the join probability distribution \\(P_{XY(w_{1:l},c_{1:l})}\\)\n\nThere is two sequences: words and classes.\nIf we ask: regardless of class what is the probability of a sentece i.e ‘the nice dog’, they are not asking the nice dog which is a DETERMINATE, ADJECTIVE NOUN, no. They are not asking that. They are asking the prob of the sentence so then we use marginalization like the formula below:\n\n\\[\nP(X = x) = \\sum_{y} P(X = x, Y = y)\n\\]\n\n\n\n\nThis is an exmaple, so based on the formula from SLide 46, we have L=3 words K=3 tags\n\nWe do not know the categories, so need to try them all. We proved before that there is an exponentially K^L growing number of how to assign tags so then we enumerate all this possible outcomes meeaning we enumerate per each row each of the possible combinations\nFor each of these rows, I know how to assing a join probability, I used the relevant \\(\\lambda\\) and the relevants \\(\\theta\\) and then I multiply them toguther all these (per row) and this gives me a number\n\nRecall: - Before I was looking for the one tag sequence for which the joint probability was maximum\nNow: - I am marginalizing out, now we are summing all the alternative probabilities. So all the alternative ways I summed them up (so in each columns beecause here we have different assignment of tags) and the result of summing along the columns (which then we have like a vector of sequence L, so the sentence lenght) and now we sum this vector( so each element in this vector will correspond to one word with all the classes summed over) is the probability of the sequence aka the sentence regardless of tag sequences because we wa\n\n\n\n\nThe algorithms that takes care of this is called the Forward Algorithm where we are interested in find the prob of the sentence regardless of their POS tags\n\n\n\n\n\n\n14.3 In short:\n\nYou are asked what is the most probable tag sequence: Viterbi\nProbability of the sentence regardless of their POS tags: Forward\n\nSide note: the thing that unites these two algorithm is called Value Recursion explained in the video"
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#coming-back-to-the-yt-video-value-recursion-for-hmms",
    "href": "blog/2023-11-13_sequence-labelling/index.html#coming-back-to-the-yt-video-value-recursion-for-hmms",
    "title": "Sequence Labelling",
    "section": "15 Coming back to the YT video: Value recursion for HMMs",
    "text": "15 Coming back to the YT video: Value recursion for HMMs\n\nFormula for HMM:\n\n\n\n\n\n\n\nHere \\(P_{XY}()\\) is the join probability of words and tags\n\n\n\n\n\n\nIn reality though you do not know the tag sequence and you only have a word sequence which you assume it was generated with an HMM generative history. With this you are interested in predicting:\n\nWhat the most probale sequence could have been that is the task of post tagging\n\n\nHere we look at the tag sequence that maximizes the posterior probability for a given input w\n\n\nYou may be interested for a language model and what you want to do is evaluate the marginal probability of the word sequence, that is the total probability regardless of what tag sequence may have generated this text. There you would asses the join probaility for each and every configuration from the tag sequence and sum all those probabilities toguether.\n\n\n\n\n\n\n\n15.1 The Value recursion\n\n15.1.1 Forward Algorithm\n\nImagine you have a sequence c1 trhough c_i which are the tags for sequence w1 throuhg w_i, where w1=the and so on.\n\nAlpha would be the marginal probability of all sequences that end with the assigment \\(c_{i=j}\\). That is making a choice for the ith position and that choice being in the jth tag position. i.e. look at \\(\\alpha(i=3, j=B)\\) (recall i=word_position, j+tag_class). Then we are taking about c1, c2 and c3=B, C1 having generated ‘the’\nWe marginalize C1 and C2, which means we trying all the posibilities:\n\nA A B\nA B B\nB A B\nB B B\n\nWe try all these posibilitis, we asses the joint probabilities, so the whole row of multiplications per each combination so for instance in the first one we would have:\n\nA A B\n\n\n\n\n\nA multiplication of all the parameters with classes A A B. Then for the second combination A B B and so on\nOnce we have calcualted all these combination we add them all toguether and thdt quantity which is the marginal probability is what we store in the function \\(\\alpha (i,j)\\)\nNow with this \\(\\alpha (3,B)\\) we can expressed in in therm os \\(\\alpha (2,A)\\) and \\(\\alpha (2,B)\\) and so on.\n\n\n\n\n\n\n\n\n\n\nRecaping Forward Algorithm\n\n\n\nThe forward recursing boilds down to \\(\\alpha (i,j)\\) which is the marginal probability of the assigment where we have generated all the wrods all they way until the ith, the ith word is tagget with the jth tag in the tagset and the sequence up unil that variable has been marginalized\n\n\nWhen i is more than one then we have a recursive call to alpha but evaluated in the previous position. So escentially to evaluate alpha(i,j) we check for all candidate tags that could be set in the previous psoition with the fixed word and we asses alpha as if that tag was indeed the tag assign to the previous position and then we transition ot the jth tag and we omit the ith word.\nalpha(4, ESO) is the probability that we are looking for because it evaluates the joint probabilities of all sequences and adds them toguether\n\n\n\n\nComplete Forward algorithm:\n\n\n\n\n\n\n\n15.2 Viterbi Algorithm\nNow we want to maximize our choice, we want the probability of the best sequence ending in (c_i=j, w_i=w_i)\nThe probability of the sequence that ends in c_i=c_j and emits the ith words from the jth tag is either the probability of the transition emission probability pair when i=j, or when is the second term of the alpha function.\n\n\n\n\nSo now the best sequence that ends up in the sequence (C_2=A, W_2=nice). Suppose for a moment that going to A is the best choice/the one that maximizes, then to get to alpha(2,A) = alpha(1,A) * \\(\\lambda_A^{A} \\theta_{nice}^{A}\\) is the biggest among the other path posibility so the path below (aplha(1,B)*…)\nNow for alpha(2,B) the best value is by going from alpha(1,A)*\\(\\lambda_A^{B} \\theta_{nice}^{A}\\)\n\n\n\n\nSo if you implement a table of alpha(i,j) values and another table of Backpointers, then you have everything that you need to compute the probability (the sums of probs from the first table) and to compute the tag sequence (from the Backpointers table) and thus outputs the best tag sequence to the user.\n\n\n15.3 Notes on these algorithms\nTo solve all htse computation we want to do it in a logarithm scale because logs convert products into sums leading to more numerically stable computations. For that we need to do some extra mods to the alpha function. With these three forumlas in red I can rewrite alpha into somthing called value recursion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSlide 53\n\n\n\n\n\n\n\n\nSlide 54\n\n\n\n\nAn HMM tagger would be a joint distribution over both tag sequences and token sequences but if you are not interested in assigninig probabilities to words or generating words then you may model with a different technique\nSo now the goal is not a generative model that you could use for taggins or for Language Modelling, now the goal is just to have a tagger.\nOther types of taggers may fit in another tools. For instance see next slide:\n\n\n\n\nSlide 55\n\n\n\n\nThere is still applications of this things, they tipically power systems for information extraction for question answering. So it is a form of labelling task with a bit of a smactic twist, I am not interest in the syntatic category of a word in its context but rather I am interest in recognizing mentions to something that is an entity in the real word thats why we call it Name-Entity. For instance ‘America Airlines’ we tagged with some Name entity.\n\nWhy this would be usefull you may ask? suppose you are dealing with question-answering then perhaps by doing name-entity recognition you find the spans of text for which you likely have a wikipedia page or an entry in some knowledge base.\n\nThe idea is to identify the blue spans, maybe it does not look like labelling, like it looks quite different from Speach tagging but now lets look at the nxt slide:\n\n\n\n\nSlide 56\n\n\n\n\nIt is a transformation of the dataset, so the dataset has been prepoceed slighly and now it is a labelling task\n\nI: inside of span\nB: beginnig\nO: Outside\nS: Single token span i.e S-LOC single location\n\nEven though is a sequence labelling task we have one label per token in the token sequence, we are construvting little brackets, because now we are setting the inside of a tag or the end of a tag or the beginnig and so on.\n\n\n\n\nSlide 57\n\n\n\n\n\n\n\n\nSlide 58\n\n\n\n\nFor example they all have the same semantical meaning but different realizations, so the sentences have in common the same meaning but expressed in a different way\n\n\n\n\nSlide 59\n\n\n\n\n\nPrototypical Semantic Roles\n\n\n\n\nSlide 60\n\n\n\n\nAnnother sequence labelling task: see next slide\n\n\n\n\nSlide 61\n\n\n\n\nHere you assing semantic roles to spans in sentences so now you think of a sentence that is specific to a VERB, so given the semantics of BROKE for i.e then Jhon is to be labeld as the AGENT and the window acts as a span of THEME\nSo the sentences from 3 to 5 are different with little change. Where would this information be? it must be in the lexicon it something about Jhon and something about being a rock that makes one thing the agent and another the instrument, so it is not in the syntax of the sentence it is not in the grammar it is really in the selection of preferences of VERBS and the attributes of NOUNS\n\n\n\n\nSlide 62\n\n\n\n\nIn these slides are two verbs in their first senses\n\n\n\n\nSlide 63\n\n\n\n\nHere if I have 7 verbs then I have sevent semantic role sequences I have: arg0… arg1, till arg6 .In POS tagging their is one sequence for one input sequence. Here is a bit different, here for every verb you have one sequence, because foe every verb you look at the sentence and you can interpret who is the agent, who is doing what to who, but if you focus in a different VERB in a the same sentence then different spans of texts will play different roles. So for every single verb you encounter in the sentence there would be a corresponding tag sequence i.e seeing at the columns on the table #1, #2 … #7. These are the tag sequences for each one of the verbs\nImagine you are designinig a semantic role labeller and you are given a sequence of inputs and there are two settings one settings is somebody tells me please tag the sequence for the verb ‘implement’ and then your model would ideally ouput something like the last column\nOr I give you the sentence and I say tag the sentence for semantic roles for the verb ‘lighten up’ and then you would predict soemthin similar like in column number 3\n\n\n\n\nSlide 64\n\n\n\n\nThe scope is now to map a sequence of words to a sequence of tags but doing that with respect to a given position because for each tth meanining the verb of interest i.e ‘use’ then wrt to that position this is the output tag sequence\n\n\n\n\nSlide 65\n\n\n\n\nIf we can express a task as annotating tokens in sequence and for every token I have tag, then normally this tags comes from a finite set. That means that an HMM is available. You could develop an HMM for psot tagging, you could develop an HMM for Nameed-Entity recognition. For isntance for pos tagging you change the tag space and maybe you motivate one or the other variant of IOBES and you could do HMMs, you could use it. A not soo god example is SLR because you cannot phrase as every token gets one tag, it is more like every token gets a tag for a certain verb. So if I change the verb then I have another tag sequence so you have a variable number of outputs sequences, one ouput sequence per verb in the token sequence. This lead us to the conlsuion of SLR are note good candidates for HMMs.\nVerbs –&gt; SRL\nHowever, even in the case that HMMs is a good choice like in post tagging and named-entity recognition it can be argued that it maynot be a choice in general because I know where I am applying it. I am applying it for the purpose of labelling sequences with some linguistic signals and if I am not interest in Language Modelling I do not care about assigning probs to the text. Thus we dont care about probs then there may be better techniques."
  },
  {
    "objectID": "blog/2023-09-05_equation-for-ml1/index.html",
    "href": "blog/2023-09-05_equation-for-ml1/index.html",
    "title": "Probability Theory in Machine Learning",
    "section": "",
    "text": "Formulas for the course at UvA: Machine Learning 1\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Probability Theory\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Probability Theory\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 5, 2023\nThis section focus on two weeks of the course. For Classification continue to this post."
  },
  {
    "objectID": "blog/2023-09-05_equation-for-ml1/index.html#rules-of-probability-theory",
    "href": "blog/2023-09-05_equation-for-ml1/index.html#rules-of-probability-theory",
    "title": "Probability Theory in Machine Learning",
    "section": "1 Rules of Probability Theory",
    "text": "1 Rules of Probability Theory\nSum Rule used in Marginalization \\[\n\\begin{align}\np(x) &= \\sum_{y \\in Y }^{} p(x,y) \\\\\n     &= \\sum_{y \\in Y }^{} p(x|y)p(y) \\nonumber\n\\end{align}\n\\]\nProduct Rule used in the Join Probability \\[\n\\begin{align}\np(x,y) = p(x|y)p(y)\n\\end{align}\n\\]"
  },
  {
    "objectID": "blog/2023-09-05_equation-for-ml1/index.html#expectation-rules",
    "href": "blog/2023-09-05_equation-for-ml1/index.html#expectation-rules",
    "title": "Probability Theory in Machine Learning",
    "section": "2 Expectation Rules",
    "text": "2 Expectation Rules\n\\[\n\\begin{align}\n    \\mathbb{E}[f(x)+g(x)] &= \\mathbb{E}[f(x)] + \\mathbb{E}[g(x)]\\\\\n    \\mathbb{E}[cf(x)] &= c\\mathbb{E}[f(x)]\\\\\n    \\mathbb{E}[c] &= c\\\\\n    \\mathbb{E}[\\mathbb{E}[f(x)]] &= \\mathbb{E}[f(x)]^2\\\\\n\\end{align}\n\\]"
  },
  {
    "objectID": "blog/2023-09-05_equation-for-ml1/index.html#probability-theory-equations",
    "href": "blog/2023-09-05_equation-for-ml1/index.html#probability-theory-equations",
    "title": "Probability Theory in Machine Learning",
    "section": "3 Probability Theory Equations",
    "text": "3 Probability Theory Equations\nExpectancies \\[\n\\begin{align}\n    \\mathbb{E}[x] &= \\int_{x}x \\, p(x) \\, dx\\\\\n    var[x] &= \\mathbb{E}[(x-\\mathbb{E}[x])^2] \\nonumber\\\\\n    &=\\mathbb{E}[f(x)^2] - \\mathbb{E}[f(x)]^2\\\\\n\\end{align}\n\\]\nWhen cov for two scalar variables \\[\n\\begin{align}\ncov[x,y] &= \\mathbb{E}[xy]-\\mathbb{E}[x]\\mathbb{E}[y]   \n\\end{align}\n\\]\nCovariance Matrix: When \\(\\textbf{x}\\), \\(\\textbf{y}\\) are vectors of random variables \\[\n\\begin{align}\ncov[\\textbf{x},\\textbf{x}] &= \\mathbb{E}[(\\textbf{x}-\\mathbb{E}[x])(\\textbf{x}-\\mathbb{E}[x])^T]\\\\  \ncov[\\textbf{z},\\textbf{z}] &= \\mathbb{E}[\\textbf{z}\\textbf{z}^T]-\\mathbb{E}[\\textbf{z}]\\mathbb{E}[\\textbf{z}]\\\\\n\\end{align}\n\\]\nGaussians: scalar and for a matrix \\[\n\\begin{align}\n\\mathcal{N}(x|\\mu , \\sigma^2) &= \\frac{1}{\\sqrt{2 \\pi  \\sigma^2}} e^{\\left(-\\frac{1}{2 \\sigma^2}(x-\\mu)^2\\right)}\\\\\n    \\mathcal{N}(x|\\mu , \\Sigma ) &= \\frac{1}{(2\\pi)^{D/2}|\\Sigma|^{1/2}}  e^{\\left(-\\frac{1}{2}(x-\\mu)^T \\Sigma^-1 (x-\\mu)\\right)}\\\\\n\\end{align}\n\\]\nThis is our model. This is what we estimate: \\[\n\\begin{align}\ny(\\underline{x})\n\\end{align}\n\\]\nThe observations can be sampled from (signal + noise): \\[\n\\begin{align}\nt = sin(\\underline{x}) + \\varepsilon\n\\end{align}\n\\]\nData Pair: For a given \\(x\\), I can get a target value \\(t\\) (the observation) \\[\n\\begin{align}\n(t, x)  \n\\end{align}\n\\]\nFor instance, we have a sampled data D, and for each \\(x\\) we have seen \\(t\\) and that is our excel file we can work with"
  },
  {
    "objectID": "blog/2023-09-05_equation-for-ml1/index.html#bayessian-linear-regression",
    "href": "blog/2023-09-05_equation-for-ml1/index.html#bayessian-linear-regression",
    "title": "Probability Theory in Machine Learning",
    "section": "4 Bayessian Linear Regression",
    "text": "4 Bayessian Linear Regression\nWe do not want to average over models but this time we want to find the best parameters over only one Data set (without splitting it) and change only our parameters.\nFor this we would consider the posterior. So what is the probability that this parameters \\(w\\) represent the actual data.\nGoal recover the probability distribution that may have generated this data (the posterior)\n\n4.1 Dimensions\n\\[\n\\begin{align}\n\\underline{t} &\\in \\mathbb{R}^{Nx1}, \\text{ $N$ amount of linear regressions}\\\\\n\\underline{w} &\\in \\mathbb{R}^{Mx1}, \\text{ $M$ amount of parameters}\\\\\nX &\\in \\mathbb{R}^{NxD}, \\text{ $N$ amount of observ, $D$ amount of models}\\\\\n% \\underline{x_i} &\\in \\mathbb{R}^{Dx1}, \\text{ $i$ the $i_{th}$ experiment} \\\\\n&= [\\underline{x_{1}}, \\underline{x_{2}}, ... ,\\underline{x_{N}}] \\nonumber \\\\\n\\underline{x_{1}} &\\in \\mathbb{R}^{Nx1} = [x_1, x_2,...,x_N]\\\\\n\\underline{\\phi}(\\underline{x}) &\\in \\mathbb{R}^{Dx1} \\to \\mathbb{R}^{Mx1}\\\\\n\\phi_{1}(\\underline{x}) &\\in \\mathbb{R}^{Nx1} \\to \\mathbb{R}^{1x1}\\\\\n\\Phi &\\in \\mathbb{R}^{NxM}\n\\end{align}\n\\]"
  },
  {
    "objectID": "blog/2023-09-05_equation-for-ml1/index.html#sequential-bayesian-learning",
    "href": "blog/2023-09-05_equation-for-ml1/index.html#sequential-bayesian-learning",
    "title": "Probability Theory in Machine Learning",
    "section": "5 Sequential Bayesian Learning",
    "text": "5 Sequential Bayesian Learning\nHere our goal is to find the parameters of w. So we want to find the values w that discribe best the distribution of our data points meaning we want to find the posterior described as:\n\\(p(w|x_1,t_1, \\alpha, \\beta)\\)\n\nWe have a prior, we assume initial values\nWe sample one data point and apply Gaussian distribution to obtain a likelihood\nWith the prior and likelihood we get the posterior (what we want)"
  },
  {
    "objectID": "blog/2023-09-05_equation-for-ml1/index.html#predictive-distribution",
    "href": "blog/2023-09-05_equation-for-ml1/index.html#predictive-distribution",
    "title": "Probability Theory in Machine Learning",
    "section": "6 Predictive Distribution",
    "text": "6 Predictive Distribution\nIf we are given a new input x’, then we want to be able to compute its new distribution meaning we want to compute the new likelihood that looks as follows:\n\\(p(t'|x', X, \\underline{t}, \\alpha, \\beta) = \\int p(t'|x', \\underline{w}, \\beta) p(\\underline{w}|X, \\underline{t}, \\alpha, \\beta)dw\\)\nThe above equation uses Marginalization over w. That does not mean that it depends on w. It’s just a dummy variable it can be another variable thus the predictive distribution does not depend on w.\nThe second term is the posterior.\n\nHere we are given all data points and we get the parameters for w. With that we can get a prior. Those are the assumptions of how the weigths should be.\nThe predictive probability does not depend on w anymore. It depends on the data, so on the experience gained so far. If a new data point comes in then we would update our predictive distribution\nFor each new point x’ we want to fins the new distribution probability for t’"
  },
  {
    "objectID": "blog/2023-10-03_the-perceptron/index.html",
    "href": "blog/2023-10-03_the-perceptron/index.html",
    "title": "The Perceptron",
    "section": "",
    "text": "Lecture Notes UvA on 19-9-2023\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                AI\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                AI\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          October 3, 2023"
  },
  {
    "objectID": "blog/2023-10-03_the-perceptron/index.html#the-perceptron-model",
    "href": "blog/2023-10-03_the-perceptron/index.html#the-perceptron-model",
    "title": "The Perceptron",
    "section": "1 The Perceptron Model",
    "text": "1 The Perceptron Model\nit just a linear model where:\n\n\n\nHere \\(\\phi(x)=x\\) for instance.\n\n1.1 Error function\n\n\n\n\n\n1.2 The Perceptron: Learning\n\n\n\nHere \\(&lt;1\\) we can also have \\(\\gamma\\)\n\n\n\n\n\n1.3 Perceptron Learning as Gradient Descent\n\n\n\n\n\n1.4 Pros with the Perceptron\n\nThe algorithm guarantees to converge if the data is linear separable\n\n\n\n1.5 Problems with the Perceptron\n\nPerceptron only works for 2 classes\nCycling theorem: many solutions if data is not linearly separable\nBased on linear combination of fixed basis functions."
  },
  {
    "objectID": "blog/2023-09-26_matrix-calculus/index.html",
    "href": "blog/2023-09-26_matrix-calculus/index.html",
    "title": "Matrix Calculus & Derivatives Ax",
    "section": "",
    "text": "Derivatives of vectors, matrix and other utils\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Vector Calculus\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Vector Calculus\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 26, 2023"
  },
  {
    "objectID": "blog/2023-09-26_matrix-calculus/index.html#transpose-properties",
    "href": "blog/2023-09-26_matrix-calculus/index.html#transpose-properties",
    "title": "Matrix Calculus & Derivatives Ax",
    "section": "Transpose Properties",
    "text": "Transpose Properties\nIf \\(\\Sigma\\) is symmetric:\n\\[\n\\begin{align}\n\\Sigma = \\Sigma^T\\\\\n\\end{align}\n\\]\nThe inverse of a symmetric matrix is also symmetric\n\\[\n\\begin{align}\n(\\Sigma^{-1})^T = (\\Sigma^T)^{-1} = \\Sigma^{-1} \\label{cov_trans_inv} \\\\\n\\end{align}\n\\]\n\n\n\n\n\n\nProof Eq. \\(\\ref{cov_trans_inv}\\)\n\n\n\n\n\n\n\nCode\nimport numpy as np\n\n# Create a symmetric matrix\nA = np.array([[4, 1, 2],\n              [1, 5, 3],\n              [2, 3, 6]])\n\n# Check if A is symmetric\nis_symmetric = np.allclose(A, A.T)\n\nif is_symmetric:\n    # Calculate the inverse of the symmetric matrix\n    A_inv = np.linalg.inv(A)\n\n    print(\"Original symmetric matrix A:\")\n    print(A)\n\n    print(\"\\nInverse of A:\")\n    print(A_inv)\nelse:\n    print(\"The matrix A is not symmetric.\")\n\n\nOriginal symmetric matrix A:\n[[4 1 2]\n [1 5 3]\n [2 3 6]]\n\nInverse of A:\n[[ 0.3         0.         -0.1       ]\n [ 0.          0.28571429 -0.14285714]\n [-0.1        -0.14285714  0.27142857]]\n\n\nHere we have shown that the inverse of a symmetric matrix its also a symmetric matrix. It is not the same because doing the inverse you do other calculations but is symmetric around the diagonal"
  },
  {
    "objectID": "blog/2023-09-26_matrix-calculus/index.html#partial-derivatives",
    "href": "blog/2023-09-26_matrix-calculus/index.html#partial-derivatives",
    "title": "Matrix Calculus & Derivatives Ax",
    "section": "Partial Derivatives",
    "text": "Partial Derivatives\nVectors:\n\\[\n\\begin{align}\n\\frac{\\partial (\\textbf{v}^T \\textbf{v})}{\\partial\\textbf{v}} &= 2\\textbf{v}^T\\\\\n\\frac{\\partial (\\textbf{v} \\textbf{v}^T)}{\\partial\\textbf{v}} &= 2\\textbf{v}^T\\\\\n\\frac{\\partial (\\textbf{x}^T \\textbf{w})}{\\partial\\textbf{x}} &= \\textbf{w}^T\\\\\n\\frac{\\partial (\\textbf{w}^T \\textbf{x})}{\\partial\\textbf{x}} &= \\textbf{w}^T\\\\\n\\end{align}\n\\]\nMatrix: \\[\n\\begin{align}\n\\frac{\\partial (\\textbf{A} \\textbf{x})}{\\partial\\textbf{x}} &= \\textbf{A}\\\\\n\\frac{\\partial (\\textbf{x}^T \\textbf{A})}{\\partial\\textbf{x}} &= \\textbf{A}^T\\\\\n\\end{align}\n\\]\nWrt Vector: \\[\n\\begin{align}\n\\frac{\\partial(\\textbf{x}^T\\textbf{A}\\textbf{x})}{\\partial\\textbf{x}} =& \\textbf{x}^T(\\textbf{A}+\\textbf{A}^T)\\\\\n\\frac{\\partial(\\textbf{w}^T\\textbf{X}^T\\textbf{y})}{\\partial\\textbf{w}} =& \\textbf{y}^T\\textbf{X}\\\\\n\\frac{\\partial(\\textbf{y}^T\\textbf{X}\\textbf{w})}{\\partial\\textbf{w}} =& \\textbf{y}^T\\textbf{X}\\\\\n\\end{align}\n\\]\nWrt Matrix: \\[\n\\begin{align}\n\\frac{\\partial(\\textbf{x}^T\\textbf{A}\\textbf{x})}{\\partial\\textbf{A}} =& \\textbf{x}\\textbf{x}^T\\\\\n\\frac{\\partial(\\textbf{a}^T\\textbf{A}\\textbf{b})}{\\partial\\textbf{A}} =& \\textbf{a}\\textbf{b}^T\\\\\n\\frac{\\partial(\\textbf{a}^T\\textbf{A}^T\\textbf{b})}{\\partial\\textbf{A}} =& \\textbf{b}\\textbf{a}^T\\\\\n\\end{align}\n\\]\nSpecial: \\[\n\\begin{align}\n\\frac{\\partial \\textbf{a}^T\\textbf{X}\\textbf{b}}{\\partial\\textbf{X}} &= \\textbf{a}\\textbf{b}^T\\\\\n\\frac{\\partial \\textbf{a}^T\\textbf{X}^{-1}\\textbf{b}}{\\partial\\textbf{X}} &= -(\\textbf{X}^{-1})^T\\textbf{a}\\textbf{b}^T(\\textbf{X}^{-1})^T\\\\\n& = - (\\textbf{X}^{-1})\\textbf{a}\\textbf{b}^T(\\textbf{X}^{-1})\\quad &\\text{If $\\textbf{X}$ is symmetric} \\nonumber \\\\\n\\frac{\\partial (\\textbf{x}-\\textbf{A}\\textbf{s})^T\\textbf{W}(\\textbf{x}-\\textbf{A}\\textbf{s})}{\\partial\\textbf{A}} &= -2\\textbf{W}(\\textbf{x}-\\textbf{A}\\textbf{s})\\textbf{s}^T \\quad &\\text{If $\\textbf{W}$ is symmetric} \\\\\n\\frac{\\partial (\\textbf{x}-\\textbf{A}\\textbf{s})^T\\textbf{W}(\\textbf{x}-\\textbf{A}\\textbf{s})}{\\partial\\textbf{s}} &= -2(\\textbf{x}-\\textbf{A}\\textbf{s})^T\\textbf{W}\\textbf{A} \\quad &\\text{If $\\textbf{W}$ is symmetric} \\\\\n\\frac{\\partial (\\textbf{x}-\\textbf{s})^T\\textbf{W}(\\textbf{x}-\\textbf{s})}{\\partial\\textbf{s}} &= -2(\\textbf{x}-\\textbf{s})\\textbf{W}^T \\quad &\\text{If $\\textbf{W}$ is symmetric}\n\\end{align}\n\\]"
  },
  {
    "objectID": "blog/2023-10-12_what-is-the-covariance-matrix/index.html",
    "href": "blog/2023-10-12_what-is-the-covariance-matrix/index.html",
    "title": "The Covariance Matrix and relation with PCA",
    "section": "",
    "text": "Description of this Post\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          October 12, 2023\nIn a 2D dimensional feature space with 10 data points, the covariance matrix provides a measure of the relationship between the two features (dimensions) and how they vary together. The covariance matrix is a 2x2 matrix that quantifies the degree to which the two features change together\nLet’s say you have two features, \\(\\textbf{x}\\) and \\(\\textbf{y}\\), and you have 10 data points with values (x_1, y_1), (x_2, y_2), …, (x_10, y_10). The covariance matrix Σ is calculated as:\n\\[\n\\Sigma = \\begin{bmatrix}\n\\text{cov}(\\textbf{x}, \\textbf{x}) & \\text{cov}(\\textbf{x}, \\textbf{y}) \\\\\n\\text{cov}(\\textbf{y}, \\textbf{x}) & \\text{cov}(\\textbf{y}, \\textbf{y})\n\\end{bmatrix}\n\\]\nWhere:\nThe covariances of two random variables (the two features) are calculated using the formula:\n\\[\n\\text{cov}(\\textbf{x}, \\textbf{y}) = \\frac{1}{N} \\sum_{n=1}^{N} (x_n - {\\bar{x}})({y}_n - \\bar{y})\n\\]\nWhere:\nNote:\nThe calculation for the covariance matrix can be also expressed as:\n\\[\n\\Sigma = \\frac{1}{N} \\sum_{n=1}^{N} (\\textbf{x}_n - \\mathbf{\\bar{x}})(\\textbf{x}_n - \\mathbf{\\bar{x}})^T\n\\]\nWhere:\nBelow some example:"
  },
  {
    "objectID": "blog/2023-10-12_what-is-the-covariance-matrix/index.html#python-example",
    "href": "blog/2023-10-12_what-is-the-covariance-matrix/index.html#python-example",
    "title": "The Covariance Matrix and relation with PCA",
    "section": "1 Python Example",
    "text": "1 Python Example\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.style.use('ggplot')\n# plt.rcParams['figure.figsize'] = (12, 8)\n\n# Normal distributed x and y vector with mean 0 and standard deviation 1\nx = np.random.normal(0, 1, 500)\ny = np.random.normal(0, 1, 500)\nX = np.vstack((x, y)).T\n\nplt.scatter(X[:, 0], X[:, 1])\nplt.title('Generated Data')\nplt.axis('equal')\nplt.show()\n\n\n\n\n\nIf two feature vectors are independent (or uncorrelated) the matrix matrix would be:\n\\[\n\\Sigma = \\begin{bmatrix}\n\\text{cov}(\\textbf{x}, \\textbf{x}) & 0 \\\\\n0 & \\text{cov}(\\textbf{y}, \\textbf{y})\n\\end{bmatrix}\n\\]\nIf this data was generated with unit cov(x,x) and unit cov(y,y) then we have a Identity covariance matrix\n\n\n\n\n\nAs x1 increases x2 increases too, because we have 0.8. We have a positive correlation on the data."
  },
  {
    "objectID": "blog/2023-10-12_what-is-the-covariance-matrix/index.html#relation-with-pca",
    "href": "blog/2023-10-12_what-is-the-covariance-matrix/index.html#relation-with-pca",
    "title": "The Covariance Matrix and relation with PCA",
    "section": "2 Relation with PCA",
    "text": "2 Relation with PCA\nWhen you multiply the \\(\\Sigma\\) covariance matrix times a vector and then again and again you end up with a vector that points to directions where you have the greatest variance in the data. So like where all points are spread out.\n\n\n\n\n\nIf I multiply the vector \\(e2\\) by the cov matrix it will not turn but will get longer and longer but will point in the same direction\nThus we want to find some vector \\(e\\) that when we multiply it with the cov matrix do not change direction. The vectors are called eigenvectors and the lambdas so the scalar version will be called eigenvalues.\nThe later point will be called our principal components which are the eigenvectors with the largest eigenvalues"
  },
  {
    "objectID": "blog/2023-10-11_principal-component-analysis/index.html",
    "href": "blog/2023-10-11_principal-component-analysis/index.html",
    "title": "Principal Component Analysis (PCA)",
    "section": "",
    "text": "Lecture Notes UvA on 9-10-2023\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Linear models\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Linear models\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          October 11, 2023"
  },
  {
    "objectID": "blog/2023-10-11_principal-component-analysis/index.html#continuous-latent-space",
    "href": "blog/2023-10-11_principal-component-analysis/index.html#continuous-latent-space",
    "title": "Principal Component Analysis (PCA)",
    "section": "1 Continuous latent space",
    "text": "1 Continuous latent space\nThe idea is of latent variables is that the data is described in the low dimensional latent space and somehow it can map it to this hight dimensional space."
  },
  {
    "objectID": "blog/2023-10-11_principal-component-analysis/index.html#principal-component-analysis-pca",
    "href": "blog/2023-10-11_principal-component-analysis/index.html#principal-component-analysis-pca",
    "title": "Principal Component Analysis (PCA)",
    "section": "2 Principal Component Analysis (PCA)",
    "text": "2 Principal Component Analysis (PCA)\nImagine I have the bottom right plot in multiple dimensions so not only 2D dimensions. I can compute a mean and a covariance matrix to fit this data.\nNow I pick only line and I will fit the data in 1D-dimension i.e using Gaussian with the mean and convariance from the original plot. This mapping depends on the direction on the line for the PCA, imagine now the green line below then the gaussian will look different\n\n\n\n\n\nSo we want to find the direction in which it maximizes the variance data. This is important because if you have a low variance then all the points map to this compressed graph and may look like one point when in reality there are plenty."
  },
  {
    "objectID": "blog/2023-10-11_principal-component-analysis/index.html#recall-orthonomal-projections",
    "href": "blog/2023-10-11_principal-component-analysis/index.html#recall-orthonomal-projections",
    "title": "Principal Component Analysis (PCA)",
    "section": "3 Recall orthonomal projections",
    "text": "3 Recall orthonomal projections\n\nThe span of a vector."
  },
  {
    "objectID": "blog/2023-10-11_principal-component-analysis/index.html#d-projection",
    "href": "blog/2023-10-11_principal-component-analysis/index.html#d-projection",
    "title": "Principal Component Analysis (PCA)",
    "section": "4 1D Projection",
    "text": "4 1D Projection\nRemarks:\n\nHere the \\(z_1\\) is the projected point into the 1D-dimensional space if we would like more than one dimension then this z_1 would be now a vector \\(\\textbf{z}_1\\) with dimensions \\(M\\)"
  },
  {
    "objectID": "blog/2023-10-11_principal-component-analysis/index.html#maximizing-the-variance-of-1-component",
    "href": "blog/2023-10-11_principal-component-analysis/index.html#maximizing-the-variance-of-1-component",
    "title": "Principal Component Analysis (PCA)",
    "section": "5 Maximizing the variance of 1 component",
    "text": "5 Maximizing the variance of 1 component\nThe principal components are the \\(u_1\\) the lines (the directions)\n\n\n\n\n\n5.1 PCA via maximum variance\n\n\n\n\n\n\n5.2 Reminder: eigen de-composition\n\n\n\n\nRemarks:\n\nThe total variance of our datapoints in the new dimensional space can be calculated by summing up the eigenvalues\nWe should think of \\(U\\) as a change of basis from the D-dimensional space to the new dimensional space. This new dimensional space its determined by how many eigevector at the end we choose\nBecause the eigenvectors are orthonormal that means when we apply do the change of basis with the A_weird we are decorrelating our data.\n\n\n\n5.3 How to choose M?\n\n\n\n\n\n\n5.4 Feature Decorrelation\n\n\n\n\n\n\n5.5 Applications: Whitening"
  },
  {
    "objectID": "blog/2023-10-11_principal-component-analysis/index.html#probabilistic-pca",
    "href": "blog/2023-10-11_principal-component-analysis/index.html#probabilistic-pca",
    "title": "Principal Component Analysis (PCA)",
    "section": "6 Probabilistic PCA",
    "text": "6 Probabilistic PCA\n\n\n\n\n\n\nRecall difference in Discrete and Continuous latent variable\n\n\n\n\nDiscrete latent models: k-means, Gaussian Mixture models\nContinuous latent models: probabilistic PCA, unsupervised regression\n\nIf you compare k-means as latent clarifier then this can be consider as an unsupervised regression\nIf you compare Gaussian-mixture model then this can be though as continuous PPCA model\n\n\nProbabilistic view of PCA:\n\nLearn it via maximum likelihood\n(Third) alternative view of PCA\nBoth latent and observed variables are Gaussian\n\n\n6.1 Continuous latent variable model\n\n\n\n\n\nWe assume that there is a latent space z from which we can sample a point z.\nThen I have this conditional p(x|z) given z what is the probability that is lands\n\n\n\n6.2 PPCA modelling assumptions\n\n\n\n\n\nRecall z was the latent variable, the hidden variable the one its making something that we have x. Remember toughs –&gt; words\n\n\nWe assume that x is formed by a linear combinations with the latent variable z, W, \\(\\mu\\) and \\(\\epsilon\\)\n\nHere we are saying that there is a linear relation between z and x.\n\n\nHere, \\(W\\), \\(\\mu\\) and \\(\\epsilon\\) are the parameters that we want to recover\nBecause z is Gaussian and noise is also modelled by Gaussian, then \\(x\\) will also be Gaussian\n\n\n\n6.3 It follows\n\n\n\n\n\n\n\n\nIn the covariance part we take out W because its not a random variable\n\n\n\n6.4 Probabilistic PCA in a picture\n\n\n\n\nFrom now on we can find the parameters by doing MLE\n\n\n6.5 The log-likelihood\n\n\n\n\n\n\n6.6 PPCA has closed-form solutions\n\n\n\n\n\n\n6.7 PPCA Summary\n\n\n\n\nThree views:\n\nMax variance, min reconstruction error, probabilistic\n\nApplications\n\nDimensionality reduction\n2D/3D visualization\nCompression\nWhitening (de-correlating features)\n(not mentioned) De-noising: discard the smallest variance features = the noise components (hopefully!)\n\nLimitations:\n\nOnly linear transformations\n\n\n\n6.8 Comparing PCA & PPCA\nThe PCA can be expressed as the maximum likelihood solution probabilistic PCA.\nAdvantages of the probabilistic PCA over the conventional PCA:\n\nWe can associate a likelihood function to the probabilistic PCA which allows a direct comparison with other probabilistic density models\nProbabilistic PCA can be used to model class-conditional densities and can thus be used in classification problems\nWe can run the model generatively to provide samples from the modeled distribution."
  },
  {
    "objectID": "blog/2023-10-11_principal-component-analysis/index.html#non-linear-pca",
    "href": "blog/2023-10-11_principal-component-analysis/index.html#non-linear-pca",
    "title": "Principal Component Analysis (PCA)",
    "section": "7 Non Linear PCA",
    "text": "7 Non Linear PCA\nFind the subspace that maximizes the variance of the projection or minimizes the reconstruction error\nBy linear we mean all the data is cluster around one contour line like the green line. The question is can we do non-linear PCA where we have not the reed line which is clearly non-linear?"
  },
  {
    "objectID": "blog/2023-10-11_principal-component-analysis/index.html#pca-using-basis-functions",
    "href": "blog/2023-10-11_principal-component-analysis/index.html#pca-using-basis-functions",
    "title": "Principal Component Analysis (PCA)",
    "section": "8 PCA using basis functions",
    "text": "8 PCA using basis functions\nThe question is how do we map these non-linear data to a linear line such that we use basis function. We can do this in two ways:\n\n\n\n\n\nUsing Neural Networks\nUsing kernel methods: we can do the mapping from original space to the new space without explicit modeling the basis functions\n\n\n\n\n\n\n\nHow to craft Basis functions?\n\n\n\n\nWe can use Neural Networks. For instance \\(\\mathbf{\\phi(\\textbf{x})} = NN(\\textbf{x})\\), where \\(\\textbf{x}\\) is the input vector\nWe can use Kernel methods where we do not make explicit use of basis functions\n\n\n\nWe will first sketch the structure of an autoencoder"
  },
  {
    "objectID": "blog/2023-10-11_principal-component-analysis/index.html#auto-encoders-auto-associative-neural-nets",
    "href": "blog/2023-10-11_principal-component-analysis/index.html#auto-encoders-auto-associative-neural-nets",
    "title": "Principal Component Analysis (PCA)",
    "section": "9 Auto-encoders (auto-associative neural nets)",
    "text": "9 Auto-encoders (auto-associative neural nets)\n\n\n\n\nIf \\(f(x)=w^Tx\\) is a linear projection that goes from D to M then this resembles to PCA where we have \\(z=\\mu_M^T(x-\\bar x)\\). So if the function \\(f(x)\\) is of form like in the PCA case then we have a linear projection that can transform our points to a lower dimensional space"
  },
  {
    "objectID": "blog/2023-10-11_principal-component-analysis/index.html#autoencoder-objective",
    "href": "blog/2023-10-11_principal-component-analysis/index.html#autoencoder-objective",
    "title": "Principal Component Analysis (PCA)",
    "section": "10 Autoencoder objective",
    "text": "10 Autoencoder objective\n\n\n\n\n\nThe mapping from input through the encoder, we call it the latent \\(z_n\\). The later is like a compression.\nBefore we will project the data into our principal components but now we let the NN learn what the latent mapping should be\nWhen we carry out this encoder and decoder without using activation functions we end up in the PCA structure\nIf we use however activation function and we use more layers than 2, then we have a non-linear model which has no closed solutions and therefore we can solve it by SGD because our error is non-convex"
  },
  {
    "objectID": "blog/2023-10-11_principal-component-analysis/index.html#autoencoder-as-generator",
    "href": "blog/2023-10-11_principal-component-analysis/index.html#autoencoder-as-generator",
    "title": "Principal Component Analysis (PCA)",
    "section": "11 Autoencoder as generator",
    "text": "11 Autoencoder as generator"
  },
  {
    "objectID": "blog/2023-10-11_principal-component-analysis/index.html#kernel-pca",
    "href": "blog/2023-10-11_principal-component-analysis/index.html#kernel-pca",
    "title": "Principal Component Analysis (PCA)",
    "section": "12 Kernel PCA",
    "text": "12 Kernel PCA\nWe are use to express things in terms of features vectors, i.e the latent is obtained by taking the features vectors and projecting it onto a lower dimensional space\nNow we are going to report our results in terms of the kernel \\(k(\\textbf{x}\\textbf{x}_n)\\). The result is that the projection would be purely in terms of the other data points via the kernel but not by my other parameters\nThis is another way how to do PCA for non-linear"
  },
  {
    "objectID": "blog/2023-07-29_cafe-negro-color-miel/index.html",
    "href": "blog/2023-07-29_cafe-negro-color-miel/index.html",
    "title": "Cafe Negro color Miel",
    "section": "",
    "text": "Cafe Negro color Miel\n        \n        \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Poems\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Spanish\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Poems\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Spanish\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          July 29, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\nby Danilo Toapanta \n\nBlog  &gt; Poems\n\n\nTus ojos son misterio\ncafes negros\nmi reflejo en ti\ncuando estoy alegre\ntus ojos sonrien\ncuando estoy triste\nellos suspiran\naveces nos quedamos quietos\nno hay palabras\npero nuestros ojos\noh vida, te lo aseguro\nellos estan\nplaticando como tortolos"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html",
    "title": "Kernel methods & SVM",
    "section": "",
    "text": "Lecture Notes UvA on 9-10-2023\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          October 15, 2023"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#kernel-methods",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#kernel-methods",
    "title": "Kernel methods & SVM",
    "section": "1 Kernel Methods",
    "text": "1 Kernel Methods\nIn Unsupervised Learning we assume a latent target. In supervised we have a target variable in Unsupervised we assume there is some relation between a latent variable \\(z\\) and our datapoints.\nSupervised Learning:\n\nRegression: is continuous, the target \\(\\in \\mathbb{R}\\)\n\nProbabilistic modelling:\n\nIn regression we want to have a continuous target variable\n\nFind model parameters via ML, MAP (or use fully Bayesian)\nIf we want to avoid overfilling we include a prior\n\n\n\n\n\n\nClassification: is discrete, the target \\(\\in \\{C1,...C_k\\}\\) finite set of options\n\nProbabilistic modelling:\n\nWe also predict distributions. Here we want to predict a probability per each class ie. generalized bernoulli distribution\nFind model parameters via ML, MAP (or use fully Bayesian)\n\nIf we want to avoid overfilling we include a prior\n\n\n\n\n\n\n\nUnsupervised Learning:\n\nClustering: is discrete. Here there is some latent classes \\(z\\)\n\nHere we can think of unsupervised classification i.e. K-Means Clustering\n\nDimensionality Reduction: is continuous. PCA assumes a continuous latent variable\n\nHere we think about an unsupervised regression\n\n\nProbabilistic methods:\n\nDefine (predictive) distributions\nFind model parameters via ML, MAP (or use fully Bayesian)\n\nDiscriminative methods:\n\nHere we no think about probabilities we just want to make decisions\nIt is more algorithmic in nature\n\nSimilarities between methods:\nDiscriminative methods (left) & Probabilistic methods (Right)\n\nLeast Square Regression &lt;-&gt; MLE Gaussian predictive distribution\nRidge Regression &lt;-&gt; MAP\nK-Means (hard assignment) &lt;-&gt; Gaussian Mixture Models (soft assigment dot point of color green but also red bluish)\n\n\nNew: we will add parametric and non-parametric models\n\nParametric models:\n\nLinear models \\(y(x)=Wx+b\\)\nGeneralized Linear models \\(y(x)=\\sigma(Wx+b)\\)\nNNs i.e our weights W and bias b\nDistribution classes (Gaussian, Bernoulli,..) i.e parametrized by mean, cov, etc\nBasis functions (this is like a hyperparameter)\n\nNon-parametric models:\n\nKernel methods: does not have parameters but still does predictions\nSVM\n\n\nTool in Machine learning is optimization\n\nOptimization:\n\nConvex (one solution: we can solve it analytically) vs non-convex (we used numerical aka brute force solutions like SGD)\nFind stationary points (solve derivative =0)\nAnalytic solutions vs numerical (SGD)\nMethod of Lagrange multipliers (used because sometimes our optimization needs to obey some constraint)\n\nEquality constraint optimization\nInequality constraint optimization"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#so-far-parametric-models",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#so-far-parametric-models",
    "title": "Kernel methods & SVM",
    "section": "2 So Far: Parametric Models",
    "text": "2 So Far: Parametric Models\n\n\n\n\n\nWe teak the parameters highlighted in green color"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#parametric-vs-non-parametric-models",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#parametric-vs-non-parametric-models",
    "title": "Kernel methods & SVM",
    "section": "3 Parametric vs Non-Parametric Models",
    "text": "3 Parametric vs Non-Parametric Models\n\n\n\n\n\nIn parametric you train then discard data and use weights W or other parameters, in Non-parametric you do predictions but you always carry the data to kae such predictions.\n\nBecause carrying big data is not efficient then you may use SVM\n\nHere we define infinitely number of functions spaces \\(M=\\infty\\)\nThis means we have a continuos representation of our space. We can sample as finely as we want, so we can discretized and the index would be one function, because \\(M=\\infty\\) then we adjust this index to the sampling rate to make it more or less smother"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#non-parametric-kernel-methods",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#non-parametric-kernel-methods",
    "title": "Kernel methods & SVM",
    "section": "4 Non-Parametric Kernel Methods",
    "text": "4 Non-Parametric Kernel Methods\n\n\n\n\nRidge regression can be defined in kernelize form without using explicit using basis functions.\n\nPrimal for the parametric case\nDual for the non-parametric representation of the model\n\nFor linear models:\n\nThe kernel it just computing the similarity between \\(x\\) and \\(x'\\)"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#kernelized-ridge-regression",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#kernelized-ridge-regression",
    "title": "Kernel methods & SVM",
    "section": "5 Kernelized Ridge Regression",
    "text": "5 Kernelized Ridge Regression"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#primal-vs-dualkernel-approach",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#primal-vs-dualkernel-approach",
    "title": "Kernel methods & SVM",
    "section": "6 Primal vs Dual/Kernel Approach",
    "text": "6 Primal vs Dual/Kernel Approach"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#kernel-trickkernel-substitution",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#kernel-trickkernel-substitution",
    "title": "Kernel methods & SVM",
    "section": "7 Kernel Trick/Kernel Substitution",
    "text": "7 Kernel Trick/Kernel Substitution\n\n\n\n\n\n\nHow it works?\n\n\n\nThe kernel trick its like calculating similarities with the input datapoint, the prediction would be heavily influenced based on point pairs that are similar\nThe kernel trick is whenever I see the form \\(\\textbf{x}_n^T \\textbf{x}_n\\) (instead of using basis functions) we will replace it with the kernel\n\\[\n\\begin{align}\n\\textbf{k}(\\textbf{x}_n^T, \\textbf{x}_m) = \\textbf{K}_{nm}\n\\end{align}\n\\]\nWe do not know what kernel will be but we can prove that if the kernel is symetric positive semi definite that there are always corresponding basis function \\(\\mathbb{\\phi}(\\textbf{x}_n)^T\\mathbb{\\phi}(\\textbf{x}_n)\\)\nSo basically we find \\(\\mathbb{\\phi}(\\textbf{x}_n)^T\\mathbb{\\phi}(\\textbf{x}_n) = \\textbf{k}(\\textbf{x}_n^T, \\textbf{x}_m) = \\textbf{K}_{nm}\\)\n\n\n\n\n\n\nIf a choice any basis function it induces a kernel simply by computing inner product in the new feature space"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#deriving-the-corresponding-feature-vector",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#deriving-the-corresponding-feature-vector",
    "title": "Kernel methods & SVM",
    "section": "8 Deriving the corresponding feature vector",
    "text": "8 Deriving the corresponding feature vector\n\n\n\n\nFor every positive definite kernel there exist a set of basis from \\(R^d\\) to \\(R^M\\). Meaning there would be a set of basis which means instead of solving for the basis we can just get a valid kernel and not learn the basis\n\n\n\n\n\n\nWhy do I want to go from basis (finite) to valid kernels (can be infinitely?\n\n\n\n\nThis is important because now I do not need to limit myself to find a a dimensional feature descriptors i.e basis in \\(R^d\\) (i.e basis like polynomials basis, or gaussians basis) now I can have a valid kernel that can basically be infinitely in basis functions \\(M = \\infty\\)\n\nSidenote: there is more chance to overfilling\n\n\n\n8.1 Note on infinite dimensional feature space of Gaussian kernels"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#kernel-trick-kernel-substitution",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#kernel-trick-kernel-substitution",
    "title": "Kernel methods & SVM",
    "section": "9 Kernel Trick/ Kernel substitution",
    "text": "9 Kernel Trick/ Kernel substitution"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#example-polynomial-kernel",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#example-polynomial-kernel",
    "title": "Kernel methods & SVM",
    "section": "10 Example: polynomial kernel",
    "text": "10 Example: polynomial kernel\n\n\n\n\nThis shows that if we have this polynomial kernel then that we can decompose it into \\(\\mathbb{\\phi}(\\textbf{x}_n)^T\\mathbb{\\phi}(\\textbf{x}_n)\\)\nWhere: \\(\\mathbb{\\phi}(\\textbf{x}) \\in \\mathbb{R}^{6}\\)"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#examples-of-valid-kernels",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#examples-of-valid-kernels",
    "title": "Kernel methods & SVM",
    "section": "11 Examples of valid Kernels",
    "text": "11 Examples of valid Kernels\n\n\n\n\n\nThe Gaussian kernel produces infinitely \\(M = \\infty\\) many basis functions"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#support-vector-machines",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#support-vector-machines",
    "title": "Kernel methods & SVM",
    "section": "12 Support vector machines",
    "text": "12 Support vector machines\nSVM are kernel methods but with sparse solutions. MEaning some \\(a_n = 0\\) so that we do not compute all datapoints but only relevant. The ones that are relevant are called suport vectors\n\n\n\n\n\nWe are guaranteed to find a solution because it is a Convex optimization problem"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#linearly-separable-dataset",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#linearly-separable-dataset",
    "title": "Kernel methods & SVM",
    "section": "13 Linearly Separable dataset",
    "text": "13 Linearly Separable dataset\n\n\n\n\n\nOne way to tell whether a classifier is better than other is to look at how far us the margin from a closes point to the decision boundary. If the margin is large then I have a stable classifier.\n\n\nGoal: we want to maximize the margin to have a stable classifier. To classify the size of the margin we can use some linear projections to the boundary we see this in the next topic\n\n\n\n\n\nThe graph above is taking into account that we classify the data correctly in two parts so the blue points in one side the red in another."
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#maximum-margin-classifier",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#maximum-margin-classifier",
    "title": "Kernel methods & SVM",
    "section": "14 Maximum Margin Classifier",
    "text": "14 Maximum Margin Classifier\nNow that we have a expression for the margin our objective is to maximize this margin\n\n\n\n\n\nIn this case we have \\(r_n\\) so we could tune \\(w\\) to obtain the maximum margin to a point. How do we do this? we follow:\n\n\n\n\n\n\nIdentify the closest point. The \\(\\kappa\\) (kappa) its introduced to say we can amplify our distance we can i.e have the distance in kiloliters or miles etc.\nTo resolve the ambiguity of measuring in kilometers or in miles or so for, we set our \\(||\\kappa \\textbf{w}|| = 1\\). This is essentially setting the unit which you want to compute the distance. You are saying then the closest point should have unit 1 this is a constraint\n\nFrom this step it follows that all the points would be my prediction times label \\(t_n \\, y_n\\) will be greater or equal to \\(1\\)\n\nWe maximize the size of the margin given by 1/|W| with the inequality constraint\n\n\n\n\n\n\n\n\n\n\n\nMaximum Margin Classifier: Goal\n\n\n\n\nMaximize \\(\\frac{1}{\\textbf{w}}\\) means minimize \\(\\frac{1}{2}||\\textbf{w}||^2\\)\nWe have \\(N\\) constraints because we need to go over each datapoint\nIt is a convex quadratic optimization problem with a quadratic loss and linear constraint. We solve this by Lagrange Multipliers"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#constrained-optimization-inequality-constraint",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#constrained-optimization-inequality-constraint",
    "title": "Kernel methods & SVM",
    "section": "15 Constrained optimization (inequality constraint)",
    "text": "15 Constrained optimization (inequality constraint)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow the solution should lie within the yellow region\n\nThere is two cases: 1. The objective could lie inside the yellow region. Then I am doing maximization without any constriant 2. If the solution lies outside then the solution would lie on the perpendicular to the yellow boundary. See point \\(x_A\\) where there is an arrow pointing to \\(x\\) (the optimum solution)\nBefore\n\nWe solve the lagrange multiplier, derive with respect to parameter ie. \\(w\\) then derive wrt to \\(\\lambda\\) and then replace this solution into \\(w\\).\n\nNow (we need additional requirements):\n\nDefine Primal Lagrangian function: \\(L = f(x) - constraint\\)\nCompute the dual lagrangian\nWith solvers solve the dual problem\n\n\nSidenote: dual optimizer (is convex) gives you optimal solutions, it is a way of convexifiyng a problem\n\nYou need to think that the dual gives you an upper bound, and you are lowering this by setting \\(\\mu\\) as much as possible"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#svm-maximum-margin-classifier",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#svm-maximum-margin-classifier",
    "title": "Kernel methods & SVM",
    "section": "16 SVM: Maximum Margin Classifier",
    "text": "16 SVM: Maximum Margin Classifier\n\nFor a maximization problem we \\(+\\) (sum) our constraint\nFor a minimization problem we \\(-\\) (subtract) our constraint\nThen you approach the limit from below\n\n\n16.1 Calculating the Lagrange\n\n\n\n\n\n\n\n\n\n\nSteps to compute the lagrange\n\n\n\n\nGoal: we want to obtain optimal values for \\(\\textbf{w}^*\\) and \\(b^*\\)\n\n\nWrite down:\n\nPrimal Lagrange function: \\(L = f(x) - constraints\\)\nWrite the KKT conditions\n\nDerive the Dual Lagrangian by setting \\(\\frac{\\partial L}{\\partial \\textbf{w}}=0\\), \\(\\frac{\\partial L}{\\partial b}=0\\)\n\nLet the machine compute what is the argmax \\(a\\) so that we obtain our parameters \\(\\textbf{w}^*\\) and \\(b^*\\)\n\n\n\n\nFor the case of SVM we start by step 1.\n\n\n\n\n\nWe write the primal Lagrange with the constriant. Also, we introduce the dual variables (lagrange multipliers) \\(\\textbf{a}_n\\) meaning for every each datapoint we want it to lie in the proper side of the boundary. This condition that \\(\\textbf{a}_n\\) imposes comes from the KKT conditions\n\nWe solve for \\(\\frac{\\partial L}{\\partial \\textbf{w}}=0\\), \\(\\frac{\\partial L}{\\partial b}=0\\) and rewrite the Primal to the Dual Lagrangian\n\n\n\n\n\nOnce we have those parameters we plug in again in the Lagrange in step 1. Then the function will be dependent on \\(a_n\\) which is then called the Dual Lagrangian\n\n\n\n\n\nRemember Dual Lagrangian would be convex so we know there would be unique solution\n\nNow that we have derived the dual we can now apply the kernel trick as follows:"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#sparse-solutions-due-to-kkt",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#sparse-solutions-due-to-kkt",
    "title": "Kernel methods & SVM",
    "section": "17 Sparse solutions due to KKT",
    "text": "17 Sparse solutions due to KKT\n\n\n\n\n\n\nKernel trick uses fewer points rather than \\(x_n\\) these are called: Support vectors\n\n\n\nDue to kernel trick we now would have used all the datapoints in our dataset but this is no longer the case because of our complimentary slackness which says that points liying on \\(y=1\\) or \\(y=-1\\) or better said when this \\(t_ny(\\textbf{x}_n)\\) is true then their lagrange multipliers: \\(a_n\\) would be zero.\nWhich means we would a couple of datapoints instead of the whole batch \\(x_n\\). These selected points are called the support vectors"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#svm-solution-for-bias-b",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#svm-solution-for-bias-b",
    "title": "Kernel methods & SVM",
    "section": "18 SVM: Solution for bias b",
    "text": "18 SVM: Solution for bias b\nSo far we have solve \\(y(\\textbf{x})\\) but we still have \\(\\textbf{b}\\). So now we solve for this latter variable:\nRecall we have the constraint that we derive deriving the primal wrt to \\(b\\):\n\n\n\n\nThat means I can pick whathever \\(\\textbf{b}\\) I want as long the KKT constraints are satisfied\nNo we use the final constraint that \\(t_ny_n(x)=1\\)\n\n\n\n\n\nIn practice when we found a solution for b its better to average them"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#maximum-margin-classifier-contours",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#maximum-margin-classifier-contours",
    "title": "Kernel methods & SVM",
    "section": "19 Maximum Margin Classifier: Contours",
    "text": "19 Maximum Margin Classifier: Contours\n\n\n\n\n\nIf we use a gaussian kernel then our Maximal Margin Classifier we will always be able to classify the points i.e we may end up with an island to classify only one point.\nThe reason why the contours are smooth is because of the sigma parameter from the gaussian. The small the sigma the more wably (unpredictable), the larger the smoother.\nNote on the sigma value: sigma very small then the similarity decays. That means the the decision boundaries would be very curvy aka irregular decision boundary. If I make sigma very large then the countours become smoother"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#note-on-outliers",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#note-on-outliers",
    "title": "Kernel methods & SVM",
    "section": "20 Note on outliers",
    "text": "20 Note on outliers\n\n\n\n\nDue to the capability of the Maximum Margin Classifier all outliers would be calssified well which sometimes may not be desirable, to avoid this irregular boundaries we introduce slackness variables. This notion leads to SVM with Soft Margins"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#soft-margin-classifiers",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#soft-margin-classifiers",
    "title": "Kernel methods & SVM",
    "section": "21 Soft Margin Classifiers",
    "text": "21 Soft Margin Classifiers\n\n\n\n\n\nWe do not move the decision boundary, we allow outliers but we add a penalty to them\nPenalty is proportional to the boundary\n\n\n\n\n\nSo now because we introduce this slack variable we have a new constraint optimization problem."
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#maximum-margin-classifiers-soft-margins",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#maximum-margin-classifiers-soft-margins",
    "title": "Kernel methods & SVM",
    "section": "22 Maximum Margin Classifiers: Soft Margins",
    "text": "22 Maximum Margin Classifiers: Soft Margins\n\n\n\n\n\nThe \\(C\\) variable would be the one that decides which points get penalize. That is, \\(C\\) prevents that every point get a slack and, our goal now is to avoid as many points to be in the wrong side of the decision boundaries.\nThus we are now minimizing three parameters: \\(\\textbf{w}\\), \\(\\textbf{b}\\) and \\(\\xi_n\\), where the slack variable should always be positive variable. This induces the following constraints\n\nSolving steps 1 -&gt; 2:\n\n\n\n\n\nPrimal variables: \\(\\textbf{w}\\), \\(\\textbf{b}\\) and \\(\\xi_n\\)\nDual variables: \\(a_n\\) and \\(\\mu_n\\)\n\nSolving steps 3 -&gt; 4:\n\nSolving the derivatives for the primal variables \\(\\textbf{w}\\), \\(\\textbf{b}\\) and \\(\\xi_n\\)\n\n\n\n\n\nSolving mid-step: Box constraints:\n\n\n\n\n\nThe box constraint comes from the green highlighted equations"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#wrapping-up-maximum-classifiers-w-soft-margins",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#wrapping-up-maximum-classifiers-w-soft-margins",
    "title": "Kernel methods & SVM",
    "section": "23 Wrapping up: Maximum Classifiers w/ Soft Margins",
    "text": "23 Wrapping up: Maximum Classifiers w/ Soft Margins\n\nIf there is no constraint \\(C -&gt; 0\\): then you allow every point in the boundary to have slack because there is essentially no penalty. That means:\n\nYou are more flexible to outliers\nYour margin becomes infinitely wide\nEvery datapoint becomes a support vector\nThere is no sparcity to the kernel matrix, because all the points would be a support vector\n\n\n\n\nIf my \\(C -&gt; \\infty\\) then I do not allow slack so that means I am very strick because I am penalizing very hugely to my slack that means I will not allow points that corss the margin. Which brings you to the case of hard margin\n\nThis means if I have an outlier I will have an smaller decision boundary because that outlier will be considered as a support vector, therefore it will lower the margin size which means I will have an unstable model when a random datapoint appears\nBefore & After"
  },
  {
    "objectID": "blog/2023-10-15_kernel-methods-&-svm/index.html#clarification-of-problems",
    "href": "blog/2023-10-15_kernel-methods-&-svm/index.html#clarification-of-problems",
    "title": "Kernel methods & SVM",
    "section": "24 Clarification of problems",
    "text": "24 Clarification of problems\nConvex optimization problems\n\n\nLinear Regression\n\nLinear regression with L2 regularization (ridge regression) and L1 regularization (lasso regression) are convex optimization problems. Ridge regression minimizes the sum of squared errors plus the L2 norm of the coefficients, while lasso minimizes the sum of squared errors plus the L1 norm of the coefficients\n\n\n\nLogistic Regression with L1 or L2 Regularization\n\nSimilar to linear regression, logistic regression can incorporate L1 or L2 regularization terms, making it a convex optimization problem\n\n\n\nSVM\n\nWe can use the Dual Lagrangian together with the kernel trick so that we find a convex solution. The dual isolates the \\(a_n\\) and also \\(x_n x_n^T\\) so then in the end we use the kernel trick and because we can express it with gaussian which where infinitely then we know we will find a solution\n\n\n\nQuadratic Discriminant Analysis (QDA)\n\nQDA is a supervised learning algorithm with a quadratic decision boundary and can be formulated as a convex optimization problem\n\n\n\nPerceptron\n\n\nNon-Convex optimization problems:\n\n\nK-Means Clustering\n\n\n\n\nGMM\n\nWe use the EM algorithm because the maths get heavy so there we run into possibility of getting stuck in local minima\n\n\n\nPCA\n\n\n\n\nNeural Networks\n\nbecause of the non-linearity introduced by the activation functions"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Danilo Toapanta",
    "section": "",
    "text": "Quick links:  Slides  |  Projects  | Books  | What I’m doing now\n\nNews\n\n\n    \n        \n            Sep 2023 - I am attending, OpenAI: AI and the Future of Humanity\n            Jun 2023 - I will do an intership at IMEC\n            May 2023 - Have been accepted to the M.Sc. in AI at UvA\n            Feb 2023 - Now the website has a Blog section\n            Nov 2023 - Have completed AI Berkeley Course\n        \n    \n\n\n\n\n\n\n\nNote\n\n\n\nThis website is under construction. To review changes visit DEV page of this site."
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "Danilo Toapanta",
    "section": "",
    "text": "Hi, there! This is Danilo.\n                    \n                    I’m an AI researcher based in the Netherlands.\n                    I studied Computer Science & Electrical Engineering in my undergraduate programme and now I am doing my master in Artificial Intelligence.\n                    When I am not trying to figure out how my computer works, I like to read books, run, go for a swim, and spend some quality time with my family.\n                    \n                    \n                        You can look me up on Github↗. \n                        Check out my LinkedIn↗. \n                        Read my lastest post. \n                        \n                        Or send me an\n                            email↗."
  },
  {
    "objectID": "coming-soon.html",
    "href": "coming-soon.html",
    "title": "Coming Soon",
    "section": "",
    "text": "Coming Soon\n        \n    \n    \n        \n            The page you requested is under construction."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Published",
    "section": "",
    "text": "# \n        \n        \n          projects:\n        \n      \n      Published\n    \n  \n\n  \n    \n      \n        \n          Show All Projects  \n        \n      \n    \n  \n  \n\n \n\n\n\n\n     \n        \n        \n            \n            1\n            \n            2\n            \n            3\n            \n            4\n        \n            \n                \n                1\n                \n                2\n        \n        \n            \n            5\n            \n            6\n            \n            7\n        \n            \n                \n                3\n        \n        \n            \n            8\n            \n            9\n            \n            10\n        \n            \n                \n                4\n        \n        \n            \n            11\n            \n            12\n            \n            13\n            \n            14\n        \n            \n                \n                5\n                \n                6\n        \n        \n            \n            15\n            \n            16\n            \n            17\n        \n            \n                \n                7\n                \n                8\n        \n        \n            \n            18\n            \n            19\n            \n            20\n            \n            21\n        \n            \n                \n                9\n        \n        \n            \n            22\n            \n            23\n        \n            \n                \n                10\n        \n        \n            \n            24\n            \n            25\n        \n            \n                \n                11\n\n\n        \n        \n            \n            \n                \n                    \n                        \n                            Website\n                            \n                            ×\n                            \n                        \n                        \n                            \n                                \n                                \n                                    \n                                    \n                                        \n                                    \n                                    \n                                    \n                                        \n                                                \n                                                    In this project I have created a website to hold my notes, show my projects, share my contact details. If you are interested in the project make sure to click on the source icon to take a look at the complete source. Cheers \n                                                \n                                            \n                                            \n                                                About\n                                             \n                                                \n                                                    Source\n                                                    \n                                                 \n                                                \n                                             \n                                                 \n                                                        \n                                                            \n                                                            \n                                                                HTML\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                Javascript\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                SCSS\n                                                               \n                                                        \n                                             \n                                            \n                                            \n                                                \n                                                \n                                                    \n                                                    \n                                                    Tags:\n                                                    \n                                                \n                                                 \n                                                        \n                                                            \n                                                                \n                                                                    Blog\n                                                                   \n                                                        \n                                                        \n                                                            \n                                                                \n                                                                    Research\n                                                                   \n                                                        \n                                             \n                                        \n                                     \n                                 \n                            \n                         \n                     \n                  \n             \n            \n            \n            \n                \n                    Website\n                \n                \n            \n            \n                \n                \n                    About\n                 \n                    \n                        Source\n                        \n                        \n                     \n                    \n                 \n                     \n                            \n                                \n                                    HTML\n                                   \n                            \n                            \n                                \n                                    Javascript\n                                   \n                            \n                            \n                                \n                                    SCSS\n                                   \n                            \n                 \n                \n                \n                    \n                    \n                        \n                        \n                        \n                        Tags:\n                        \n                    \n                     \n                            \n                                \n                                    \n                                        Blog\n                                       \n                            \n                            \n                                \n                                    \n                                        Research\n                                       \n                            \n                 \n            \n        \n        \n        \n            \n            \n                \n                    \n                        \n                            ML Project\n                            \n                            ×\n                            \n                        \n                        \n                            \n                                \n                                \n                                    \n                                    \n                                        \n                                    \n                                    \n                                    \n                                        \n                                                \n                                                    \n                                                \n                                            \n                                            \n                                                About\n                                             \n                                                \n                                                    Source\n                                                    \n                                                 \n                                                \n                                             \n                                                 \n                                                        \n                                                            \n                                                            \n                                                                Python\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                OpenSpiel\n                                                               \n                                                        \n                                             \n                                            \n                                            \n                                                \n                                                \n                                                    \n                                                    \n                                                    Tags:\n                                                    \n                                                \n                                                 \n                                                        \n                                                            \n                                                                \n                                                                    Machine Learning\n                                                                   \n                                                        \n                                             \n                                        \n                                     \n                                 \n                            \n                         \n                     \n                  \n             \n            \n            \n            \n                \n                    ML Project\n                \n                \n            \n            \n                \n                \n                    About\n                 \n                    \n                        Source\n                        \n                        \n                     \n                    \n                 \n                     \n                            \n                                \n                                    Python\n                                   \n                            \n                            \n                                \n                                    OpenSpiel\n                                   \n                            \n                 \n                \n                \n                    \n                    \n                        \n                        \n                        \n                        Tags:\n                        \n                    \n                     \n                            \n                                \n                                    \n                                        Machine Learning\n                                       \n                            \n                 \n            \n        \n        \n        \n            \n            \n                \n                    \n                        \n                            EA Project\n                            \n                            ×\n                            \n                        \n                        \n                            \n                                \n                                \n                                    \n                                    \n                                        \n                                    \n                                    \n                                    \n                                        \n                                                \n                                                    \n                                                \n                                            \n                                            \n                                                About\n                                             \n                                                \n                                                    Source\n                                                    \n                                                 \n                                                \n                                             \n                                                 \n                                                        \n                                                            \n                                                            \n                                                                Python\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                Numba\n                                                               \n                                                        \n                                             \n                                            \n                                            \n                                                \n                                                \n                                                    \n                                                    \n                                                    Tags:\n                                                    \n                                                \n                                                 \n                                                        \n                                                            \n                                                                \n                                                                    Optimization\n                                                                   \n                                                        \n                                             \n                                        \n                                     \n                                 \n                            \n                         \n                     \n                  \n             \n            \n            \n            \n                \n                    EA Project\n                \n                \n            \n            \n                \n                \n                    About\n                 \n                    \n                        Source\n                        \n                        \n                     \n                    \n                 \n                     \n                            \n                                \n                                    Python\n                                   \n                            \n                            \n                                \n                                    Numba\n                                   \n                            \n                 \n                \n                \n                    \n                    \n                        \n                        \n                        \n                        Tags:\n                        \n                    \n                     \n                            \n                                \n                                    \n                                        Optimization\n                                       \n                            \n                 \n            \n        \n        \n        \n            \n            \n                \n                    \n                        \n                            CV Project\n                            \n                            ×\n                            \n                        \n                        \n                            \n                                \n                                \n                                    \n                                    \n                                        \n                                    \n                                    \n                                    \n                                        \n                                                \n                                                    \n                                                \n                                            \n                                            \n                                                About\n                                             \n                                                \n                                                    Source\n                                                    \n                                                 \n                                                \n                                             \n                                                 \n                                                        \n                                                            \n                                                            \n                                                                Python\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                Kaggle\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                Tensorflow\n                                                               \n                                                        \n                                             \n                                            \n                                            \n                                                \n                                                \n                                                    \n                                                    \n                                                    Tags:\n                                                    \n                                                \n                                                 \n                                                        \n                                                            \n                                                                \n                                                                    Computer Vision\n                                                                   \n                                                        \n                                                        \n                                                            \n                                                                \n                                                                    Control Systems\n                                                                   \n                                                        \n                                             \n                                        \n                                     \n                                 \n                            \n                         \n                     \n                  \n             \n            \n            \n            \n                \n                    CV Project\n                \n                \n            \n            \n                \n                \n                    About\n                 \n                    \n                        Source\n                        \n                        \n                     \n                    \n                 \n                     \n                            \n                                \n                                    Python\n                                   \n                            \n                            \n                                \n                                    Kaggle\n                                   \n                            \n                            \n                                \n                                    Tensorflow\n                                   \n                            \n                 \n                \n                \n                    \n                    \n                        \n                        \n                        \n                        Tags:\n                        \n                    \n                     \n                            \n                                \n                                    \n                                        Computer Vision\n                                       \n                            \n                            \n                                \n                                    \n                                        Control Systems\n                                       \n                            \n                 \n            \n        \n        \n        \n            \n            \n                \n                    \n                        \n                            AI Project\n                            \n                            ×\n                            \n                        \n                        \n                            \n                                \n                                \n                                    \n                                    \n                                        \n                                    \n                                    \n                                    \n                                        \n                                                \n                                                    \n                                                \n                                            \n                                            \n                                                About\n                                             \n                                                \n                                                    Source\n                                                    \n                                                 \n                                                \n                                             \n                                                 \n                                                        \n                                                            \n                                                            \n                                                                Python\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                LateX\n                                                               \n                                                        \n                                             \n                                            \n                                            \n                                                \n                                                \n                                                    \n                                                    \n                                                    Tags:\n                                                    \n                                                \n                                                 \n                                                        \n                                                            \n                                                                \n                                                                    Machine Learning\n                                                                   \n                                                        \n                                                        \n                                                            \n                                                                \n                                                                    Algorithms\n                                                                   \n                                                        \n                                             \n                                        \n                                     \n                                 \n                            \n                         \n                     \n                  \n             \n            \n            \n            \n                \n                    AI Project\n                \n                \n            \n            \n                \n                \n                    About\n                 \n                    \n                        Source\n                        \n                        \n                     \n                    \n                 \n                     \n                            \n                                \n                                    Python\n                                   \n                            \n                            \n                                \n                                    LateX\n                                   \n                            \n                 \n                \n                \n                    \n                    \n                        \n                        \n                        \n                        Tags:\n                        \n                    \n                     \n                            \n                                \n                                    \n                                        Machine Learning\n                                       \n                            \n                            \n                                \n                                    \n                                        Algorithms\n                                       \n                            \n                 \n            \n        \n        \n        \n            \n            \n                \n                    \n                        \n                            BSc Thesis\n                            \n                            ×\n                            \n                        \n                        \n                            \n                                \n                                \n                                    \n                                    \n                                        \n                                    \n                                    \n                                    \n                                        \n                                                \n                                                    \n                                                \n                                            \n                                            \n                                                About\n                                             \n                                                \n                                                    Paper\n                                                    \n                                                 \n                                                \n                                             \n                                                 \n                                                        \n                                                            \n                                                            \n                                                                C++\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                LateX\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                Arduino\n                                                               \n                                                        \n                                             \n                                            \n                                            \n                                                \n                                                \n                                                    \n                                                    \n                                                    Tags:\n                                                    \n                                                \n                                                 \n                                                        \n                                                            \n                                                                \n                                                                    Electrical Engineering\n                                                                   \n                                                        \n                                             \n                                        \n                                     \n                                 \n                            \n                         \n                     \n                  \n             \n            \n            \n            \n                \n                    BSc Thesis\n                \n                \n            \n            \n                \n                \n                    About\n                 \n                    \n                        Paper\n                        \n                     \n                    \n                 \n                     \n                            \n                                \n                                    C++\n                                   \n                            \n                            \n                                \n                                    LateX\n                                   \n                            \n                            \n                                \n                                    Arduino\n                                   \n                            \n                 \n                \n                \n                    \n                    \n                        \n                        \n                        \n                        Tags:\n                        \n                    \n                     \n                            \n                                \n                                    \n                                        Electrical Engineering\n                                       \n                            \n                 \n            \n        \n        \n        \n            \n            \n                \n                    \n                        \n                            C++ Project\n                            \n                            ×\n                            \n                        \n                        \n                            \n                                \n                                \n                                    \n                                    \n                                        \n                                    \n                                    \n                                    \n                                        \n                                                \n                                                    \n                                                \n                                            \n                                            \n                                                About\n                                             \n                                                \n                                                    Source\n                                                    \n                                                 \n                                                \n                                             \n                                                 \n                                                        \n                                                            \n                                                            \n                                                                C++\n                                                               \n                                                        \n                                             \n                                            \n                                            \n                                                \n                                                \n                                                    \n                                                    \n                                                    Tags:\n                                                    \n                                                \n                                                 \n                                                        \n                                                            \n                                                                \n                                                                    Software Engineering\n                                                                   \n                                                        \n                                             \n                                        \n                                     \n                                 \n                            \n                         \n                     \n                  \n             \n            \n            \n            \n                \n                    C++ Project\n                \n                \n            \n            \n                \n                \n                    About\n                 \n                    \n                        Source\n                        \n                        \n                     \n                    \n                 \n                     \n                            \n                                \n                                    C++\n                                   \n                            \n                 \n                \n                \n                    \n                    \n                        \n                        \n                        \n                        Tags:\n                        \n                    \n                     \n                            \n                                \n                                    \n                                        Software Engineering\n                                       \n                            \n                 \n            \n        \n        \n        \n            \n            \n                \n                    \n                        \n                            Control Systems Project\n                            \n                            ×\n                            \n                        \n                        \n                            \n                                \n                                \n                                    \n                                    \n                                        \n                                    \n                                    \n                                    \n                                        \n                                                \n                                                    \n                                                \n                                            \n                                            \n                                                About\n                                             \n                                                \n                                                    Source\n                                                    \n                                                 \n                                                \n                                             \n                                                 \n                                                        \n                                                            \n                                                            \n                                                                20-sim\n                                                               \n                                                        \n                                             \n                                            \n                                            \n                                                \n                                                \n                                                    \n                                                    \n                                                    Tags:\n                                                    \n                                                \n                                                 \n                                                        \n                                                            \n                                                                \n                                                                    Electrical Engineering\n                                                                   \n                                                        \n                                             \n                                        \n                                     \n                                 \n                            \n                         \n                     \n                  \n             \n            \n            \n            \n                \n                    Control Systems Project\n                \n                \n            \n            \n                \n                \n                    About\n                 \n                    \n                        Source\n                        \n                        \n                     \n                    \n                 \n                     \n                            \n                                \n                                    20-sim\n                                   \n                            \n                 \n                \n                \n                    \n                    \n                        \n                        \n                        \n                        Tags:\n                        \n                    \n                     \n                            \n                                \n                                    \n                                        Electrical Engineering\n                                       \n                            \n                 \n            \n        \n\n\n         \n            All\n        \n         \n            HTML\n        \n         \n            Javascript\n        \n         \n            SCSS\n        \n         \n            All\n        \n         \n            Python\n        \n         \n            OpenSpiel\n        \n         \n            All\n        \n         \n            Python\n        \n         \n            Numba\n        \n         \n            All\n        \n         \n            Python\n        \n         \n            Kaggle\n        \n         \n            Tensorflow\n        \n         \n            All\n        \n         \n            Python\n        \n         \n            LateX\n        \n         \n            All\n        \n         \n            C++\n        \n         \n            LateX\n        \n         \n            Arduino\n        \n         \n            All\n        \n         \n            C++\n        \n         \n            All\n        \n         \n            20-sim\n        \n         \n            Blog\n        \n         \n            Research\n        \n         \n            Machine Learning\n        \n         \n            Optimization\n        \n         \n            Computer Vision\n        \n         \n            Control Systems\n        \n         \n            Machine Learning\n        \n         \n            Algorithms\n        \n         \n            Electrical Engineering\n        \n         \n            Software Engineering\n        \n         \n            Electrical Engineering\n        \n         \n            website\n        \n         \n            ml_project\n        \n         \n            ea_project\n        \n         \n            cv_project\n        \n         \n            ai_project\n        \n         \n            bsc_thesis\n        \n         \n            c_project\n        \n         \n            control_systems_project\n        \n\n\nNo matching items"
  },
  {
    "objectID": "books/index.html",
    "href": "books/index.html",
    "title": "Books",
    "section": "",
    "text": "Books\n\n\nThis section covers various books that I have read and think are worth recommending.\n\n\n\n\n\n\nGoal of this section\n\n\n\n\n\n\nRefer to this page when my friends ask me what I read\nKeep a colection of books including the author’s name\n\n\n\n\n\n\n\n\n\n        \n            \n                \n                Atomic Habits\n                James Clear\n            \n        \n\n\n        \n            \n                \n                Unclutter Your Life in One Week\n                Erin Rooney Doland\n            \n        \n\n\n\n         \n            \n                \n                \n                    The Tipping Point\n                    Malcolm Gladwell\n                \n            \n        \n\n\n\n        \n            \n                \n                Mindset\n                Carol S. Dweck\n            \n        \n\n\n\n        \n            \n                \n                The Four-Hour Workweek\n                Tim Ferriss\n            \n        \n\n\n\n        \n            \n                \n                Blink\n                Malcolm Gladwell\n            \n        \n\n\n\n        \n            \n                \n                The Tipping Point\n                Malcolm Gladwell\n            \n        \n\n\n\n        \n            \n                \n                The Information\n                James Gleick\n            \n        \n\n\n\n        \n            \n                \n                The Practice\n                Seth Godin\n            \n        \n\n\n\n        \n            \n                \n                All Marketers are Liars\n                Seth Godin\n            \n        \n\n\n\n        \n            \n                \n                Emotional Intelligence\n                Daniel Goleman\n            \n        \n\n\n\n        \n            \n                \n                Originals\n                Adam Grant\n            \n        \n\n\n\n        \n            \n                \n                You Can't Make This Stuff Up\n                Lee Gutkind\n            \n        \n\n\n\n        \n            \n                \n                Mindfulness in Plain English\n                Bhante Henepola Gunaratana\n            \n        \n\n\n\n        \n            \n                \n                The Joy of Less\n                Francine Jay\n            \n        \n\n\n\n        \n            \n                \n                Farsighted\n                Steven Johnson\n            \n        \n\n\n\n        \n            \n                \n                Where Good Ideas Come From\n                Steven Johnson"
  },
  {
    "objectID": "blog/2023-09-04_mnist-classification/index.html",
    "href": "blog/2023-09-04_mnist-classification/index.html",
    "title": "MNIST Classification",
    "section": "",
    "text": "Classification example using Tensorflow\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 4, 2023\n        \n      \n      \n        \n      \n      \n\n    \n        Quick Links\n    \n         Quick Links:\n                                    \n                 Notebook\n                        \n                                    \n                 requirements.txt"
  },
  {
    "objectID": "blog/2023-09-04_mnist-classification/index.html#how-to-run-locally",
    "href": "blog/2023-09-04_mnist-classification/index.html#how-to-run-locally",
    "title": "MNIST Classification",
    "section": "1 How to run locally",
    "text": "1 How to run locally\n$ pip install -r requirements.txt"
  },
  {
    "objectID": "blog/2023-09-04_mnist-classification/index.html#importing-all-libraries",
    "href": "blog/2023-09-04_mnist-classification/index.html#importing-all-libraries",
    "title": "MNIST Classification",
    "section": "2 Importing all libraries",
    "text": "2 Importing all libraries\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nimport cv2\nnp.random.seed(42)                          # This allows us to reproduce the results from our script\nfrom keras.models import Sequential             \nfrom keras.layers import Dense, Activation\nfrom keras.optimizers import Adam, SGD\nfrom keras.utils import to_categorical \n\n\n(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\nprint('Total no of Images: ',X_train.shape[0]) \nprint('Size of Image:', X_train.shape[1:])\nprint('Total no of labels:', y_train.shape)\n\nTotal no of Images:  60000\nSize of Image: (28, 28)\nTotal no of labels: (60000,)\n\n\n\n# Look input data\nnum = 10\nnum_row = 2\nnum_col = 5\nimages = X_train[:num]\nlabels = y_train[:num]\n\n# Ploting images\nfig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\nfor i in range(num):\n    ax = axes[i//num_col, i%num_col]\n    ax.imshow(images[i], cmap='gray')\n    ax.set_title('Label: {}'.format(labels[i]))\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "blog/2023-09-04_mnist-classification/index.html#prepare-input-data",
    "href": "blog/2023-09-04_mnist-classification/index.html#prepare-input-data",
    "title": "MNIST Classification",
    "section": "3 Prepare input data",
    "text": "3 Prepare input data\n\nX_train = X_train.reshape((X_train.shape[0],-1))\nX_test = X_test.reshape((X_test.shape[0], -1))\n\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\nprint(X_train.shape, X_test.shape)\n\n(60000, 784) (10000, 784)\n\n\n\n# Normalize data\nX_train = X_train/255\nX_test = X_test/255\n\n# print(X_train[0])\nX_train.shape\n\n(60000, 784)\n\n\n\n# Perfom one encoding\n\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\nprint(y_train.shape)\n\n(60000, 10)\n\n\n\nnum_classes = y_test.shape[1]\nnum_pixels = 784"
  },
  {
    "objectID": "blog/2023-09-04_mnist-classification/index.html#defining-the-model",
    "href": "blog/2023-09-04_mnist-classification/index.html#defining-the-model",
    "title": "MNIST Classification",
    "section": "4 Defining the model",
    "text": "4 Defining the model\n\n# Define baseline model\n\ndef baseline_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(256, input_dim=num_pixels, activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    \n    return model\n\n\n# Build the model\nmodel = baseline_model()\nmodel.summary()\n\nModel: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_6 (Dense)             (None, 256)               200960    \n                                                                 \n dense_7 (Dense)             (None, 64)                16448     \n                                                                 \n dense_8 (Dense)             (None, 10)                650       \n                                                                 \n=================================================================\nTotal params: 218058 (851.79 KB)\nTrainable params: 218058 (851.79 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\nopt = SGD(lr = 0.001)\nmodel.compile(loss='categorical_crossentropy', optimizer= opt, metrics=['accuracy'])\n\nWARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD."
  },
  {
    "objectID": "blog/2023-09-04_mnist-classification/index.html#train-model",
    "href": "blog/2023-09-04_mnist-classification/index.html#train-model",
    "title": "MNIST Classification",
    "section": "5 Train model",
    "text": "5 Train model\n\nmodel.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n\nEpoch 1/5\n1875/1875 [==============================] - 9s 4ms/step - loss: 0.6029 - accuracy: 0.8422\nEpoch 2/5\n1875/1875 [==============================] - 7s 4ms/step - loss: 0.2849 - accuracy: 0.9181\nEpoch 3/5\n1875/1875 [==============================] - 7s 4ms/step - loss: 0.2314 - accuracy: 0.9346\nEpoch 4/5\n1875/1875 [==============================] - 8s 4ms/step - loss: 0.1962 - accuracy: 0.9440\nEpoch 5/5\n1875/1875 [==============================] - 8s 4ms/step - loss: 0.1701 - accuracy: 0.9510\n\n\n&lt;keras.src.callbacks.History at 0x13e2b0b50&gt;"
  },
  {
    "objectID": "blog/2023-09-04_mnist-classification/index.html#test-model",
    "href": "blog/2023-09-04_mnist-classification/index.html#test-model",
    "title": "MNIST Classification",
    "section": "6 Test model",
    "text": "6 Test model\n\nscores = model.evaluate(X_test, y_test, verbose=1)\nprint(\"Error: %.2f%%\" % (100-scores[1]*100))\n\n313/313 [==============================] - 1s 3ms/step - loss: 0.1672 - accuracy: 0.9516\nError: 4.84%"
  },
  {
    "objectID": "blog/2023-09-04_mnist-classification/index.html#predicting",
    "href": "blog/2023-09-04_mnist-classification/index.html#predicting",
    "title": "MNIST Classification",
    "section": "7 Predicting",
    "text": "7 Predicting\n\nimg_width, img_height = 28, 28\ngray_image = X_test[0]\nplt.imshow(gray_image,cmap='Greys')\nplt.show()\n# gray_image.shape\nx = np.expand_dims(gray_image, axis=0)\nx = x.reshape((1, -1))\n\n\n\n\n\npreds = model.predict(x)\nprob = np.argmax(preds, axis=1)\n\nprint('Predicted value is ', prob)\nprint('Probability across all numbers :', preds[0])\n\n1/1 [==============================] - 0s 30ms/step\nPredicted value is  [7]\nProbability across all numbers : [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]"
  },
  {
    "objectID": "blog/2022-12-29_cuando-miras-al-cielo/index.html",
    "href": "blog/2022-12-29_cuando-miras-al-cielo/index.html",
    "title": "Cuando miras al cielo",
    "section": "",
    "text": "Cuando miras al cielo\n        \n        \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Poems\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Spanish\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Poems\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Spanish\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          December 29, 2022\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\nby Danilo Toapanta \n\nBlog  &gt; Poems\n\n\nEn el cesped yace tu cuerpo\ndonde tus ideas viajan por las nubes\ntus manos tratan de alcanzar el cielo\ntu mente siente la textura de algodón\npero tu cuerpo sabe que yace en el cesped."
  },
  {
    "objectID": "blog/2023-01-12_2022-into-2023/index.html",
    "href": "blog/2023-01-12_2022-into-2023/index.html",
    "title": "2022 into 2023",
    "section": "",
    "text": "2022 into 2023\n        \n        \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                News\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                News\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          January 12, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\nHappy New Year! Time to write another year in review. This will be the first time I’ve done this. Here are all the previous ones:\n\n2022 into 2023\n\nI have really high hopes for 2023! It’s only a few days in and so far so good. I’ve really had a chance to relax, rest, and reset."
  },
  {
    "objectID": "blog/2023-11-13_modelling-syntactic-structure/index.html",
    "href": "blog/2023-11-13_modelling-syntactic-structure/index.html",
    "title": "Modelling Syntactic Structure",
    "section": "",
    "text": "Modelling Syntactic Structure\n        \n        \n                    \n                \n                    Description of this Post\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                NLP\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                NLP\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          November 13, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\n\n\n\n\n\nSlide 2\n\n\n\n\n\n\n\n\nSlide 3\n\n\n\n\n\nBoW\n\nBag of Words does not consider order, it is basically counting what occur in a sentence in arbitrary order\n\nMarkov Models\n\nThey are bags of phrases, they have better units but are very sparse\n\nHMMs:\n\nNow we work in the tag space. Here we push the memory layer again to another space, in the tag space. So no memory in the word space itself. We capture shallo syntactic patterns such as NOUN is preceeded by an ADJECTIVE in english\nHMMs does not really have power for semantics because words are drawn conditionally independently\n\n\n\n\nSlide 4\n\n\n\n\nNow instead of just categories we talk about phrase categories.\nYou can now group words into phrases and these phrases can be labeled for their syntactic role\n\n\n\n\n\n\n\n\n\nSlide 10\n\n\n\n\nNow instead of isolated tags now we considered as phrases\n\n\n\n\nSlide 11\n\n\n\n\nA phrase usually has what is called a syntactic head, and usually is the first occurrences that name the phrase for i.e NP, NOUN is the head. All remaining after or before its optional but in needs to contain the head\n\n\n\n\nSlide 12\n\n\n\n\nConstituency is groups of words that act as a unit once you identify them. An evidence for this is that they appear in similar syntactic environments i.e NP ‘Nounn Phrases’ tend to appear before a verb\n\n\n\n\n\nSlide 14\n\n\n\n\n\n\n\n\nSlide 15\n\n\n\n\n\n\n\n\nSlide 16\n\n\n\n\n\nSymbols\n\n\nWe start from a vocabulary of symbols or (the constants): words\ni.e ‘I’, ‘eat’, ‘pizza’\nYou have non-terminals or (variables): phrasal categories\n‘S’, ‘NP’, ‘VP’\n\n\nRules: tells you how to rewrite a non-terminal category into a string that is made up of terminal and non-terminal symbols\n\nThe grammar is context free if on the left side of the any rule you have a single non-terminal. That makes it context free. IF there would be a collection of terminals on the left hand side, that would be context sensitive grammar\n\n\n\n\nSlide 17\n\n\n\n\nEvery single CFGs is an algorithm to represent a (in)finite set of strings. Is a finite representation of an infinite object\n\n\n\n\nSlide 18\n\n\n\n\n(constants): - \\(\\sum\\) terminals symbols: words\ni.e ‘I’, ‘eat’, ‘pizza’\n(variables): - \\(\\textbf{V}\\) non-terminals symbols: phrasal categories\ni.e ‘S’, ‘NP’, ‘VP’, ‘ADJ’, ‘DET’\nIn this set there a start symbol called \\(S\\) that belongs to \\(\\textbf{V}\\). We will put this one at the top of the context free grammar tree\n\n\n\n\nSlide 19\n\n\n\n\nThe arity is defined by the longest right hand side on the rule.\nAll CFGs can be rewritten to be binary that accepts the same exact strings, so the sentences that one accept is the same as the one the other would accept\n\n\n\n\nSlide 20\n\n\n\n\nCFG gives a recipe to generate text.\nA derivation is a sequence of strings. We start with the ‘start’ symbol then recursively we rewrite the leftmost non-terminal (‘S’,‘NN’.. ) sequence X.\nX is a sequence that belongs to \\(\\textbf{V}\\) so it can be a subset like:\nX:{‘S’, ‘DET’}\n\n\n\n\nSlide 21\n\n\n\n\nIf we are able to determine with the CFG then the sequence its part of the language, the grammar specifies the language, the set of words sequences. If you can derive a word sequences then it is part of the grammar implied by this CFG, its name then you would use is called the hug of the derivation\n\n\n\n\nSlide 22\n\n\n\n\n\nYou start with S\nThe left most symbol is S, then this is rewriten as Np, VP. There is a rule in the grammar that says S -&gt; NP, VP\nNP are usually DETERMINANTS or NOUNS, so we write that\nD, now can be replace by its terminal/constant i.e ‘the’\nN, can be rewrite it as ‘dog’ and so son..\n\nWe accomplished with this ‘the dog has barked loudly’ which is a full sentence. We use a depth-first order going always left.\nFrom top to bottom: generation, the opposite its recognition.\n\n\n\n\nSlide 23\n\n\n\n\nWhere does the preposition attach? Does it attach to the noun pizza? So it is pizza with anchovies on top, or does the preposition attach to the verb phrase eat pizza, which then becomes the instrument of eating\nPrepositions are words that show the relationship between a noun (or pronoun) and other elements in a sentence:\n\nIn: I live in the city.\nOn: The book is on the table.\nUnder: The cat is under the chair.\nBetween: Choose between the two options.\nBehind: The sun sets behind the mountains.\nAcross: They walked across the bridge.\nThrough: We walked through the park.\nAbove: The plane is flying above the clouds.\nBeneath: The treasure is buried beneath the sand.\nNear: The store is near the school.\n\nSo here there is ambiguity in syntactic parsing. The way we deal with structural ambiguity is by learning a probability distribution\nThere is not a tree for every single sentence in english so now we have to rely on a prob distribution\n\n\n\n\n\n\n\nSlide 27\n\n\n\n\n\n\n\n\nSlide 28\n\n\n\n\n\n\n\n\nSlide 29\n\n\n\n\nTo assign prob to a ‘Derivation’ we need random variables again. Here the length of the rule derivation R1…R_m is not the same as the length of the words sequence W1…W_L\nThe derivations length depends on the grammar, but for every tree structure at the bottom then you find words, so for every sequence of M rule applications there is a sequence of words that you can read at the bottom. I will assign a probability to a derivation by asigning probs to each one of the rules that I applied given the rules that I have already applied (so that is chain rule as how we did it for a sequence of words, but now we do chain rule for a sequence of rules)\n\n\n\n\nSlide 30\n\n\n\n\nFor now we are gonna make Markov assumptions and make rules independently. We are gonna assign probabilities to each rule independently fo the next. A rule in itself it is not an atomic thing. A rule is a pair, a rule has not terminal on the left and a string on the right\nThis is the trick to introduce some dependency:\nWe will generate the right hand side of the rule given is not a terminal symbol. So basically we imitate the process by which you go deeper and deeper until you find a terminal\nSo you look at the non-terminal and you will rewrite it without access to more context.\n\n\n\n\nSlide 31\n\n\n\n\n\n\n\n\nSlide 32\n\n\n\n\nYou can sample from the generative history.\n\nStart a queue with an S inside. If all symbols there are terminals, then you are go to go that is a sentence\nIF not true, pick the left most, pop it, take it from that thing and replace it by the RHS of a rule (that has that symbol on the LHS and note that you will have multiple rules, but they have probabilities so you draw one of them follwoing the distribution of their probabilities) rewrite that symbol. Do that with certain probability and repeat from 2.\n\n\n\n\n\nSlide 33\n\n\n\n\nWe have a condition distribution where we condition on, the LHS non-terminan symbol\nWe generate the RHS string so i.e.\nIf S is the variable you are rewritting and you happen to know two rules, NP-&gt;VP and S-&gt; VP. So you either write a NOUN PHRASE and concatenate with it or you have a VERB PHRASE and you concatenate it. So here we have two parameters, they are probabilities, they are normalized and they summ up to one\nPCFG (usually the number of outcomes will be fixed but here is different), here it is not for every symbol you condition on, the number of outcomes depends on how many rules you know for that symbol. So I know two rules for the start S, but I know 3 terminals for the non-terminal NOUN, cat, dog and bird. So the categorical distribution will have different number of probabilities this time\nSo the categorical distribution will have different number of probs in them, so when you are given a derivation how do we get its probability mass. Yoy multiply the probabilities for the rules that are inside. And where do we find these probabilities, well this is tabular, so in table\n\n\n\n\nSlide 34\n\n\n\n\nGiven a dataset can you do MLE, to find the probability that you would rewrite a varaible ‘b’ into a string Beta. ie.e maybe ‘v=NP’ and BETA=the terminal NOUN\nSo what is the probability that you would write a NOUN PHRASE as a sequence of DETERMINER followed by a NOUN. For that to come up I give you a model: PCFG, I give you the model description, I give you an al algorithm so MLE, and give you a dataset.\nSo this in next slide is how we compute the MLE\n\\(\\theta\\) is the name of the table, the row is ‘v’ and the column=sequence on the right so Beta\nSo we count how many times v has rewrite to B and you divide the numer of times you have seen ‘v’\nSo if this was a NP rewrite to a DETERMINER and a NOUN then, we count how many times I have seen this divide by how many times I have seen NP being rewrite by whatever\n\n\n\n\n\n\n\n\n\nSlide 40"
  },
  {
    "objectID": "blog/2023-06-09_on-the-topic/index.html",
    "href": "blog/2023-06-09_on-the-topic/index.html",
    "title": "On the topic of Optimization",
    "section": "",
    "text": "Below the apps I use in a daily basis to make my life easier\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Workflow\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Lua\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Workflow\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Lua\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          June 9, 2023\n        \n      \n      \n        \n      \n      \n\n    \n        Quick Links\n    \n         Quick Links:\n                                     Microsoft Edge\n                        \n                                     Hammerspoon Code"
  },
  {
    "objectID": "blog/2023-06-09_on-the-topic/index.html#microsoft-edge",
    "href": "blog/2023-06-09_on-the-topic/index.html#microsoft-edge",
    "title": "On the topic of Optimization",
    "section": "1 Microsoft Edge",
    "text": "1 Microsoft Edge\n\nPrefer this over Safari because of add-ons. Chrome is the same\n\nI used it to install apps like YouTube or Google Translator so that when I hit a shortcut command, it opens that app. Here it’s an example."
  },
  {
    "objectID": "blog/2023-06-09_on-the-topic/index.html#hammerspoon",
    "href": "blog/2023-06-09_on-the-topic/index.html#hammerspoon",
    "title": "On the topic of Optimization",
    "section": "2 Hammerspoon",
    "text": "2 Hammerspoon\n\nI use this application to create global shortcuts. Donwload App\n\nUses Lua programming language to assign keybindings to certain actions. Here a sneak peek of what can you do.\n--- Open App\nfunction open(name)\n    return function()\n        hs.application.launchOrFocus(name)\n        if name == 'Finder' then\n            hs.appfinder.appFromName(name):activate()\n        end\n    end\nend\nFor complete implementation visit this repo.\nThe above function can be called to open an app: Google Maps by an i.e. the shortcut: ⌘ + M\n--- Binding Keys\nhs.hotkey.bind({ \"cmd\" }, \"M\", open(\"Google Maps\"))\n\n2.1 Windows Approach\nFor Windows alternative see the code below:\n\n\nCode\n\n#MaxHotkeysPerInterval 200\n!WheelUp::Volume_Up\n!WheelDown::Volume_Down\n!MButton::Volume_Mute\n&lt;#!e::\nRun, %WINDIR%\\explorer.exe\nreturn\n!q::Send !{F4}\nreturn\n&lt;#!x::\nRun, msedge.exe\nreturn\n!y::\nRun, C:\\Users\\datoapnta\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\YouTube.lnk\nreturn"
  },
  {
    "objectID": "blog/2023-06-09_on-the-topic/index.html#honourable-mentions",
    "href": "blog/2023-06-09_on-the-topic/index.html#honourable-mentions",
    "title": "On the topic of Optimization",
    "section": "3 Honourable Mentions",
    "text": "3 Honourable Mentions\n\nThe apps above can do the same, but I like the UX interface.\n\n\n\n\nApp\nDescription\n\n\n\n\nBetterTouchTool\nEnables trackpad new gestures shortcuts\n\n\nAutoHotkey\nSame as Hammerspoon but for Windows\n\n\nTiles\nWindows manager (allows keybindings)"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html",
    "title": "Classification and Decision Theory",
    "section": "",
    "text": "Notes for the course at UvA: Machine Learning 1\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Classification\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Classification\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 25, 2023\nThis section focus on third week of the course. For Regression continue to this post."
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#classification-through-decision-regions",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#classification-through-decision-regions",
    "title": "Classification and Decision Theory",
    "section": "1 Classification through decision regions",
    "text": "1 Classification through decision regions\n\nHere the targets can take only discrete values. In Linear Regression the targets were continuous\n\n\\[\n\\begin{align}\n\\underline{x} &\\in \\mathbb{R}^{Dx1}, \\text{ $D$ Dimensional Space}\\\\\n&= [x_1, .., x_D]^T \\nonumber\n\\end{align}\n\\]\n\nFor instance when \\(D=2\\) we can think of \\(x_1\\) as the amount of black pixels in the image, and \\(x_2\\) as the white pixels. Then I can clasify one image into this 2-D dimensional space. So in the xy-plane one image has \\((x1,x2)\\) coordinates\nWe dive \\(\\underline{x}\\) into \\(K\\) Decision Regions \\(R_k\\).\nFor each Decision Region \\(R_k\\) we assign it to a class \\(C_k\\).\nThe target \\(\\underline{t} \\in \\{C_1,...,C_k\\}\\) meaning the target can be classified either \\(C_1\\) or the target can be classified as \\(C_2\\)"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#linear-classification",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#linear-classification",
    "title": "Classification and Decision Theory",
    "section": "2 Linear Classification",
    "text": "2 Linear Classification\n\nNote: do not confuse \\(D\\) the amount of data points with this new \\(D\\) where we talk about the dimensionality of how each data point is represented (the coordinates)\n\n\nThe classification is done by only linear decision boundaries\n\nFor \\(D\\)-dimensional input space: \\(\\underline{x}\\in\\mathbb{R}^{D}\\). The decision surface is a \\(D-1\\) dimensional hyperplane. For instance:\n\nThe decision boundaries can take a form of a line, i.e when \\(\\underline{x}\\in\\mathbb{R}^{D=2x1}\\) meaning the dots are drawn in the \\(x,y\\) coordinates\nThe decision boundaries can take a form of a plane, i.e when \\(\\underline{x}\\in\\mathbb{R}^{D=3x1}\\) meaning the dots are drawn in the \\(x,y,z\\) coordinates\n\nLinear Classifiers have however some constraints: one-versus-one, or one-vs-rest cannot classified in one specific region when majority vote its applied. There is class of decisions"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#decision-theory",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#decision-theory",
    "title": "Classification and Decision Theory",
    "section": "3 Decision Theory",
    "text": "3 Decision Theory\nHere we talked about when we consider a classifier (a model) a good classifier.\n\nWe talk about the Bayes Error Rate\nHow to minimize the misclassification rate\n\nModel that you start with:\n\nClass-conditional densities: \\(p(\\underline{x}|C_k)\\) aka (Likelihood)\nPrior class probabilities: \\(p(C_k)\\)\n\nFrom these two you can derive:\n\nThe Joint distribution \\(p(\\underline{x}, C_k)\\)\n\n\\[\n\\begin{align}\np(\\underline{x}, C_k)=p(\\underline{x}|C_k)p(C_k)\n\\end{align}\n\\]\n\nThe Posterior \\(p(C_k|\\underline{x})\\).\n\n\\[\n\\begin{align}\np(C_k|\\underline{x}) = \\frac{p(\\underline{x}| C_k)p(C_k)}{p(\\underline{x})}\n\\end{align}\n\\]\n\nDecision Theory tell us that the best prediction for input \\(\\underline{x}\\) is to choose the class with highest joint \\(p(\\underline{x}, C_k)\\)\nOr equivalently: choose class with the highest posterior \\(p(C_k|\\underline{x})\\)\nDecision boundary between \\(C_k\\) and \\(C_j\\) are at \\(p(C_k | \\underline{x})=p(C_j | \\underline{x})\\)"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#from-bayes-rule-to-bayes-classifiers",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#from-bayes-rule-to-bayes-classifiers",
    "title": "Classification and Decision Theory",
    "section": "4 From Bayes Rule to Bayes Classifiers",
    "text": "4 From Bayes Rule to Bayes Classifiers\n\\[\n\\begin{align}\np(C|X) = \\frac{P(X|C)P(C)}{P(X)} \\\\\n\\end{align}\n\\]\nWhere:\n\n\\(P(C|X)\\) is the Posterior (Given the data what is the prob of being class C_k)\n\\(P(X|C)\\) is the Likelihood (How the data is distributed given C)\n\\(P(C)\\) is the Prior\n\\(P(X)\\) is the Evidence/ Marginal likelihood\n\nThe evidence \\(P(X)\\) can also be decomposed in:\n\\[\n\\begin{align}\nP(X) &= \\sum_{j}{}P(X,C_j)\\\\\n     &= \\sum_{j}{}P(X|C_j)P(C_j) \\\\\n\\end{align}\n\\]\nUnlike regression, I will have one likelihood per each class, mainly:\n\\[\n\\begin{align}\np(X|C_0) \\quad \\text{and} \\quad p(X|C_1) \\\\\n\\end{align}\n\\]\nFor instance for \\(K=2\\) two classes. This means per each class we are going to have our own model\nThe decicion boundary then becomes equal when both likelihoods are equal:\n\\[\n\\begin{align}\np(C_0|X) &= p(C_1|X) \\quad \\text{Decision Boundary}\\\\\n% P(X, C_0) &= p(X, C_1) \\nonumber\n\\end{align}\n\\]\nHere:\n\n\\(P(C_0|X)\\) is the Posterior probability"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#types-of-classification",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#types-of-classification",
    "title": "Classification and Decision Theory",
    "section": "5 Types of Classification",
    "text": "5 Types of Classification\n\nDecision Trees\nLogistic Regressions\nBayes Classifiers (Generative): first fit P(x|C) and then use Bayes Rule to flip it and tell which type of class correspond \\(x\\)\n\nNaive Bayes: you put an x and it gives you to which class \\(K\\) correponds\nGaussian Likelihood: here \\(p(x|C_k) = N(\\mu_k, \\Sigma_k)\\)\nQDA: Quadratic discriminant analysis\n\nShared Parameters\nLDA: Linear Discriminant Analysis\n\n\n\n\n5.1 Gaussian Generative Classifiers\nHere we assume arbitrary covariance matrices for each class\n\\[\n\\begin{align}\np(x|C_k) = N(\\mu_k, \\Sigma_k)\n\\end{align}\n\\]\n\nEach class \\(K\\) is going to have its normal distribution. And each of these distributions would be completely different from the others.\n\n\nQuadratic Discriminant Analysis\nHere the decision boundary would be quadratic.\nHere the covariances would different for each class, like so:\n\\[\n\\begin{align}\n1&=\\frac{p(x, C_2)}{p(x, C_1)} \\\\\n&=\\frac{p(x| C_2)p(C_2)}{p(x| C_1)p(C_1)} \\nonumber\n\\end{align}\n\\]\nTaking the log at both sides\n\\[\n\\begin{align}\n0 &= log N(\\mu_2, \\Sigma_2) - log N(\\mu_1, \\Sigma_1) + log \\frac{p(C_2)}{p(C_1)}\n\\end{align}\n\\]\nIf you solve the equation above then you end up with quadratic terms.\nThis tell us that now we can handle non-linear separate cases now the data can needs to be quadratic separable.\n\n\n5.1.1 Shared Parameters\n\n\nLinear Discriminant Analysis\nHere the decision boundary would be linear.\nHere the covariances would be the same: 1 covariance matrix like so:\n\\[\n\\begin{align}\n0 &= log N(\\mu_2, \\Sigma) - log N(\\mu_1, \\Sigma) + log \\frac{p(C_2)}{p(C_1)}\n\\end{align}\n\\]\nHere we do not impose \\(diag\\{\\Sigma_k\\}\\), we can have Naive Bayes approach here. The latter meaning we can indeeed if we want have the covariance matrices to be \\(diag\\{\\Sigma_k\\}\\). In this called we called. Naive Bayes applied to LDA.\n\nNaive Bayes applied to LDA: same/shared parameters for \\(\\Sigma_k\\) and \\(diag\\{\\Sigma_k\\}\\)\n\n\n\n\nUnderstanding Covariance and Variance\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import multivariate_normal\nimport matplotlib.colorbar as cbar\n\n# Define the mean and covariance matrix for the original case\nmean = [0, 0]\ncovariance_matrix = [[2, 1], [1, 2]]  # Example covariance matrix\n\n# Create a grid of points\nx, y = np.meshgrid(np.linspace(-5, 5, 100), np.linspace(-5, 5, 100))\npos = np.dstack((x, y))\n\n# Create a multivariate Gaussian distribution for the original case\nrv = multivariate_normal(mean, covariance_matrix)\n\n# Calculate the probability density at each point in the grid for the original case\npdf = rv.pdf(pos)\n\n# Calculate eigenvalues and eigenvectors for the original case\neigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n\n# Define the scale factor for the arrows\nscale_factor = 2.0\n\n# Create the first subplot for the original case\nplt.subplot(1, 2, 1)\nplt.contourf(x, y, pdf, cmap='viridis')\nfor i in range(2):\n    plt.arrow(\n        mean[0],\n        mean[1],\n        eigenvectors[i, 0] * np.sqrt(eigenvalues[i]) * scale_factor,\n        eigenvectors[i, 1] * np.sqrt(eigenvalues[i]) * scale_factor,\n        head_width=0.2,\n        head_length=0.2,\n        fc='r',\n        ec='r',\n    )\nplt.annotate(f'Var(X) = {eigenvalues[0]:.2f}', xy=(-3, 3), color='white')\nplt.annotate(f'Var(Y) = {eigenvalues[1]:.2f}', xy=(-3, 2), color='white')\nplt.annotate(f'Cov(X, Y) = {covariance_matrix[0][1]:.2f}', xy=(-3, 1), color='white')\nplt.title('Original Case (Covariance ≠ 0)')\n\n# Define the mean and covariance matrix for the equal variance case\nequal_variance_cov_matrix = np.diag([2, 2])  # Equal variance along both dimensions\n\n# Create a multivariate Gaussian distribution for the equal variance case\nrv_equal_variance = multivariate_normal(mean, equal_variance_cov_matrix)\n\n# Calculate the probability density at each point in the grid for the equal variance case\npdf_equal_variance = rv_equal_variance.pdf(pos)\n\n# Create the second subplot for the equal variance case\nplt.subplot(1, 2, 2)\nplt.contourf(x, y, pdf_equal_variance, cmap='viridis')\nplt.annotate(f'Var(X) = {equal_variance_cov_matrix[0, 0]:.2f}', xy=(-3, 3), color='white')\nplt.annotate(f'Var(Y) = {equal_variance_cov_matrix[1, 1]:.2f}', xy=(-3, 2), color='white')\nplt.title('Equal Variance Case (Covariance = 0)')\n\n# Set common labels\nfor ax in plt.gcf().axes:\n    ax.set_xlabel('X')\n    ax.set_ylabel('Y')\n\n# Ensure equal aspect ratio for both subplots\nfor ax in plt.gcf().axes:\n    ax.set_aspect('equal', adjustable='box')\n\n# Create a new axes for the legend with adjusted width\ncax = plt.gcf().add_axes([0.96, 0.3, 0.02, 0.4])  # Adjust the width and position as needed\n\n# Plot vertical colorbar for the legend\ncbar.ColorbarBase(cax, cmap='viridis', orientation='vertical', label='Probability Density')\n\n# Adjust the overall layout\nplt.subplots_adjust(wspace=0.3)\n\nplt.show()\n\n\n\n\n\nThis plot visually illustrates how variance represents the spread along each dimension, and the arrows depict how the covariance matrix encodes the relationships between the dimensions in a Gaussian distribution.\n\nOriginal Case (Covariance ≠ 0):\n\n\nIn the first plot (Original Case), the color yellow represents regions where the probability density is higher. In a Gaussian distribution, the probability density is highest at the mean (center) of the distribution and decreases as you move away from the mean. The color yellow typically corresponds to higher probability values in this context.\n\n\nEqual Variance Case (Covariance = 0):\n\n\nIn the second plot (Equal Variance Case), the color yellow also represents regions of higher probability density. Even though the covariance is zero, meaning there is no linear relationship between the X and Y dimensions, the multivariate Gaussian distribution still has a peak at the mean (center) in each dimension. The color yellow again corresponds to higher probability values in this context.\n\n\n\n\n\nQDA: they have separate Covariances\nLDA: they share a non-zero covariance\nHere the shared variances mean for example 3 in the y-direction and 1 in the x-direction, they however contain a non-zero covariance\nHere the shared variances mean for example 1 in the y-direction and 1 in the x-direction, they however contain a zero covariance."
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#probabilistic-generative-models-k2",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#probabilistic-generative-models-k2",
    "title": "Classification and Decision Theory",
    "section": "6 Probabilistic Generative Models \\(K=2\\)",
    "text": "6 Probabilistic Generative Models \\(K=2\\)\n\\[\n\\begin{align}\nP(C_1|x) &= \\frac{p(x|C_1)p(C_1)}{p(x|C_1)p(C_1)p(x|C_2)p(C_2)}\\\\\n&= \\frac{1}{1+e^-a}\\nonumber\\\\\n\\end{align}\n\\]\nWhere \\(a\\) is the log odds:\n\\[\n\\begin{align}\na &= \\ln\\frac{p(x|C_1)p(C_1)}{p(x|C_2)p(C_2)}\\label{log_odds}\\\\\n\\end{align}\n\\]\nThis can be expressed as the Sigmoid Function:\n\\[\n\\begin{align}\n\\sigma &= \\frac{1}{1+e^{(-a)}}\\\\\n\\end{align}\n\\]\n\nWhen the log odds its possitive in the sigmud function it will converge to 1. This means I am certain it will be class \\(C_1\\)\nIf the log odds is equal meaning not clue which class to assign. The probability of classifing the target to either class is 0.5.\n\nFor \\(a\\) to be equal to zero. I need \\(a=\\ln(1)\\). This 1 means \\(p(x|C_1)p(C_1)=p(x|C_2)p(C_2)\\)\n\nWhen the log odds its negative, the sigmoid function will go to zero. This means I am certain it will be class \\(C_2\\)"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#probabilistic-generative-models-generalk",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#probabilistic-generative-models-generalk",
    "title": "Classification and Decision Theory",
    "section": "7 Probabilistic Generative Models, general:\\(K\\)",
    "text": "7 Probabilistic Generative Models, general:\\(K\\)\n\n\n\n\n\n\nRemember\n\n\n\nYou are given:\n\nClass-conditional densities: \\(p(x|C_k)\\) aka Likelihood\nPrior class probabilities: \\(p(Ck)\\)\n\nWith these two guys you can get:\n\nJoint Distribution: \\(p(x,C_k) = p(x|C_k)p(C_k)\\) the numerator\nThe Posterior \\(p(C_k|x)=\\frac{p(x|C_k)p(C_k)}{p(x)}\\)\n\nGoal:\n\nFind \\(p(C_k|x)\\) so that you can determine the class of \\(x\\) by knowing the Decision boundaries\n\n\n\n\n\\[\n\\begin{align}\nP(C_k|x) &= \\frac{p(x|C_k)p(C_k)}{\\sum_{j=1}^{K}p(x|C_j)p(C_j)}\\\\\n&= \\frac{e^{a_k}}{\\sum_{j=1}^{K}e^{a_j}}\\label{softmax}\\\\\na_k &= \\ln(p(x|C_k)p(C_k)) \\nonumber\n\\end{align}\n\\]\nWhere \\(\\ref{softmax}\\) is called the Softmax:\n\nif \\(a_k&gt;&gt;a_j\\) for all \\(j \\neq k\\) then \\(p(C_k|x)=1\\) and \\(p(C_j|x)=0\\)\nThe Softmax reduces to the Simoid function when \\(K=2\\)\n\n\n7.0.1 How to parametrize Class Conditional Densities (aka The Likelihood)?\nWith Gaussians!\n\\[\n\\begin{align}\np(x|C_k)&=\\mathcal{N}(x|\\mu_k , \\Sigma_k ) \\\\\n        &= \\frac{1}{(2 \\pi)^{D/2}} \\frac{1}{|\\Sigma_k|^{1/2}} \\exp^{\\{-\\frac{1}{2}(x-\\mu_k)^T \\Sigma_k^-1 (x-\\mu_k)\\}} \\label{gaussian_lda}\\\\\n\\end{align}\n\\]\n\nWhere the Gaussian is going to be multivariate and it will be \\(D\\)-dimensional due to the input being \\(x \\in \\mathbb{R}^{D}\\)\n\nThis means for each \\(\\mu_k\\) and \\(\\Sigma_k\\) I would have a different Gaussian distribution\n\n\\(\\Sigma_k\\) determines the shape of my distribution. Like in the python plot above in the left graph\n\nWhen we assume each of these Gaussian share the same the Covariance matrix: \\(\\Sigma_k\\) then we are talking about LDA\nTo determine the decision boundary we have that:\n\\[\n\\begin{align}\np(C_1|X) &= \\frac{1}{1+e^(-a)} = \\sigma(a)\\\\\n\\end{align}\n\\]\nWhere \\(a\\) is defined was defined as the log odds. So replacing \\(p(x|C_k)\\) so replacing \\(\\ref{gaussian_lda}\\) (the Gaussians) in the log odds \\(\\ref{log_odds}\\) give us The Generalized Linear Model:\n\\[\n\\begin{align}\np(C_1|x) &= \\sigma(\\underline{w}^T\\underline{x}+w_o)\\\\\n\\end{align}\n\\]\nAnd now recall that the decision boundary happens when \\(p(C_1|x) = p(C_2|x)\\).\n\nThis all means if we want to make decisions based on the posterior distributions, then \\(a=0\\) meaning the prob/prob is 1 or the \\(\\sigma(a) = \\frac{1}{2}\\)"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#lda-maximum-likelihood-for-k2",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#lda-maximum-likelihood-for-k2",
    "title": "Classification and Decision Theory",
    "section": "8 LDA: Maximum Likelihood for K=2",
    "text": "8 LDA: Maximum Likelihood for K=2\n\nGoal: recover the Gaussian distributions (the join distribution = p(X, C_k)) that have generated the data. To accomplished that we need to take the MLE over the the Gaussian conditional densities aka the likelihood and solve for \\(u_k\\), \\(\\Sigma\\) and priors \\(p(C_k)\\)\n\n\n\n\n\n\n\nIsometric Covariance definition\n\n\n\n\n\nIt is a special case of a covariance matrix where all off-diagonal elements are zero, and the diagonal elements are equal, representing a constant variance or dispersion in all dimensions.\nMathematically, an isometric covariance matrix Σ can be represented as:\n\nΣ = σ² * I\n\nWhere:\n\nΣ is the covariance matrix.\nσ² is the common variance or dispersion parameter.\nI is the identity matrix, which has ones on the diagonal and zeros elsewhere.\n\nIn this form, each element along the diagonal of the covariance matrix Σ is equal to σ², and all off-diagonal elements are zero. This implies that the variables in a multivariate distribution with an isometric covariance matrix have equal variances and are uncorrelated with each other.\n\n\n\nGiven:\n\nGaussian conditional densities aka Likelihoods:\n\n\\[\n\\begin{align}\np(x|C_k) = \\frac{1}{(2 \\pi)^{D/2}} \\frac{1}{|\\Sigma_k|^{1/2}} \\exp^{\\{-\\frac{1}{2}(x-\\mu_k)^T \\Sigma_k^-1 (x-\\mu_k)\\}} \\nonumber\\\\\n\\end{align}\n\\]\n\nPrior \\(p(C_k)\\)\nBecause we have \\(k=2\\) then we can assign \\(p(C_1) = q\\) and \\(p(C_2) = 1-q\\)\n\nWith 1. and 2. we can solve for the Joint distributions:\nFor \\(x_n\\) with \\(t_n =1\\): \\[\n\\begin{align}\np(x_n, C_1) &= p(x_n|C_1)p(C_1) = q \\, N(x_n|\\mu_1,\\Sigma) \\\\\n\\end{align}\n\\]\nFor \\(x_n\\) with \\(t_n =0\\): \\[\n\\begin{align}\np(x_n, C_2) &= p(x_n|C_2)p(C_2) = (1-q) \\, N(x_n|\\mu_2, \\Sigma)\\\\\n\\end{align}\n\\]\n\n\\(t_n\\) is binary if I do \\(\\sum t_n\\) here I am counting the number of times \\(t_n\\) is equals to 1.\n\n\n8.1 Deriving \\(q_{ML}\\)\n\\[\n\\begin{align}\nq_{ML} &= \\frac{1}{N} \\sum_{n=1}^{N} t_n = \\frac{N_1}{N}\\\\\n\\end{align}\n\\]\n\n\\(q\\) is the prior probability of observing class \\(K=1\\). The result above means the total number of observations that I have observed \\(t_n=1\\)\n\n\n\n8.2 Deriving \\(\\mu{ML}\\)\n\\[\n\\begin{align}\n\\mu_{1,ML} &= \\frac{1}{N_1} \\sum_{n=1}^{N} t_n \\, x_n\\\\\n\\end{align}\n\\]\n\n\\(\\mu_{1,Ml}\\) is the sample mean of all my observations where \\(x_n\\) belongs to class \\(K=1\\). Here $t_n =1 $ when the class is 1.\n\n\\[\n\\begin{align}\n\\mu_{2,ML} &= \\frac{1}{N_2} \\sum_{n=1}^{N} (1-t_n) \\, x_n\\\\\n\\end{align}\n\\]\n\n\\(\\mu_{2,Ml}\\) is the sample mean of all my observations where \\(x_n\\) belongs to class \\(K=2\\)\n\n\n\n8.3 Covariance for discrete Random Variables\nFor class \\(i\\) the covariance matrix can be calculated as: \\[\n\\begin{align}\n\\Sigma_i &= \\frac{1}{N_i}\\sum_{n=1}^{N_i}(x_n-\\mu_i)(x_n-\\mu_i)^T \\\\\n\\end{align}\n\\]\nWhere:\n\n\\(N_i\\) ​is the number of data points in class \\(i\\)\n\\(x_n\\) is a data point in class \\(i\\)\n\\(\\mu_i\\) is the mean vector of class \\(i\\)\n\n\n\n\n\n\n\nHow to classify a new data point?\n\n\n\n\n\n\nGaussian Classifier: Once you have the covariance matrices for each class, you can use them to build a Gaussian classifier. The Gaussian classifier estimates the likelihood of a given data point belonging to each class based on the probability density function of a multivariate Gaussian distribution with the class’s mean and covariance matrix.\nClassification: When you receive a new data point, you calculate the likelihood of it belonging to each class using the Gaussian distribution parameters (mean and covariance matrix) for each class. You can then assign the data point to the class with the highest likelihood.\n\n\n\n\nThe whole point of LDA was explained at: here\n\n\n8.4 Disadvantages of LDA\n\nSensitive to outliers. Meaning if I have a point really far from \\(\\mu_1\\) then it induces a large shift to the actual \\(\\mu_1\\)\nRelies in handcrafted features, if I go to high dimensional spaces I need to make choices and complicates things\nThe same as regression, here in clarification with LDA the MLE MAximum Likelihood are prone to overfilling. The latter because any regularization has been applied\n\nSo far:"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#probabilistic-generative-models-discrete",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#probabilistic-generative-models-discrete",
    "title": "Classification and Decision Theory",
    "section": "9 Probabilistic Generative Models: Discrete",
    "text": "9 Probabilistic Generative Models: Discrete\nIn this section we parametrize the class-conditional density with other distributions\n\nSo far we parametrize the Class conditional distributions with Gaussians. We can use however different ones. This is necessary when ie. the data it is not continuous and for instance its discrete.\nIn the Continuous space the number of parameters does not scales as much as in the discrete where then we have for i.e a binary classification to \\(2^D\\) parameters. The reasons is that we cannot fit anymore a Gaussains distribution to the discrete variables\n\nTo contrast the huge num. of parameters then we are going to make a model assumption that is:\n\nNaive Bayes assumption: feature value are treated as independent when conditioned on class \\(C_k\\).\n\nThe above means that we are going to model each feature value with its own distribution. This in turn means that to model \\(p(x|C_k, \\lambda_1,...,\\lambda_D)\\) we will have \\(D\\) number of parameters. The following equation accounts for that using the product symbol.\nGiven:\n\nClass-conditional probabilities: \\[\n\\begin{align}\np(x|C_k) &= \\prod_{i=1}^{D} \\, p(x_i|C_k) \\\\\n&= \\prod_{i=1}^{D} \\,  \\pi_{k_i}^{x_i}(1- \\pi_{k_i}^{x_i})^{1-x_i} \\nonumber\n\\end{align}\n\\]\n\nHere:\n\n\\(x_i\\) takes the value \\(0\\) or \\(1\\) given my class \\(C_k\\)\n\nThe above equation was modeled using the bernoulli equation\n\n\n\n\n\n\nEffect of changing parameters in Bernoulli distribution\n\n\n\n\n\nThe Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes, often referred to as “success” and “failure.” It is named after Swiss mathematician Jacob Bernoulli. The Bernoulli distribution is used to represent situations where an event can result in one of two possible outcomes, typically denoted as 1 (success) or 0 (failure).\nHere are the key characteristics and properties of the Bernoulli distribution:\n\nParameters: The Bernoulli distribution has a single parameter, denoted as “p,” which represents the probability of success (or the probability of the outcome being 1). The parameter “q” represents the probability of failure (q = 1 - p).\nProbability Mass Function (PMF): The probability mass function of the Bernoulli distribution is defined as follows:\nP(X = x) = p^x * q^(1-x)\nWhere:\n\nP(X = x) is the probability of the random variable X taking the value x (either 0 or 1).\np is the probability of success (X = 1).\nq is the probability of failure (X = 0).\n\nMean and Variance:\n\nThe mean (expected value) of a Bernoulli random variable is E(X) = p.\nThe variance of a Bernoulli random variable is Var(X) = p(1-p).\n\nSupport: The Bernoulli distribution is defined over the set of values {0, 1}.\n\nApplications of the Bernoulli distribution: - Modeling coin flips (heads or tails). - Modeling success/failure outcomes, such as whether a product is defective (failure) or non-defective (success). - Modeling binary decisions, such as whether a customer makes a purchase (success) or does not make a purchase (failure).\nExample Scenario: Suppose you have a coin that is not fair; it is biased. When you flip this biased coin, it does not have an equal chance of landing on heads (H) or tails (T). Instead, it has a higher probability of landing on heads.\nProbability of Success (Heads): In this example, we have a probability of success (getting heads) denoted as “p.” Let’s say that “p” is equal to 0.6. This means that when you flip the coin, there is a 60% chance of getting heads (H) and a 40% chance of getting tails (T).\nUsing the Bernoulli Distribution: To model this coin-flipping scenario, you can use a Bernoulli distribution. In this context:\n\nThe outcome “1” can represent success (getting heads).\nThe outcome “0” can represent failure (getting tails).\n\nThe Bernoulli distribution allows you to calculate the probability of success (1) or failure (0) for each coin flip.\nBernoulli Distribution Parameters: - Parameter “p” is the probability of success (1), which is 0.6 in this case. - Parameter “q” is the probability of failure (0), which is 1 - p, or 0.4 in this case.\nUsing the Bernoulli PMF: The Bernoulli probability mass function (PMF) allows you to calculate the probability of each outcome:\n\nP(X = 1) represents the probability of getting heads (success), which is equal to “p” or 0.6.\nP(X = 0) represents the probability of getting tails (failure), which is equal to “q” or 0.4.\n\nInterpreting the Results: When you flip this biased coin multiple times, the Bernoulli distribution helps you understand the likelihood of getting heads (success) or tails (failure) for each individual flip. For example:\n\nIf you flip the coin 10 times, you would expect to get heads approximately 6 times (0.6 * 10) on average.\nHowever, the actual outcomes in any given sequence of 10 flips may vary around this expected value due to randomness.\n\nThe Bernoulli distribution provides a mathematical framework to model and analyze such binary outcomes in scenarios like coin flipping, where there are two possible results with different probabilities of occurrence.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import bernoulli\n\n# Define the probability of success (getting heads)\np = 0.6\n\n# Number of coin flips\nnum_flips = 10\n\n# Simulate the outcomes of flipping the biased coin 10 times\noutcomes = bernoulli.rvs(p, size=num_flips)\n\n# Calculate the PMF of the Bernoulli distribution\nx = [0, 1]\npmf = bernoulli.pmf(x, p)\n\n# Create a bar plot to visualize the PMF\nplt.figure()\n\nplt.subplot(1, 2, 1)\nplt.bar(x, pmf, align='center', alpha=0.7)\nplt.xticks(x)\nplt.xlabel('Outcome')\nplt.ylabel('Probability')\nplt.title(f'Bernoulli Distribution PMF (p={p})')\n\nplt.subplot(1, 2, 2)\nplt.bar(range(num_flips), outcomes, align='center', alpha=0.7)\nplt.xticks(range(num_flips))\nplt.xlabel('Coin Flip')\nplt.ylabel('Outcome (0 or 1)')\nplt.title(f'Outcomes of {num_flips} Coin Flips (p={p})')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\\(\\pi_{k_i}=p(x_i=1|C_k)\\)\n\nNow the number of parameters per class is \\(D\\)\n\nWith this parametrization we can calculate the posterior probability: \\(p(C_k|x)\\) where we can compute it with our recently parametrized-bernouli like class density aka the likelihood. Here modeling the prior follows the same as how we did it with the class-density akak Likelihood, With these two we can get the joint aka the evidence evidence.\nRemember the evidence is the marginalization (sumation) over the joint (\\(p(x,C_k)\\)).\n\\[\n\\begin{align}\np(x) = \\sum_{k=1}^{K}p(x,C_k) = \\sum_{k=1}^{K}p(x|C_k)p(C_k)\n\\end{align}\n\\]"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#discriminative-linear-models",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#discriminative-linear-models",
    "title": "Classification and Decision Theory",
    "section": "10 Discriminative Linear Models",
    "text": "10 Discriminative Linear Models\nWe go away momentarily from the prob view and try model the discriminant function without describing first a prob model.\nWe will do the following. Given input \\(x \\in \\mathbb{R}^{Dx1}\\) and targets \\(t \\in {C1, C2}={-1,1}\\)\n\\[\n\\begin{align}\ny(x,\\overline{w})&=f(\\overline{w}^t \\boldsymbol{\\phi}) \\\\\n\\boldsymbol{\\phi} &= (\\phi_{0}(x),\\phi_{1}(x),...,\\phi_{M-1}(x))^T\n\\end{align}\n\\]\nThis model is linear with respect to \\(w\\)"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#least-squares-for-classification",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#least-squares-for-classification",
    "title": "Classification and Decision Theory",
    "section": "11 Least Squares for Classification",
    "text": "11 Least Squares for Classification\nWe are gonna have for each \\(K\\) a linear model (discriminant function)\n\\[\n\\begin{align}\ny_k = (\\textbf{x}) = \\textbf{w}_{k}^{T}\\textbf{x} + w_{k0}\n\\end{align}\n\\]\nWhere:\n\nInputs: \\(\\textbf{x} \\in \\mathbb{R}^{Dx1}\\), \\(D\\)-Dimensional feature vector (data points that describe each vector)\ni.e for \\(D=10\\) we have \\(\\textbf{x}_n = (x1, x2, ...,x_D)^T = (0,1,0,...0)\\)\nFor instance in the document classifier form the practicals, we have that each word from the document will add up to form a \\(D\\) vector. Each element in this vector correspond \\(0\\) or \\(1\\) indicating whether a word belongs or not to the document.\n\\(\\textbf{w}_k^T \\in \\mathbb{R}^{1xD}\\) is the weight vector for class \\(k\\)\n\\(w_{k0}\\) is the bias term.\n\nWe can generalize this not only for one \\(y_k\\) but for all \\(K\\text{s}\\) like so:\n\\[\n\\begin{align}\n\\textbf{y} =  \\mathbf{\\widetilde W}^T \\mathbf{\\tilde x}\n\\end{align}\n\\]\nWhere:\n\nMatrix \\(\\mathbf{\\widetilde W} \\in \\mathbb{R}^{MxK}\\): has in the kth column \\(\\mathbf{\\tilde w}_k = (w_{k0}, \\textbf{w})^T \\in \\mathbb{R}^{(D+1)x1} \\in \\mathbb{R}^{Mx1}\\)\nMatrix \\(\\mathbf{\\widetilde W}^T \\in \\mathbb{R}^{KxM}\\)\n\\(\\mathbf{\\tilde{x}} = (1, \\textbf{w})^T \\in \\mathbb{R}^{(D+1)x1}\\in \\mathbb{R}^{Mx1}\\)\nVector: \\(\\textbf{y(x)} \\in \\mathbb{R}^{Kx1}\\)\n\nRemember at the end \\(y_k\\) is just a number (you can think of a number that tells you how far \\(x\\) is from the decision surface)so we are going to assign \\(\\textbf{x}\\) to class \\(C_k\\) if: \\[\n\\DeclareMathOperator*{\\argmax}{argmax}\n\\begin{align}\nk = \\argmax_{j} \\, y_j(\\textbf{x})\\\\\n\\end{align}\n\\]\nNow, for this to work we need target values so that we can minimize our error function:\n\\[\n\\begin{align}\nE_D(\\mathbf{\\widetilde W})=\\frac{1}{2}Tr[(\\mathbf{\\widetilde X}\\mathbf{\\widetilde W} - \\mathbf{\\widetilde T})^T(\\mathbf{\\widetilde X}\\mathbf{\\widetilde W} - \\mathbf{\\widetilde T})]\n\\end{align}\n\\]\n\n\n\n\n\n\nRemember: What was Linear Regresion & Do we get the target values?\n\n\n\n\n\nIn simple linear regression, there is one target value, whereas in multiple linear regression, there can be multiple target values.\nIn a typical linear regression problem, you are given the input features (independent variables) and the corresponding target values (dependent variables) as training data. The goal of linear regression is to learn a linear relationship between the input features and the target values\nInput Features (Independent Variables): These are the variables that you use to make predictions. Each data point in the dataset has a set of input features.\nTarget Values (Dependent Variables): These are the values you are trying to predict or estimate based on the input features. Each data point in the dataset has a corresponding target value.\nThe linear regression model is trained using this dataset to find the coefficients (weights) for the input features that minimize the mean squared error between the predicted values and the actual target values. Once the model is trained, you can use it to make predictions on new or unseen data.\n\n\n\nIn the above equation \\(E_D\\):\n\n\\(X \\in \\mathbb{R}^{Nx(D+1)} \\in \\mathbb{R}^{NxM}\\), where each row is a different observation (a different number of document like in the practicals) represented by the vector \\(\\mathbf{\\tilde{x}}_n\\)\nTarget: \\(T \\in \\mathbb{R}^{NxK}\\), where each row is a different one-hot encoded vector that is trying to predict what is the class that \\(\\mathbf{\\tilde{x}}_n\\) belongs to. The one-hot enconding means that for that particular kth value is 1 meaning it belongs to the kth class and for the rest is zero.\n\\(t \\in \\mathbb{R}^{Kx1}\\) where \\(t \\in \\{C_1, C_2, ..., C_k\\}\\) and \\(K\\) classes\ni.e for \\(K=4\\) for binary classification we have we have \\(t = (0, 0, 0, 1)^T\\). The latter would be the one-hot encoding for \\(K=4\\) documents\ni.e if \\(k=5\\) my one-hot encoding when it is predicting for class k=3 would be. \\(t_n=(0,0,1,0,0)^T\\)\n\n\\(Tr\\): Sum of the diagonal matrix\n\n\nGoal: Now that we have defined our error we want to minimize it as a function of \\(W\\) so that when we new values for \\(x\\) come, then we multiply with our computed \\(W\\) and finally get our predicted \\(y(x)\\).\n\nSolution:\n\\[\n\\begin{align}\n\\mathbf{\\widetilde W}_{LS} = (\\mathbf{\\widetilde X}^T\\mathbf{\\widetilde X})^{-1}\\mathbf{\\widetilde X}^T\\textbf{T} = \\mathbf{\\widetilde X}^\\dagger\\textbf{T}\n\\end{align}\n\\]\nFinally to predict the label for \\(\\mathbf{\\tilde{x}}\\) we use our discriminant function: \\[\n\\begin{align}\n\\textbf{y}_{LS}(\\textbf{x})&=\\mathbf{\\widetilde W}_{LS}^T\\mathbf{\\tilde{x}}\\\\\n& \\in \\mathbb{R}^{KxM} \\, \\in \\mathbb{R}^{Mx1} \\nonumber\\\\\n&\\in \\mathbb{R}^{Kx1}\\nonumber\n\\end{align}\n\\]\nSo one number per each class. We get a vector with dimensions \\(K\\) because this vector was one-hot encoded so that means we have to look at the value that contains \\(1\\) and that \\(k_{th}\\) element would be our class \\(C_k\\)\n\nDiscriminant functions are used to classify data points into different classes based on the values of the discriminant function\n\n\n11.1 Why Linear Regresion for Classification is not a good idea?\n\nThe decision boundaries are sensitive to outliers. Our Linear Regresion wants our distance to be as close to \\(y(x)=1\\) if the target value is also \\(1\\), but if there is outliers then these points will influence the decision boundary skewing it.\nFor \\(k&gt;2\\) some decision regions can become very small or are even completely ignored\nThe components of the \\(\\textbf{y}_{LS}(\\textbf{x})\\) are not real probabilities"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#multi-class-logistic-regression",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#multi-class-logistic-regression",
    "title": "Classification and Decision Theory",
    "section": "12 Multi-class Logistic Regression",
    "text": "12 Multi-class Logistic Regression\nConsider logistic regresion for \\(K\\) classes with \\(N\\) training vectors \\(\\{x_n\\}_{n=1}^{N}\\). Each of these vectors is mapped to a different feature vector.\n\\[\n\\begin{align}\n\\phi_n = \\phi(x_n) = (\\phi_0(x_n), \\phi_1(x_n), ..., \\phi_{M-1}(x_n))^T\n\\end{align}\n\\]\n\nEach vector \\(x_n\\) has a target vector \\(t_n\\) of size \\(K\\)\n\n\\[\n\\begin{align}\nt_n = (t_{n1}, t_{n2}, ..., t_{nK})^T\n\\end{align}\n\\]\nWhere, \\(t_{nk} = 1\\) if \\(x_n \\in C_k\\), \\(0\\) otherwise.\n\nThe input data can be collected in a matrix \\(X\\) such that the n-th row is given by \\(\\textbf{x}_{n}^{T}\\). The targets can also be collected in a matrix \\(T\\) where each n-th row is given by \\(\\textbf{t}_{n}^{T}\\)\n\nWe have:\n\\[\n\\begin{align}\ny_k(\\phi) = p(C_k|\\phi(x), \\textbf{w}_1,...,\\textbf{w}_K) = \\frac{exp(a_k)}{\\sum_{j=1}^{K}exp(a_j)}\n\\end{align}\n\\]\nWhere we have \\(a_k = \\textbf{w}_{k}^{T}\\phi\\)\nDimensions:\n\\[\n\\begin{align}\n\\textbf{y(x)} &= (y_1(x),...,y_k(x) )^T &\\in \\mathbb{R}^{Kx1} \\nonumber\\\\\n\\phi &= \\phi(x) = (\\phi_0(x), ..., \\phi_{M-1}(x))^T &\\in \\mathbb{R}^{Mx1}\\nonumber\\\\\n\\mathbf{\\phi}_n &= \\phi(x_n) = (\\phi_0(x_n), ..., \\phi_{M-1}(x_n))^T\\nonumber\\\\\n\\Phi &= (\\phi_1, \\phi_2, ..., \\phi_{N})^T &\\in \\mathbb{R}^{NxM}\\nonumber\\\\\n\\mathbf{w}_k &= (w_{k0},...,w_{k(M-1)})^T \\in \\mathbb{R}^{(D+1)x1} &\\in \\mathbb{R}^{Mx1}\\nonumber\\\\\nX &= (\\textbf{x}_1,...,\\textbf{x}_N)^T \\in \\mathbb{R}^{Nx(D+1)} &\\in \\mathbb{R}^{NxM}\\nonumber\\\\\n\\textbf{t}_n &= (t_{n1}, ...,t_{nK})^T  &\\in \\mathbb{R}^{1xK}\\nonumber\\\\\nT &= (\\textbf{t}_1,...,\\textbf{t}_N)^T &\\in \\mathbb{R}^{NxK}\\nonumber\\\\\n\\end{align}\n\\]\n\n12.1 Multivariate Gaussian Distribution\nThe PDF: \\[\n\\begin{align}\nf(\\mathbf{x} | \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}) = \\frac{1}{(2\\pi)^{\\frac{n}{2}} |\\boldsymbol{\\Sigma}|^{\\frac{1}{2}}} \\exp\\left(-\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu})^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu})\\right)\\\\\n\\end{align}\n\\]\nWhere:\n\n\\(\\mathbf{x}\\) represents the vector of random variables (n-dimensional).\n\\(\\boldsymbol{\\mu}\\) is the mean vector, which is also an n-dimensional vector.\n\\(\\boldsymbol{\\Sigma}\\) is the covariance matrix, which is an n x n symmetric positive-definite matrix.\n\\(|\\boldsymbol{\\Sigma}|\\) represents the determinant of the covariance matrix.\n\\((\\mathbf{x} - \\boldsymbol{\\mu})^T\\) represents the transpose of the vector \\((\\mathbf{x} - \\boldsymbol{\\mu}\\)).\n\\(\\boldsymbol{\\Sigma}^{-1}\\) is the inverse of the covariance matrix."
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#fixed-bssis-functions",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#fixed-bssis-functions",
    "title": "Classification and Decision Theory",
    "section": "13 Fixed Bssis Functions",
    "text": "13 Fixed Bssis Functions\nIn the context of basis functions, the statement “Easy way to define nonlinear models (wrt the original features) via linear models (in the parameters)” means that you can represent complex, nonlinear relationships between your input features and the output variable by using a linear model in terms of transformed or “basis” functions. Let’s break down what this statement implies:\n\nNonlinear Models: Nonlinear models are those that cannot be expressed as simple linear relationships between the input features and the output. In many real-world problems, the relationships between variables are not linear, which makes modeling them directly with linear models (like linear regression) challenging.\nOriginal Features: These are the raw input features of your data. For example, if you’re working with a dataset of house prices, the original features might include the number of bedrooms, square footage, and location.\nBasis Functions: Basis functions are mathematical functions that transform the original features into a new set of features. These new features are designed to capture the underlying nonlinear relationships in the data. Common basis functions include polynomial functions (e.g., squaring a feature to capture quadratic relationships) and radial basis functions (used in radial basis function networks).\nLinear Models (in the Parameters): Despite the use of basis functions to transform the input features, the model’s structure is still linear in terms of its parameters. This means that you can express the output variable as a linear combination of the transformed features, where the coefficients of this linear combination are the parameters of the model. For example, you might have a model like:\ny = w0 + w1 * basis_function1(x) + w2 * basis_function2(x) + ... + wn * basis_functionn(x)\nHere, w0, w1, w2, ..., wn are the model parameters, and basis_function1(x), basis_function2(x), ... are the transformed features created by the basis functions.\n\nSo, the statement is highlighting that by using basis functions to transform the original features, you can still use a linear model in terms of its parameters to capture complex, nonlinear relationships in the data. This approach makes it easier to model nonlinear data patterns while benefiting from the simplicity and interpretability of linear models when it comes to parameter estimation and inference."
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#faq",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#faq",
    "title": "Classification and Decision Theory",
    "section": "14 FAQ",
    "text": "14 FAQ\n\n\n\n\n\n\n1. Why if correlated features are treated independently, the evidence for a class will be overcounted?\n\n\n\n\n\nI apologize for any confusion. Let me break down that fragment for better clarity:\n\nEvidence for a Class: When we talk about “evidence for a class” in a classification problem, we’re referring to the information or characteristics of a data point’s features that suggest or indicate which class that data point should belong to. This evidence is essentially the input data that the classification algorithm uses to make predictions.\nCorrelated Features: Correlated features are features that have some degree of statistical relationship or similarity between them. In the context of a classification problem, correlated features might provide similar or redundant information about the data.\nRedundant or Overlapping Information: When features are correlated, it means that some of the information they provide is redundant or overlapping. In other words, these features may convey the same or very similar details about the data point. For example, if you have two highly correlated features, knowing the value of one feature might give you a good idea about the value of the other.\nTreating Features Independently: In some classification algorithms, especially simple ones like Naive Bayes, each feature is treated as if it is completely independent of the others. This assumption simplifies the modeling process but can be problematic when features are correlated.\nCounting Shared Information Multiple Times: When you treat correlated features independently, you essentially consider the shared or overlapping information multiple times. For example, if two features are highly correlated and you treat them independently, you might effectively count the same information twice, once for each correlated feature. This can lead to an overestimation of the importance of that shared information.\n\nTo illustrate this concept, consider a classification task where you’re trying to predict whether an email is spam (class 1) or not spam (class 0) based on two features: the number of times the word “money” appears in the email and the number of times the word “cash” appears. If these two features are highly correlated (i.e., they tend to occur together), treating them independently might lead to double-counting the evidence related to financial terms, which could skew the classification result. Therefore, it’s important to handle correlated features appropriately in order to make accurate predictions.\n\n\n\n\n\n\n\n\n\n2. What is the Köppen climate classification system?\n\n\n\n\n\nIt consists of five primary climate groups, which are further subdivided into various climate types. Here’s a breakdown of the primary climate groups and their associated climate types:\n\nGroup A: Tropical Climates:\n\nAf: Tropical rainforest climate\nAm: Tropical monsoon climate\nAw: Tropical wet and dry or savanna climate\n\nGroup B: Dry Climates:\n\nBWh: Hot desert climate\nBWk: Cold desert climate\nBSh: Hot semi-arid climate\nBSk: Cold semi-arid climate\n\nGroup C: Temperate Climates:\n\nCfa: Humid subtropical climate\nCwa: Monsoon-influenced humid subtropical climate\nCfb: Oceanic or maritime climate\nCfc: Subpolar oceanic climate\nCsa: Mediterranean climate\nCsb: Mediterranean climate with dry summer\nCwa: Monsoon-influenced humid subtropical climate\nCwc: Cold subtropical highland climate\n\nGroup D: Continental Climates:\n\nDfa: Hot-summer humid continental climate\nDfb: Warm-summer humid continental climate\nDfc: Subarctic or boreal climate\nDwa: Hot-summer subarctic climate\nDwb: Warm-summer subarctic climate\n\nGroup E: Polar Climates:\n\nET: Tundra climate\nEF: Ice cap climate\n\n\nAdditionally, there is a Group H: Highland Climates category for high-altitude regions with their own unique climate characteristics.\nSo, there are a total of 12 primary climate types within the Köppen climate classification system, and each of these primary types can be further refined with additional letters and numbers to provide more specific details about temperature and precipitation patterns.\n\n\n\n\n\n\n\n\n\n3. What are Generative Models?\n\n\n\n\n\nIn machine learning, generative models are a class of models used to learn the underlying probability distribution of the data. These models are called “generative” because they can generate new data samples that resemble the training data. In other words, they capture the structure and patterns within the data and can be used to create synthetic data points that are statistically similar to the real data.\n\nHow NB is a generative model?\n\nIn generative models we model two things: 1. the class-conditional densities p(x|C_k) 2. the class priors p(C_k). With these two we can compute the join distribution.\nFurthermore, one can use Bayes Theorem to compute the posterior p(C_k|x). Looking at the equation above we see that we have defined the numerator as the joint distribution obtained from our generative model. For the denominator part, we have computed the evidence by marginalising over the k classes.\nHaving done this, (we have used Naive Bayes to model the distribution of our features values as independent to decrease the number of parameters) we have obtain the posterior probability which can be used to determine class membership for each new input x.\nAs referred in Bishop, approaches that explicit or implicitly model the distribution of input as well as the outputs are known as generative models. They called generative models because by sampling from them it is possible to generate synthetic data points in the input space.\n\nWhat does it mean by Generative models?\n\nIn Bishop we have:\n\nApproaches that explicitly or implicitly model the distribution of inputs as well as outputs are known as generative models, because by sampling from them it is possible to generate synthetic data points in the input space.\n\nThe statement you provided highlights a key characteristic of generative models and explains why they are called “generative.” Let’s break down the meaning of this statement:\n\nApproaches that explicitly or implicitly model the distribution of inputs as well as outputs: This part of the statement refers to machine learning models that are designed to not only capture the relationship between inputs and outputs but also to learn the underlying probability distribution of the inputs. In other words, these models aim to understand how the input data is generated probabilistically.\nKnown as generative models: These models are commonly referred to as “generative models” because they have the capability to generate synthetic data points that resemble the real data. This is achieved by sampling from the learned distribution of inputs. In essence, generative models can create new data instances that are statistically similar to the training data.\nBy sampling from them it is possible to generate synthetic data points in the input space: This part of the statement explains the practical significance of generative models. Once a generative model has learned the data distribution, you can use it to create new data points. These new data points are generated by sampling from the probability distribution of inputs that the model has learned during training.\n\nHere’s a simple example to illustrate this concept: Consider a generative model trained on a dataset of images of cats. The model learns not only to recognize cats but also the underlying distribution of features that define what a cat looks like. Once trained, you can sample from this model, and it will generate new images of cats that resemble those in the training data. These generated images are synthetic data points in the input space because they represent new, artificial cat images that the model has “generated” based on what it has learned about cats.\n\n\n\n\n\n\n\n\n\n4. Convex regions\n\n\n\n\n\nLet’s consider a 2D space, and we have a convex region “C1.” We’ll choose two points within this region, x0 and x1. Then, we’ll create a line segment by varying λ between 0 and 1 and plot the points on the line segment. If all points on the line segment remain within C1, it indicates that C1 is convex.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define the convex region C1 (a circle for this example)\nradius = 2\ncenter = (0, 0)\n\n# Generate random points within C1\ntheta = np.linspace(0, 2 * np.pi, 100)\nx0 = center[0] + radius * np.cos(theta)\ny0 = center[1] + radius * np.sin(theta)\n\n# Choose two points x0 and x1 within C1\nx0_point = (1, 1)\nx1_point = (-1, 1)\n\n# Create a figure and axis\nfig, ax = plt.subplots()\n\n# Plot C1 as a filled circle\nax.fill(x0, y0, 'b', alpha=0.5)\n\n# Plot the two chosen points x0 and x1\nax.plot(x0_point[0], x0_point[1], 'ro', label='x0')\nax.plot(x1_point[0], x1_point[1], 'go', label='x1')\n\n# Generate points along the line segment defined by x0 and x1\nlambdas = np.linspace(0, 1, 50)\nline_points = [(1 - l) * np.array(x0_point) + l * np.array(x1_point) for l in lambdas]\n\n# Check if all points on the line segment are within C1\nall_inside_c1 = all(np.linalg.norm(p - center) &lt;= radius for p in line_points)\n\n# Highlight the line segment\nif all_inside_c1:\n    ax.plot([p[0] for p in line_points], [p[1] for p in line_points], 'k-', label='Line Segment (Convex)')\nelse:\n    ax.plot([p[0] for p in line_points], [p[1] for p in line_points], 'r-', label='Line Segment (Not Convex)')\n\n# Set axis limits\nax.set_xlim(-3, 3)\nax.set_ylim(-3, 3)\n\n# Add labels and legend\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Convex Region and Line Segment')\nax.legend()\n\n# Show the plot\nplt.grid(True)\nplt.show()\n\n\n\n\n\nIn this example, we define a convex region “C1” as a circle. We choose two points, x0 and x1, within C1 and create a line segment by interpolating between them using λ values. If all points on the line segment remain within the circle (C1), it indicates that C1 is convex. The plot will show the circle, the two chosen points, and the line segment along with labels and a legend."
  },
  {
    "objectID": "blog/2023-07-24_the-right-tool/index.html",
    "href": "blog/2023-07-24_the-right-tool/index.html",
    "title": "Picking the right tool to show your Machine Learning project",
    "section": "",
    "text": "Picking the right tool to show your Machine Learning project\n        \n        \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                DevOps\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                            \n                            \n                                Shiny\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                DevOps\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                                            \n                            \n                               \n                                Shiny\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          July 24, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\n\n\n\n\n\n\nDisclaimer\n\n\n\nFor sake of keeping my thoughts run smoothly this page may contain typos. Bear with Danilo.\n\n\n\n\nThe reason\nI have come across the question on where to host the models that I have trained and display its outputs in an interactive way.\nWhile doing some googling I came across different technologies which much of which have been recently launched, provided the pletora of machine learning application these days. So here a couple of things that I have learnt:\n\n\nStatic websites just got better!\nFor static websites, there is pretty much not too many available options. Statics sites like this one make use of javascript as the backbone to run expensive tasks and usually data science tools these days operate with Python, Julia or R.\nBeing said that, pyscript seems to pose a first steps on how to run python in HTML. Found this was a relief because then I discovered that Python code is able to be written in a portable binary-code format WASM, which in turn means you can write Python and run it at the server side. For a more thorugh explanation about this you can check this video explanation.\n\n\nIf Python available which technology to use?\nHere gets tricky, if you want to have a fast and easy to deployment usually there is no much customization, and by that I mean curky ads and logos like: made by.. not to much fan of those. Following a simple chart that I have found really usefull to solve my enquires, I am attaching the source link here for reference.\n Source: 1\n\n\nThe decision\nAll set and stone, I have only some requirements to jump into learning a new technology and those are\n\nScalable: I want to be able to not just use it for my blog but for future work as well\nOn the look: if it has not been used for the last couple of years then something new is on the look\nBalance-learning-curve: I have learnt Haskell and let me tell you, prototyping and designing code is another world in functional language. So I want be a eager learning while still discovering more tools next couple of months in the road.\n\nConsidering these facts: I am planing to stick with Shiny for the time being."
  },
  {
    "objectID": "blog/2023-06-05_how-hash-table-works/index.html",
    "href": "blog/2023-06-05_how-hash-table-works/index.html",
    "title": "How PCY Algorithm works",
    "section": "",
    "text": "An Effective Hash-Based Algorithm for Mining Association Rules.\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Data Mining\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Data Mining\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          June 5, 2023\n        \n      \n      \n        \n      \n      \n\n    \n        Quick Links\n    \n         Quick Links:\n                                    \n                 Code\n                        \n                                     See Article"
  },
  {
    "objectID": "blog/2023-06-05_how-hash-table-works/index.html#initializing-the-transaction-baskets",
    "href": "blog/2023-06-05_how-hash-table-works/index.html#initializing-the-transaction-baskets",
    "title": "How PCY Algorithm works",
    "section": "Initializing the transaction baskets",
    "text": "Initializing the transaction baskets\n\nimport numpy as np\nimport pandas as pd\nimport itertools\n\n\n# initialize lists\ndata = [[1,2,5], [2,3,5], [4,5], [1,6,7], [2,3,5,7], [1,2,7]]\npairs = [list(itertools.combinations(i, 2)) for i in data]\nmydict = {'Items':data, 'Pairs': pairs}\n\n# Create the pandas DataFrame with column name is provided explicitly\ndf = pd.DataFrame(mydict)\n\n# Print dataframe\ndisplay(df)\n\n\n\n\n\n\n\n\nItems\nPairs\n\n\n\n\n0\n[1, 2, 5]\n[(1, 2), (1, 5), (2, 5)]\n\n\n1\n[2, 3, 5]\n[(2, 3), (2, 5), (3, 5)]\n\n\n2\n[4, 5]\n[(4, 5)]\n\n\n3\n[1, 6, 7]\n[(1, 6), (1, 7), (6, 7)]\n\n\n4\n[2, 3, 5, 7]\n[(2, 3), (2, 5), (2, 7), (3, 5), (3, 7), (5, 7)]\n\n\n5\n[1, 2, 7]\n[(1, 2), (1, 7), (2, 7)]"
  },
  {
    "objectID": "blog/2023-06-05_how-hash-table-works/index.html#calculating-the-supports",
    "href": "blog/2023-06-05_how-hash-table-works/index.html#calculating-the-supports",
    "title": "How PCY Algorithm works",
    "section": "Calculating the supports",
    "text": "Calculating the supports\n\nprint(data)\n\n[[1, 2, 5], [2, 3, 5], [4, 5], [1, 6, 7], [2, 3, 5, 7], [1, 2, 7]]\n\n\n\nsupports = {}\nfor row in data:\n    for e in row:\n        if e not in supports:\n            supports[e] = 0\n\n# Sorting dictionary\nsorted_dict = supports.keys()\nsuppports = sorted(sorted_dict)\nprint(supports)\n\n{1: 0, 2: 0, 5: 0, 3: 0, 4: 0, 6: 0, 7: 0}\n\n\n\nfor row in data:\n    for e in row:\n        supports[e] += 1\n\nprint(supports)\n\n{1: 3, 2: 4, 5: 4, 3: 2, 4: 1, 6: 1, 7: 3}\n\n\n\nitem = [ key for key, value in supports.items()]\nsupp = [ value for key, value in supports.items()]\nunique_items_count = {'Itemset': item, 'Sup': supp}\n\ndf_item_sup = pd.DataFrame(unique_items_count)\ndisplay(df_item_sup)\n\n\n\n\n\n\nTable 1: Support\n\n\n\nItemset\nSup\n\n\n\n\n0\n1\n3\n\n\n1\n2\n4\n\n\n2\n5\n4\n\n\n3\n3\n2\n\n\n4\n4\n1\n\n\n5\n6\n1\n\n\n6\n7\n3\n\n\n\n\n\n\n\n\n\nPass 1\n\ndef hash_f_pair(i,j):\n    return (i*j) % 7\n\n\nunique_items = []\nfor row in pairs:\n    for e in row:\n        if e not in unique_items:\n            unique_items.append(e)\nprint(unique_items)\n\n[(1, 2), (1, 5), (2, 5), (2, 3), (3, 5), (4, 5), (1, 6), (1, 7), (6, 7), (2, 7), (3, 7), (5, 7)]\n\n\n\nunique_items[0][1]\n\n2\n\n\n\nhash_value_pairs = []\nfor e in unique_items:\n        hash_value_pairs.append(hash_f_pair(e[0],e[1]))\nprint(hash_value_pairs)\n\n[2, 5, 3, 6, 1, 6, 6, 0, 0, 0, 0, 0]\n\n\n\nmy_dict2 = {}\nfor pair in unique_items:\n    my_dict2[str(pair)] = 0\nprint(my_dict2)\n\n{'(1, 2)': 0, '(1, 5)': 0, '(2, 5)': 0, '(2, 3)': 0, '(3, 5)': 0, '(4, 5)': 0, '(1, 6)': 0, '(1, 7)': 0, '(6, 7)': 0, '(2, 7)': 0, '(3, 7)': 0, '(5, 7)': 0}\n\n\n\nfor row in pairs:\n    for e in row:\n        my_dict2[str(e)] +=1\n\nprint(my_dict2)\n\n{'(1, 2)': 2, '(1, 5)': 1, '(2, 5)': 3, '(2, 3)': 2, '(3, 5)': 2, '(4, 5)': 1, '(1, 6)': 1, '(1, 7)': 2, '(6, 7)': 1, '(2, 7)': 2, '(3, 7)': 1, '(5, 7)': 1}\n\n\n\ncounts = [ value for key, value in my_dict2.items()]\nprint(counts)\n# df_counts = pd.DataFrame()\n\n[2, 1, 3, 2, 2, 1, 1, 2, 1, 2, 1, 1]\n\n\n\nunique_items_count = {'Pairs': unique_items, 'Count': counts, 'Hash': hash_value_pairs}\nprint(unique_items_count)\n\n{'Pairs': [(1, 2), (1, 5), (2, 5), (2, 3), (3, 5), (4, 5), (1, 6), (1, 7), (6, 7), (2, 7), (3, 7), (5, 7)], 'Count': [2, 1, 3, 2, 2, 1, 1, 2, 1, 2, 1, 1], 'Hash': [2, 5, 3, 6, 1, 6, 6, 0, 0, 0, 0, 0]}\n\n\n\ndf_counts = pd.DataFrame(unique_items_count)\ndisplay(df_counts)\n\n\n\n\n\n\nTable 2: Hash Pair Table\n\n\n\nPairs\nCount\nHash\n\n\n\n\n0\n(1, 2)\n2\n2\n\n\n1\n(1, 5)\n1\n5\n\n\n2\n(2, 5)\n3\n3\n\n\n3\n(2, 3)\n2\n6\n\n\n4\n(3, 5)\n2\n1\n\n\n5\n(4, 5)\n1\n6\n\n\n6\n(1, 6)\n1\n6\n\n\n7\n(1, 7)\n2\n0\n\n\n8\n(6, 7)\n1\n0\n\n\n9\n(2, 7)\n2\n0\n\n\n10\n(3, 7)\n1\n0\n\n\n11\n(5, 7)\n1\n0\n\n\n\n\n\n\n\n\nMinium support count is 2 so we eliminate from the Pair list the items that have less than 2 from Table 1. The resulting table is called the Candidate Pairs.\n\ndf_counts_after = df_counts.drop([5, 6, 8])\ndisplay(df_counts_after)\n\n\n\n\n\n\nTable 3: Hash Pair Table after Pass 1\n\n\n\nPairs\nCount\nHash\n\n\n\n\n0\n(1, 2)\n2\n2\n\n\n1\n(1, 5)\n1\n5\n\n\n2\n(2, 5)\n3\n3\n\n\n3\n(2, 3)\n2\n6\n\n\n4\n(3, 5)\n2\n1\n\n\n7\n(1, 7)\n2\n0\n\n\n9\n(2, 7)\n2\n0\n\n\n10\n(3, 7)\n1\n0\n\n\n11\n(5, 7)\n1\n0\n\n\n\n\n\n\n\n\n\n\nPass 2\nThe final step is to build a table from Table 2 that counts the number of ocurrences per hash value.\n\nhash_values = [x for x in range(max(hash_value_pairs)+1)]\nmy_dict3 = {}\nfor e in hash_values:\n    my_dict3[e] = 0\n\nfor i, hash_value in enumerate(df_counts[\"Hash\"]):\n    my_dict3[hash_value] += df_counts[\"Count\"][i]\nprint(my_dict3)\n\ndata_bucket = {\"Bucket\": hash_values, \"Count\": my_dict3.values()}\ndf_bucket_count = pd.DataFrame(data_bucket)\ndisplay(df_bucket_count)\n\n{0: 7, 1: 2, 2: 2, 3: 3, 4: 0, 5: 1, 6: 4}\n\n\n\n\n\n\n\n\n\nBucket\nCount\n\n\n\n\n0\n0\n7\n\n\n1\n1\n2\n\n\n2\n2\n2\n\n\n3\n3\n3\n\n\n4\n4\n0\n\n\n5\n5\n1\n\n\n6\n6\n4\n\n\n\n\n\n\n\nWith the result above we can look back to table Table 3 and see which hash values, have a value lower than the minimum support count. That is hash value 4 and 5. With this result we look at table Table 3 and delete those corresponding hash values. The final result is teh Final Candidates\n\ndf_counts_after_pass2 = df_counts_after.drop([1])\ndisplay(df_counts_after_pass2)\n\n\n\n\n\n\n\n\nPairs\nCount\nHash\n\n\n\n\n0\n(1, 2)\n2\n2\n\n\n2\n(2, 5)\n3\n3\n\n\n3\n(2, 3)\n2\n6\n\n\n4\n(3, 5)\n2\n1\n\n\n7\n(1, 7)\n2\n0\n\n\n9\n(2, 7)\n2\n0\n\n\n10\n(3, 7)\n1\n0\n\n\n11\n(5, 7)\n1\n0"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "\nPython\n",
    "section": "",
    "text": "In this section Danilo writes down his notes, the things he has figured out about his computer, and ocasionally when feeling inspired he writes poems.\n\n\n\n\n\n\nShowing All Posts\n\n \n\nShow All Posts \n\n\n\n\n\n\n\nNotes\n\n\n\n\n\n\n\n\n #   published: \n\n\nPython\n\n\n\n\n\n\n\n\n\n     \n    \n        \n        \n            \n            1\n        \n            \n        \n        \n            \n            2\n        \n            \n        \n        \n            \n            3\n        \n            \n        \n        \n            \n            4\n        \n            \n        \n        \n            \n            5\n        \n            \n        \n        \n            \n            6\n        \n            \n        \n        \n            \n            7\n        \n            \n        \n        \n            \n            8\n        \n            \n        \n        \n        \n            \n                \n                1\n        \n        \n        \n            \n                \n                2\n        \n        \n            \n            9\n        \n            \n        \n        \n            \n            10\n        \n            \n        \n        \n            \n            11\n        \n            \n        \n        \n        \n            \n        \n        \n            \n            12\n        \n            \n                \n                3\n        \n        \n            \n            13\n        \n            \n                \n                4\n        \n        \n            \n            14\n            \n            15\n        \n            \n                \n                5\n        \n        \n            \n            16\n            \n            17\n        \n            \n                \n                6\n        \n        \n            \n            18\n            \n            19\n        \n            \n                \n                7\n        \n        \n            \n            20\n            \n            21\n        \n            \n                \n                8\n        \n        \n            \n            22\n        \n            \n                \n                9\n        \n        \n        \n            \n        \n        \n            \n            23\n            \n            24\n        \n            \n                \n                10\n        \n        \n            \n            25\n        \n            \n                \n                11\n        \n        \n            \n            26\n            \n            27\n        \n            \n                \n                12\n        \n        \n            \n            28\n        \n            \n                \n                13\n        \n        \n            \n            29\n        \n            \n                \n                14\n        \n        \n            \n            30\n        \n            \n                \n                15\n                \n                16\n        \n        \n        \n            \n                \n                17\n        \n        \n            \n            31\n        \n            \n                \n                18\n        \n        \n            \n            32\n        \n            \n                \n                19\n                \n                20\n        \n        \n            \n            33\n        \n            \n                \n                21\n                \n                22\n        \n        \n            \n            34\n        \n            \n                \n                23\n        \n        \n            \n            35\n        \n            \n                \n                24\n        \n        \n            \n            36\n        \n            \n                \n                25\n        \n        \n            \n            37\n        \n            \n                \n                26\n                \n                27\n        \n        \n            \n            38\n        \n\n2023\n    \n    \n                \n                        \n                            \n                                Nov 22\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Lexical semantics and word embeddings NEW\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Nov 22\n                        \n                \n                \n                        \n                            \n                                Nov 22\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Compositional semantics and sentence representations\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Nov 22\n                        \n                \n                \n                        \n                            \n                                Nov 20\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Convolutional Neural Networks\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Nov 20\n                        \n                \n                \n                        \n                            \n                                Nov 20\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Modern ConvNets\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Nov 20\n                        \n                \n                \n                        \n                            \n                                Nov 20\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Deep Learning Optimizations II\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Nov 20\n                        \n                \n                \n                        \n                            \n                                Nov 13\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Modelling Syntactic Structure\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Nov 13\n                        \n                \n                \n                        \n                            \n                                Nov 13\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Sequence Labelling\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Nov 13\n                        \n                \n                \n                        \n                            \n                                Nov 08\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Deep Learning Optimizations I\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Nov 08\n                        \n                \n                \n                        \n                            \n                                Nov 07\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Numpy reshape RGB image to 1D array\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Nov 07\n                        \n                \n                \n                        \n                            \n                                Nov 05\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Script to extract pages of PDF as images & apply crop\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Nov 05\n                        \n                \n                \n                        \n                            \n                                Nov 05\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Deep Feedforward Networks\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Nov 05\n                        \n                \n                \n                        \n                            \n                                Nov 02\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Language modelling\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Nov 02\n                        \n                \n                \n                        \n                            \n                                Oct 15\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Kernel methods & SVM\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Oct 15\n                        \n                \n                \n                        \n                            \n                                Oct 12\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        The Covariance Matrix and relation with PCA\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Oct 12\n                        \n                \n                \n                        \n                            \n                                Oct 12\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Bayes Rule Equation\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Oct 12\n                        \n                \n                \n                        \n                            \n                                Oct 11\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Principal Component Analysis (PCA)\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Oct 11\n                        \n                \n                \n                        \n                            \n                                Oct 07\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Latent Variable Models & K-Means Clustering\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Oct 07\n                        \n                \n                \n                        \n                            \n                                Oct 04\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Neural networks\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Oct 04\n                        \n                \n                \n                        \n                            \n                                Oct 04\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Logistic Regression\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Oct 04\n                        \n                \n                \n                        \n                            \n                                Oct 03\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        The Perceptron\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Oct 03\n                        \n                \n                \n                        \n                            \n                                Sep 26\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Matrix Calculus & Derivatives Ax\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 26\n                        \n                \n                \n                        \n                            \n                                Sep 26\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Maximum Likelihood vs Maximum a Posteriori Estimation\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 26\n                        \n                \n                \n                        \n                            \n                                Sep 25\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Classification and Decision Theory\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 25\n                        \n                \n                \n                        \n                            \n                                Sep 24\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Una rosa color morada\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 24\n                        \n                \n                \n                        \n                            \n                                Sep 05\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Probability Theory in Machine Learning\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 05\n                        \n                \n                \n                        \n                            \n                                Sep 04\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        MNIST Classification\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 04\n                        \n                \n                \n                        \n                            \n                                Sep 03\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        When you get older\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 03\n                        \n                \n                \n                        \n                            \n                                Aug 21\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Automating the creation of Blog posts\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Aug 21\n                        \n                \n                \n                        \n                            \n                                Aug 18\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        How to use widgets in jupyter notebooks\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Aug 18\n                        \n                \n                \n                        \n                            \n                                Jul 29\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Cafe Negro color Miel\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Jul 29\n                        \n                \n                \n                        \n                            \n                                Jul 24\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Picking the right tool to show your Machine Learning project\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Jul 24\n                        \n                \n                \n                        \n                            \n                                Jun 20\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Running my first Marathon\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Jun 20\n                        \n                \n                \n                        \n                            \n                                Jun 09\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        On the topic of Optimization\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Jun 09\n                        \n                \n                \n                        \n                            \n                                Jun 05\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        How PCY Algorithm works\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Jun 05\n                        \n                \n                \n                        \n                            \n                                May 29\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Markdown structure, titles and CSS\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                May 29\n                        \n                \n                \n                        \n                            \n                                Jan 29\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Displaying jupyter notebooks\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Jan 29\n                        \n                \n                \n                        \n                            \n                                Jan 12\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        2022 into 2023\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Jan 12\n                        \n                \n    \n\n\n         \n            NLP\n        \n         \n            NLP\n        \n         \n            Deep Learning\n        \n         \n            Deep Learning\n        \n         \n            Deep Learning\n        \n         \n            NLP\n        \n         \n            NLP\n        \n         \n            Deep Learning\n        \n         \n            Deep Learning\n        \n         \n            NLP\n        \n         \n            Education\n        \n         \n            Education\n        \n         \n            Education\n        \n         \n            Education\n        \n         \n            Machine Learning\n        \n         \n            Education\n        \n         \n            Machine Learning\n        \n         \n            Education\n        \n         \n            Machine Learning\n        \n         \n            Education\n        \n         \n            Machine Learning\n        \n         \n            Education\n        \n         \n            Education\n        \n         \n            Machine Learning\n        \n         \n            Poems\n        \n         \n            Education\n        \n         \n            Machine Learning\n        \n         \n            Machine Learning\n        \n         \n            Poems\n        \n         \n            Extension\n        \n         \n            Poems\n        \n         \n            DevOps\n        \n         \n            Life\n        \n         \n            Workflow\n        \n         \n            Data Mining\n        \n         \n            Markdown\n        \n         \n            Analysis\n        \n         \n            News\n        \n         \n            Python\n        \n         \n            Python\n        \n         \n            Probability\n        \n         \n            Linear models\n        \n         \n            Python\n        \n         \n            Python\n        \n         \n            Python\n        \n         \n            AI\n        \n         \n            Vector Calculus\n        \n         \n            Classification\n        \n         \n            Spanish\n        \n         \n            Probability Theory\n        \n         \n            Python\n        \n         \n            Spanish\n        \n         \n            Quarto\n        \n         \n            Python\n        \n         \n            Python\n        \n         \n            Spanish\n        \n         \n            Python\n        \n         \n            Shiny\n        \n         \n            Amsterdam\n        \n         \n            Running\n        \n         \n            Lua\n        \n         \n            Python\n        \n         \n            Testing\n        \n         \n            Testing\n        \n         \n            Python\n        \n         \n            2023-table\n        \n\n\nNo matching items\n\n\n\n\n\n\n\n     \n    \n        \n        \n            \n            1\n        \n            \n                \n                1\n        \n        \n            \n            2\n        \n\n2022\n    \n    \n                \n                        \n                            \n                                Dec 29\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Cuando miras al cielo NEW\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Dec 29\n                        \n                \n                \n                        \n                            \n                                Nov 05\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Welcome To My Blog\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Nov 05\n                        \n                \n    \n\n\n         \n            Poems\n        \n         \n            News\n        \n         \n            Spanish\n        \n         \n            2022-table\n        \n\n\nNo matching items\n\n\n\n\n\n  \n  \n    \n    CATEGORIES\n      \n    \n      \n  \n  \n  \n    \n      TAGS"
  },
  {
    "objectID": "blog/2023-11-07_numpy-reshape-rgb-image-to-1d-array/index.html",
    "href": "blog/2023-11-07_numpy-reshape-rgb-image-to-1d-array/index.html",
    "title": "Numpy reshape RGB image to 1D array",
    "section": "",
    "text": "Numpy reshape RGB image to 1D array\n        \n        \n                    \n                \n                    Description of this Notebook\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          November 7, 2023\n        \n      \n      \n        \n      \n      \n\n    \n        Quick Links\n    \n         Quick Links:\n                                    \n                 Code\n                        \n            \n    \n\n\nImagine you want to train a NN with:\n\nX: s x 3 x 32 x 32\n\nWhere:\n\ns: num samples\n3 x 32 x 32: color img\n\nNow to feed in the NN we want the shapes to be:\n\nX: s x (3072)\n\nDo we lose information? The answers is not, we just reshape X.\nThe following takes 2 imgs, with dimensions 2x2:\n\nimport numpy as np\n\n# Create example 3x2x2 images (two images)\noriginal_images = np.array([[[[1, 2],\n                             [3, 4]],\n                            [[5, 6],\n                             [7, 8]],\n                            [[9, 10],\n                             [11, 12]]],\n\n                           [[[13, 14],\n                             [15, 16]],\n                            [[17, 18],\n                             [19, 20]],\n                            [[21, 22],\n                             [23, 24]]]])\n\n# Print the shape of the original images\nprint(\"Original Images Shape:\", original_images.shape)\n\n# Print the original images\nprint(\"Original Images:\\n\", original_images)\n\n# Reshape the images into num_imgs x (3*2*2) matrices\nnum_imgs = original_images.shape[0]\nreshaped_images = original_images.reshape(num_imgs, -1)\n\n# Print the shape of the reshaped images\nprint(\"Reshaped Images Shape:\", reshaped_images.shape)\n\n# Print the reshaped images\nprint(\"Reshaped Images:\\n\", reshaped_images)\n\nOriginal Images Shape: (2, 3, 2, 2)\nOriginal Images:\n [[[[ 1  2]\n   [ 3  4]]\n\n  [[ 5  6]\n   [ 7  8]]\n\n  [[ 9 10]\n   [11 12]]]\n\n\n [[[13 14]\n   [15 16]]\n\n  [[17 18]\n   [19 20]]\n\n  [[21 22]\n   [23 24]]]]\nReshaped Images Shape: (2, 12)\nReshaped Images:\n [[ 1  2  3  4  5  6  7  8  9 10 11 12]\n [13 14 15 16 17 18 19 20 21 22 23 24]]"
  },
  {
    "objectID": "blog/2023-10-12_bayes-rule/index.html",
    "href": "blog/2023-10-12_bayes-rule/index.html",
    "title": "Bayes Rule Equation",
    "section": "",
    "text": "Description of this Post\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Probability\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Probability\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          October 12, 2023"
  },
  {
    "objectID": "blog/2023-10-12_bayes-rule/index.html#bayes-theorem",
    "href": "blog/2023-10-12_bayes-rule/index.html#bayes-theorem",
    "title": "Bayes Rule Equation",
    "section": "1 Bayes Theorem",
    "text": "1 Bayes Theorem\n\\[\n\\begin{align}\np(C|X) = \\frac{P(X|C)P(C)}{P(X)} \\\\\n\\end{align}\n\\]\nWhere:\n\n\\(P(C|X)\\) is the Posterior (Given the data what is the prob of being class C_k)\n\\(P(X|C)\\) is the Likelihood (How the data is distributed given C)\n\\(P(C)\\) is the Prior\n\\(P(X)\\) is the Evidence/ Marginal likelihood\n\nThe evidence \\(P(X)\\) can also be decomposed in:\n\\[\n\\begin{align}\nP(X) &= \\sum_{j}{}P(X,C_j)\\\\\n     &= \\sum_{j}{}P(X|C_j)P(C_j) \\\\\n\\end{align}\n\\]"
  },
  {
    "objectID": "blog/2023-06-20_running-my-first-marathon/index.html",
    "href": "blog/2023-06-20_running-my-first-marathon/index.html",
    "title": "Running my first Marathon",
    "section": "",
    "text": "I will be running at the 42km TCS Amsterdam 2023, 15th October\n                \n            \n                        \n            \n                                            \n\n                    \n                                            \n                            \n                                All\n                            \n                         \n                                            \n                            \n                                Life\n                            \n                         \n                                            \n                            \n                                TAGS\n                            \n                         \n                                            \n                            \n                                Amsterdam\n                            \n                         \n                                            \n                            \n                                Running\n                            \n                         \n                    \n                    \n                                    \n                            \n        \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          June 20, 2023\n        \n      \n      \n        \n      \n      \n\n        \n                 Slides\n                 Code\n                 Video\nThe idea of running a marathon its exiting. Specially when I did a half-marathon and reach the goal feeling a champ."
  },
  {
    "objectID": "blog/2023-06-20_running-my-first-marathon/index.html#during-the-training",
    "href": "blog/2023-06-20_running-my-first-marathon/index.html#during-the-training",
    "title": "Running my first Marathon",
    "section": "During the training",
    "text": "During the training\nTo prepare runnign at be acustomed during the competition after looking at some post and blogs I have decided to come up with my own plan, the idea is to prepare it by my own because I will be still be bussy during the month of October\nFor that reason, I have compelled the following traning plan, after looking analysis how other do it."
  },
  {
    "objectID": "blog/2023-06-20_running-my-first-marathon/index.html#during-the-marathon",
    "href": "blog/2023-06-20_running-my-first-marathon/index.html#during-the-marathon",
    "title": "Running my first Marathon",
    "section": "During the marathon",
    "text": "During the marathon\n\nThe pace\nFrom experience I know it can be tricky to fall into the tramp or going as fast as other people will do it. I have made this mistake and I find myself not sticking to my goals. The whole purpose of training its to test how capable I am and compare myself with myself. Thus, to avoid ‘hittin the wall’ I would like to analalize…"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "",
    "text": "Lecture Notes UvA on 2-10-2023\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          October 7, 2023"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#supervised-learning",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#supervised-learning",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "1 Supervised Learning",
    "text": "1 Supervised Learning\nHere the mission of the model is to learn the relation between the labels and the features."
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#unsupervised-learning",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#unsupervised-learning",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "2 Unsupervised Learning",
    "text": "2 Unsupervised Learning\nYou do not have labels you only have features.\nThe mission of the model is to discover latent or hidden structures.\nLatent means to be not measurable, to be hidden i.e. thoughts –&gt; words. You can sample words, you have data from the words, but for thoughts you don’t have data available, the variable is hidden\n\n\n\n\nUnsupervised learning is understanding the data discovering properties to exploit."
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#unsupervised-vs.-supervised-learning",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#unsupervised-vs.-supervised-learning",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "3 Unsupervised vs. Supervised learning",
    "text": "3 Unsupervised vs. Supervised learning"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#latent-variable-models",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#latent-variable-models",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "4 Latent variable Models",
    "text": "4 Latent variable Models\n\n\n\n\nIn Unsupervised learning:\nYou have Latent variable \\(Z\\) and that generates \\(X\\).\nIn supervised learning:\nFor instance in Classification you would have features \\(X\\) and that generates some label \\(y\\).\n\n\nSo you could think of Unsupervised learning as we are given our labels and we need to learn the features that generate the label\n\n\\(Z\\) in the figure above are the labels. We want to get the distriution of the data in the continuous case i.e. by marginalizing over \\(z\\) to get the probability of the data alone."
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#examples",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#examples",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "5 Examples",
    "text": "5 Examples\n\n\n\n\n\nFor instance in Clustering we are given scattered plot data and you want to find the hidden groups.\nFor instance in Dimensionality Reduction you are given a 2-dim data and you wonder whether you can learn a lower representation that could describe my data"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#k-means-clustering",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#k-means-clustering",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "6 K-Means Clustering",
    "text": "6 K-Means Clustering\n\nGoal: Automatically partition unlabeled data into groups of similar data points.\n\n\nUseful for:\n\nAutomatically organizing data.\nUnderstanding hidden structure in data.\nPreprocessing for downstream analysis."
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#applications",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#applications",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "7 Applications",
    "text": "7 Applications"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#clustering-with-k-means",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#clustering-with-k-means",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "8 Clustering with K-means",
    "text": "8 Clustering with K-means\n\nGoal: minimize distance between data points and \\(k\\) cluster representations"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#k-means",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#k-means",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "9 K-means",
    "text": "9 K-means\n\n\n\n\n\nYou need to set \\(K\\) the number of clusters ahead of time\nThe mean \\(m_j\\) per ach cluster\nThe cluster that corresponds \\(C_j\\)\nYou only compute the \\(x_n\\) that belongs to that cluster \\(C_j\\) so that we do not compute for all data points\n\n\n\n\n\n\\(|C_j|\\) is the number of datapoints assigned to that cluster \\(j\\)"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#k-means-clustering-example",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#k-means-clustering-example",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "10 K-Means Clustering Example",
    "text": "10 K-Means Clustering Example\n0. Randomly initialize \\(k=3\\) means to data points. (That means we will end up with \\(3\\) Clusters)\n\n\n\n\n1. Assign point to cluster with nearest representation.\n\n\n\n\n2. Compute new cluster representation by taking mean of currently assigned points.\n\n\n\n\nThe coloured points you see above are the new computed means. They are NOT data points they are just the locations where the mean should be.\nRepeat: Step 1 -&gt; 2\n1. Assign point to cluster with nearest representation.\n\n\n\n\n2. Compute new cluster representation by taking mean of currently assigned points.\n\n\n\n\nRepeat: Step 1 -&gt; 2\n1. Assign point to cluster with nearest representation.\n\n\n\n\n2. Compute new cluster representation by taking mean of currently assigned points.\n\n\n\n\nConverging\n1. Assign point to cluster with nearest representation.\n\n\n\n\n\nNote: The algorithm has converged: the cluster assignments do not change. So stop here\n\n\nFinal means and cluster assignments"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#k-means-clustering-pipeline",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#k-means-clustering-pipeline",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "11 K-Means Clustering Pipeline",
    "text": "11 K-Means Clustering Pipeline\nOur model is represented by our \\(k\\) mean vectors: \\(\\{{m_j\\}}_{j=1}^{k}\\)"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#k-means-optimization",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#k-means-optimization",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "12 K-Means: Optimization",
    "text": "12 K-Means: Optimization\n\nThe number of iterations to get the same error is lower in the second run\nThe cost in the same iteration number is higuer in the first iteration\n\n\n\n\n\n\n\nAlgorithm guaranteed to decrease error at each iteration, but not guaranteed to obtain Global Optimum.\nIn between:\n\nIn Linear Regression you can find the global minimum\nIn Neural Networks we cannot never find the global optima, we need to adjust our steep size\nIn K-means you guarantee to reduce error but not guaranteed that if you keep decreasing you will find global minimum.\n\n\nFor the last reason above (the not guaranteeing thing people in practice re-run algorithm multiple times (and take solution with lowest cost, for instance)"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#k-means-overfitting",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#k-means-overfitting",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "13 K-Means: Overfitting",
    "text": "13 K-Means: Overfitting\n\n\n\nThe more clusters we have, the better the chance that a cluster mean will be near held-out data, thus improving the validation error. Thus, looking at validation error alone is not helpful.\nSo how do we quantify this, because the more clusters then the lower the validation error. How do we choose an appropriate \\(k\\)-number: Answer with the Elbow method discussed below"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#k-means-choosing-k",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#k-means-choosing-k",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "14 k-Means: Choosing \\(k\\)",
    "text": "14 k-Means: Choosing \\(k\\)\n\nMethod 1\n\nElbow method: is called like this because think about the error function and your arm. Now we look at the point of hinge where the error loss changes significantly.\n\nFor instance in the image below you find your elbow point where adding more cluster does not improve the error.\n\n\n\n\n\nMethod 2\nAnother method to choose an appropiate \\(k\\) value is: to have a modified error function that account for the number of clusters:\n\n\n\n\nFor instance if I have \\(k=1\\) then the newly introduced term becomes zero. But if you have more than one cluster it is going to get penalize with a factor \\(\\lambda\\)\n\n\nMethod 3\nHere you do external supervision, that means i.e. you have houses clustering by price and size, if you new or wanted to group some houses intentionally then you could stop the \\(k\\)-size number increasing because you have knowledge domain. Thus you control the granularity.\n\n\nMethod 4\n\n\n\n\nYou want the Dunn index to be large, meaning you want in the numerator to be large meaning the minimum distance between cluster representations (so between means) should be large and conversely you want the denominator to be small meaning that you want the maximum distance between points within the cluster to be close to one another (meaning we want to have all point very close to the mean of this cluster)"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#k-means-generalizations",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#k-means-generalizations",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "15 K-Means: Generalizations",
    "text": "15 K-Means: Generalizations\nYou could also compute the error function \\(E\\) with other function rather than squarer error, you could for instance use another distance function like Hamming, or medians like below:"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#improvements-for-big-data",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#improvements-for-big-data",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "16 Improvements for Big Data",
    "text": "16 Improvements for Big Data\n\nWhen the data is long then we may take a lot of time to compute one iteration, the solution for this could be to use:\n\nStochastic gradient: for each datapoint, update nearest cluster mean”\n\n\nWhat this equation is allowing us is to compute the mean not looking at all the data points, again we have the value \\(\\eta\\) which is our learning rate\nThe mean that we are computing its only nearest to the cluster we compute it"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#application-image-compression",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#application-image-compression",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "17 Application: image compression",
    "text": "17 Application: image compression"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#failures-of-k-means",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#failures-of-k-means",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "18 Failures of K-Means",
    "text": "18 Failures of K-Means\nThis is because of the reliance of square distance, then the points close to the means do not preserve the non-euclidean aspect of this data\n\n\n\n\nHere we should expect to see three clusters: 2 ears and 1 face. The explanation to this is because we cannot modify how th distance will be computed. That means we cannot say that the region of the ears to have a smaller distance, compared to the face’s mean.\n\n\n\n\nAnother way to look at this problems is that, you cannot change the scale of the clusters, every cluster would have more or less the same square distance around its cluster mean. That means that you cannot have tighter distance for the ears and more relaxed notion of distance for the same. They are gonna have same squared distances with equal weight."
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#pros-cons-of-k-means",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#pros-cons-of-k-means",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "19 Pros & Cons of K-Means",
    "text": "19 Pros & Cons of K-Means\n\nGood:\n\nSimple to implement\nFast\n\nBad:\n\nLocal minima\nModel only “spherical” clusters that cannot change size\nSensitive to the features scale\nNumber of clusters \\(K\\) to be chosen in advance\nCluster assignments are “hard”, not probabilistic =&gt; next topic, Gaussian Mixture Model"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#minimize-error-em-algorithm",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#minimize-error-em-algorithm",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "20 Minimize Error (EM Algorithm)",
    "text": "20 Minimize Error (EM Algorithm)\n\nThe above algorithm can be formalized in the Expectation Maximization\n\n\nThe E step computes the assignments\nThe M step computes the means\n\n\n\n\n\nSame as computing:\n\n\n\n\n\n20.1 Derivation of M-Step"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#constrained-optimization",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#constrained-optimization",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "21 Constrained optimization",
    "text": "21 Constrained optimization\n\n\n\n\n\n21.1 Lagrange Constrained Optimization: Example"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#probabilistic-version-of-k-means-clustering",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#probabilistic-version-of-k-means-clustering",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "Probabilistic version of k-Means Clustering",
    "text": "Probabilistic version of k-Means Clustering\n\nIn this section we talked about the probabilistic side of k-means"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#clustering-with-gaussian-mixture-model-gmm",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#clustering-with-gaussian-mixture-model-gmm",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "22 Clustering with Gaussian Mixture Model (GMM)",
    "text": "22 Clustering with Gaussian Mixture Model (GMM)\n\nWe assume that the data follows a generative model. Recall what a generative model is:\n\n\nApproaches that explicitly or implicitly model the distribution of inputs as well as outputs are known as generative models, because by sampling from them it is possible to generate synthetic data points in the input space.\n\n\nWe also assume that with each observation there is an associated discrete latent variable. Recall what latent variable is:\n\n\nA latent variable is a variable that is not directly observed is hidden like our thoughs, that is z\n\nFor instance: in the image below we see that the purple data, each of these dots is related to a latent variable \\(z\\), for instance a discrete class \\(z\\) i.e, that can take on the values {red, green, or blue}. Now these latent variables are hidden is not directly observable, you dont’ know them. Here the latent variable is discrete can take values like: red, green and so on, can also be like the example of the houses, it can be boat houses, studios and so on.\nRecap from the upper text. It means that we are no seeing the bottom left graph with the distinctions between classes but we only see the purple dots\n\nWe also assume there is a join distribution \\((x,z) \\sim p(x,z)\\) so in this case in the left plot\n\n\nGoal: given our unlabelled data \\(x \\sim p(x)\\) (purple dots) you want to go to a cluster ( from our latent variable) assignment. Mathematically you want to be able to compute \\(p(z|\\textbf{x})\\) which is the right bottom graph where you see all datapoints assigned one color. For instance you want to say that a purple dot in the corner belows to class \\(z = green\\) or another dot that belongs to \\(z = blue\\). How do we do this? Sol: in a probabilistic way using Multiple Gaussians hence called Gaussian Mixture models."
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#modelling-assumptions",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#modelling-assumptions",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "23 Modelling assumptions",
    "text": "23 Modelling assumptions\n\nWe model our prior with a Generalized Bernoulli distribution\n\nCategorical Distribution: \\[\nP(X = x_i) = p_i, \\quad \\text{for } i = 1, 2, \\ldots, K\n\\]\nwhere \\(p_i\\) is the probability of outcome \\(x_i\\), and \\(\\sum_{i=1}^{K} p_i = 1\\).\nGeneralized Bernoulli: \\[\nP(X = x) = \\theta^x (1 - \\theta)^{1 - x}, \\quad \\text{for } x = 0, 1\n\\]\nwhere \\(\\theta\\) is the probability of \\(X = 1\\), and \\((1 - \\theta)\\) is the probability of \\(X = 0\\)\n\nThe second part part of our generative model is the latent class or conditional distributions \\(p(\\textbf{x}|z_k)\\) modelled with Gaussians. NOTE this is not the likelihood\n\n\\(p(\\textbf{x}|z_k)\\): is the probability that if I know the class \\(z_k\\) then I will observed the data in i.e the red region, see picture above in orange highlighted\n\nThe \\(\\pi_k\\), \\(\\mu_k\\), \\(\\Sigma_k\\) are learnable parameters\nWith the prior and the latent conditional distribution we can compute the joint \\(p(\\textbf{x},z_k =1)\\). That is, we compute the probability for each class\nGiven this model we can define a \\(p(x)\\) for the entire data set which is simply the marginalization over \\(z\\). But this is gonna be a sum of Gaussians, see the equation at bottom of slide. Because of the sum of gaussians we call it Gaussian mixture model\n\n\n\n\n\nThis is how we model \\(p(x)\\) but now we want to optimize it and since we are working in a probabilistic setting: we can compute the posterior \\(p(z_k=1|\\textbf{x})\\) which we know we can get it with Bayes rule.\n\n\\(p(z_k=1|\\textbf{x})\\) I have a observation x and we want to know to which class \\(z\\) it belongs. But this will give a opacity meaning its not totally certain\n\n\nRecall our goal is to get: \\(p(z_k=1|\\textbf{x})\\). Also recall that in k-means we have a hard assignment of labels. in this case because we are using probabilities then we will end up with soft assignment which means that we will have i.e. one point as green color but also a bit transparent with a red color.\n\n\n23.1 The Posterior\n\n\n\n\n\n\n23.2 The Log-likelihood\n\nThe likelihood can be optimized i,e by taking the log and then derivative with respect to its parameters \\(\\mu_k\\), \\(\\Sigma_k\\)\n\nWait a min, but when you replace the gaussian (which is how we assume to model the data) then because of the sumation over \\(\\pi_k\\) things get matematically and analitically complicated and then we need to resort in another optimization rather just taking the derivative and set it to zero. Thus Expecation Maximization comes into play\nCrucial bit why we are taking the log-likelihood as \\(p(\\text{x})\\). See this below:\n\n\n\n\n\nThat is why we compute:"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#expectation-maximization-algorithm-em",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#expectation-maximization-algorithm-em",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "24 Expectation-Maximization algorithm (EM)",
    "text": "24 Expectation-Maximization algorithm (EM)\n\nHere we assume the posteriors \\(\\gamma(z_k)\\) do not depend on the parameters\n\nHow to get to teh answers for the parameters?\n\nWith the values for the parameters anc compute the expected posterior\nMaximize for parameters\n\nThe cycle repeats"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#example-gmm",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#example-gmm",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "25 Example: GMM",
    "text": "25 Example: GMM\n\nHere the optimization of the likelihood is called Maximization\n\n\n\n\n\nIn K-means I only updated the cluster centers whereas here I update all the parameters \\(\\pi_k\\), \\(\\mu_k\\), \\(\\Sigma_k\\)"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#derivations-for-em-algorithm",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#derivations-for-em-algorithm",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "26 Derivations for EM algorithm",
    "text": "26 Derivations for EM algorithm\n\nRefer to slides"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#the-mouse-data-again",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#the-mouse-data-again",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "27 The mouse data again",
    "text": "27 The mouse data again\n\n\n\n\nDifferences between K-Means and GMM: - K-means can only custer groups of the same size, so same distances from each mean cluster - GMM can compensate for this"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#how-do-we-assign-points-to-cluster",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#how-do-we-assign-points-to-cluster",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "28 How do we assign points to cluster?",
    "text": "28 How do we assign points to cluster?"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#final-remarks",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#final-remarks",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "29 Final remarks",
    "text": "29 Final remarks\n\n\n\n\n\nWe need more initializations in GMM because of different parameters so the trick its to do it with k-means\nSame as k-means we cannot expect to find the best solution so the global minimum for the parameters because the problem its not convex. That means the final solution depends on how you initializes the model parameters\nThe last point refers that GMM is for unsupervised learning so you compute things with the latent variable whereas in QDA its for supervised learning."
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#faq",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html#faq",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "30 FAQ",
    "text": "30 FAQ\n\n\n\n\n\n\nWhat is Latent variable?\n\n\n\n\n\nA latent variable is a variable that is not directly observed but is inferred or estimated from other observed variables\nFor example, in psychology, intelligence is a latent variable because it cannot be directly measured. Instead, researchers use various observable indicators, such as IQ test scores, academic performance, and problem-solving abilities, to infer a person’s level of intelligence.\nLatent class analysis (LCA) is a statistical technique used to identify unobservable or latent classes or groups within a population based on patterns of responses to a set of observed categorical variables\nWhat do we use Latent variables for?\nThe primary role of the latent variables is to allow a complicated distribution over the observed variables to be represented in terms of a model constructed from simpler (typically exponential family) conditional distributions.\n\n\n\n\n\n\n\n\n\nCategorical Distribution AND Generalized Bernoulli Distribution:\n\n\n\n\n\nThe categorical distribution describes the probability distribution of a discrete random variable with \\(K\\) possible outcomes or categories. The probability mass function (PMF) of the categorical distribution is given by:\n\\[\nP(X = x_i) = p_i, \\quad \\text{for } i = 1, 2, \\ldots, K\n\\]\nwhere \\(p_i\\) is the probability of outcome \\(x_i\\), and \\(\\sum_{i=1}^{K} p_i = 1\\).\nGeneralized Bernoulli Distribution: The generalized Bernoulli distribution is a distribution for a binary random variable that can take on values 0 or 1 with different probabilities. The PMF of the generalized Bernoulli distribution is given by:\n\\[\nP(X = x) = \\theta^x (1 - \\theta)^{1 - x}, \\quad \\text{for } x = 0, 1\n\\]\nwhere \\(\\theta\\) is the probability of \\(X = 1\\), and \\((1 - \\theta)\\) is the probability of \\(X = 0\\). This distribution is sometimes used when modeling binary data with different success probabilities."
  },
  {
    "objectID": "blog/2023-11-05_script-to-extract-pages-of-pdf-as-images-and-crop-them/index.html",
    "href": "blog/2023-11-05_script-to-extract-pages-of-pdf-as-images-and-crop-them/index.html",
    "title": "Script to extract pages of PDF as images & apply crop",
    "section": "",
    "text": "Description of this Notebook\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          November 5, 2023\n        \n      \n      \n        \n      \n      \n\n    \n        Quick Links\n    \n         Quick Links:\n                                    \n                 Code"
  },
  {
    "objectID": "blog/2023-11-05_script-to-extract-pages-of-pdf-as-images-and-crop-them/index.html#goal",
    "href": "blog/2023-11-05_script-to-extract-pages-of-pdf-as-images-and-crop-them/index.html#goal",
    "title": "Script to extract pages of PDF as images & apply crop",
    "section": "Goal",
    "text": "Goal\nImagine you want to extract pages from a PDF as images and then you want to crop them to an specific size. The following scrip does exactly that\npip install Pillow\npip install pdf2image\nbrew install poppler\n\nfrom pdf2image import convert_from_path\nfrom PIL import Image\nimport os\n\n# Function to crop an image to specific dimensions\ndef crop_image(input_path, output_path, left, top, right, bottom):\n    image = Image.open(input_path)\n    cropped_image = image.crop((left, top, right, bottom))\n    cropped_image.save(output_path)\n\n# Function to extract all pages from a PDF and crop them as images\ndef extract_and_crop_pdf(pdf_path, output_dir, width, crop_up, crop_down):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    images = convert_from_path(pdf_path)\n\n    for page_number, pdf_image in enumerate(images):\n        output_path = os.path.join(output_dir, f'page_{page_number + 1}.png')\n\n        # Calculate the crop coordinates\n        left = (pdf_image.width - width) // 2\n        top = crop_up\n        right = left + width\n        bottom = pdf_image.height - crop_down\n\n        # Save the image as a temporary file\n        temp_image_path = os.path.join(output_dir, f'temp_page_{page_number + 1}.png')\n        pdf_image.save(temp_image_path)\n\n        # Crop the temporary image and save the final cropped image\n        crop_image(temp_image_path, output_path, left, top, right, bottom)\n\n        # Clean up the temporary image\n        os.remove(temp_image_path)\n\nif __name__ == '__main__':\n    input_pdf = 'input.pdf'  # Specify the input PDF file\n    output_directory = 'output_images'  # Specify the output folder\n    crop_up = 177  # Change this to your desired crop for height up\n    crop_down = 118  # Change this to your desired crop for height down\n    target_width = 2667  # Change this to your desired width\n\n    extract_and_crop_pdf(input_pdf, output_directory, target_width, crop_up, crop_down)"
  },
  {
    "objectID": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html",
    "href": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html",
    "title": "Automating the creation of Blog posts",
    "section": "",
    "text": "A Python solution to create blog posts from the command line\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Extension\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Quarto\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Extension\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Quarto\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 21, 2023\n        \n      \n      \n        \n      \n      \n\n    \n        Quick Links\n    \n         Quick Links:\n                                    \n                 Code\n                        \n                                    \n                 Repository\nVideo"
  },
  {
    "objectID": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html#motivation",
    "href": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html#motivation",
    "title": "Automating the creation of Blog posts",
    "section": "1 Motivation",
    "text": "1 Motivation\nWhen putting together a blog post, there are several steps that are time consuming. For instance, creating a directory with the date for the slug, then a title name and followed a YAML header that suits the format of the article. All this can be time consuming and hence in this post I will show how I have automated the creation of template posts to write code right away rather that setting this up\n\nGoal: from a simple command line i.e. mkblog notebook 'How to rock' a folder with the current date and the title-name i.e. 2023-08-21_how-to-rock will be created. Then the script should copy a pre-build post model that will modify the header’s date, title, href (for downloable Jupyter Notebooks) i.e:\n\ntitle: \"How to create Dynamic plots\"\ndate: \"2023-08-21\""
  },
  {
    "objectID": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html#creating-the-script",
    "href": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html#creating-the-script",
    "title": "Automating the creation of Blog posts",
    "section": "2 Creating the script",
    "text": "2 Creating the script\nThe first thing that came to my mind when creating the script was to the type of post. On a general level I have classify them in three categories\n\npost: this is a normal qmd file that can hold articles and is capable to run R, Python, JavaScript and so on.\npoems: this is a qmd modified version that enables the formatting that you see in my poems.\nnotebook: this is a ipynb file that can be executed using my conda environments\n\nThe question is now how to set all this up. Reviewing at scripting languages and ways on how to create extension for html files I realised all this could be done with python.\nHere down below the script that makes all this possible\n\n2.1 Make a Directory\n\n\ncreate_dir.py\n\n\nimport os \nimport sys\nfrom datetime import datetime\nimport shutil\n\ndef create_post(type_file, post_name):\n\n    # Save a copy only name\n    raw_post_name = post_name\n\n    # Example: \"how-to-rock\"\n    post_name = post_name.lower().replace(\" \", \"-\")\n\n    # Current Date: \"2023-08-21\"\n    current_date = datetime.today().strftime('%Y-%m-%d')\n\n    # Folder name: \"2023-08-21_how-to-rock\"\n    folder_name = current_date + '_' + post_name\n\n    # Current Directory path\n    current_dir = os.getcwd()\n    \n    # Output Directory\n    output_path = current_dir + \"/out\"\n\n    # Folder Path: \"../out/2023-08-21_how-to-rock\"\n    path_folder = os.path.join(output_path, folder_name)\n\n    # Make a Directory\n    os.mkdir(path_folder)\n    print(\"Directory '% s' created!\" % folder_name)\n\n# Name of Post\n# 0 is the name of the py file\n# 1 is the first argument\n\ntype_file = \"notebook\" # sys.argv[1]\npost_name = \"how to rock\" # sys.argv[2]             \n\ncreate_post(type_file, post_name)\n\nDirectory '2023-08-21_how-to-rock' created!\n\n\n\n\n2.2 Copy, move & edit a Blog’s Template\nAfter we have created a folder, we can proceed to make a copy of a user-defined template with settings that we may want to use for that specific type of post. For instance for my notebook posts I want to modify the date of the header, its title name and the ref link to download the output of the Jupyter notebook.\nFor this to scale and be able to fire the script from any directory I will point to a specific folder where I will make all this changes and then move those modified files to my ../blog section.\nThe structure of my files where the script is stored is as follows:\n\n\nTerminal\n\n_extensions\n└── mkpost\n    ├── create_dir.py\n    ├── out\n    ├── splitWin.app\n    └── templates\n        ├── notebook\n        │   └── index.ipynb\n        ├── poems\n        │   └── index.qmd\n        └── post\n            └── index.qmd\n\n\n\n\n\n\n\nNote\n\n\n\nTo print the tree structure you see above I have used: brew install tree and then tree &lt;path&gt;\n\n\nIn the folder view you find mkpost as the folder that holds the script previously shown. There is also out folder which contains the folder just created 2023-08-21_how-to-rock. There is also splitWin.app which will talk in section  and lastly a folder called templates where you can see index.* files that will be copied to our newly created folder.\nFollowing the continuation of the python script that does all the moving, copying and editing.\n\n\ncreate_dir.py\n\n\ndef create_file(type_file):\n    # -------------- CREATE FILE --------------\n    # Holds available extensions\n    dic = {'post': 'qmd', 'poems':'qmd', 'notebook':'ipynb'}\n    file_extension = dic[type_file]\n    \n    # Source path: \"../template/file_type/index.ext\"\n    source_file = f\"templates/{type_file}/index.{file_extension}\"\n    \n    # File name \"index.ext\"\n    file_name = f\"index.{file_extension}\"\n\n    # Destination path: \"../out/2023-08-21_how-to-rock/index.ext\"\n    destination_file = os.path.join(path_folder, file_name)\n\n    # Creating a Copy from Template folder\n    shutil.copy(source_file, destination_file)\n\n    # -------------- UPDATE HEADER --------------\n    lines = open(destination_file, 'r').readlines()\n    \n    if (type_file == \"notebook\"):\n        title_row = 9\n        lines[title_row] = f'    \\\"title: \\\\\"{raw_post_name.capitalize()}\\\\\"\\\\n\\\",'\n\n        date_row = 11\n        lines[date_row] = f'    \\\"date: \\\\\"{current_date}\\\\\"\\\\n\\\",'\n\n        code_name_row = 16\n        post_code_name = post_name + '.out.ipynb'\n        lines[code_name_row] = f'    \\\"      file-name: {post_code_name}\\\\n\\\",'\n\n    else:\n        title_row = 1\n        lines[title_row] = f'title: \"{raw_post_name.capitalize()}\"\\n'\n\n        date_row = 3\n        lines[date_row] = f'date: \"{current_date}\"\\n'\n\n    file = open(destination_file, 'w')\n    file.writelines(lines)\n    file.close()\n    \n    # -------------- MOVE FILE --------------\n    # Folder Path: \"../out/2023-08-21_how-to-rock\"\n    src = path_folder\n\n    # Path to Blog\n    dst = \"../../blog\"\n    shutil.move(src, dst)       \n    \n\nif (type_file == \"post\"):\n    create_file(\"post\")\nelif (type_file == \"notebook\"):\n    create_file(\"notebook\")\nelif (type_file == \"poems\"):\n    create_file(\"poems\")\nelse:\n    print(f\"Wrong type_file: {type_file}. Available: 'post', 'poems' or 'notebook'\")\n    sys.exit()\n    \n\nThe code above does the following:\n\nWhen the user inputs the name and the type_file it looks at the template folder with the specified extension and does the copying\nUpdates the header changing date to the current date at the moment of creating the directory, title with the name we input in the terminal and, lastly if is a notebook it changes the href to enable the user download the notebook.\nOnce all changes are done, the folder with the index.* file are move to the blog section."
  },
  {
    "objectID": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html#fire-it-up-from-terminal",
    "href": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html#fire-it-up-from-terminal",
    "title": "Automating the creation of Blog posts",
    "section": "3 Fire it up from terminal",
    "text": "3 Fire it up from terminal\nFor convenience, no matter in which directory of your computer you are in, this section cover how to fire it up the script that we have created. For starters, if you are running macOS or Linux most likely you will be using bash, zsh or fish shells. These shells, as it comes to not surprise, can launch scripts with user-defined strings defined.\nFor my liking I have decided to proceed with:\n\n\nTerminal\n\nmkblog [type_file] [\"name_post\"]\n\nTo enable this, you have to cd to your .bash_profile or .zshrc in my case. Then we will define the alias mkblog and will do the following:\n\ncd to the path where we have stored our python script. That is _extensions\nExecute the script using python\nOpen my workspace in Visual Studio\nOpen the index.* we just created i.e. in the dir \"2023-08-21_how-to-rock\"\nMake quarto render that file. Voila start coding!\n\n\n\n.zshrc\n\n# Creates script to open blog post\nmkblog() {\n  cd ../path/more_path/_extensions/mkpost\n  python create_dir.py $1 $2\n  cd ..\n  cd ..\n  code website.code-workspace\n  BACKUPDIR=$(ls -td blog/*/ | head -1)\n  cd $BACKUPDIR\n  FILENAME=$(ls | sort -f)\n  code $FILENAME\n  quarto preview $FILENAME \n}"
  },
  {
    "objectID": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html#bonus---create-an-script-to-split-views",
    "href": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html#bonus---create-an-script-to-split-views",
    "title": "Automating the creation of Blog posts",
    "section": "Bonus - Create an script to split views",
    "text": "Bonus - Create an script to split views\n\nWhen working with large screen I would like to place in the left side the file I created and in the right side my browser to preview the changes I made while editing my file. If you are familiar with AppleScript then you will be at home with the following lines.\n\n\nsplitWin.app\n\nactivate application \"Visual Studio Code\"\nrepeat 1 times\n    tell application \"System Events\" to key code 123 using {command down}\nend repeat\n\nactivate application \"Microsoft Edge\"\nrepeat 1 times\n    tell application \"System Events\" to key code 124 using {command down}\nend repeat\n\nLong story short, the script will send the keystrokes cmd + ←, cmd + → to each application and thus split the windows to left and right. How to accomplished this behavior? Glad you asked, I invite your to read this post where I go through how I made my life easier using Lua Shortcuts."
  },
  {
    "objectID": "blog/2023-09-24_color-rosa/index.html",
    "href": "blog/2023-09-24_color-rosa/index.html",
    "title": "Una rosa color morada",
    "section": "",
    "text": "Una rosa color morada\n        \n        \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Poems\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Spanish\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Poems\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Spanish\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 24, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\nby Danilo Toapanta \n\nBlog  &gt; Poems\n\n\nVida mia te escribo esta carta\nno una, ni dos, las veces que sea\nporque el de querer querer\nya no es color rosa morado\npero azul-amarillo\naveces rojo apaciguado.\n\nEs por eso vida mia,\ntemo que el color rosado\nte parezca morado\ncuando caiga la noche\ny no estes a mi lado.\n\nTe miro de reojo\ntu piensas infinito\nno palpitas ni titubeas\nestas firme como el hierro.\n\nPero asi tan altiva,\ndelicada es tu otra esquina\nEn la noche aqui te respondo,\ny con certeza a mi lado\ntus manos encuentran las mias\n\nLa noche fria afuera palpita\nel viento resumba la ventana\ntu soñando profundo y yo aqui\nescribiendo porque el rosado\nya no es morado."
  },
  {
    "objectID": "blog/2023-11-02_language-modelling/index.html",
    "href": "blog/2023-11-02_language-modelling/index.html",
    "title": "Language modelling",
    "section": "",
    "text": "Description of this Post\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                NLP\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                NLP\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          November 2, 2023"
  },
  {
    "objectID": "blog/2023-11-02_language-modelling/index.html#example-of-categorical-distribution",
    "href": "blog/2023-11-02_language-modelling/index.html#example-of-categorical-distribution",
    "title": "Language modelling",
    "section": "1 Example of Categorical Distribution",
    "text": "1 Example of Categorical Distribution\n\nVocabulary:\nV=3, {dog, cat,bird}\nNum Observations:\nN=9\nCategories:\nC=3, {negative, neutral, positive}\nDataset:\nD={(class1, word1)…}\n\n\n1.1 Formula for parameter estimation\n\n\n\n\n\n\n\n\nHere the denominator means to count all pairs that have the same class\n\nTabular Representation:\n\n\\[\nW|C=c \\, \\textasciitilde \\, \\text{ Categorical}(\\theta_{1:V}^{(c)})\n\\]\n\n\n\n\n\nThe dataset:\n\n\n\n\nMaximum Likelihood Estimates:"
  },
  {
    "objectID": "blog/2023-11-02_language-modelling/index.html#smoothing",
    "href": "blog/2023-11-02_language-modelling/index.html#smoothing",
    "title": "Language modelling",
    "section": "2 Smoothing",
    "text": "2 Smoothing\n\n\n\n\nFor instance if I have to compute the prob for \\(\\theta_{bird}^{neg}=\\frac{0}{3}\\) then because I will have a zero probability then I can use only the count plus some constant (smoothing)so that the probability estimate does not become \\(0\\)\nFor instance:\n\n\n\n\nHere 0.1 is the smoothing constant\n\nSo if not smoothing then use probs, if use smoothing the we use the counts\n\n\n\n\n\nSlide 1\n\n\n\n\n\n\n\n\nSlide 2\n\n\n\n\n\n\n\n\nSlide 3\n\n\n\n\n\n\n\n\nSlide 4\n\n\n\n\n\n\n\n\nSlide 5\n\n\n\n\n\n\n\n\nSlide 6\n\n\n\n\n\n\n\n\nSlide 7\n\n\n\n\n\n\n\n\nSlide 8\n\n\n\n\n\n\n\n\nSlide 9\n\n\n\n\n\n\n\n\nSlide 10\n\n\n\n\n\n\n\n\nSlide 11\n\n\n\n\n\n\n\n\nSlide 12\n\n\n\n\n\n\n\n\nSlide 13\n\n\n\n\n\n\n\n\nSlide 14\n\n\n\n\n\n\n\n\nSlide 15\n\n\n\n\n\n\n\n\nSlide 16\n\n\n\n\n\n\n\n\nSlide 17\n\n\n\n\n\n\n\n\nSlide 18\n\n\n\n\n\n\n\n\nSlide 19\n\n\n\n\n\n\n\n\nSlide 20\n\n\n\n\n\n\n\n\nSlide 21\n\n\n\n\n\n\n\n\nSlide 22\n\n\n\n\n\n\n\n\nSlide 23\n\n\n\n\n\n\n\n\nSlide 24\n\n\n\n\n\n\n\n\nSlide 25\n\n\n\n\n\n\n\n\nSlide 26\n\n\n\n\n\n\n\n\nSlide 27\n\n\n\n\n\n\n\n\nSlide 28\n\n\n\n\n\n\n\n\nSlide 29\n\n\n\n\n\n\n\n\nSlide 30\n\n\n\n\n\n\n\n\nSlide 31\n\n\n\n\n\n\n\n\nSlide 32\n\n\n\n\n\n\n\n\nSlide 33\n\n\n\n\n\n\n\n\nSlide 34\n\n\n\n\n\n\n\n\nSlide 35\n\n\n\n\n\n\n\n\nSlide 36\n\n\n\n\n\n\n\n\nSlide 37\n\n\n\n\n\n\n\n\nSlide 38\n\n\n\n\n\n\n\n\nSlide 39\n\n\n\n\n\n\n\n\nSlide 40\n\n\n\n\n\n\n\n\nSlide 41\n\n\n\n\n\n\n\n\nSlide 42\n\n\n\n\n\n\n\n\nSlide 43\n\n\n\n\n\n\n\n\nSlide 44\n\n\n\n\n\n\n\n\nSlide 45\n\n\n\n\n\n\n\n\nSlide 46\n\n\n\n\n\n\n\n\nSlide 47\n\n\n\n\n\n\n\n\nSlide 48\n\n\n\n\n\n\n\n\nSlide 49\n\n\n\n\n\n\n\n\nSlide 50\n\n\n\n\n\n\n\n\nSlide 51\n\n\n\n\n\n\n\n\nSlide 52\n\n\n\n\n\n\n\n\nSlide 53\n\n\n\n\n\n\n\n\nSlide 54\n\n\n\n\n\n\n\n\nSlide 55\n\n\n\n\n\n\n\n\nSlide 56\n\n\n\n\n\n\n\n\nSlide 57\n\n\n\n\n\n\n\n\nSlide 58\n\n\n\n\n\n\n\n\nSlide 59\n\n\n\n\n\n\n\n\nSlide 60\n\n\n\n\n\n\n\n\nSlide 61\n\n\n\n\n\n\n\n\nSlide 62\n\n\n\n\n\n\n\n\nSlide 63\n\n\n\n\n\n\n\n\nSlide 64\n\n\n\n\n\n\n\n\nSlide 65\n\n\n\n\n\n\n\n\nSlide 66\n\n\n\n\n\n\n\n\nSlide 67\n\n\n\n\n\n\n\n\nSlide 68\n\n\n\n\n\n\n\n\nSlide 69\n\n\n\n\n\n\n\n\nSlide 70\n\n\n\n\n\n\n\n\nSlide 71\n\n\n\n\n\n\n\n\nSlide 72\n\n\n\n\n\n\n\n\nSlide 73\n\n\n\n\n\n\n\n\nSlide 74\n\n\n\n\n\n\n\n\nSlide 75\n\n\n\n\n\n\n\n\nSlide 76"
  },
  {
    "objectID": "sites/index.html",
    "href": "sites/index.html",
    "title": "My Sites",
    "section": "",
    "text": "My Sites\n\n\n\n\n\n\nMain section where I keep track of important news about my professional carrier.\n\n\nHOME\n\n\n\n\n\n\n\n\nAbout me, my interests and experience, and my work as a AI Research Engineer.\n\n\nABOUT\n\n\n\n\n\n\n\n\nI sometimes write about what I’m doing and learning, mostly about CS and building websites.\n\n\nBLOG\n\n\n\n\n\n\n\n\nI have worked on big-scale projects. Here are links to their repos, websites and any other resources.\n\n\nPROJECTS\n\n\n\n\n\n\n\n\nSlides and resources from talks I’ve given for educational purposes or conferences.\n\n\nSLIDES\n\n\n\n\n\n\n\n\n\nWhat I have read and I am reading at the moment. Recomendations? I’d love to hear from you!\n\n\nBOOKS"
  },
  {
    "objectID": "notes/2023-09-03_create-website-using-local/index.html",
    "href": "notes/2023-09-03_create-website-using-local/index.html",
    "title": "Create Website using Local",
    "section": "",
    "text": "Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 3, 2023"
  },
  {
    "objectID": "notes/2023-09-03_create-website-using-local/index.html#setting-up-the-terminal",
    "href": "notes/2023-09-03_create-website-using-local/index.html#setting-up-the-terminal",
    "title": "Create Website using Local",
    "section": "1 Setting up the Terminal",
    "text": "1 Setting up the Terminal\nFirst you need to have an idea to control the terminal. Look at the following link\n\nEnvironments\n\n\nCreate an environment called web with python\nconda create -n web python=3.7\nTo activate the new environment\nconda activate web\nTo move terminal to website folder in Desktop:\ncd /Users/datoapanta/Desktop/website"
  },
  {
    "objectID": "notes/2023-09-03_create-website-using-local/index.html#setting-up-next.js",
    "href": "notes/2023-09-03_create-website-using-local/index.html#setting-up-next.js",
    "title": "Create Website using Local",
    "section": "2 Setting up Next.js",
    "text": "2 Setting up Next.js\n\nInstallation Guide\n\nTo kills a port\nnpx kill-port 3000"
  },
  {
    "objectID": "notes/2023-10-09_numpy-arrays/index.html",
    "href": "notes/2023-10-09_numpy-arrays/index.html",
    "title": "Numpy Arrays",
    "section": "",
    "text": "Numpy Arrays\n        \n        \n                    \n                \n                    Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          October 9, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\n# To create 1D array (5,) aka list\narray = [1, 2, 3]\n\n# To create 2D array (5,1)\narray = [[9],[9],[9],[9],[9]]\n\n# To create 2D array (1,5)\narray = [[9, 9, 9, 9, 9]]\n\n\nCode\nimport numpy as np\narray_2d = np.array([[9, 9, 9, 9, 9]])\narray_1d = np.array([1,1,1,1,1])\nprint(array_2d + array_1d)\nprint((array_2d+array_1d).shape)\n\n\n[[10 10 10 10 10]]\n(1, 5)\n\n\n\n2D-array of (1,5) \\(+\\) 1D-array aka list of (5,):\n\n2D-array of (1,5)\n\n\n\n\nCode\nimport numpy as np\narray_2d = np.array([[1], [2], [3], [4], [5]])\n\n# Create a 1D array of shape (5,)\narray_1d = np.array([10, 20, 30, 40, 50])\n\n# Add the 2D array and 1D array\nresult = array_2d + array_1d\n\nprint(result)\nprint(result.shape)\n\n\n[[11 21 31 41 51]\n [12 22 32 42 52]\n [13 23 33 43 53]\n [14 24 34 44 54]\n [15 25 35 45 55]]\n(5, 5)\n\n\n\n2D-array of (5,1) \\(+\\) 1D-array aka list of (5,):\n\n2D-array of (5,5) this is due to broadcasting see fig below"
  },
  {
    "objectID": "notes/2023-08-27_changes-to-vanilla-quarto/index.html",
    "href": "notes/2023-08-27_changes-to-vanilla-quarto/index.html",
    "title": "Changes to Vanilla Quarto",
    "section": "",
    "text": "Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 27, 2023"
  },
  {
    "objectID": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#find-styles-code-highlighting",
    "href": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#find-styles-code-highlighting",
    "title": "Changes to Vanilla Quarto",
    "section": "1 Find Styles Code Highlighting",
    "text": "1 Find Styles Code Highlighting\n\nPandoc highlight styles: /Applications/quarto/share/pandoc/highlight-styles"
  },
  {
    "objectID": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#changes-the-moon-icon",
    "href": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#changes-the-moon-icon",
    "title": "Changes to Vanilla Quarto",
    "section": "2 Changes the moon icon",
    "text": "2 Changes the moon icon\n\nChange toggle-icons: /Applications/quarto/share/formats/html/bootstrap/\\_bootstrap-rules.scss\n/Users/datoapanta/Desktop/danilotpnta.github.io/docs/site_libs/bootstrap/bootstrap-dark.min.css\nI change the SVG from this site: https://icons.getbootstrap.com/icons/moon/\n\n\n\nCopy this\n\n// .navbar .quarto-color-scheme-toggle:not(.alternate) .bi::before {\n//   background-image: url('data:image/svg+xml,&lt;svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" fill=\"#{colorToRGBA($navbar-light-color)}\" class=\"bi bi-toggle-off\" viewBox=\"0 0 16 16\"&gt;&lt;path d=\"M11 4a4 4 0 0 1 0 8H8a4.992 4.992 0 0 0 2-4 4.992 4.992 0 0 0-2-4h3zm-6 8a4 4 0 1 1 0-8 4 4 0 0 1 0 8zM0 8a5 5 0 0 0 5 5h6a5 5 0 0 0 0-10H5a5 5 0 0 0-5 5z\"/&gt;&lt;/svg&gt;');\n// }\n\n// Toggle MOON\n.navbar .quarto-color-scheme-toggle:not(.alternate) .bi::before {\n  background-image: url('data:image/svg+xml,&lt;svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" fill=\"#{colorToRGBA($navbar-light-color)}\" class=\"bi bi-toggle-off\" viewBox=\"0 0 16 16\"&gt;&lt;path d=\"M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278zM4.858 1.311A7.269 7.269 0 0 0 1.025 7.71c0 4.02 3.279 7.276 7.319 7.276a7.316 7.316 0 0 0 5.205-2.162c-.337.042-.68.063-1.029.063-4.61 0-8.343-3.714-8.343-8.29 0-1.167.242-2.278.681-3.286z\"/&gt;&lt;/svg&gt;');\n}\n\n// Toggle MOON filled\n// .navbar .quarto-color-scheme-toggle.alternate .bi::before {\n//   background-image: url('data:image/svg+xml,&lt;svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" fill=\"#{colorToRGBA($navbar-light-color)}\" class=\"bi bi-toggle-on\" viewBox=\"0 0 16 16\"&gt;&lt;path d=\"M5 3a5 5 0 0 0 0 10h6a5 5 0 0 0 0-10H5zm6 9a4 4 0 1 1 0-8 4 4 0 0 1 0 8z\"/&gt;&lt;/svg&gt;');\n// }\n\n.navbar .quarto-color-scheme-toggle.alternate .bi::before {\n  background-image: url('data:image/svg+xml,&lt;svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" fill=\"#{colorToRGBA($navbar-light-color)}\" class=\"bi bi-toggle-on\" viewBox=\"0 0 16 16\"&gt;&lt;path d=\"M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z\"/&gt;&lt;/svg&gt;');\n}"
  },
  {
    "objectID": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#changes-title-of-categories-to-all-categories",
    "href": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#changes-title-of-categories-to-all-categories",
    "title": "Changes to Vanilla Quarto",
    "section": "3 Changes title of “Categories” to “All Categories”",
    "text": "3 Changes title of “Categories” to “All Categories”\n\n/Applications/quarto/bin/quarto.js\n\nCopy this:\n// headingEl.innerText = localizedString(format, kListingPageFieldCategories);\nheadingEl.innerText = \"All Categories\";"
  },
  {
    "objectID": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#remove-the-all-from-categories-sidebar",
    "href": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#remove-the-all-from-categories-sidebar",
    "title": "Changes to Vanilla Quarto",
    "section": "4 Remove the “All” from “Categories” Sidebar",
    "text": "4 Remove the “All” from “Categories” Sidebar\n\n/Applications/quarto/bin/quarto.js\n\nCopy this:\nconst allCategory = localizedString(format, kListingPageCategoryAll);\n// const allEl = categoryElement(doc, allCategory, formatFn(allCategory, totalCategories), \"\");"
  },
  {
    "objectID": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#adds-extra-feature-to-the-headeroffset-function",
    "href": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#adds-extra-feature-to-the-headeroffset-function",
    "title": "Changes to Vanilla Quarto",
    "section": "5 Adds extra feature to the headerOffset function",
    "text": "5 Adds extra feature to the headerOffset function\n\nIf the header is absolute then the header.height will be zero to fix the TOC\n/Applications/quarto/share/projects/website/navigation/quarto-nav.js\n\n\n\nCopy this\n\n// function headerOffset() {\n//   // Set an offset if there is are fixed top navbar\n//   const headerEl = window.document.querySelector(\"header.fixed-top\");\n//   if (headerEl) {\n//     return headerEl.clientHeight;\n//   } else {\n//     return 0;\n//   }\n// }\n\nfunction headerOffset() {\n  // Set an offset if there is are fixed top navbar\n  const headerEl = window.document.querySelector(\"header.fixed-top\");\n  if (headerEl) {\n    // If the page is a blog post then return the height as 0\n    const blogSection = window.document.querySelector(\"header.blog-page\");\n    if (blogSection) {\n      // Add extra padding to display well the navbar\n      document.getElementById(\n        \"quarto-content\"\n      ).style.paddingTop = `${headerEl.clientHeight}px`;\n      // returns 0 to fix the TOC where it displays the section\n      return 0;\n    } else {\n      return headerEl.clientHeight;\n    }\n  } else {\n    return 0;\n  }\n}"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html",
    "title": "Features, tools & improvements website",
    "section": "",
    "text": "Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 27, 2023"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#change-directories",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#change-directories",
    "title": "Features, tools & improvements website",
    "section": "1 Change directories:",
    "text": "1 Change directories:\n_quarto.yml http://localhost:4200/dev/ include_footer.js: http://localhost:4200/links.js"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#include-a-page-on-how-to-use-the-command-line",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#include-a-page-on-how-to-use-the-command-line",
    "title": "Features, tools & improvements website",
    "section": "2 Include a page on how to use the command line:",
    "text": "2 Include a page on how to use the command line:\nhttps://www.taniarascia.com/how-to-use-the-command-line-for-apple-macos-and-linux/"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#read-how-to-use-node.js",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#read-how-to-use-node.js",
    "title": "Features, tools & improvements website",
    "section": "3 Read how to use Node.js:",
    "text": "3 Read how to use Node.js:\nhttps://www.taniarascia.com/how-to-install-and-use-node-js-and-npm-mac-and-windows/"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#firebase-real-time-database-for-my-static-website",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#firebase-real-time-database-for-my-static-website",
    "title": "Features, tools & improvements website",
    "section": "4 FIREBASE REAL TIME DATABASE FOR MY STATIC WEBSITE",
    "text": "4 FIREBASE REAL TIME DATABASE FOR MY STATIC WEBSITE\nhttps://xyzcoder.github.io/firebase/2019/03/17/firebase-real-time-database.html https://stackoverflow.com/questions/46574537/how-to-set-up-cloud-firestore-for-static-hosted-website https://maxbarry.medium.com/how-i-used-google-drive-and-firebase-to-give-my-static-site-a-cms-7226e01a51b5\n[To create a like button]- https://mazipan.space/en/create-simple-like-button-using-firebase-rtdb"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#copy-the-about-page-of",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#copy-the-about-page-of",
    "title": "Features, tools & improvements website",
    "section": "5 Copy the about page of:",
    "text": "5 Copy the about page of:\nhttps://beamilz.com/about.html"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#copy-his-cv",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#copy-his-cv",
    "title": "Features, tools & improvements website",
    "section": "6 Copy his CV:",
    "text": "6 Copy his CV:\nhttps://slama.dev/cv.pdf"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#review-the-subscribe-letter",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#review-the-subscribe-letter",
    "title": "Features, tools & improvements website",
    "section": "7 Review the Subscribe letter:",
    "text": "7 Review the Subscribe letter:\nhttps://taniarascia.substack.com/archive"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#html-js-css-container",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#html-js-css-container",
    "title": "Features, tools & improvements website",
    "section": "8 HTML, JS, CSS container",
    "text": "8 HTML, JS, CSS container\nhttps://jsbin.com/zusihologo/edit?html,css,output"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#select-sizes",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#select-sizes",
    "title": "Features, tools & improvements website",
    "section": "9 Select sizes:",
    "text": "9 Select sizes:\nhttps://jsbin.com/zusihologo/edit?html,css,"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#this-is-how-you-create-small-slides",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#this-is-how-you-create-small-slides",
    "title": "Features, tools & improvements website",
    "section": "10 This is how you create small slides:",
    "text": "10 This is how you create small slides:\nSLIDES FORMAT: RMD!!! https://github.com/djnavarro/slides-arrow-latinr-2022/blob/main/index.qmd\n\nSlides: https://slides.com/danilotoapanta\nCheck Codebox Sandbox and also embeeding html with Stackbitz\n\n\n\n\nLook into Google SEO to make page appear\nI like this blog: https://blog.meain.io/2023/releasing-scopeline-el/\nfix the content bar make it like her: https://ellakaye.co.uk/"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#javacript-to-counter",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#javacript-to-counter",
    "title": "Features, tools & improvements website",
    "section": "11 Javacript to counter:",
    "text": "11 Javacript to counter:\n/Users/datoapanta/Desktop/garrickadenbuie-com/_quarto.yml\nhttps://counter.dev/dashboard.html?demo=1\n– Fix the monospace"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#make-related-posts-like-this",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#make-related-posts-like-this",
    "title": "Features, tools & improvements website",
    "section": "12 Make related posts like this:",
    "text": "12 Make related posts like this:\n\nhttps://mattorb.com/swift-conciseness-and-trade-offs/\nhttps://github.blog/2023-08-04-a-checklist-and-guide-to-get-your-repository-collaboration-ready/#:~:text=about%20other%C2%A0plans%3F-,Related%20posts,-Engineering"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#add-tree-boxes-projects",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#add-tree-boxes-projects",
    "title": "Features, tools & improvements website",
    "section": "13 Add tree boxes projects:",
    "text": "13 Add tree boxes projects:\n\nViews\nTotal Projects\nMost clicked category"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#install-analytics",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#install-analytics",
    "title": "Features, tools & improvements website",
    "section": "14 Install Analytics:",
    "text": "14 Install Analytics:\n\nhttps://stats.arp242.net/?hl-period=year&period-start=2022-08-08&period-end=2023-08-08&filter=&daily=off"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#create-this-website",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#create-this-website",
    "title": "Features, tools & improvements website",
    "section": "15 Create this website",
    "text": "15 Create this website\nhttps://note.nkmk.me/en/python-os-mkdir-makedirs/"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#make-use-of-jupyter-widgets",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#make-use-of-jupyter-widgets",
    "title": "Features, tools & improvements website",
    "section": "16 Make use of jupyter widgets",
    "text": "16 Make use of jupyter widgets"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#copy-this-for-the-button-of-widgets",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#copy-this-for-the-button-of-widgets",
    "title": "Features, tools & improvements website",
    "section": "17 Copy this for the button of widgets:",
    "text": "17 Copy this for the button of widgets:\nhttps://wiki.manjaro.org/index.php?title=Main_Page/nl&action=history"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#encrypt-pages-with-password",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#encrypt-pages-with-password",
    "title": "Features, tools & improvements website",
    "section": "18 Encrypt pages with password",
    "text": "18 Encrypt pages with password\nhttps://robinmoisson.github.io/staticrypt/"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#implement-further-reading-like-this",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#implement-further-reading-like-this",
    "title": "Features, tools & improvements website",
    "section": "19 Implement further reading like this:",
    "text": "19 Implement further reading like this:\nhttps://engineeringfordatascience.com/posts/how_to_use_allure_pytest_bdd_and_allure_pytest_in_the_same_project/#further-reading"
  },
  {
    "objectID": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#make-use-of-ai-voice-to-read-my-poems",
    "href": "notes/2023-08-27_features-tools-&-improvements-website-/index.html#make-use-of-ai-voice-to-read-my-poems",
    "title": "Features, tools & improvements website",
    "section": "20 Make use of AI voice to read my poems",
    "text": "20 Make use of AI voice to read my poems"
  },
  {
    "objectID": "notes/2023-10-06_how-to-embed-ml-application/index.html",
    "href": "notes/2023-10-06_how-to-embed-ml-application/index.html",
    "title": "How to embed ML application?",
    "section": "",
    "text": "Example how to add ml application from gradio.app\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          October 6, 2023"
  },
  {
    "objectID": "notes/2023-10-06_how-to-embed-ml-application/index.html#adding-the-script",
    "href": "notes/2023-10-06_how-to-embed-ml-application/index.html#adding-the-script",
    "title": "How to embed ML application?",
    "section": "1 Adding the script",
    "text": "1 Adding the script\n&lt;script type=\"module\"\nsrc=\"https://gradio.s3-us-west-2.amazonaws.com/3.36.1/gradio.js\"&gt;\n&lt;/script&gt;\n&lt;gradio-app space=\"ForBo7/FloodDetector\"&gt;&lt;/gradio-app&gt;"
  },
  {
    "objectID": "notes/2023-10-06_how-to-embed-ml-application/index.html#styling",
    "href": "notes/2023-10-06_how-to-embed-ml-application/index.html#styling",
    "title": "How to embed ML application?",
    "section": "2 Styling",
    "text": "2 Styling\nTo avoid lines surrounding, add to theme-light.scss\n.info.svelte-1kyws56.svelte-1kyws56 {\n    display: none !important;\n}\n\n.embed-container.svelte-1kyws56.svelte-1kyws56 {\n    border: none !important;\n}"
  },
  {
    "objectID": "notes/2023-08-22_commands-for-quarto/index.html",
    "href": "notes/2023-08-22_commands-for-quarto/index.html",
    "title": "Commands Quarto",
    "section": "",
    "text": "Commands Quarto\n        \n        \n                    \n                \n                    A useful list of Quarto commands\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Quarto\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Quarto\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 22, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\n# Creates website in folder 'mysite'\nquarto create-project /Users/datoapanta/Desktop/mysite --type website  \n\n# To render it and preview in local host\nquarto preview mysite\n\n# Creates blog in folder 'blog'\nquarto create-project /Users/datoapanta/Desktop/blog --type website:blog\n\n# To render it and preview in local host\nquarto preview blog"
  },
  {
    "objectID": "now/index.html",
    "href": "now/index.html",
    "title": "Danilo Toapanta",
    "section": "",
    "text": "What I’m working on right now\n\n\nUpdated on August 16th, 2023.\n\n\n    \n\n\nCore Habits\n\nRead ≧ 20 min\nExercise ≧ 1 hour\nMeditate ≧ 10 minutes\nRun weekly ≧ 18km\n\n\n\nInternship\n\nConnect Hugging Face ML application to repo\nYAML automation for downloading JPEG\n\n\n\nWebsite\n\nFinishing up the project page.\nFuture features can be found at DEV\n\n\n\nR Studio\n\nLearning file management\n\n\n\nReading\n\nAtomic Habits by James Clear\n\n—\n\nBooks I’ve enjoy reading\n\n\n\nArchive \n\n\n\n\n\n\n\nWhat I’m working on right now\n\n\nUpdated on July 24th, 2023.\n\n\n    \n\n\nCore habits\n\nRead ≧ 20 min\nExercise ≧ 1 hour\nMeditate ≧ 10 minutes\n\n\n\nWebsite\n\nGet a domain to publish this site\nFuture features can be found at DEV\n\n\n\nReading\n\n12 Rules for Life by Jordan Peterson\n\n\n\n\n\n\n\nWhat I’m working on right now\n\n\nUpdated on June 28th, 2023\n\n\n    \n\n\n\nWebsite\n\nStart coding from scracth this site"
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#limitation-of-the-hmm",
    "href": "blog/2023-11-13_sequence-labelling/index.html#limitation-of-the-hmm",
    "title": "Sequence Labelling",
    "section": "16 Limitation of the HMM",
    "text": "16 Limitation of the HMM\n\n\n\n\nSlide 66\n\n\n\n\n\nCannot model long term dependencies, it is very local. Token are not even depent on one another they are conditionally independent given the tags where they were generated from\nThe context is only of the previous tags it does not use linguistics context it use some sintatic context but very limited one just the previous tags\nAs a tagger you are given good english and you are mapping to tag sequences and what happens is that if the tag for a certain position depends on a word that is very far away from it then the HMM cannot see. For instance some name entities may have long names for instance United States Airles, or people with long names. Conclusion HMMS cannot reduce the entrophy of what the label of a certain category may be you need to look far and the HMMs cannot do that\n\n\n\n\n\nSlide 67\n\n\n\n\nBecause the HMMs need to generate text they use very farily limited use of linguistic context in \\(w_{1:L}\\). Using more of thse context in a generative model it will break certain algorithms that you need for training and using these models like the vitori or forward algorithm\nSo to allow a category to interact with more words you would break those algorithms you would make then not scalable.\nIt will also make our CPDs more sparce if we try to memorize more phrases everything gets sparce\n\n\n\n\nSlide 68\n\n\n\n\nUnseen wors and phrases will come out and the HMM would be lost\nIt may also be cases that we would like to extract the fine features of a word fors instance ending in ‘-ed’ or stating with ‘un’ and so on but this cannot be by the HMM because it cannot analyse more fine-grained features."
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#section",
    "href": "blog/2023-11-13_sequence-labelling/index.html#section",
    "title": "Sequence Labelling",
    "section": "1.1 ",
    "text": "1.1 \n\n\n\n\nSlide 69\n\n\n\n\nLet’s imagine I want to tag the 4th word. I could collect features from the surronding context of that position so I could get features from a windows to the left or a window from the right and features from the word cute itself. In the features I have this vector where I only have one \\(1\\), I could have design more features as: ‘is there capital letters’, ‘does it end in ed?’ and so on more features.\nThis table is bigger in the linguistic context so its more rich than the HMM These are handmade feature vectors"
  },
  {
    "objectID": "blog/2023-11-13_sequence-labelling/index.html#how-to-move-from-the-hmms",
    "href": "blog/2023-11-13_sequence-labelling/index.html#how-to-move-from-the-hmms",
    "title": "Sequence Labelling",
    "section": "17 How to move from the HMMs?",
    "text": "17 How to move from the HMMs?\n\n17.1 First idea: use feature-rich models\n\n\n\n\nSlide 69\n\n\n\n\nLet’s imagine I want to tag the 4th word. I could collect features from the surronding context of that position so I could get features from a windows to the left or a window from the right and features from the word cute itself. In the features I have this vector where I only have one \\(1\\), I could have design more features as: ‘is there capital letters’, ‘does it end in ed?’ and so on more features.\nThis table is bigger in the linguistic context so its more rich than the HMM These are handmade feature vectors\n\n\n17.2 Second idea:desing one classifier and use it many times\n\nHere we map the features of the context to the prob values of the clases using a log linear model\n\n\n\n\n\nSlide 70\n\n\n\n\nFrom the feature vector ‘cute’ predict a vector of probability values as large as the number of classes that adds up to one. Lets explain: if you have a feature representation of a context and your goal is to spit out a prob vector, then you could use a linear model.\nSo from however many features you have, you do a linear operation to obtain exaclty the number of classe you are working withs. For sintance here 11 clases and I am working with 3V features, then I do one linear transformation from 3V features to 11. This vector with 11 cordinates in it, these are not probabilities are real values to force them to become prob we use Softmax. K=11 calsses, D is the dimensionality of the feature vector, if we are using the feature vector from the previous slide that is 3V. So then the number of weights would be 3V * K. Because for every feature you wanna get the importance of the feature towards a class. And also you get the biases which you could think of as the margin frequency of the class regardless of any features. One linear transform maps from D dimensions to K dimensions this thigns are called ‘scores’, ‘logits’. Logits can be though of log probabilites that are not normalized and then the softmax functions maps to K probs.\nWhat we achieve by this is that no matter with position you are you can use the same model, it does not get bigger or smaller to tag the first word, the second, the … its just one classifier that can be sued over and over.\n\n\n\n\nSlide 71\n\n\n\n\nIf I have a sentence from \\(w_{1:l}\\) and I am looking at an specific position of it with those two things I can get the prob values for the classes that I may classify. That is the \\(f\\) the prob vector, one prob per each class. Yuo decide how to decide \\(f\\)\n\n\n\n\n\n\n\nSlide 75\n\n\n\n\nWe have created a tagger by not considering the sequence but only about classification. The idea is that for every position in the sequence that you would want to tag you pretend this is a classification task you dont care that you are actually tagging and entire sequence. You classify one position at the time independently of what you do for other positions. The key for this to work is to featurize the context in which you perfom the clasifications so if I want to classify ‘united’ I have a feature vector that describes best I can ‘united’ in the sentence meaning I am ‘united’ there is adimension for that. There is a feature for ‘my neighboor is an upper case letter’.\n\nIf you do independent classification, so independetly of what you do in other steps do you see a problem in the picture above where I have annotated where is the beginning, inside and end of the span (meaning there is an structure)? If I perform independent decision it is easy to programm but my lead to a problem. The problem is:\nYou get nonsense tag sequences: [O I O ] here you cannot be inside if you have not even enter one\nThe problem with tagging independetly then is that tagging is ins’t made of independent stps and specficially the structure that you want to output it contains constraints so the ouput sequence is constraint not any scramble of tags would do. A better one would be [O S I O] as in ot"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#how-research-gets-done-at-il-marie-curie.",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#how-research-gets-done-at-il-marie-curie.",
    "title": "Deep Learning Optimizations I",
    "section": "72 How research gets done at Il Marie Curie.",
    "text": "72 How research gets done at Il Marie Curie.\n“Nothing in life is to be\n\n\n\n\nSlide 75"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#batch-gradient-descent-for-neural-nets",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#batch-gradient-descent-for-neural-nets",
    "title": "Deep Learning Optimizations I",
    "section": "7 Batch gradient descent for neural nets’",
    "text": "7 Batch gradient descent for neural nets’\n\n\n\n\nSlide 8"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#batch-gradient-descent-for-neural-nets-loss-surfaces",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#batch-gradient-descent-for-neural-nets-loss-surfaces",
    "title": "Deep Learning Optimizations I",
    "section": "6 Batch gradient descent for neural nets’ loss surfaces",
    "text": "6 Batch gradient descent for neural nets’ loss surfaces\n\n\n\n\nSlide 8"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#so-curvature-is-determine-by-the-second-derivative-so-its-determined-by-the-hessian",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#so-curvature-is-determine-by-the-second-derivative-so-its-determined-by-the-hessian",
    "title": "Deep Learning Optimizations I",
    "section": "29 So curvature is determine by the second derivative so its determined by the Hessian",
    "text": "29 So curvature is determine by the second derivative so its determined by the Hessian"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#quizz",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#quizz",
    "title": "Deep Learning Optimizations I",
    "section": "38 Quizz",
    "text": "38 Quizz\n\n\n\n\nSlide 40\n\n\n\n\nWhy does flat minima generalize better on test data?\n\nWe cannot say that generally they have lower loss values\nIt is a true statement but it is not the reason. So it does not matter whether you add more precision. For i.e you can add float64 instead and still does not change things\nTrue\nWe do not use test for training"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#setting-the-learning-rate",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#setting-the-learning-rate",
    "title": "Deep Learning Optimizations I",
    "section": "44 Setting the learning rate",
    "text": "44 Setting the learning rate\n\n\n\n\nSlide 47\n\n\n\n\ngenerally we go from a high to low lr either by:\n\nstep decay: ie divide lr by 10 every x number of epochs\ngradually going low the learning rate\n\nThe heuristics for this is that you first will find some general area in which the loss is pretty good but then this large learning step size keeps jumping around the local minimum, and now if you decrease the learning rate now it can optimize whithin this valley, and whithin this value can go further down"
  },
  {
    "objectID": "blog/2023-11-08_deep-learning-optimizations-i/index.html#quiz-1",
    "href": "blog/2023-11-08_deep-learning-optimizations-i/index.html#quiz-1",
    "title": "Deep Learning Optimizations I",
    "section": "73 Quiz",
    "text": "73 Quiz\n\n\n\n\nSlide 76\n\n\n\n\n\nSetting all the weights to “42”\n\nAnswers:\n\nis wrong as setting the weights to zero is hard to learn, but if all same then all evolve in the similar way\nYes, it does train but very slowly because at least the bias will add some variance\nThis works as long as all the neurons are set to some number between 0 and 100, but this does not matter to much so this will be able to train\nSame explanation to 1. The same number then all evolve in the same way and will not train properly"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html",
    "title": "Deep Learning Optimizations II",
    "section": "",
    "text": "Description of this Post\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Deep Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Deep Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          November 20, 2023"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#title",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#title",
    "title": "Deep Learning Optimizations II",
    "section": "81 Title",
    "text": "81 Title\n\n\n\n\nSlide 87"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#last-time",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#last-time",
    "title": "Deep Learning Optimizations II",
    "section": "1 Last time:",
    "text": "1 Last time:\n\n\n\n\nSlide 2"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#lecture-overview",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#lecture-overview",
    "title": "Deep Learning Optimizations II",
    "section": "1 Lecture overview",
    "text": "1 Lecture overview\n\n\n\n\nSlide 4"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#lecture-overview-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#lecture-overview-1",
    "title": "Deep Learning Optimizations II",
    "section": "2 Lecture overview",
    "text": "2 Lecture overview\n\n\n\n\nSlide 4"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#title-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#title-1",
    "title": "Deep Learning Optimizations II",
    "section": "82 Title",
    "text": "82 Title\n\n\n\n\nSlide 87"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#title-2",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#title-2",
    "title": "Deep Learning Optimizations II",
    "section": "84 Title",
    "text": "84 Title\n\n\n\n\nSlide 87"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#ression-gravitation",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#ression-gravitation",
    "title": "Deep Learning Optimizations II",
    "section": "4 ression: Gravitation",
    "text": "4 ression: Gravitation\n\n\n\n\nSlide 7"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#bias-variance-tradeoff",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#bias-variance-tradeoff",
    "title": "Deep Learning Optimizations II",
    "section": "5 Bias-variance tradeoff",
    "text": "5 Bias-variance tradeoff\n\n\n\n\nSlide 8\n\n\n\n\nThe single best prediction of the parameters\nA good estimator is a function whose output is close to the true underlying thetha that generated the data"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#bias-variance-tradeoff-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#bias-variance-tradeoff-1",
    "title": "Deep Learning Optimizations II",
    "section": "6 Bias-variance tradeoff",
    "text": "6 Bias-variance tradeoff\n\n\n\n\nSlide 9\n\n\n\n\nBias\nEstimator’s expected value= so the ouput of our thetha estimate and the true value of that parameter\nBias comes from not being able to model the real model in a correct way\nVariance\nSo if you use a different training set or a different split how different are the learnt NNs parameters. If differ a lot then high variance"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#bias-variance-tradeoff-2",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#bias-variance-tradeoff-2",
    "title": "Deep Learning Optimizations II",
    "section": "7 Bias-variance tradeoff",
    "text": "7 Bias-variance tradeoff\n\n\n\n\nSlide 10\n\n\n\n\nHigh variance & low bias, your model on average get it right but it has a high variance because it wants to model all noise, so overfilling, it spread all over the place\nHigh bias and low variance, in average it does not even get it correct so underfitting"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#overfitting",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#overfitting",
    "title": "Deep Learning Optimizations II",
    "section": "8 Overfitting",
    "text": "8 Overfitting\n\n\n\n\nSlide 11"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#overfitting-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#overfitting-1",
    "title": "Deep Learning Optimizations II",
    "section": "9 Overfitting",
    "text": "9 Overfitting\n\n\n\n\nSlide 12\n\n\n\n\nIt will learn to recognize that the img contains hourses not by the hourses but the watermark. This is seen in the heat-map where the point of attention is in the watermark. This is overfitting"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#overfitting-2",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#overfitting-2",
    "title": "Deep Learning Optimizations II",
    "section": "10 Overfitting",
    "text": "10 Overfitting\n\n\n\n\nSlide 13\n\n\n\n\nTo avoid overfitting we use regularization"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#overfitting-how-powerful-are-neural-networks",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#overfitting-how-powerful-are-neural-networks",
    "title": "Deep Learning Optimizations II",
    "section": "11 Overfitting: how “powerful” are neural networks?",
    "text": "11 Overfitting: how “powerful” are neural networks?\n\n\n\n\nSlide 14"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#this-isnt-the-full-story..",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#this-isnt-the-full-story..",
    "title": "Deep Learning Optimizations II",
    "section": "12 This isn’t the full story..",
    "text": "12 This isn’t the full story..\n\n\n\n\nSlide 15"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#update-2019-double-descent",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#update-2019-double-descent",
    "title": "Deep Learning Optimizations II",
    "section": "13 Update 2019: Double Descent",
    "text": "13 Update 2019: Double Descent\n\n\n\n\nSlide 16\n\n\n\n\nDash line is where the data samples equals the number of parameters\nSo in the top right image even if we have increase the number of hidden layers and our training error is zero then our test set is still decreasing that is weird.\nSo here we then presume that bigger model will have lower error.\nBefore we use to have a curve upwrads from the tipical bias/variance curve in the prev slide, but the weird thing is that where the dash line meets then this error starts to decrease again.\nTwo answers: smoothness and regularization"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#double-descent-smoothness-from-bigger-models",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#double-descent-smoothness-from-bigger-models",
    "title": "Deep Learning Optimizations II",
    "section": "14 Double-descent: Smoothness from bigger models",
    "text": "14 Double-descent: Smoothness from bigger models\n\n\n\n\nSlide 17\n\n\n\n\nIn the x axis you have the number of times SGD was proceed, so the amount of units of texts akak ‘words’ were processed\nWe can see that with larger models I require fewer samples to reach a lower test loss\nAlso when they reach stability they can provide with a test loss which is the best shot they can give and this depends on their size, larger models give more accurate results\nAlso it shows that the quicker models learns quickler than the smaller model. So while the smaller model for a given number of tokens the large model learns more quickler.\nThis is Language models still not applicable for vision.\nWe also can say that (in language models) in terms of flops is more efficient to learn large models for fewer steps than to learn small models for larger amount of steps"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#double-descent-in-practice",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#double-descent-in-practice",
    "title": "Deep Learning Optimizations II",
    "section": "15 Double-descent in practice?",
    "text": "15 Double-descent in practice?\n\n\n\n\nSlide 18\n\n\n\n\nIn practice if you increase the number of neurons you may be closer to overfitting. For that we need regularization"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#regularization",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#regularization",
    "title": "Deep Learning Optimizations II",
    "section": "16 Regularization",
    "text": "16 Regularization\n\n\n\n\nSlide 19\n\n\n\n\nHere we reduce the complexity of a NN and avoid ovverfitting"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#regularization-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#regularization-1",
    "title": "Deep Learning Optimizations II",
    "section": "20 2) £,-regularization",
    "text": "20 2) £,-regularization\n\n\n\n\nSlide 23"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#regularization-2",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#regularization-2",
    "title": "Deep Learning Optimizations II",
    "section": "20 2) £,-regularization",
    "text": "20 2) £,-regularization\n\n\n\n\nSlide 23"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#regularization-3",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#regularization-3",
    "title": "Deep Learning Optimizations II",
    "section": "20 2) £,-regularization",
    "text": "20 2) £,-regularization\n\n\n\n\nSlide 23"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#regularization-4",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#regularization-4",
    "title": "Deep Learning Optimizations II",
    "section": "20 2) £,-regularization",
    "text": "20 2) £,-regularization\n\n\n\n\nSlide 23"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#why-do-l1-and-l2-regularizations-work",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#why-do-l1-and-l2-regularizations-work",
    "title": "Deep Learning Optimizations II",
    "section": "21 Why do L1 and L2 Regularizations work?",
    "text": "21 Why do L1 and L2 Regularizations work?\n\n\n\n\nSlide 24\n\n\n\n\nL2 regularization has basically a circular constraint area because you have w1^2 + w2^2 needs to be constant so all these combinations would be a circle\nSo the contours of the loss function in red will intercept the constrains regions at an axis. What that means is that if you are trying to find in this case the optimal loss, then it touches the constraint region where one of the values is set to zero while with L2 regularization there is no particular point where you could make one of the weights zero\nThis is because it needs to have the sum of the squares to be a small value but there is no particular motivation to have a similar weigth dimension to be equal to zero, so there is no reason to have sparse weights in L2"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#effect-linear-regression-example",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#effect-linear-regression-example",
    "title": "Deep Learning Optimizations II",
    "section": "22 Effect: linear regression example",
    "text": "22 Effect: linear regression example\n\n\n\n\nSlide 25\n\n\n\n\nHere the alpha goes from strong to weak\nIn L1 it puches some weights to zero and then stay zero aftwer a while and it is not like all of them get smaller at the same time but some of them stay quite high for a loong time, and now increasing alpha here you are making individual weights close to zero.\nL2 Regularization (Weight Decay): Encourages smaller weights but does not force them to be exactly zero. It smoothens the weights but doesn’t induce sparsity.\nL1 Regularization: Promotes sparsity by adding a penalty term based on the absolute values of the weights. This can lead to some weights being exactly zero."
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#early-stopping",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#early-stopping",
    "title": "Deep Learning Optimizations II",
    "section": "23 3) Early stopping",
    "text": "23 3) Early stopping\n\n\n\n\nSlide 26"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#early-stopping-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#early-stopping-1",
    "title": "Deep Learning Optimizations II",
    "section": "24 3) Early stopping",
    "text": "24 3) Early stopping\n\n\n\n\nSlide 27\n\n\n\n\n*Typo: with better test set error\nThe model at this stage have low variance because they are not overfitting"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#early-stopping-2",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#early-stopping-2",
    "title": "Deep Learning Optimizations II",
    "section": "25 3) Early stopping",
    "text": "25 3) Early stopping\n\n\n\n\nSlide 28"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#why-does-early-stopping-work-as-regularization",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#why-does-early-stopping-work-as-regularization",
    "title": "Deep Learning Optimizations II",
    "section": "26 Why does early-stopping work as regularization?",
    "text": "26 Why does early-stopping work as regularization?\n\n\n\n\nSlide 29"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#why-does-early-stopping-work-as-regularization-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#why-does-early-stopping-work-as-regularization-1",
    "title": "Deep Learning Optimizations II",
    "section": "27 Why does early-stopping work as regularization?",
    "text": "27 Why does early-stopping work as regularization?\n\n\n\n\nSlide 30\n\n\n\n\nHere weight decay they mean by L2-regularization\n\n\n\n\n\n\nWeight decay (L2-loss) vs Early Stopping\n\n\n\n\n\nWeight decay, also known as L2 regularization, is a technique to prevent overfitting by adding a penalty term to the loss function that is proportional to the squared magnitudes of the weights. This regularization term discourages the model from learning very large weights and encourages a smoother and more generalized solution.\nEarly Stopping:\nEarly stopping is a regularization technique used during the training of a machine learning model, typically in the context of iterative optimization algorithms like gradient descent. The idea behind early stopping is to monitor the model’s performance on a validation set during training and stop the training process when the performance on the validation set starts to degrade, even if the performance on the training set continues to improve.\n\nMechanism: Monitor a performance metric (e.g., validation loss) on a separate validation set during training.\nDecision Criteria: Stop training when the performance on the validation set starts to worsen or fails to improve for a certain number of consecutive epochs.\nPurpose: Prevent overfitting by terminating training before the model starts to memorize noise in the training data.\n\nWeight Decay (L2 Regularization):\nWeight decay, also known as L2 regularization, is a technique to prevent overfitting by adding a penalty term to the loss function that is proportional to the squared magnitudes of the weights. This regularization term discourages the model from learning very large weights and encourages a smoother and more generalized solution.\n\nMechanism: Add a term to the loss function that penalizes large weights by adding the sum of squared weights multiplied by a regularization strength.\nDecision Criteria: No specific stopping criterion; regularization is applied throughout the training process.\nPurpose: Encourage the model to have smaller and more evenly distributed weights, preventing overfitting.\n\nKey Differences:\n\nFocus:\n\nEarly stopping focuses on monitoring the model’s performance during training and stopping when the validation performance indicates potential overfitting.\nWeight decay focuses on adjusting the optimization objective by penalizing large weights, aiming to prevent overfitting from the beginning of training.\n\nDecision Criteria:\n\nEarly stopping makes decisions based on the validation performance, and the training stops when the validation performance degrades.\nWeight decay does not have a specific stopping criterion; it is a continuous regularization technique applied throughout training.\n\nImplementation:\n\nEarly stopping involves monitoring and interrupting the training loop.\nWeight decay involves adding a regularization term to the loss function during each iteration of the optimization algorithm.\n\n\nIn practice, these techniques can be used together to enhance the regularization effect and improve the generalization performance of a machine learning model."
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-the-problem-it-addresses",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-the-problem-it-addresses",
    "title": "Deep Learning Optimizations II",
    "section": "28 4) Dropout: the problem it addresses",
    "text": "28 4) Dropout: the problem it addresses\n\n\n\n\nSlide 31"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-why-does-it-work",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-why-does-it-work",
    "title": "Deep Learning Optimizations II",
    "section": "29 4) Dropout: why does it work?",
    "text": "29 4) Dropout: why does it work?\n\n\n\n\nSlide 32"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-why-does-it-work-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-why-does-it-work-1",
    "title": "Deep Learning Optimizations II",
    "section": "30 4) Dropout: why does it work?",
    "text": "30 4) Dropout: why does it work?\n\n\n\n\nSlide 33"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-how-is-it-implemented",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-how-is-it-implemented",
    "title": "Deep Learning Optimizations II",
    "section": "31 4) Dropout: how is it implemented?",
    "text": "31 4) Dropout: how is it implemented?\n\n\n\n\nSlide 34\n\n\n\n\nYou switch the activations to 0, and now say with Bernulli you have 50% neurons working\nDuring testing you are not learning so you use all the neurons\n\nNow with Dropout you cannot have neurons that are inactive, because you drop all other neurons so now they need to work\nDecreases overfitting"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout",
    "title": "Deep Learning Optimizations II",
    "section": "32 Dropout",
    "text": "32 Dropout\n\n\n\n\nSlide 35"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-1",
    "title": "Deep Learning Optimizations II",
    "section": "33 Dropout",
    "text": "33 Dropout\n\n\n\n\nSlide 36"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-2",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-2",
    "title": "Deep Learning Optimizations II",
    "section": "34 Dropout",
    "text": "34 Dropout\n\n\n\n\nSlide 37"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-3",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-3",
    "title": "Deep Learning Optimizations II",
    "section": "35 Dropout",
    "text": "35 Dropout\n\n\n\n\nSlide 38"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-4",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-4",
    "title": "Deep Learning Optimizations II",
    "section": "36 Dropout",
    "text": "36 Dropout\n\n\n\n\nSlide 39"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-5",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-5",
    "title": "Deep Learning Optimizations II",
    "section": "37 Dropout",
    "text": "37 Dropout\n\n\n\n\nSlide 40"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-us.-bagging",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-us.-bagging",
    "title": "Deep Learning Optimizations II",
    "section": "38 Dropout US. Bagging",
    "text": "38 Dropout US. Bagging\n\n\n\n\nSlide 41\n\n\n\n\nBagging, also known as bootstrap aggregation, is the ensemble learning method that is commonly used to reduce variance within a noisy dataset. It is train in parallel\n\n\n\n\nBagging:\n\nHas its corresponding training set that is different from the whole training set\nUses all neurons\n\nDropout:\n\nIt does not employ all neurons\nThey are not trained they only get one SGD because you have many infinitely subnetworks, so if you apply dropout it is very unlikely that you trian the same subentwork many times"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-beyond-bagging",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-beyond-bagging",
    "title": "Deep Learning Optimizations II",
    "section": "39 Dropout beyond Bagging",
    "text": "39 Dropout beyond Bagging\n\n\n\n\nSlide 42"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#data-augmentation",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#data-augmentation",
    "title": "Deep Learning Optimizations II",
    "section": "40 5) Data augmentation",
    "text": "40 5) Data augmentation\n\n\n\n\nSlide 43"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#data-augmentation-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#data-augmentation-1",
    "title": "Deep Learning Optimizations II",
    "section": "41 Data augmentation",
    "text": "41 Data augmentation\n\n\n\n\nSlide 44"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#one-note-about-backtranslation-though",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#one-note-about-backtranslation-though",
    "title": "Deep Learning Optimizations II",
    "section": "42 One note about backtranslation though:",
    "text": "42 One note about backtranslation though:\n\n\n\n\nSlide 45"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#common-computer-vision-augmentations-visualised",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#common-computer-vision-augmentations-visualised",
    "title": "Deep Learning Optimizations II",
    "section": "43 Common computer vision augmentations visualised",
    "text": "43 Common computer vision augmentations visualised\n\n\n\n\nSlide 46"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#data-augmentation-2",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#data-augmentation-2",
    "title": "Deep Learning Optimizations II",
    "section": "44 Data augmentation",
    "text": "44 Data augmentation\n\n\n\n\nSlide 47"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#data-augmentation-3",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#data-augmentation-3",
    "title": "Deep Learning Optimizations II",
    "section": "45 Data augmentation",
    "text": "45 Data augmentation\n\n\n\n\nSlide 48"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#other-regularizations",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#other-regularizations",
    "title": "Deep Learning Optimizations II",
    "section": "46 Other regularizations",
    "text": "46 Other regularizations\n\n\n\n\nSlide 49"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#various-ways-to-regularise",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#various-ways-to-regularise",
    "title": "Deep Learning Optimizations II",
    "section": "47 Various ways to regularise",
    "text": "47 Various ways to regularise\n\n\n\n\nSlide 50"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#title-3",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#title-3",
    "title": "Deep Learning Optimizations II",
    "section": "84 Title",
    "text": "84 Title\n\n\n\n\nSlide 87"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#data-preprocessing",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#data-preprocessing",
    "title": "Deep Learning Optimizations II",
    "section": "49 Data preprocessing",
    "text": "49 Data preprocessing\n\n\n\n\nSlide 52\n\n\n\n\nHere basically if we have in same scale then our weights will not be elongated like in the elipse, now they would be able to take the same step size in the correct direction"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#normalizing-input-data",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#normalizing-input-data",
    "title": "Deep Learning Optimizations II",
    "section": "50 Normalizing Input Data",
    "text": "50 Normalizing Input Data\n\n\n\n\nSlide 53\n\n\n\n\nThis we apply in the input stage:\nNormalization is a linear operator so you can put this back into the NN after you have trained if you want to"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#normalizing-intermediate-layers",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#normalizing-intermediate-layers",
    "title": "Deep Learning Optimizations II",
    "section": "51 Normalizing intermediate layers",
    "text": "51 Normalizing intermediate layers\n\n\n\n\nSlide 54\n\n\n\n\nHere we talked about the normalization within the NN"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#batch-normalization",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#batch-normalization",
    "title": "Deep Learning Optimizations II",
    "section": "52 Batch normalization",
    "text": "52 Batch normalization\n\n\n\n\nSlide 55"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#batch-normalization-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#batch-normalization-1",
    "title": "Deep Learning Optimizations II",
    "section": "53 Batch normalization",
    "text": "53 Batch normalization\n\n\n\n\nSlide 56\n\n\n\n\n\n\n\n\n\n\nHow does batch normalization works?\n\n\n\n\n\nBatch Normalization (BatchNorm) is a technique used in neural networks to improve the training stability and speed by normalizing the inputs of each layer. It was introduced by Sergey Ioffe and Christian Szegedy in their paper “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.”\nHere’s a high-level overview of how Batch Normalization works:\n\n53.1 Steps of Batch Normalization:\n\nNormalization:\n\nFor each mini-batch during training, normalize the input by subtracting the mean and dividing by the standard deviation. The normalization is applied independently to each feature (dimension) in the input.\n\n\\(\\hat{x}^{(k)} = \\frac{x^{(k)} - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}\\)\nWhere:\n\n\\(\\hat{x}^{(k)}\\) is the normalized output for the k-th feature.\n\\(x^{(k)}\\) is the input for the k-th feature.\n\\(\\mu\\) is the mean of the mini-batch.\n\\(\\sigma^2\\) is the variance of the mini-batch.\n\\(\\epsilon\\) is a small constant added for numerical stability.\n\nScale and Shift:\n\nIntroduce learnable parameters (scale and shift) for each feature to allow the model to adapt during training.\n\n\\(y^{(k)} = \\gamma \\hat{x}^{(k)} + \\beta\\)\nWhere:\n\n\\(y^{(k)}\\) is the final output for the k-th feature.\n\\(\\gamma\\) is a learnable scale parameter.\n\\(\\beta\\) is a learnable shift parameter.\n\nTraining and Inference:\n\nDuring training, the mean and variance are computed for each mini-batch and used for normalization.\nDuring inference, running averages of mean and variance from the training phase are typically used for normalization to ensure consistency.\n\n\n\n\n53.2 Benefits of Batch Normalization:\n\nImproved Training Stability:\n\nHelps mitigate the internal covariate shift problem, leading to more stable and faster convergence during training.\n\nReduced Sensitivity to Initialization:\n\nReduces the sensitivity of the model to the choice of initial weights.\n\nAllows Higher Learning Rates:\n\nEnables the use of higher learning rates, which can accelerate training.\n\nActs as Regularization:\n\nIntroduces a slight regularization effect, reducing the need for other regularization techniques.\n\nApplicability to Various Architectures:\n\nCan be applied to various types of neural network architectures, including fully connected layers, convolutional layers, and recurrent layers.\n\n\nBatch Normalization has become a standard component in many deep learning architectures due to its effectiveness in improving training stability and convergence speed."
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#batch-normalization-the-algorithm",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#batch-normalization-the-algorithm",
    "title": "Deep Learning Optimizations II",
    "section": "54 Batch normalization — The algorithm",
    "text": "54 Batch normalization — The algorithm\n\n\n\n\nSlide 57"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#how-does-batch-normalization-help-optimization",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#how-does-batch-normalization-help-optimization",
    "title": "Deep Learning Optimizations II",
    "section": "55 How does batch normalization help optimization?",
    "text": "55 How does batch normalization help optimization?\n\n\n\n\nSlide 58\n\n\n\n\nBecause some layers will push ouputs in one direction, then other layers will not use this. With batch norm we centered data so that all layers train around these centered inputs"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#how-does-batch-normalization-help-optimization-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#how-does-batch-normalization-help-optimization-1",
    "title": "Deep Learning Optimizations II",
    "section": "56 How does batch normalization help optimization?",
    "text": "56 How does batch normalization help optimization?\n\n\n\n\nSlide 59"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#benefits-of-batch-normalization",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#benefits-of-batch-normalization",
    "title": "Deep Learning Optimizations II",
    "section": "57 Benefits of Batch normalization",
    "text": "57 Benefits of Batch normalization\n\n\n\n\nSlide 60"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#ohui7",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#ohui7",
    "title": "Deep Learning Optimizations II",
    "section": "58 ; Ohui7: ;",
    "text": "58 ; Ohui7: ;\n\n\n\n\nSlide 61"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#batch-normalization-at-test-time",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#batch-normalization-at-test-time",
    "title": "Deep Learning Optimizations II",
    "section": "59 Batch normalization at test time",
    "text": "59 Batch normalization at test time\n\n\n\n\nSlide 62\n\n\n\n\nThe important thing is that when you go to test time, you dont have batches (you dont want anything that is depended on how you construct the batch) because that means if you take another batch is not the same which then is not reproducible.\nSo what we usually do is keep a moving average of the mean and variance during training, and then at test time you plug them\nBasically you extract the mean and the variance form the training and use it in test data"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#disadvantages-of-batch-normalization",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#disadvantages-of-batch-normalization",
    "title": "Deep Learning Optimizations II",
    "section": "60 Disadvantages of batch normalization",
    "text": "60 Disadvantages of batch normalization\n\n\n\n\nSlide 63\n\n\n\n\n\nIt requires you to have large batch sizes because otherwhise the estimate of mean and variance is too noisy\nProblematic if you have discrepancy of the training and tst data\nNow the loss you get from training sample A, depends on what other training sample are present in the batch via this normalization of the mean and variance\nOne disadvantage is that is usually the reason for bugs, because if you keep estimating the mean and variances for the test data but now it is not reproducible because it will depend on the batch itself"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#disadvantages-of-batch-normalization-with-distributed-training",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#disadvantages-of-batch-normalization-with-distributed-training",
    "title": "Deep Learning Optimizations II",
    "section": "61 Disadvantages of batch normalization with distributed training",
    "text": "61 Disadvantages of batch normalization with distributed training\n\n\n\n\nSlide 64\n\n\n\n\n\nDifferent values across GPU\nIf you batch size is small in a single GPU, but maybe you have 10 GPUs running and for 10 GPUs your batch size is bigger, it will be a stupid idea to estimate 10 very noisy estimate of the mean and variance but instead you should compute across the GPU"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#layer-normalization",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#layer-normalization",
    "title": "Deep Learning Optimizations II",
    "section": "62 Layer normalization",
    "text": "62 Layer normalization\n\n\n\n\nSlide 65\n\n\n\n\nHere mean and variance are not computed across batch but across all channels and spatial dimensions.\nSo now the statistics are independent of the batch size because now they depend on the feature dimensions see example below:\n\n\n\n\n\n\nExample Layer normalization\n\n\n\n\n\nLayer Normalization is a normalization technique similar to Batch Normalization but operates on a per-sample basis rather than per-minibatch. It normalizes the inputs of a layer across the features (dimensions) for each individual sample. Here’s an example of how Layer Normalization is typically applied:\n\nimport torch\nimport torch.nn as nn\n\n# Assuming input has shape (batch_size, num_features)\ninput_data = torch.randn(32, 64)\n\n# Layer Normalization\nlayer_norm = nn.LayerNorm(normalized_shape=64)\noutput = layer_norm(input_data)\n\n# Display input and output shapes\nprint(\"Input shape:\", input_data.shape)\nprint(\"Output shape:\", output.shape)\n\nInput shape: torch.Size([32, 64])\nOutput shape: torch.Size([32, 64])\n\n\nIn this example:\n\ninput_data is a random tensor with shape (32, 64), representing a batch of 32 samples, each with 64 features.\nnn.LayerNorm is the Layer Normalization layer provided by PyTorch. The normalized_shape parameter specifies the number of features in the input tensor.\nThe output tensor is the result of applying Layer Normalization to the input data.\n\nLayer Normalization normalizes the values along the feature dimension independently for each sample. This means that each feature in a sample is normalized based on its mean and standard deviation across the entire sample, rather than across a batch as in Batch Normalization.\nLayer Normalization is useful when the batch size is small or when working with sequences of varying lengths, as it normalizes each sample independently. It has been widely used in natural language processing tasks and recurrent neural networks.\n\n\n\nBasically, we have that our mean and std will be computed across dimensions, so on the columns, not on each input. So then each sample (so each row) we make it with this mean and std to be distributed between 0 and 1.\nThis is great for RNN, or other stuff that requires small batch sizes.\nHere the same operations happens at training and test time.\nSo now instead of normalizing across data samples now we basically i.e. if the input is an image that each color should be roughly be ocurring the same amount of spread across all the image, because now we normalize it across channel dimensions"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#layer-normalization-ln",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#layer-normalization-ln",
    "title": "Deep Learning Optimizations II",
    "section": "63 Layer normalization (LN)",
    "text": "63 Layer normalization (LN)\n\n\n\n\nSlide 66"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#instance-normalization-in",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#instance-normalization-in",
    "title": "Deep Learning Optimizations II",
    "section": "64 Instance normalization (IN)",
    "text": "64 Instance normalization (IN)\n\n\n\n\nSlide 67\n\n\n\n\nInstance normalization now you do layer normalization but per channel and per training example.\nSo now the network should be agnostic to the constract of the original iamge and of the constrast whithin the channels\nNot used that often\nHere we compute the mean and var per sample but not per channel.\n\n\n\n\n\n\nHow Instance Normalization works\n\n\n\n\n\nInstance Normalization is a normalization technique similar to Batch Normalization and Layer Normalization but operates on a per-instance basis. It normalizes the activations of each individual sample independently. Here’s an explanation of how Instance Normalization works:\n\n64.1 Instance Normalization Steps:\n\nInput Tensor:\n\nAssume you have an input tensor \\(X\\) with shape \\((N, C, H, W)\\), where:\n\n\\(N\\) is the batch size.\n\\(C\\) is the number of channels.\n\\(H\\) is the height of the feature map.\n\\(W\\) is the width of the feature map.\n\n\nCalculate Mean and Variance:\n\nFor each instance (sample) in the batch, calculate the mean \\(\\mu\\) and variance \\(\\sigma^2\\) along each channel independently. This is done for each channel and each instance separately.\n\n\\[\\mu_c = \\frac{1}{H \\cdot W} \\sum_{i=1}^{H} \\sum_{j=1}^{W} X_{n,c,i,j}\\]\n\\[\\sigma^2_c = \\frac{1}{H \\cdot W} \\sum_{i=1}^{H} \\sum_{j=1}^{W} (X_{n,c,i,j} - \\mu_c)^2\\]\nNormalize:\n\nNormalize each channel of each instance independently using the calculated mean and standard deviation:\n\n\\[\\hat{X}_{n,c,i,j} = \\frac{X_{n,c,i,j} - \\mu_c}{\\sqrt{\\sigma^2_c + \\epsilon}}\\]\nWhere:\n\n\\(\\hat{X}_{n,c,i,j}\\) is the normalized value.\n\\(X_{n,c,i,j}\\) is the original input value.\n\\(\\mu_c\\) is the mean of the channel \\(c\\) for the instance \\(n\\).\n\\(\\sigma^2_c\\) is the variance of the channel \\(c\\) for the instance \\(n\\).\n\\(\\epsilon\\) is a small constant added for numerical stability.\n\nScale and Shift:\n\nIntroduce learnable scale (\\(\\gamma\\)) and shift (\\(\\beta\\)) parameters for each channel:\n\n\\[Y_{n,c,i,j} = \\gamma_c \\hat{X}_{n,c,i,j} + \\beta_c\\]\nWhere:\n\n\\(Y_{n,c,i,j}\\) is the final normalized output.\n\\(\\gamma_c\\) is a learnable scale parameter for channel \\(c\\).\n\\(\\beta_c\\) is a learnable shift parameter for channel \\(c\\).\n\n\n\n\n64.2 Benefits of Instance Normalization:\n\nNormalization Across Samples:\n\nInstance Normalization normalizes each instance independently, making it suitable for scenarios where batch sizes may vary or are small.\n\nReduces Covariate Shift:\n\nSimilar to Batch Normalization, Instance Normalization helps reduce internal covariate shift, leading to more stable training.\n\nApplicability to Style Transfer:\n\nInstance Normalization has found applications in style transfer tasks in computer vision.\n\n\nInstance Normalization is often used in computer vision tasks, especially in scenarios where the batch size may be small or when normalization across instances is desired."
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#group-normalization-gn",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#group-normalization-gn",
    "title": "Deep Learning Optimizations II",
    "section": "65 Group normalization (GN)",
    "text": "65 Group normalization (GN)\n\n\n\n\nSlide 68\n\n\n\n\nWe are gonna group different certain channels toguether. So we are not normalizing per channel but per groups, for instance 5 channels.\n\nIf you have only one group then you recover layer nomalization because layer normal normalizes across all channels and not per channel\nIf you have more number of channel group toguether i.e 3 channels group together then you do Instance normalization. meaning you compute the mean per sample across each channel\n\n\nIn Grouped Convs, you are basically separating the hidden layers or the hidden channels in hidden groups which makes computations more easier\nThis is better than batch normalization for small batches &lt;32"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#a-comparison-of-different-normalizations",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#a-comparison-of-different-normalizations",
    "title": "Deep Learning Optimizations II",
    "section": "66 A comparison of different normalizations",
    "text": "66 A comparison of different normalizations\n\n\n\n\nSlide 69"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#weight-normalization",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#weight-normalization",
    "title": "Deep Learning Optimizations II",
    "section": "67 Weight normalization",
    "text": "67 Weight normalization\n\n\n\n\nSlide 70\n\n\n\n\nYou can thing the weights like a vector, you can have its magnitude and its direction. Now with this g can learn this parameter which tells you how long you want to go in that direction\n\n\n\n\nSlide 72\n\n\n\n\n\n\n\n\nSlide 73"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#references",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#references",
    "title": "Deep Learning Optimizations II",
    "section": "68 References",
    "text": "68 References\n\n\n\n\nSlide 71"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#title-4",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#title-4",
    "title": "Deep Learning Optimizations II",
    "section": "84 Title",
    "text": "84 Title\n\n\n\n\nSlide 87"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#title-5",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#title-5",
    "title": "Deep Learning Optimizations II",
    "section": "84 Title",
    "text": "84 Title\n\n\n\n\nSlide 87"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#learning-rate",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#learning-rate",
    "title": "Deep Learning Optimizations II",
    "section": "68 Learning rate",
    "text": "68 Learning rate\n\n\n\n\nSlide 74"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#convergence",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#convergence",
    "title": "Deep Learning Optimizations II",
    "section": "69 Convergence",
    "text": "69 Convergence\n\n\n\n\nSlide 75\n\n\n\n\nTo achieve convergence you need tehse two equations:\n\nall learning over time should be infinitely to allow for exploration\nThe quadratic term should be less than infite to converge"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#learning-rate-schedules",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#learning-rate-schedules",
    "title": "Deep Learning Optimizations II",
    "section": "70 Learning rate schedules",
    "text": "70 Learning rate schedules\n\n\n\n\nSlide 76\n\n\n\n\nYou also make a warmpup learning rate so you start by going up in a linear fashion"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#in-practice",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#in-practice",
    "title": "Deep Learning Optimizations II",
    "section": "71 In practice",
    "text": "71 In practice\n\n\n\n\nSlide 77"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#quiz",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#quiz",
    "title": "Deep Learning Optimizations II",
    "section": "3 Quiz",
    "text": "3 Quiz\n\n\n\n\nSlide 6\n\n\n\n\nWhy left would be preferred?\n\nsimpler model\ngeneralize better to unseen data\n\nWhy the right is better?\n\nWe are actually fitting all the data points\nThe right hand side is the ground truth\nYou dont care about extrapolating"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-rate",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#dropout-rate",
    "title": "Deep Learning Optimizations II",
    "section": "73 Dropout rate",
    "text": "73 Dropout rate\n\n\n\n\nSlide 79"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#batch-size",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#batch-size",
    "title": "Deep Learning Optimizations II",
    "section": "74 Batch size",
    "text": "74 Batch size\n\n\n\n\nSlide 80"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#designing-cnns-to-become-even-better.-dont-try-this-at-home",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#designing-cnns-to-become-even-better.-dont-try-this-at-home",
    "title": "Deep Learning Optimizations II",
    "section": "75 Designing CNNs to become even better. (Don’t try this at home)",
    "text": "75 Designing CNNs to become even better. (Don’t try this at home)\n\n\n\n\nSlide 81\n\n\n\n\nArchitecture, which model do you use?"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#number-of-layers-and-neurons",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#number-of-layers-and-neurons",
    "title": "Deep Learning Optimizations II",
    "section": "76 Number of layers and neurons",
    "text": "76 Number of layers and neurons\n\n\n\n\nSlide 82\n\n\n\n\nProgress is not only in the architecture side, for example if you want to develop better algorithms, you want to have just a neural network which can identify between cats and dogs, there is multiple ways:\n\nCome up with a new architecture\nCome up with better gradients and better weights of the NNs"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#babysitting-deep-nets",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#babysitting-deep-nets",
    "title": "Deep Learning Optimizations II",
    "section": "77 Babysitting Deep Nets",
    "text": "77 Babysitting Deep Nets\n\n\n\n\nSlide 83\n\n\n\n\nfor classifying 8 classes, the loss should be -log(1/8) and you check whether is true, if it gets worst performance that randomly guessing so something is wrong"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#logging-tools",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#logging-tools",
    "title": "Deep Learning Optimizations II",
    "section": "78 Logging tools",
    "text": "78 Logging tools\n\n\n\n\nSlide 84"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#babysitting-deep-nets-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#babysitting-deep-nets-1",
    "title": "Deep Learning Optimizations II",
    "section": "79 Babysitting Deep Nets",
    "text": "79 Babysitting Deep Nets\n\n\n\n\nSlide 85\n\n\n\n\nLink1"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#reading-material",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#reading-material",
    "title": "Deep Learning Optimizations II",
    "section": "80 Reading material",
    "text": "80 Reading material\n\n\n\n\nSlide 86"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#title-6",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#title-6",
    "title": "Deep Learning Optimizations II",
    "section": "87 Title",
    "text": "87 Title\n\n\n\n\nSlide 87"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html",
    "title": "Convolutional Neural Networks",
    "section": "",
    "text": "Description of this Post\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Deep Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Deep Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          November 20, 2023"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html",
    "href": "blog/2023-11-20_modern-convnets/index.html",
    "title": "Modern ConvNets",
    "section": "",
    "text": "Description of this Post\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Deep Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Deep Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          November 20, 2023"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#title",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#title",
    "title": "Convolutional Neural Networks",
    "section": "107 Title",
    "text": "107 Title\n\n\n\n\nSlide 129"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#optimizing-neural-networks",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#optimizing-neural-networks",
    "title": "Convolutional Neural Networks",
    "section": "1 Optimizing neural networks",
    "text": "1 Optimizing neural networks\n\n\n\n\nSlide 2"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#multi-layer-perceptrons-recap",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#multi-layer-perceptrons-recap",
    "title": "Convolutional Neural Networks",
    "section": "2 Multi-layer perceptrons (Recap)",
    "text": "2 Multi-layer perceptrons (Recap)\n\n\n\n\nSlide 3"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#multi-layer-perceptrons-recap-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#multi-layer-perceptrons-recap-1",
    "title": "Convolutional Neural Networks",
    "section": "3 Multi-layer perceptrons (Recap)",
    "text": "3 Multi-layer perceptrons (Recap)\n\n\n\n\nSlide 4\n\n\n\n\nPrior knowledge, is something that we know about the data, we want to bring this into the design of the NNs"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#consider-an-image",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#consider-an-image",
    "title": "Convolutional Neural Networks",
    "section": "4 Consider an image",
    "text": "4 Consider an image\n\n\n\n\nSlide 5"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#hubel-and-wiesel-nobel-prize-for-physiology-or-medicine-in-1981",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#hubel-and-wiesel-nobel-prize-for-physiology-or-medicine-in-1981",
    "title": "Convolutional Neural Networks",
    "section": "5 Hubel and Wiesel: Nobel Prize for Physiology or Medicine in 1981",
    "text": "5 Hubel and Wiesel: Nobel Prize for Physiology or Medicine in 1981\n\n\n\n\nSlide 6\n\n\n\n\nHere when we see edges, there is some electricity"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#filters-yes.-how-about-learnable-filters",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#filters-yes.-how-about-learnable-filters",
    "title": "Convolutional Neural Networks",
    "section": "6 Filters, yes. How about learnable filters",
    "text": "6 Filters, yes. How about learnable filters\n\n\n\n\nSlide 7\n\n\n\n\nCanny and GAbor filters they all try to find edges, then it can be used for recognition purposes."
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#filters-yes.-how-about-learnable-filters-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#filters-yes.-how-about-learnable-filters-1",
    "title": "Convolutional Neural Networks",
    "section": "7 Filters, yes. How about learnable filters",
    "text": "7 Filters, yes. How about learnable filters\n\n\n\n\nSlide 8"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#the-convolution-operation",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#the-convolution-operation",
    "title": "Convolutional Neural Networks",
    "section": "8 The convolution operation",
    "text": "8 The convolution operation\n\n\n\n\nSlide 9"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#the-convolution-operation-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#the-convolution-operation-1",
    "title": "Convolutional Neural Networks",
    "section": "9 The convolution operation",
    "text": "9 The convolution operation\n\n\n\n\nSlide 10\n\n\n\n\n\n\n\n\n\n\n\n\nHere f*g is the convolution in red line. In the 1D case\nHere g is the kernel"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-for-2d-images",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-for-2d-images",
    "title": "Convolutional Neural Networks",
    "section": "10 Convolution for 2D images",
    "text": "10 Convolution for 2D images\n\n\n\n\nSlide 11\n\n\n\n\nNow our kernel is 2D"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-for-2d-images-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-for-2d-images-1",
    "title": "Convolutional Neural Networks",
    "section": "11 Convolution for 2D images",
    "text": "11 Convolution for 2D images\n\n\n\n\nSlide 12"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#examples",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#examples",
    "title": "Convolutional Neural Networks",
    "section": "12 Examples",
    "text": "12 Examples\n\n\n\n\nSlide 13"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#examples-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#examples-1",
    "title": "Convolutional Neural Networks",
    "section": "13 Examples",
    "text": "13 Examples\n\n\n\n\nSlide 14\n\n\n\n\nSobel fires for vertical edges"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#quiz",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#quiz",
    "title": "Convolutional Neural Networks",
    "section": "14 Quiz",
    "text": "14 Quiz\n\n\n\n\nSlide 15\n\n\n\n\n\nIt will emphasize edges\n\nIf you take a CNN and you have weights uniform then you would not have this edge detectors and the NN would not train well\nThis is like adding prior knowledge because we know edges are supper important to detect whether is a cat or a dog"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#the-motivation-of-convolutions",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#the-motivation-of-convolutions",
    "title": "Convolutional Neural Networks",
    "section": "15 The motivation of convolutions",
    "text": "15 The motivation of convolutions\n\n\n\n\nSlide 16\n\n\n\n\nLocal connectivity, for ie if you want to detect edges, you dont need to look at the whole image and because you share the parameters, the weights are tied and you are more efficient."
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#the-motivation-of-convolutions-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#the-motivation-of-convolutions-1",
    "title": "Convolutional Neural Networks",
    "section": "16 The motivation of convolutions",
    "text": "16 The motivation of convolutions\n\n\n\n\nSlide 17\n\n\n\n\nThis saves quite a bit of neurons connected, so less parameters, this is the same as analysing an img of 16x16, but now instead we use filters so that we can detect edges and only with these edges we have now building blocks which are less than computing the whole image.\nHere the kernel would be of width 3"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#the-motivation-of-convolutions-2",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#the-motivation-of-convolutions-2",
    "title": "Convolutional Neural Networks",
    "section": "17 The motivation of convolutions",
    "text": "17 The motivation of convolutions\n\n\n\n\nSlide 18\n\n\n\n\nSo here in the left the NN has a receptive field of size 3, because this is how much a neuron can look up, so it is the kernel size. But per layer the receptive field gradually grows which allow you to have a hierarchical structure\n\nFor instance the neurons at layer 50 now they can see at the whole image and can put image into context. This is how you go from local to global"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#the-motivation-of-convolutions-3",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#the-motivation-of-convolutions-3",
    "title": "Convolutional Neural Networks",
    "section": "18 The motivation of convolutions",
    "text": "18 The motivation of convolutions\n\n\n\n\nSlide 19"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#the-motivation-of-convolutions-4",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#the-motivation-of-convolutions-4",
    "title": "Convolutional Neural Networks",
    "section": "19 The motivation of convolutions",
    "text": "19 The motivation of convolutions\n\n\n\n\nSlide 20\n\n\n\n\nIf the input shift then the outputs does the same, this is not the case for a fully connected NN"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#a-simple-convolution-saves-space",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#a-simple-convolution-saves-space",
    "title": "Convolutional Neural Networks",
    "section": "20 A simple convolution: saves space!",
    "text": "20 A simple convolution: saves space!\n\n\n\n\nSlide 21\n\n\n\n\nThe bigger the filter the more zeros we will have"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#the-pooling-operations-not",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#the-pooling-operations-not",
    "title": "Convolutional Neural Networks",
    "section": "21 The pooling operations (not **)",
    "text": "21 The pooling operations (not **)\n\n\n\n\nSlide 22"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#lenet-5",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#lenet-5",
    "title": "Convolutional Neural Networks",
    "section": "23 LeNet-5",
    "text": "23 LeNet-5\n\n\n\n\nSlide 23\n\n\n\n\nHere you do not have global pooling so an img of 29x29 would not have worked\nThe hidden dimensionalities are called channels, and the pooling is applied to all channels. So pooling operations do not change dimensionality but change the spatial extent.\nSo each layer would have channels those are all the squares in a layer, pooling it is apploed to every channel and per channel it reduces its square matrix to a lower width and lower height\n\n23.1 More\nLeNet-5, a convolutional neural network architecture proposed by Yann LeCun and his collaborators in 1998, does not use global average pooling in its original design. LeNet-5 primarily relies on subsampling layers (pooling layers) and fully connected layers.\nThe typical structure of LeNet-5 consists of alternating convolutional layers with subsampling (pooling) layers, followed by fully connected layers. The pooling layers in LeNet-5 perform down-sampling through operations like max pooling. Global average pooling was not a commonly used technique at the time LeNet-5 was introduced.\nGlobal average pooling became more prominent in later CNN architectures, such as Google’s Inception models and the popular ResNet architectures\n\n\n23.2 Global Pooling\nGlobal pooling (or global average pooling) is a technique used in convolutional neural networks (CNNs) to reduce the spatial dimensions of a feature map to a single value or a vector. It involves taking the average (or maximum) value across all spatial locations of each feature map, resulting in a global representation.\nHere’s an example of global average pooling with Python using NumPy:\nimport numpy as np\n\n# Assume you have a 3x3 feature map with 2 channels\nfeature_map = np.array([\n    [[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n    [[10, 11, 12], [13, 14, 15], [16, 17, 18]]\n])\n\n# Apply global average pooling\nglobal_avg_pooled = np.mean(feature_map, axis=(0, 1))\n\n# Print the original feature map and the result after global average pooling\nprint(\"Original Feature Map:\")\nprint(feature_map)\nprint(\"\\nGlobal Average Pooled Result:\")\nprint(global_avg_pooled)\nIn this example, feature_map is a 3x3 feature map with 2 channels. The np.mean function is used to compute the average along the spatial dimensions (axis 0 and 1). The resulting global_avg_pooled is a vector representing the global average-pooled values for each channel.\nThe output should look like this:\nOriginal Feature Map:\n[[[ 1  2  3]\n  [ 4  5  6]\n  [ 7  8  9]]\n\n [[10 11 12]\n  [13 14 15]\n  [16 17 18]]]\n\nGlobal Average Pooled Result:\n[8.5 9.5 10.5]\nIn this case, the global average pooling operation has computed the average value for each channel across all spatial locations, resulting in a global representation for each channel. This global representation is often used as a compact and informative input to subsequent layers or for making predictions in the network."
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#alexnet-similar-principles-but-some-extra-engineering.",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#alexnet-similar-principles-but-some-extra-engineering.",
    "title": "Convolutional Neural Networks",
    "section": "24 AlexNet: similar principles, but some extra engineering.",
    "text": "24 AlexNet: similar principles, but some extra engineering.\n\n\n\n\nSlide 24\n\n\n\n\n\n\n\n\n\nSlide 25\n\n\n\n\nWeight sharing in convolutional neural networks (CNNs) refers to the practice of using the same set of learnable parameters (weights and biases) for multiple units or neurons in a layer. In other words, the weights are shared across different spatial locations in the input.\nThe key idea behind weight sharing is to enforce translation invariance in the features learned by the convolutional layers. In an image, certain features (e.g., edges, textures) are meaningful regardless of their specific location. By using shared weights, the network can learn to detect these features at different spatial positions, leading to a more robust and generalizable representation.\nHere’s a brief explanation of weight sharing in CNNs:\n\nConvolutional Operation:\n\nIn a convolutional layer, a set of filters (also known as kernels) is applied to the input image or feature map.\nEach filter is characterized by a set of learnable weights and biases.\n\nSpatial Weight Sharing:\n\nInstead of having unique weights for each spatial location in the input, weight sharing involves using the same set of weights across different spatial locations.\nFor example, if a filter detects a certain feature (e.g., an edge) at one location, the same filter with the same weights can be used to detect the same feature at a different location.\n\nBenefits:\n\nReduces the number of learnable parameters in the network, making it more computationally efficient.\nEncourages the learning of spatially invariant features, enhancing the network’s ability to recognize patterns across different locations.\n\nTranslation Invariance:\n\nWeight sharing helps the network achieve translation invariance, meaning that it can recognize features regardless of their position in the input.\n\n\n\n24.1 CNN and Weight Sharing\nCNN is primarily used for image classification and segmentation, and it works by finding similar patterns throughout the input. These patterns can be found by sliding a filter with shared weights across the input. The shared weights concept allows the network to learn the same pattern, regardless of its position in the input"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#title-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#title-1",
    "title": "Convolutional Neural Networks",
    "section": "108 Title",
    "text": "108 Title\n\n\n\n\nSlide 129"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#what-shape-should-the",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#what-shape-should-the",
    "title": "Convolutional Neural Networks",
    "section": "25 What shape should the",
    "text": "25 What shape should the\n\n\n\n\nSlide 28"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#what-shape-should-the-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#what-shape-should-the-1",
    "title": "Convolutional Neural Networks",
    "section": "25 What shape should the",
    "text": "25 What shape should the\n\n\n\n\nSlide 27"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#what-shape-should-the-2",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#what-shape-should-the-2",
    "title": "Convolutional Neural Networks",
    "section": "26 What shape should the",
    "text": "26 What shape should the\n\n\n\n\nSlide 28"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations",
    "title": "Convolutional Neural Networks",
    "section": "37 31) Activations",
    "text": "37 31) Activations\n\n\n\n\nSlide 49"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-1",
    "title": "Convolutional Neural Networks",
    "section": "39 31) Activations",
    "text": "39 31) Activations\n\n\n\n\nSlide 41"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-2",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-2",
    "title": "Convolutional Neural Networks",
    "section": "47 31) Activations",
    "text": "47 31) Activations\n\n\n\n\nSlide 49"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-3",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-3",
    "title": "Convolutional Neural Networks",
    "section": "41 31) Activations",
    "text": "41 31) Activations\n\n\n\n\nSlide 43"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-4",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-4",
    "title": "Convolutional Neural Networks",
    "section": "42 31) Activations",
    "text": "42 31) Activations\n\n\n\n\nSlide 44"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-5",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-5",
    "title": "Convolutional Neural Networks",
    "section": "43 31) Activations",
    "text": "43 31) Activations\n\n\n\n\nSlide 45"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-6",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-6",
    "title": "Convolutional Neural Networks",
    "section": "47 31) Activations",
    "text": "47 31) Activations\n\n\n\n\nSlide 49"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-7",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-7",
    "title": "Convolutional Neural Networks",
    "section": "45 31) Activations",
    "text": "45 31) Activations\n\n\n\n\nSlide 47"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-8",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-8",
    "title": "Convolutional Neural Networks",
    "section": "46 31) Activations",
    "text": "46 31) Activations\n\n\n\n\nSlide 48"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-9",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-9",
    "title": "Convolutional Neural Networks",
    "section": "47 31) Activations",
    "text": "47 31) Activations\n\n\n\n\nSlide 49"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-10",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-10",
    "title": "Convolutional Neural Networks",
    "section": "48 31) Activations",
    "text": "48 31) Activations\n\n\n\n\nSlide 50"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-11",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-11",
    "title": "Convolutional Neural Networks",
    "section": "48 31) Activations",
    "text": "48 31) Activations\n\n\n\n\nSlide 50"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-12",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-12",
    "title": "Convolutional Neural Networks",
    "section": "49 31) Activations",
    "text": "49 31) Activations\n\n\n\n\nSlide 51"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-13",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-13",
    "title": "Convolutional Neural Networks",
    "section": "50 31) Activations",
    "text": "50 31) Activations\n\n\n\n\nSlide 52"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-14",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-14",
    "title": "Convolutional Neural Networks",
    "section": "49 31) Activations",
    "text": "49 31) Activations\n\n\n\n\nSlide 51"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-15",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-15",
    "title": "Convolutional Neural Networks",
    "section": "50 31) Activations",
    "text": "50 31) Activations\n\n\n\n\nSlide 52"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-16",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-16",
    "title": "Convolutional Neural Networks",
    "section": "46 31) Activations",
    "text": "46 31) Activations\n\n\n\n\nSlide 48"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-17",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-17",
    "title": "Convolutional Neural Networks",
    "section": "47 31) Activations",
    "text": "47 31) Activations\n\n\n\n\nSlide 49"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-18",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-18",
    "title": "Convolutional Neural Networks",
    "section": "48 31) Activations",
    "text": "48 31) Activations\n\n\n\n\nSlide 50"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-19",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-19",
    "title": "Convolutional Neural Networks",
    "section": "49 31) Activations",
    "text": "49 31) Activations\n\n\n\n\nSlide 51"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-20",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-20",
    "title": "Convolutional Neural Networks",
    "section": "50 31) Activations",
    "text": "50 31) Activations\n\n\n\n\nSlide 52"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-21",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-21",
    "title": "Convolutional Neural Networks",
    "section": "49 31) Activations",
    "text": "49 31) Activations\n\n\n\n\nSlide 51"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-22",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-22",
    "title": "Convolutional Neural Networks",
    "section": "50 31) Activations",
    "text": "50 31) Activations\n\n\n\n\nSlide 52"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-23",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activations-23",
    "title": "Convolutional Neural Networks",
    "section": "50 31) Activations",
    "text": "50 31) Activations\n\n\n\n\nSlide 52"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations",
    "title": "Convolutional Neural Networks",
    "section": "26 3D Activations",
    "text": "26 3D Activations\n\n\n\n\nSlide 30\n\n\n\n\nInstead of calling it RGB channels, we just call it channels"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-1",
    "title": "Convolutional Neural Networks",
    "section": "27 3D Activations",
    "text": "27 3D Activations\n\n\n\n\nSlide 32\n\n\n\n\nNow the activations contain width and height and also depth.\nThe depth is govern by the hidden dimensionality of the NN"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-2",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-2",
    "title": "Convolutional Neural Networks",
    "section": "28 3D Activations",
    "text": "28 3D Activations\n\n\n\n\nSlide 34"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-3",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-3",
    "title": "Convolutional Neural Networks",
    "section": "29 3D Activations",
    "text": "29 3D Activations\n\n\n\n\nSlide 35\n\n\n\n\nHere this is a convolution kernel, with kernel size 5x5\nNow our neuron has a kernel size of 5x5 weights and also x3 because it has 3 channels\nSo each Neuron as a 3D filter"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#putting-it-together",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#putting-it-together",
    "title": "Convolutional Neural Networks",
    "section": "41 Putting it together",
    "text": "41 Putting it together\n\n\n\n\nSlide 57"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#putting-it-together-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#putting-it-together-1",
    "title": "Convolutional Neural Networks",
    "section": "42 Putting it together",
    "text": "42 Putting it together\n\n\n\n\nSlide 58"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#putting-it-together-2",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#putting-it-together-2",
    "title": "Convolutional Neural Networks",
    "section": "43 Putting it together",
    "text": "43 Putting it together\n\n\n\n\nSlide 59"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#putting-it-together-3",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#putting-it-together-3",
    "title": "Convolutional Neural Networks",
    "section": "44 Putting it together",
    "text": "44 Putting it together\n\n\n\n\nSlide 60"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#putting-it-together-4",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#putting-it-together-4",
    "title": "Convolutional Neural Networks",
    "section": "45 Putting it together",
    "text": "45 Putting it together\n\n\n\n\nSlide 61"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#putting-it-together-5",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#putting-it-together-5",
    "title": "Convolutional Neural Networks",
    "section": "46 Putting it together",
    "text": "46 Putting it together\n\n\n\n\nSlide 62"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#putting-it-together-6",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#putting-it-together-6",
    "title": "Convolutional Neural Networks",
    "section": "47 Putting it together",
    "text": "47 Putting it together\n\n\n\n\nSlide 63"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#putting-it-together-7",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#putting-it-together-7",
    "title": "Convolutional Neural Networks",
    "section": "48 Putting it together",
    "text": "48 Putting it together\n\n\n\n\nSlide 64\n\n\n\n\nHere all these coloured layers in the cube are filters which are neurons. All these neurons act only in one hidden layer8"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride",
    "title": "Convolutional Neural Networks",
    "section": "49 Convolution: Stride",
    "text": "49 Convolution: Stride\n\n\n\n\nSlide 65"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-1",
    "title": "Convolutional Neural Networks",
    "section": "50 Convolution: Stride",
    "text": "50 Convolution: Stride\n\n\n\n\nSlide 66"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-2",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-2",
    "title": "Convolutional Neural Networks",
    "section": "51 Convolution: Stride",
    "text": "51 Convolution: Stride\n\n\n\n\nSlide 67"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-3",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-3",
    "title": "Convolutional Neural Networks",
    "section": "52 Convolution: Stride",
    "text": "52 Convolution: Stride\n\n\n\n\nSlide 68"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-4",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-4",
    "title": "Convolutional Neural Networks",
    "section": "53 Convolution: Stride",
    "text": "53 Convolution: Stride\n\n\n\n\nSlide 69"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-5",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-5",
    "title": "Convolutional Neural Networks",
    "section": "54 Convolution: Stride",
    "text": "54 Convolution: Stride\n\n\n\n\nSlide 70"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-6",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-6",
    "title": "Convolutional Neural Networks",
    "section": "55 Convolution: Stride",
    "text": "55 Convolution: Stride\n\n\n\n\nSlide 71\n\n\n\n\nIn each time sum across channels because if you want to detect something you want to use all the colors, all the incoming channels\nSo each convolution sums all channels like in RGB, because you dont want a filter that only looks at blue, one that only looks at red .."
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-7",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-7",
    "title": "Convolutional Neural Networks",
    "section": "56 Convolution: Stride",
    "text": "56 Convolution: Stride\n\n\n\n\nSlide 72\n\n\n\n\nHere in the next slide we see that stride is the number of squares that are moved, so the kernel filter will i.e stride=3 will slide every two squares"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-8",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-8",
    "title": "Convolutional Neural Networks",
    "section": "57 Convolution: Stride",
    "text": "57 Convolution: Stride\n\n\n\n\nSlide 73"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-9",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-9",
    "title": "Convolutional Neural Networks",
    "section": "58 Convolution: Stride",
    "text": "58 Convolution: Stride\n\n\n\n\nSlide 74"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-10",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-stride-10",
    "title": "Convolutional Neural Networks",
    "section": "59 Convolution: Stride",
    "text": "59 Convolution: Stride\n\n\n\n\nSlide 75"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-padding",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-padding",
    "title": "Convolutional Neural Networks",
    "section": "60 Convolution: Padding",
    "text": "60 Convolution: Padding\n\n\n\n\nSlide 76"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-padding-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-padding-1",
    "title": "Convolutional Neural Networks",
    "section": "61 Convolution: Padding",
    "text": "61 Convolution: Padding\n\n\n\n\nSlide 77"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-padding-2",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-padding-2",
    "title": "Convolutional Neural Networks",
    "section": "62 Convolution: Padding",
    "text": "62 Convolution: Padding\n\n\n\n\nSlide 78"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-padding-3",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-padding-3",
    "title": "Convolutional Neural Networks",
    "section": "63 Convolution: Padding",
    "text": "63 Convolution: Padding\n\n\n\n\nSlide 79"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution",
    "title": "Convolutional Neural Networks",
    "section": "64 Convolution:",
    "text": "64 Convolution:\n\n\n\n\nSlide 81\n\n\n\n\nW_out is what you get in the ouput layer of the slide (so for one filter)"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-1",
    "title": "Convolutional Neural Networks",
    "section": "65 Convolution:",
    "text": "65 Convolution:\n\n\n\n\nSlide 81"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#x1-convolution",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#x1-convolution",
    "title": "Convolutional Neural Networks",
    "section": "65 1x1 Convolution",
    "text": "65 1x1 Convolution\n\n\n\n\nSlide 82\n\n\n\n\nIt looks at all the values in the depth, so in RGB, or more importantly in deep NNs the different hidden layers and they just mixed those information together"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#x1-convolution-a-computationally-cheap-method",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#x1-convolution-a-computationally-cheap-method",
    "title": "Convolutional Neural Networks",
    "section": "66 1x1 Convolution: a computationally cheap method",
    "text": "66 1x1 Convolution: a computationally cheap method\n\n\n\n\nSlide 83\n\n\n\n\nHere in the 5x5x32 the convolution will be done over the 192 channels, 32 times (because we have 32 filters as depth), so sliding the filter a lot\nIn the bottom case we reduce the number of channels so now we reduce computations"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#take-3min-discuss-with-your-neighbor",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#take-3min-discuss-with-your-neighbor",
    "title": "Convolutional Neural Networks",
    "section": "67 Take 3min: discuss with your neighbor:",
    "text": "67 Take 3min: discuss with your neighbor:\n— ~wafko+rdt ae AA a a4 ~ + =\n\n\n\n\nSlide 84"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#dilated-convolutions",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#dilated-convolutions",
    "title": "Convolutional Neural Networks",
    "section": "68 Dilated Convolutions",
    "text": "68 Dilated Convolutions\n\n\n\n\nSlide 85\n\n\n\n\nThis is very usefull if you need to deal with a huge image, but dont want huge hidden activations\nIf you do this then you can quickly downscale the image, without ignoring too many things\nAlso think that dilation its less expensive because doing 5x5 its more expensive than doing 3x3, so you can learn 3x3 but with holes in between and that is more efficient to consider large spatial footprint"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#pooling",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#pooling",
    "title": "Convolutional Neural Networks",
    "section": "69 Pooling",
    "text": "69 Pooling\n\n\n\n\nSlide 86"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#pooling-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#pooling-1",
    "title": "Convolutional Neural Networks",
    "section": "70 Pooling",
    "text": "70 Pooling\n\n\n\n\nSlide 87"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#max-poolina",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#max-poolina",
    "title": "Convolutional Neural Networks",
    "section": "71 Max Poolina",
    "text": "71 Max Poolina\n\n\n\n\nSlide 88"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#getting-rid-of-pooling",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#getting-rid-of-pooling",
    "title": "Convolutional Neural Networks",
    "section": "72 Getting rid of pooling",
    "text": "72 Getting rid of pooling\n\n\n\n\nSlide 89\n\n\n\n\nInstead of using pooling you can use a larger stride (so how many squares we slide) that we talk about\nIn Transformers pooling it is also not used anymore\nIn CNN is used"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#example-convnet",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#example-convnet",
    "title": "Convolutional Neural Networks",
    "section": "73 Example ConvNet",
    "text": "73 Example ConvNet\n\n\n\n\nSlide 93\n\n\n\n\nEvery filter is one row here"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#example-convnet-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#example-convnet-1",
    "title": "Convolutional Neural Networks",
    "section": "74 Example ConvNet",
    "text": "74 Example ConvNet\n\n\n\n\nSlide 93"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#example-convnet-2",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#example-convnet-2",
    "title": "Convolutional Neural Networks",
    "section": "75 Example ConvNet",
    "text": "75 Example ConvNet\n\n\n\n\nSlide 92"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#example-convnet-3",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#example-convnet-3",
    "title": "Convolutional Neural Networks",
    "section": "76 Example ConvNet",
    "text": "76 Example ConvNet\n\n\n\n\nSlide 93"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#quiz-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#quiz-1",
    "title": "Convolutional Neural Networks",
    "section": "67 Quiz:",
    "text": "67 Quiz:\n\n\n\n\nSlide 84\n\n\n\n\n\n\n\n\nIn the case of a fully connected layer, it connects everything in the layer. And even the 1x1 convolution it takes the full input dimensionality meaning it takes a look at all 192 channels still. In the 1x1 it reduces the number of connections comparing to fully connected and also it mixes local information\n\n\n\n\n\n\n\nMore differences:\n\n\n\n\n\nA 1x1 convolutional layer and a fully-connected layer (dense layer) are similar in that they both perform a linear transformation on the input data, but there are key differences between the two.\n\n67.1 1x1 Convolutional Layer:\n\nSpatial Information:\n\nA 1x1 convolutional layer operates on spatial information in the input tensor.\nIt applies convolutional filters with a size of 1x1, which means it processes information at individual spatial locations.\nUseful for capturing relationships between channels but does not capture spatial patterns.\n\nParameter Sharing:\n\nUtilizes parameter sharing, similar to larger convolutional layers.\nEach element in the output is the result of a weighted sum of its input elements, considering all channels.\n\nOutput Dimensions:\n\nThe output dimensions depend on the number of 1x1 filters used.\n\n\n\n\n67.2 Fully-Connected Layer:\n\nFlattening:\n\nA fully-connected layer operates on the flattened version of the input.\nIt considers all elements in the input tensor as individual input features.\n\nParameter Sharing:\n\nEach neuron in a fully-connected layer has its set of weights for every input feature.\nNo parameter sharing between different neurons.\n\nOutput Dimensions:\n\nThe output dimensions are determined by the number of neurons in the layer.\n\n\n\n\n67.3 Differences:\n\nSpatial vs. Global Information:\n\n1x1 convolutional layers capture spatial information within each channel.\nFully-connected layers operate on global information, considering all elements as individual features.\n\nParameter Sharing:\n\n1x1 convolutions use parameter sharing, making them more efficient for processing spatially correlated features.\nFully-connected layers lack parameter sharing, resulting in a larger number of parameters.\n\nComputational Efficiency:\n\n1x1 convolutions are computationally more efficient than fully-connected layers, especially in scenarios with spatially structured data.\n\nUsage in Convolutional Networks:\n\n1x1 convolutions are commonly used in convolutional neural networks (CNNs) to adjust the number of channels and perform feature transformations.\nFully-connected layers are typically used in the final layers of a neural network for classification.\n\n\n\n\n\n\n\n\n\n\nYou dont loss necessarily information, we do not want to do it at the beginning because mixing, red, blue and green per pixel does not do much. It makes sense to do it later if you have edges on top of edges and then you mix this information, it makes more sense.\n\nIt is also not good to apply 1x1 when you do not want translation invariance\nevery 1x1 is strictly local, every neuron as a receptive field so there is actually spatial information there"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#rosalind-franklin",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#rosalind-franklin",
    "title": "Convolutional Neural Networks",
    "section": "75 Rosalind Franklin:",
    "text": "75 Rosalind Franklin:\nHow research gets done part 4 everyday life can\n\n\n\n\nSlide 95"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#title-2",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#title-2",
    "title": "Convolutional Neural Networks",
    "section": "109 Title",
    "text": "109 Title\n\n\n\n\nSlide 129"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#alexnet",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#alexnet",
    "title": "Convolutional Neural Networks",
    "section": "76 AlexNet",
    "text": "76 AlexNet\n\n\n\n\nSlide 97"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#alexnet-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#alexnet-1",
    "title": "Convolutional Neural Networks",
    "section": "77 AlexNet",
    "text": "77 AlexNet\n\n\n\n\nSlide 98"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activation-function",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activation-function",
    "title": "Convolutional Neural Networks",
    "section": "78 Activation function",
    "text": "78 Activation function\n\n\n\n\nSlide 99\n\n\n\n\nFaster to train because of simple Relu, and also the gradients are not vanishing because you have the gradient of 1 starting from the positive direction\nWhy does gradient do not vanish with Relu?\nThe vanishing gradient problem refers to the issue where the gradients of the loss function with respect to the weights become extremely small during backpropagation, making it challenging for the model to learn and update its parameters effectively. This problem is particularly associated with activation functions that squash their input into a small range, such as the sigmoid or hyperbolic tangent (tanh) functions.\nReLU (Rectified Linear Unit), on the other hand, has a non-saturating activation behavior, which means that it does not squash its input into a small range.\nReLU does not saturate in the positive region of its input. For positive input values, the gradient remains constant (1), leading to consistent and non-vanishing gradients during backpropagation."
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#activation-function-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#activation-function-1",
    "title": "Convolutional Neural Networks",
    "section": "79 Activation function",
    "text": "79 Activation function\n\n\n\n\nSlide 100"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#training-with-multiple-gpus",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#training-with-multiple-gpus",
    "title": "Convolutional Neural Networks",
    "section": "80 Training with multiple GPUs",
    "text": "80 Training with multiple GPUs\n\n\n\n\nSlide 101"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#training-with-multiple-gpus-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#training-with-multiple-gpus-1",
    "title": "Convolutional Neural Networks",
    "section": "81 Training with multiple GPUs",
    "text": "81 Training with multiple GPUs\n\n\n\n\nSlide 102"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#on-that-note-communicating-between-gpus-pytorch",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#on-that-note-communicating-between-gpus-pytorch",
    "title": "Convolutional Neural Networks",
    "section": "82 On that note: Communicating between GPUs: PyTorch",
    "text": "82 On that note: Communicating between GPUs: PyTorch\n\n\n\n\nSlide 103"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#local-response-normalization",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#local-response-normalization",
    "title": "Convolutional Neural Networks",
    "section": "83 Local Response Normalization",
    "text": "83 Local Response Normalization\n\n\n\n\nSlide 104"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#overlapping-pooling",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#overlapping-pooling",
    "title": "Convolutional Neural Networks",
    "section": "84 Overlapping Pooling",
    "text": "84 Overlapping Pooling\n\n\n\n\nSlide 105"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#overlapping-pooling-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#overlapping-pooling-1",
    "title": "Convolutional Neural Networks",
    "section": "85 Overlapping Pooling",
    "text": "85 Overlapping Pooling\n\n\n\n\nSlide 106"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#overall-architecture",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#overall-architecture",
    "title": "Convolutional Neural Networks",
    "section": "86 Overall architecture",
    "text": "86 Overall architecture\n\n\n\n\nSlide 107\n\n\n\n\nThe max pooling make a vector per every image"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#the-overfitting-problem",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#the-overfitting-problem",
    "title": "Convolutional Neural Networks",
    "section": "87 The Overfitting Problem",
    "text": "87 The Overfitting Problem\n\n\n\n\nSlide 108\n\n\n\n\nIf a have a cnn that has many parameter more than my data input will i overfit?\nIf your CNN has a large number of parameters (i.e., it’s a complex model) and you have a small dataset, there is an increased risk of overfitting. A complex model may have the capacity to memorize the training data, capturing noise and outliers instead of learning generalizable patterns.\nAlthoug all these increase training time but high performance"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#the-learned-filters",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#the-learned-filters",
    "title": "Convolutional Neural Networks",
    "section": "88 The learned filters",
    "text": "88 The learned filters\n\n\n\n\nSlide 109"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#removing-layer-7",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#removing-layer-7",
    "title": "Convolutional Neural Networks",
    "section": "89 Removing layer 7",
    "text": "89 Removing layer 7\n\n\n\n\nSlide 110"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#removing-layer-6-7",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#removing-layer-6-7",
    "title": "Convolutional Neural Networks",
    "section": "90 Removing layer 6, 7",
    "text": "90 Removing layer 6, 7\n\n\n\n\nSlide 111"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#removing-layer-3-4",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#removing-layer-3-4",
    "title": "Convolutional Neural Networks",
    "section": "91 Removing layer 3, 4",
    "text": "91 Removing layer 3, 4\n\n\n\n\nSlide 112\n\n\n\n\nWe dont save that much parameters because convolutional layers are more efficient (they are not fully connected, not too many parameters)"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#removing-layer-3-4-6-7",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#removing-layer-3-4-6-7",
    "title": "Convolutional Neural Networks",
    "section": "92 Removing layer 3, 4, 6, 7",
    "text": "92 Removing layer 3, 4, 6, 7\n\n\n\n\nSlide 113"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#translation-invariance",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#translation-invariance",
    "title": "Convolutional Neural Networks",
    "section": "93 Translation invariance",
    "text": "93 Translation invariance\n\n\n\n\nSlide 114\n\n\n\n\nDespite saying that CNN tend to be equivariant which means if you shift the input the output should also shift you can see that if you do that with these images, where you are just shifting the images the outputs do vary quite a lot\nSo CNN do not learn something that is explicit symmetrical or explicitly equivariant. Equivariance may be a good prior that we put in, but that does not mean that that really happens"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#scale-invariance",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#scale-invariance",
    "title": "Convolutional Neural Networks",
    "section": "94 Scale invariance",
    "text": "94 Scale invariance\n\n\n\n\nSlide 115\n\n\n\n\nSame with scale, we have said that we apply the pooling operations so therefore we can be a bit invariant to scaling, but still NNs tend not to be super scale invariant"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#rotation-invariance",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#rotation-invariance",
    "title": "Convolutional Neural Networks",
    "section": "95 Rotation invariance",
    "text": "95 Rotation invariance\n\n\n\n\nSlide 116"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#further-reading",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#further-reading",
    "title": "Convolutional Neural Networks",
    "section": "96 Further reading",
    "text": "96 Further reading\n\n\n\n\nSlide 117\n\n\n\n\n\n\n\n\nSlide 118"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#title-3",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#title-3",
    "title": "Convolutional Neural Networks",
    "section": "128 Title",
    "text": "128 Title\n\n\n\n\nSlide 129"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#transfer-learning-carry-benefits-from-large-dataset-to-the-small-one",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#transfer-learning-carry-benefits-from-large-dataset-to-the-small-one",
    "title": "Convolutional Neural Networks",
    "section": "97 Transfer learning: carry benefits from large dataset to the small one!",
    "text": "97 Transfer learning: carry benefits from large dataset to the small one!\n\n\n\n\nSlide 119"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#update-transfer-learning",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#update-transfer-learning",
    "title": "Convolutional Neural Networks",
    "section": "98 UPDATE: Transfer learning",
    "text": "98 UPDATE: Transfer learning\n\n\n\n\nSlide 120"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#why-use-transfer-learning",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#why-use-transfer-learning",
    "title": "Convolutional Neural Networks",
    "section": "99 Why use Transfer Learning?",
    "text": "99 Why use Transfer Learning?\n\n\n\n\nSlide 121\n\n\n\n\nThe answer is yes even if you have saved the weights from a extremely good model and you have a small dataset"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convnets-are-good-in-transfer-learning",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convnets-are-good-in-transfer-learning",
    "title": "Convolutional Neural Networks",
    "section": "100 Convnets are good in transfer learning",
    "text": "100 Convnets are good in transfer learning\n\n\n\n\nSlide 122\n\n\n\n\nFine Tune the whole NN\nOr use the CNN as feature extractor"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#solution-i-fine-tune-hr-using-hg-as-initialization",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#solution-i-fine-tune-hr-using-hg-as-initialization",
    "title": "Convolutional Neural Networks",
    "section": "101 Solution I: Fine-tune hr using hg as initialization",
    "text": "101 Solution I: Fine-tune hr using hg as initialization\n\n\n\n\nSlide 123"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#initializing-hp-with-hs",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#initializing-hp-with-hs",
    "title": "Convolutional Neural Networks",
    "section": "102 Initializing hp with hs",
    "text": "102 Initializing hp with hs\n\n\n\n\nSlide 124\n\n\n\n\nImagnet, it outputs 1000 categories. If you want to classification for 30 categories then you need to throw that one away and restart training a new classifier to your needs\nAlexNet, you can start removing some layers depending on how much data you have"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#initializing-hp-with-hs-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#initializing-hp-with-hs-1",
    "title": "Convolutional Neural Networks",
    "section": "103 Initializing hp with hs",
    "text": "103 Initializing hp with hs\n\n\n\n\nSlide 125\n\n\n\n\nif you pertained your NN in ImgNet and now you want to do Satalite classification then it may be usefull to find tune even those layers the bottom ones"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#gr",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#gr",
    "title": "Convolutional Neural Networks",
    "section": "104 gr",
    "text": "104 gr\nof\nHow to fine-tune? a8? go ue\n\n\n\n\nSlide 126"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#solution-ii-use-h-as-a-feature-extractor-for-hr",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#solution-ii-use-h-as-a-feature-extractor-for-hr",
    "title": "Convolutional Neural Networks",
    "section": "105 Solution II: Use h, as a feature extractor for hr",
    "text": "105 Solution II: Use h, as a feature extractor for hr\n\n\n\n\nSlide 127"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#transfer-learning-benchmarks-techniques",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#transfer-learning-benchmarks-techniques",
    "title": "Convolutional Neural Networks",
    "section": "106 Transfer learning benchmarks & techniques",
    "text": "106 Transfer learning benchmarks & techniques\n\n\n\n\nSlide 128"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#title-4",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#title-4",
    "title": "Convolutional Neural Networks",
    "section": "129 Title",
    "text": "129 Title\n\n\n\n\nSlide 129"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#title",
    "href": "blog/2023-11-20_modern-convnets/index.html#title",
    "title": "Modern ConvNets",
    "section": "1 Title",
    "text": "1 Title\n\n\n\n\nSlide 1"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#lecture-overview",
    "href": "blog/2023-11-20_modern-convnets/index.html#lecture-overview",
    "title": "Modern ConvNets",
    "section": "2 Lecture overview",
    "text": "2 Lecture overview\n\n\n\n\nSlide 2"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#understanding-deep-embeddings",
    "href": "blog/2023-11-20_modern-convnets/index.html#understanding-deep-embeddings",
    "title": "Modern ConvNets",
    "section": "3 Understanding deep embeddings",
    "text": "3 Understanding deep embeddings\n\n\n\n\nSlide 3"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#the-deep-layers-will-gradually-learn-more-abstract-features.",
    "href": "blog/2023-11-20_modern-convnets/index.html#the-deep-layers-will-gradually-learn-more-abstract-features.",
    "title": "Modern ConvNets",
    "section": "4 The deep layers will gradually learn more abstract features.",
    "text": "4 The deep layers will gradually learn more abstract features.\n\n\n\n\nSlide 4"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#this-deep-lower-dimensional-space-learns-meaningful-structures",
    "href": "blog/2023-11-20_modern-convnets/index.html#this-deep-lower-dimensional-space-learns-meaningful-structures",
    "title": "Modern ConvNets",
    "section": "5 This deep, lower dimensional space learns meaningful structures",
    "text": "5 This deep, lower dimensional space learns meaningful structures\n\n\n\n\nSlide 5"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#what-do-the-different-layers-in-a-deep-neural-network-learn",
    "href": "blog/2023-11-20_modern-convnets/index.html#what-do-the-different-layers-in-a-deep-neural-network-learn",
    "title": "Modern ConvNets",
    "section": "7 What do the different layers in a deep neural network learn",
    "text": "7 What do the different layers in a deep neural network learn\n\n\n\n\nSlide 7"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#what-do-the-different-layers-in-a-deep-neural-network-learn-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#what-do-the-different-layers-in-a-deep-neural-network-learn-1",
    "title": "Modern ConvNets",
    "section": "7 What do the different layers in a deep neural network learn",
    "text": "7 What do the different layers in a deep neural network learn\n\n\n\n\nSlide 7"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#how-do-these-layers-correspond-to-semantics-numerical-evaluation",
    "href": "blog/2023-11-20_modern-convnets/index.html#how-do-these-layers-correspond-to-semantics-numerical-evaluation",
    "title": "Modern ConvNets",
    "section": "8 How do these layers correspond to “semantics”: numerical evaluation",
    "text": "8 How do these layers correspond to “semantics”: numerical evaluation\n\n\n\n\nSlide 8"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#lets-wake-up-summarize-the-last-few-minutes-to-your-neighbor.",
    "href": "blog/2023-11-20_modern-convnets/index.html#lets-wake-up-summarize-the-last-few-minutes-to-your-neighbor.",
    "title": "Modern ConvNets",
    "section": "9 . Let’s wake up: Summarize the last few minutes to your neighbor. |",
    "text": "9 . Let’s wake up: Summarize the last few minutes to your neighbor. |\n\n\n\n\nSlide 9"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#x1-convolution-a-computationally-cheap-method",
    "href": "blog/2023-11-20_modern-convnets/index.html#x1-convolution-a-computationally-cheap-method",
    "title": "Modern ConvNets",
    "section": "10 1x1 Convolution: a computationally cheap method",
    "text": "10 1x1 Convolution: a computationally cheap method\nLast time a\n\n\n\n\nSlide 10"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#x1-convolution-a-computationally-cheap-method-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#x1-convolution-a-computationally-cheap-method-1",
    "title": "Modern ConvNets",
    "section": "11 1x1 Convolution: a computationally cheap method",
    "text": "11 1x1 Convolution: a computationally cheap method\nO d a e o Eg 28x28x192 -&gt; 24x24x32 | 5X5 e —10008V, eee —l | |\n\n\n\n\nSlide 11"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#convnet-configuration",
    "href": "blog/2023-11-20_modern-convnets/index.html#convnet-configuration",
    "title": "Modern ConvNets",
    "section": "12 ConvNet Configuration",
    "text": "12 ConvNet Configuration\nAIRN] B [| C | D 7 —£ |\n11 weight | 11 weight | 13 weight | 16 weight 16 weight | 19 weight\nTacenern lace Tan&lt;ce nee Tacenee Tacs Ta&lt;ceneern\n\n\n\n\nSlide 12"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#vggi16",
    "href": "blog/2023-11-20_modern-convnets/index.html#vggi16",
    "title": "Modern ConvNets",
    "section": "13 VGGI16",
    "text": "13 VGGI16\n\n\n\n\nSlide 13"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#characteristics",
    "href": "blog/2023-11-20_modern-convnets/index.html#characteristics",
    "title": "Modern ConvNets",
    "section": "14 Characteristics",
    "text": "14 Characteristics\n\n\n\n\nSlide 14"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#why-3x3-filters",
    "href": "blog/2023-11-20_modern-convnets/index.html#why-3x3-filters",
    "title": "Modern ConvNets",
    "section": "15 Why 3x3 filters?",
    "text": "15 Why 3x3 filters?\n\n\n\n\nSlide 15"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#why-3x3-filters-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#why-3x3-filters-1",
    "title": "Modern ConvNets",
    "section": "16 Why 3x3 filters?",
    "text": "16 Why 3x3 filters?\n\n\n\n\nSlide 16"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#why-3x3-filters-2",
    "href": "blog/2023-11-20_modern-convnets/index.html#why-3x3-filters-2",
    "title": "Modern ConvNets",
    "section": "17 Why 3x3 filters?",
    "text": "17 Why 3x3 filters?\n\n\n\n\nSlide 17"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#why-3x3-filters-3",
    "href": "blog/2023-11-20_modern-convnets/index.html#why-3x3-filters-3",
    "title": "Modern ConvNets",
    "section": "18 Why 3x3 filters?",
    "text": "18 Why 3x3 filters?\n\n\n\n\nSlide 18"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#even-smaller-filters",
    "href": "blog/2023-11-20_modern-convnets/index.html#even-smaller-filters",
    "title": "Modern ConvNets",
    "section": "19 Even smaller filters?",
    "text": "19 Even smaller filters?\n\n\n\n\nSlide 19"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#overall-shapes-and-sizes-when-inputting-a-224x224-image",
    "href": "blog/2023-11-20_modern-convnets/index.html#overall-shapes-and-sizes-when-inputting-a-224x224-image",
    "title": "Modern ConvNets",
    "section": "20 Overall shapes and sizes when inputting a 224x224 image:",
    "text": "20 Overall shapes and sizes when inputting a 224x224 image:\n\n\n\n\nSlide 20"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#training",
    "href": "blog/2023-11-20_modern-convnets/index.html#training",
    "title": "Modern ConvNets",
    "section": "21 Training",
    "text": "21 Training\n\n\n\n\nSlide 21"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#feature-maps",
    "href": "blog/2023-11-20_modern-convnets/index.html#feature-maps",
    "title": "Modern ConvNets",
    "section": "22 Feature maps",
    "text": "22 Feature maps\n\n\n\n\nSlide 22"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#filters",
    "href": "blog/2023-11-20_modern-convnets/index.html#filters",
    "title": "Modern ConvNets",
    "section": "23 Filters",
    "text": "23 Filters\n\n\n\n\nSlide 23"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#class-outputs",
    "href": "blog/2023-11-20_modern-convnets/index.html#class-outputs",
    "title": "Modern ConvNets",
    "section": "24 Class Outputs",
    "text": "24 Class Outputs\n\n\n\n\nSlide 24"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#title-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#title-1",
    "title": "Modern ConvNets",
    "section": "25 Title",
    "text": "25 Title\n\n\n\n\nSlide 25"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#basic-idea",
    "href": "blog/2023-11-20_modern-convnets/index.html#basic-idea",
    "title": "Modern ConvNets",
    "section": "26 Basic idea",
    "text": "26 Basic idea\n\n\n\n\nSlide 26"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#basic-idea-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#basic-idea-1",
    "title": "Modern ConvNets",
    "section": "27 Basic idea",
    "text": "27 Basic idea\n\n\n\n\nSlide 27"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#inception-module",
    "href": "blog/2023-11-20_modern-convnets/index.html#inception-module",
    "title": "Modern ConvNets",
    "section": "28 Inception module",
    "text": "28 Inception module\n\n\n\n\nSlide 28"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#inception-module-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#inception-module-1",
    "title": "Modern ConvNets",
    "section": "29 Inception module",
    "text": "29 Inception module\n\n\n\n\nSlide 29"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#architecture",
    "href": "blog/2023-11-20_modern-convnets/index.html#architecture",
    "title": "Modern ConvNets",
    "section": "30 Architecture",
    "text": "30 Architecture\n\n\n\n\nSlide 30"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#architecture-the-inception-module",
    "href": "blog/2023-11-20_modern-convnets/index.html#architecture-the-inception-module",
    "title": "Modern ConvNets",
    "section": "31 Architecture: the “Inception” module",
    "text": "31 Architecture: the “Inception” module\n\n\n\n\nSlide 31"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#architecture-the-auxiliary-classifier-idea",
    "href": "blog/2023-11-20_modern-convnets/index.html#architecture-the-auxiliary-classifier-idea",
    "title": "Modern ConvNets",
    "section": "32 Architecture: the auxiliary classifier idea",
    "text": "32 Architecture: the auxiliary classifier idea\n\n\n\n\nSlide 32"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#why-aux-classifiers-vanishing-gradients",
    "href": "blog/2023-11-20_modern-convnets/index.html#why-aux-classifiers-vanishing-gradients",
    "title": "Modern ConvNets",
    "section": "33 Why aux classifiers? Vanishing gradients",
    "text": "33 Why aux classifiers? Vanishing gradients\n\n\n\n\nSlide 33"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#architecture-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#architecture-1",
    "title": "Modern ConvNets",
    "section": "34 Architecture",
    "text": "34 Architecture\n\n\n\n\nSlide 34"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#inceptions-v2-v3-v4-.",
    "href": "blog/2023-11-20_modern-convnets/index.html#inceptions-v2-v3-v4-.",
    "title": "Modern ConvNets",
    "section": "35 Inceptions v2, v3, V4, ….",
    "text": "35 Inceptions v2, v3, V4, ….\n\n\n\n\nSlide 35"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#title-2",
    "href": "blog/2023-11-20_modern-convnets/index.html#title-2",
    "title": "Modern ConvNets",
    "section": "36 Title",
    "text": "36 Title\n\n\n\n\nSlide 36"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#alexnet-2012",
    "href": "blog/2023-11-20_modern-convnets/index.html#alexnet-2012",
    "title": "Modern ConvNets",
    "section": "37 AlexNet (2012)",
    "text": "37 AlexNet (2012)\n\n\n\n\nSlide 37"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#evolution",
    "href": "blog/2023-11-20_modern-convnets/index.html#evolution",
    "title": "Modern ConvNets",
    "section": "38 Evolution",
    "text": "38 Evolution\n\n\n\n\nSlide 38"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#title-3",
    "href": "blog/2023-11-20_modern-convnets/index.html#title-3",
    "title": "Modern ConvNets",
    "section": "39 Title",
    "text": "39 Title\n\n\n\n\nSlide 39"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#evolution-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#evolution-1",
    "title": "Modern ConvNets",
    "section": "40 Evolution",
    "text": "40 Evolution\n\n\n\n\nSlide 40"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#evolution-2",
    "href": "blog/2023-11-20_modern-convnets/index.html#evolution-2",
    "title": "Modern ConvNets",
    "section": "41 Evolution",
    "text": "41 Evolution\n\n\n\n\nSlide 41"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#why-care-about-architectures-heres-why",
    "href": "blog/2023-11-20_modern-convnets/index.html#why-care-about-architectures-heres-why",
    "title": "Modern ConvNets",
    "section": "42 Why care about architectures… here’s why:",
    "text": "42 Why care about architectures… here’s why:\n\n\n\n\nSlide 42"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#some-facts-about-resnets",
    "href": "blog/2023-11-20_modern-convnets/index.html#some-facts-about-resnets",
    "title": "Modern ConvNets",
    "section": "43 Some facts about ResNets",
    "text": "43 Some facts about ResNets\n\n\n\n\nSlide 43"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#hypothesis",
    "href": "blog/2023-11-20_modern-convnets/index.html#hypothesis",
    "title": "Modern ConvNets",
    "section": "44 Hypothesis",
    "text": "44 Hypothesis\n\n\n\n\nSlide 44"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#hypothesis-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#hypothesis-1",
    "title": "Modern ConvNets",
    "section": "45 Hypothesis",
    "text": "45 Hypothesis\n\n\n\n\nSlide 45"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#hypothesis-2",
    "href": "blog/2023-11-20_modern-convnets/index.html#hypothesis-2",
    "title": "Modern ConvNets",
    "section": "46 Hypothesis",
    "text": "46 Hypothesis\n\n\n\n\nSlide 46"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#however-when-trained-the-deeper-network-has-higher-training-error",
    "href": "blog/2023-11-20_modern-convnets/index.html#however-when-trained-the-deeper-network-has-higher-training-error",
    "title": "Modern ConvNets",
    "section": "47 However, when trained the deeper network has higher training error",
    "text": "47 However, when trained the deeper network has higher training error\n\n\n\n\nSlide 47"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#testing-the-hypothesis",
    "href": "blog/2023-11-20_modern-convnets/index.html#testing-the-hypothesis",
    "title": "Modern ConvNets",
    "section": "48 Testing the hypothesis",
    "text": "48 Testing the hypothesis\n\n\n\n\nSlide 48"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#observation",
    "href": "blog/2023-11-20_modern-convnets/index.html#observation",
    "title": "Modern ConvNets",
    "section": "49 Observation",
    "text": "49 Observation\n\n\n\n\nSlide 49"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#the-residual-idea-intuitively",
    "href": "blog/2023-11-20_modern-convnets/index.html#the-residual-idea-intuitively",
    "title": "Modern ConvNets",
    "section": "50 The “residual idea”, intuitively",
    "text": "50 The “residual idea”, intuitively\n\n\n\n\nSlide 50"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#the-residual-block",
    "href": "blog/2023-11-20_modern-convnets/index.html#the-residual-block",
    "title": "Modern ConvNets",
    "section": "51 The residual block",
    "text": "51 The residual block\n\n\n\n\nSlide 51"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#no-degradation-anymore",
    "href": "blog/2023-11-20_modern-convnets/index.html#no-degradation-anymore",
    "title": "Modern ConvNets",
    "section": "52 No degradation anymore",
    "text": "52 No degradation anymore\n\n\n\n\nSlide 52"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#resnet-breaks-records",
    "href": "blog/2023-11-20_modern-convnets/index.html#resnet-breaks-records",
    "title": "Modern ConvNets",
    "section": "53 ResNet breaks records",
    "text": "53 ResNet breaks records\n\n\n\n\nSlide 53"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#resnet-variants-resnext-resnext",
    "href": "blog/2023-11-20_modern-convnets/index.html#resnet-variants-resnext-resnext",
    "title": "Modern ConvNets",
    "section": "54 _ResNet variants & ResNeXt | ResNext",
    "text": "54 _ResNet variants & ResNeXt | ResNext\n\n\n\n\nSlide 54"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#some-observations",
    "href": "blog/2023-11-20_modern-convnets/index.html#some-observations",
    "title": "Modern ConvNets",
    "section": "55 Some observations",
    "text": "55 Some observations\n\n\n\n\nSlide 55"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#quiz-on-the-right-you-see-the",
    "href": "blog/2023-11-20_modern-convnets/index.html#quiz-on-the-right-you-see-the",
    "title": "Modern ConvNets",
    "section": "56 . Quiz: On the right you see the ;",
    "text": "56 . Quiz: On the right you see the ;\n\n\n\n\nSlide 56"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#highwaynet-slightly-earlier-than-resnets-in-2015",
    "href": "blog/2023-11-20_modern-convnets/index.html#highwaynet-slightly-earlier-than-resnets-in-2015",
    "title": "Modern ConvNets",
    "section": "57 HighwayNet (slightly earlier than ResNets in 2015)",
    "text": "57 HighwayNet (slightly earlier than ResNets in 2015)\n\n\n\n\nSlide 57"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#densenet",
    "href": "blog/2023-11-20_modern-convnets/index.html#densenet",
    "title": "Modern ConvNets",
    "section": "58 DenseNet",
    "text": "58 DenseNet\n\n\n\n\nSlide 58"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#densenet-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#densenet-1",
    "title": "Modern ConvNets",
    "section": "59 DenseNet",
    "text": "59 DenseNet\n\n\n\n\nSlide 59"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#densenet-2",
    "href": "blog/2023-11-20_modern-convnets/index.html#densenet-2",
    "title": "Modern ConvNets",
    "section": "60 DenseNet",
    "text": "60 DenseNet\n\n\n\n\nSlide 60"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#densenets",
    "href": "blog/2023-11-20_modern-convnets/index.html#densenets",
    "title": "Modern ConvNets",
    "section": "61 DenseNets",
    "text": "61 DenseNets\n\n\n\n\nSlide 61"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#trend-has-not-stopped-with-densenet",
    "href": "blog/2023-11-20_modern-convnets/index.html#trend-has-not-stopped-with-densenet",
    "title": "Modern ConvNets",
    "section": "62 Trend has not stopped with DenseNet",
    "text": "62 Trend has not stopped with DenseNet\n\n\n\n\nSlide 62"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#mobilenets-depthwise-convolutions-for-high-latency",
    "href": "blog/2023-11-20_modern-convnets/index.html#mobilenets-depthwise-convolutions-for-high-latency",
    "title": "Modern ConvNets",
    "section": "63 MobileNets: Depthwise convolutions for high latency",
    "text": "63 MobileNets: Depthwise convolutions for high latency\n\n\n\n\nSlide 63"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#bagnet-solving-imagenet-with-tiny-9x9-sized-puzzle-pieces",
    "href": "blog/2023-11-20_modern-convnets/index.html#bagnet-solving-imagenet-with-tiny-9x9-sized-puzzle-pieces",
    "title": "Modern ConvNets",
    "section": "64 BagNet: Solving ImageNet with tiny 9x9 sized puzzle pieces?",
    "text": "64 BagNet: Solving ImageNet with tiny 9x9 sized puzzle pieces?\n\n\n\n\nSlide 64"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#imagenet-mostly-textures",
    "href": "blog/2023-11-20_modern-convnets/index.html#imagenet-mostly-textures",
    "title": "Modern ConvNets",
    "section": "65 ImageNet: mostly textures?",
    "text": "65 ImageNet: mostly textures?\n\n\n\n\nSlide 65"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#how-research-gets-done-part-5",
    "href": "blog/2023-11-20_modern-convnets/index.html#how-research-gets-done-part-5",
    "title": "Modern ConvNets",
    "section": "66 How research gets done part 5",
    "text": "66 How research gets done part 5\nIsamu Akasaki: “As Thomas Edison said, ‘Genius is one percent inspiration and 99 perspiration.’ | say this to younger\n\n\n\n\nSlide 66"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#a.-_",
    "href": "blog/2023-11-20_modern-convnets/index.html#a.-_",
    "title": "Modern ConvNets",
    "section": "67 a. = _",
    "text": "67 a. = _\n\n\n\n\nSlide 67"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#region-based-convolutional-neural-network-r-cnn",
    "href": "blog/2023-11-20_modern-convnets/index.html#region-based-convolutional-neural-network-r-cnn",
    "title": "Modern ConvNets",
    "section": "68 Region-based Convolutional Neural Network (R-CNN)",
    "text": "68 Region-based Convolutional Neural Network (R-CNN)\n\n\n\n\nSlide 68"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#r-cnn",
    "href": "blog/2023-11-20_modern-convnets/index.html#r-cnn",
    "title": "Modern ConvNets",
    "section": "69 R-CNN",
    "text": "69 R-CNN\n\n\n\n\nSlide 69"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#improving-the-bounding-boxes",
    "href": "blog/2023-11-20_modern-convnets/index.html#improving-the-bounding-boxes",
    "title": "Modern ConvNets",
    "section": "70 Improving the Bounding Boxes",
    "text": "70 Improving the Bounding Boxes\n\n\n\n\nSlide 70"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#to-summarize",
    "href": "blog/2023-11-20_modern-convnets/index.html#to-summarize",
    "title": "Modern ConvNets",
    "section": "71 To summarize",
    "text": "71 To summarize\n\n\n\n\nSlide 71"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#r-cnn-is-really-quite-slow-for-a-few-simple-reasons",
    "href": "blog/2023-11-20_modern-convnets/index.html#r-cnn-is-really-quite-slow-for-a-few-simple-reasons",
    "title": "Modern ConvNets",
    "section": "72 R-CNN is really quite slow for a few simple reasons:",
    "text": "72 R-CNN is really quite slow for a few simple reasons:\n\n\n\n\nSlide 72"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#some-results",
    "href": "blog/2023-11-20_modern-convnets/index.html#some-results",
    "title": "Modern ConvNets",
    "section": "73 Some results",
    "text": "73 Some results\n\n\n\n\nSlide 73"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn",
    "href": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn",
    "title": "Modern ConvNets",
    "section": "74 Fast R-CNN",
    "text": "74 Fast R-CNN\n\n\n\n\nSlide 74"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn-insight-1-region-of-interest-pooling-roipool",
    "href": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn-insight-1-region-of-interest-pooling-roipool",
    "title": "Modern ConvNets",
    "section": "75 Fast R-CNN Insight 1: Region of Interest Pooling (ROIPool)",
    "text": "75 Fast R-CNN Insight 1: Region of Interest Pooling (ROIPool)\n\n\n\n\nSlide 75"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#region-of-interest-pooling-roipool",
    "href": "blog/2023-11-20_modern-convnets/index.html#region-of-interest-pooling-roipool",
    "title": "Modern ConvNets",
    "section": "76 Region of Interest Pooling (ROIPool)",
    "text": "76 Region of Interest Pooling (ROIPool)\n\n\n\n\nSlide 76"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#region-of-interest-pooling-roipool-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#region-of-interest-pooling-roipool-1",
    "title": "Modern ConvNets",
    "section": "77 Region of Interest Pooling (ROIPool)",
    "text": "77 Region of Interest Pooling (ROIPool)\n\n\n\n\nSlide 77"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#region-of-interest-pooling-roipool-2",
    "href": "blog/2023-11-20_modern-convnets/index.html#region-of-interest-pooling-roipool-2",
    "title": "Modern ConvNets",
    "section": "78 Region of Interest Pooling (ROIPool)",
    "text": "78 Region of Interest Pooling (ROIPool)\n\n\n\n\nSlide 78"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#region-of-interest-pooling-roipool-3",
    "href": "blog/2023-11-20_modern-convnets/index.html#region-of-interest-pooling-roipool-3",
    "title": "Modern ConvNets",
    "section": "79 Region of Interest Pooling (ROIPool)",
    "text": "79 Region of Interest Pooling (ROIPool)\n\n\n\n\nSlide 79"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn-insight-2-combine-all-models-into-one-network",
    "href": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn-insight-2-combine-all-models-into-one-network",
    "title": "Modern ConvNets",
    "section": "80 Fast R-CNN Insight 2: Combine All Models into One Network",
    "text": "80 Fast R-CNN Insight 2: Combine All Models into One Network\n\n\n\n\nSlide 80"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn-joint-training-framework",
    "href": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn-joint-training-framework",
    "title": "Modern ConvNets",
    "section": "81 Fast R-CNN: Joint training framework",
    "text": "81 Fast R-CNN: Joint training framework\n\n\n\n\nSlide 81"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn-steps",
    "href": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn-steps",
    "title": "Modern ConvNets",
    "section": "82 Fast R-CNN: Steps",
    "text": "82 Fast R-CNN: Steps\n\n\n\n\nSlide 82"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn-steps-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn-steps-1",
    "title": "Modern ConvNets",
    "section": "83 Fast R-CNN: Steps",
    "text": "83 Fast R-CNN: Steps\n\n\n\n\nSlide 83"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn-steps-2",
    "href": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn-steps-2",
    "title": "Modern ConvNets",
    "section": "84 Fast R-CNN: Steps",
    "text": "84 Fast R-CNN: Steps\n\n\n\n\nSlide 84"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn-steps-3",
    "href": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn-steps-3",
    "title": "Modern ConvNets",
    "section": "85 Fast R-CNN: Steps",
    "text": "85 Fast R-CNN: Steps\n\n\n\n\nSlide 85"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn-steps-4",
    "href": "blog/2023-11-20_modern-convnets/index.html#fast-r-cnn-steps-4",
    "title": "Modern ConvNets",
    "section": "86 Fast R-CNN: Steps",
    "text": "86 Fast R-CNN: Steps\n\n\n\n\nSlide 86"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#smart-training",
    "href": "blog/2023-11-20_modern-convnets/index.html#smart-training",
    "title": "Modern ConvNets",
    "section": "87 Smart training",
    "text": "87 Smart training\n\n\n\n\nSlide 87"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#some-results-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#some-results-1",
    "title": "Modern ConvNets",
    "section": "88 Some results",
    "text": "88 Some results\n\n\n\n\nSlide 88"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#fast-rcnn",
    "href": "blog/2023-11-20_modern-convnets/index.html#fast-rcnn",
    "title": "Modern ConvNets",
    "section": "89 Fast-RCNN",
    "text": "89 Fast-RCNN\n\n\n\n\nSlide 89"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#faster-r-cnn---speeding-up-region-proposal",
    "href": "blog/2023-11-20_modern-convnets/index.html#faster-r-cnn---speeding-up-region-proposal",
    "title": "Modern ConvNets",
    "section": "90 Faster R-CNN - Speeding Up Region Proposal",
    "text": "90 Faster R-CNN - Speeding Up Region Proposal\n\n\n\n\nSlide 90"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#faster-r-cnn",
    "href": "blog/2023-11-20_modern-convnets/index.html#faster-r-cnn",
    "title": "Modern ConvNets",
    "section": "91 Faster R-CNN",
    "text": "91 Faster R-CNN\n\n\n\n\nSlide 91"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#faster-r-cnn-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#faster-r-cnn-1",
    "title": "Modern ConvNets",
    "section": "92 Faster R-CNN",
    "text": "92 Faster R-CNN\n\n\n\n\nSlide 92"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#faster-r-cnn-girshick2016",
    "href": "blog/2023-11-20_modern-convnets/index.html#faster-r-cnn-girshick2016",
    "title": "Modern ConvNets",
    "section": "93 Faster R-CNN [Girshick2016]",
    "text": "93 Faster R-CNN [Girshick2016]\n\n\n\n\nSlide 93"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#mask-r-cnn",
    "href": "blog/2023-11-20_modern-convnets/index.html#mask-r-cnn",
    "title": "Modern ConvNets",
    "section": "94 Mask R-CNN",
    "text": "94 Mask R-CNN\n\n\n\n\nSlide 94"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#mask-r-cnn-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#mask-r-cnn-1",
    "title": "Modern ConvNets",
    "section": "95 Mask R-CNN",
    "text": "95 Mask R-CNN\n\n\n\n\nSlide 95"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#mask-r-cnn-2",
    "href": "blog/2023-11-20_modern-convnets/index.html#mask-r-cnn-2",
    "title": "Modern ConvNets",
    "section": "96 Mask R-CNN",
    "text": "96 Mask R-CNN\n\n\n\n\nSlide 96"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#roialign---realigning-roipool-to-be-more-accurate",
    "href": "blog/2023-11-20_modern-convnets/index.html#roialign---realigning-roipool-to-be-more-accurate",
    "title": "Modern ConvNets",
    "section": "97 RoIAlign - Realigning RoIPool to be More Accurate",
    "text": "97 RoIAlign - Realigning RoIPool to be More Accurate\n\n\n\n\nSlide 97"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#roialign---realigning-roipool-to-be-more-accurate-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#roialign---realigning-roipool-to-be-more-accurate-1",
    "title": "Modern ConvNets",
    "section": "98 RoIAlign - Realigning RoIPool to be More Accurate",
    "text": "98 RoIAlign - Realigning RoIPool to be More Accurate\n\n\n\n\nSlide 98"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#section",
    "href": "blog/2023-11-20_modern-convnets/index.html#section",
    "title": "Modern ConvNets",
    "section": "99 99",
    "text": "99 99\nperson OO lumbrella.97\nroa 97 person.66 ia person 7” umbreta.26umbroia. 99 TF skateboard: ’ ) aoe\nutnbrella1.00.\n—-_ , ee Te gt\n\n\n\n\nSlide 99"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#becoming-fully-convolutional",
    "href": "blog/2023-11-20_modern-convnets/index.html#becoming-fully-convolutional",
    "title": "Modern ConvNets",
    "section": "100 Becoming fully convolutional",
    "text": "100 Becoming fully convolutional\n\n\n\n\nSlide 100"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#upsampling-the-output",
    "href": "blog/2023-11-20_modern-convnets/index.html#upsampling-the-output",
    "title": "Modern ConvNets",
    "section": "101 Upsampling the output",
    "text": "101 Upsampling the output\n\n\n\n\nSlide 101"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#deconvolution",
    "href": "blog/2023-11-20_modern-convnets/index.html#deconvolution",
    "title": "Modern ConvNets",
    "section": "102 “Deconvolution”",
    "text": "102 “Deconvolution”\n\n\n\n\nSlide 102"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#end-to-end-pixels-to-pixels-network",
    "href": "blog/2023-11-20_modern-convnets/index.html#end-to-end-pixels-to-pixels-network",
    "title": "Modern ConvNets",
    "section": "103 End-to-end, pixels-to-pixels network",
    "text": "103 End-to-end, pixels-to-pixels network\n\n\n\n\nSlide 103"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#end-to-end-pixels-to-pixels-network-1",
    "href": "blog/2023-11-20_modern-convnets/index.html#end-to-end-pixels-to-pixels-network-1",
    "title": "Modern ConvNets",
    "section": "104 End-to-end, pixels-to-pixels network",
    "text": "104 End-to-end, pixels-to-pixels network\n\n\n\n\nSlide 104"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#references",
    "href": "blog/2023-11-20_modern-convnets/index.html#references",
    "title": "Modern ConvNets",
    "section": "105 References",
    "text": "105 References\n\n\n\n\nSlide 105"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#start-with",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#start-with",
    "title": "Deep Learning Optimizations II",
    "section": "2 Start with",
    "text": "2 Start with\n\n\n\n\nSlide 5"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#quiz-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#quiz-1",
    "title": "Deep Learning Optimizations II",
    "section": "58 Quiz",
    "text": "58 Quiz\n\n\n\n\nSlide 61\n\n\n\n\nThere is no answer here"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#digression-gravitation",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#digression-gravitation",
    "title": "Deep Learning Optimizations II",
    "section": "4 Digression: Gravitation",
    "text": "4 Digression: Gravitation\n\n\n\n\nSlide 7"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#why-the-right-is-better",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#why-the-right-is-better",
    "title": "Deep Learning Optimizations II",
    "section": "4 Why the right is better?",
    "text": "4 Why the right is better?"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#l-regularization",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#l-regularization",
    "title": "Deep Learning Optimizations II",
    "section": "17 1) €l-regularization",
    "text": "17 1) €l-regularization\n\n\n\n\nSlide 20"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#l2-regularization",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#l2-regularization",
    "title": "Deep Learning Optimizations II",
    "section": "17 1) L2-regularization",
    "text": "17 1) L2-regularization\n\n\n\n\nSlide 20\n\n\n\n\nReferred to weight decay or Ritch regression in the linear case\nOmega is proportional to how large the weights are\nMinimizing this is also the same as if you assume a Gaussian prior on your weight, here you assume the weights are Gaussian distributed"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#l2-regularization-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#l2-regularization-1",
    "title": "Deep Learning Optimizations II",
    "section": "18 1) L2-regularization",
    "text": "18 1) L2-regularization\n\n18.1 L2 & L1 Formula\n\n\n\n\n\n\n\n\n\n\nL2 example Python\n\n\n\n\n\nThe L2 loss, also known as the Euclidean loss or Mean Squared Error (MSE), is a common loss function used in regression problems. It measures the average squared difference between the predicted values and the actual values.\nThe formula for L2 loss is given by:\n\\(L2\\_loss = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\\)\nWhere:\n\n\\(N\\) is the number of data points.\n\\(y_i\\) is the true (ground truth) value for the i-th data point.\n\\(\\hat{y}_i\\) is the predicted value for the i-th data point.\n\nHere’s a simple example in Python using NumPy:\n\n\nCode\nimport numpy as np\n\n# Generate some example data\ntrue_values = np.array([2, 4, 5, 4, 5])\npredicted_values = np.array([1.5, 3.5, 4.8, 4.2, 5.2])\n\n# Calculate L2 loss\nl2_loss = np.mean((true_values - predicted_values)**2)\n\nprint(\"L2 Loss:\", l2_loss)\n\n\nL2 Loss: 0.12400000000000003\n\n\nThe L2 loss is calculated by taking the mean of the squared differences between the true and predicted values. The smaller the L2 loss, the better the model’s predictions align with the true values.\n\n\n\n\n\n\n\nSlide 21\n\n\n\n\nLamda tells you how important the regularization is, if:\n\nLambda high then puts all the weights towards zero\nLambda is zero, then it learns the typical loss and do not care about regularization\n\nLambda during trainnig is fixed, if you want to find the best one you need to run lots of experiments"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#l1-regularization",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#l1-regularization",
    "title": "Deep Learning Optimizations II",
    "section": "19 2) L1-regularization",
    "text": "19 2) L1-regularization\n\n\n\n\nSlide 22\n\n\n\n\nIsotropics means is equal in all directions\nNow if you take the gradient of this, now if you take derivative of w, because you want to optimize then it end ups a 1/2. So you end up with a constant factor in the loss that keeps getting substracted. So what happens is that we end up substracting a constant to our weights.\nSo it substract a bit from the positive weights and adds a bit to the negative weights and pushed them towards zero"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#l1-regularization-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#l1-regularization-1",
    "title": "Deep Learning Optimizations II",
    "section": "20 2) L1-regularization",
    "text": "20 2) L1-regularization\n\n\n\n\nSlide 23\n\n\n\n\nL1 leads to sparce weights, so that means more weights will be closer to zero\nIf alpha here increases then that means weights become zero"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#normalization",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#normalization",
    "title": "Deep Learning Optimizations II",
    "section": "48 Normalization",
    "text": "48 Normalization\n\n\n\n\nSlide 51\n\n\n\n\nPutting data into a common shape without distorting tis shape"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#benefits-of-batch-normalization-1",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#benefits-of-batch-normalization-1",
    "title": "Deep Learning Optimizations II",
    "section": "57 Benefits of Batch normalization",
    "text": "57 Benefits of Batch normalization\n\n\n\n\nSlide 60\n\n\n\n\n\nTrain faster because all layers train similarly quickly\nAllows you to have high learning rates because you wont have vanishing or exploding gradients because everything is 0-1 distributed\nMakes weights easier to initialize, because you know everything will be between 0-1\nMake activations function sensible because all the activation functions have something special about zero\nHave added noise that comes from estimating the batch statistics, any noise that may help is regularization. Here the noise reduces overfitting and that acts as a regularization so that your model does not overfit.\nPut it simple: Noise Disrupts Patterns"
  },
  {
    "objectID": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#quiz-2",
    "href": "blog/2023-11-20_deep-learning-optimizations-ii/index.html#quiz-2",
    "title": "Deep Learning Optimizations II",
    "section": "72 Quiz",
    "text": "72 Quiz\n\n\n\n\nSlide 78\n\n\n\n\nWe do all of the above,\n\nIt is good that if the loss explode you check the individual values of the gradients,\nor was the batch size was so small that something could have affect it\nor was the learning rate too high that even a small batch it was not too but but the large learning rate was too big tha then it end up in a completely broken spot in the NNs"
  },
  {
    "objectID": "blog/2023-11-20_modern-convnets/index.html#what-do-the-different-layers-in-a-deep-neural-netwok-learn",
    "href": "blog/2023-11-20_modern-convnets/index.html#what-do-the-different-layers-in-a-deep-neural-netwok-learn",
    "title": "Modern ConvNets",
    "section": "6 What do the different layers in a deep neural netwok learn",
    "text": "6 What do the different layers in a deep neural netwok learn\n\n\n\n\nSlide 6"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#the-pooling-operations",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#the-pooling-operations",
    "title": "Convolutional Neural Networks",
    "section": "22 The pooling operations",
    "text": "22 The pooling operations\n\n\n\n\nSlide 22\n\n\n\n\nPooling functions are another way to incorporate prior knowledge. It aggregates the activations. This can be local or global\nYou can max pool, or average pool the activations in some rectangular neighborhood. It reduces the space size and improves the efficiency and it also increases robustness\nIt also incorporates invariance to translations, because it will not matter whether the 6 would be in that corner or so on so on\nAt the last step you could od average global pooling, and just have one vector out, and in this vector will be trained to represent the whole image. Here you could apply a fully connected layer if you care classification\nMin, max all are differentiable. If you instead would have and argmax then it will not be differentiable\nSo pooling operations like the global ones, also allow you to be independent in which input image you feed into your NN"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-4",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-4",
    "title": "Convolutional Neural Networks",
    "section": "30 3D Activations",
    "text": "30 3D Activations\n\n\n\n\nSlide 38\n\n\n\n\n\n\n30.1 Example: Not-moving Filter\n\n\n\n\nHere we have:\n\nInput Layer: 3x32x32\nKernel 5-size: 3x5x5\n\nIf we do not slide the filter then we are gonna end up with:\n\nPre-output: 3x1x1 (three scalar values per each channel)\n\nNow we do a summation over the three channels and we have thus:\n\nOutput: 1x1x1\n\n\n\n30.2 Example: Sliding Filter\n \nImagine now that we slide this 3D filter along all the input layer, then we end up:\n\nPre-ouput: 3x(28)x(28), where we compute (width - kernel_size + 1) = (32-5+1)\n\nNow we sum over all three channel element wise and end up with:\n\nOutput: 1x28x28"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-5",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-5",
    "title": "Convolutional Neural Networks",
    "section": "31 3D Activations",
    "text": "31 3D Activations\n\n\n\n\nSlide 42"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-6",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-6",
    "title": "Convolutional Neural Networks",
    "section": "32 3D Activations",
    "text": "32 3D Activations\n\n\n\n\nSlide 44"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-7",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-7",
    "title": "Convolutional Neural Networks",
    "section": "33 3D Activations",
    "text": "33 3D Activations\n\n\n\n\nSlide 45\n\n\n\n\nIf you now slide the filter with as many neurons we will get:\n\nOuput: depth x (\\(l\\)) x (\\(l\\))\n\nWhere \\(l\\) = width - kernel_size + 1"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-8",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-8",
    "title": "Convolutional Neural Networks",
    "section": "34 3D Activations",
    "text": "34 3D Activations\n\n\n\n\nSlide 47"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-9",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-9",
    "title": "Convolutional Neural Networks",
    "section": "35 3D Activations",
    "text": "35 3D Activations\n\n\n\n\nSlide 50"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-10",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-10",
    "title": "Convolutional Neural Networks",
    "section": "36 3D Activations",
    "text": "36 3D Activations\n\n\n\n\nSlide 52"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-11",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-11",
    "title": "Convolutional Neural Networks",
    "section": "37 3D Activations",
    "text": "37 3D Activations\n\n\n\n\nSlide 53"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-12",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-12",
    "title": "Convolutional Neural Networks",
    "section": "38 3D Activations",
    "text": "38 3D Activations\n\n\n\n\nSlide 54"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-13",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-13",
    "title": "Convolutional Neural Networks",
    "section": "39 3D Activations",
    "text": "39 3D Activations\n\n\n\n\nSlide 55"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-14",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-14",
    "title": "Convolutional Neural Networks",
    "section": "40 3D Activations",
    "text": "40 3D Activations\n\n\n\n\nSlide 56"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-15",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-15",
    "title": "Convolutional Neural Networks",
    "section": "41 3D Activations",
    "text": "41 3D Activations\n\n\n\n\nSlide 56"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-16",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-16",
    "title": "Convolutional Neural Networks",
    "section": "43 3D Activations",
    "text": "43 3D Activations\n\n\n\n\nSlide 56"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-17",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-17",
    "title": "Convolutional Neural Networks",
    "section": "44 3D Activations",
    "text": "44 3D Activations\n\n\n\n\nSlide 56"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-18",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-18",
    "title": "Convolutional Neural Networks",
    "section": "44 3D Activations",
    "text": "44 3D Activations\n\n\n\n\nSlide 56"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-19",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-19",
    "title": "Convolutional Neural Networks",
    "section": "45 3D Activations",
    "text": "45 3D Activations\n\n\n\n\nSlide 56"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-20",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-20",
    "title": "Convolutional Neural Networks",
    "section": "46 3D Activations",
    "text": "46 3D Activations\n\n\n\n\nSlide 56"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-21",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-21",
    "title": "Convolutional Neural Networks",
    "section": "47 3D Activations",
    "text": "47 3D Activations\n\n\n\n\nSlide 55"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-22",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-22",
    "title": "Convolutional Neural Networks",
    "section": "48 3D Activations",
    "text": "48 3D Activations\n\n\n\n\nSlide 56"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-23",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-23",
    "title": "Convolutional Neural Networks",
    "section": "49 3D Activations",
    "text": "49 3D Activations\n\n\n\n\nSlide 56"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-24",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-24",
    "title": "Convolutional Neural Networks",
    "section": "50 3D Activations",
    "text": "50 3D Activations\n\n\n\n\nSlide 56"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-25",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-25",
    "title": "Convolutional Neural Networks",
    "section": "51 3D Activations",
    "text": "51 3D Activations\n\n\n\n\nSlide 56"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-26",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#d-activations-26",
    "title": "Convolutional Neural Networks",
    "section": "52 3D Activations",
    "text": "52 3D Activations\n\n\n\n\nSlide 56"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-vs-pooling-in-2d",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#convolution-vs-pooling-in-2d",
    "title": "Convolutional Neural Networks",
    "section": "21 Convolution vs Pooling in 2D",
    "text": "21 Convolution vs Pooling in 2D"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#quiz-2",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#quiz-2",
    "title": "Convolutional Neural Networks",
    "section": "74 Quiz",
    "text": "74 Quiz\n\n\n\n\nSlide 94\n\n\n\n\nIf you choose the kernel size to be the same as the input image then it is fully connected.\nMathematically 1\nImplementation wise 2"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#max-pooling",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#max-pooling",
    "title": "Convolutional Neural Networks",
    "section": "71 Max Pooling",
    "text": "71 Max Pooling\n\n\n\n\nSlide 88"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#how-research-gets-done-part-4",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#how-research-gets-done-part-4",
    "title": "Convolutional Neural Networks",
    "section": "75 How research gets done part 4",
    "text": "75 How research gets done part 4\n\n\n\n\nSlide 95\n\n\n\n\n\n\n\n\nSlide 96"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#how-to-fine-tune-a8-go-ue",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#how-to-fine-tune-a8-go-ue",
    "title": "Convolutional Neural Networks",
    "section": "104 How to fine-tune? a8? go ue",
    "text": "104 How to fine-tune? a8? go ue\n\n\n\n\nSlide 126"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#how-to-fine-tune",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#how-to-fine-tune",
    "title": "Convolutional Neural Networks",
    "section": "104 How to fine-tune?",
    "text": "104 How to fine-tune?\n\n\n\n\nSlide 126"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#solution-ii-use-h-as-a-feature-extractor-for-ht",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#solution-ii-use-h-as-a-feature-extractor-for-ht",
    "title": "Convolutional Neural Networks",
    "section": "105 Solution II: Use h, as a feature extractor for hT",
    "text": "105 Solution II: Use h, as a feature extractor for hT\n\n\n\n\nSlide 127"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#solution-i-fine-tune-ht-using-hg-as-initialization",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#solution-i-fine-tune-ht-using-hg-as-initialization",
    "title": "Convolutional Neural Networks",
    "section": "101 Solution I: Fine-tune hT using hg as initialization",
    "text": "101 Solution I: Fine-tune hT using hg as initialization\n\n\n\n\nSlide 123"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#solution-i-fine-tune-ht-using-hs-as-initialization",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#solution-i-fine-tune-ht-using-hs-as-initialization",
    "title": "Convolutional Neural Networks",
    "section": "101 Solution I: Fine-tune hT using hS as initialization",
    "text": "101 Solution I: Fine-tune hT using hS as initialization\n\n\n\n\nSlide 123"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#initializing-ht-with-hs",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#initializing-ht-with-hs",
    "title": "Convolutional Neural Networks",
    "section": "102 Initializing hT with hS",
    "text": "102 Initializing hT with hS\n\n\n\n\nSlide 124\n\n\n\n\nImagnet, it outputs 1000 categories. If you want to classification for 30 categories then you need to throw that one away and restart training a new classifier to your needs\nAlexNet, you can start removing some layers depending on how much data you have"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#initializing-ht-with-hs-1",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#initializing-ht-with-hs-1",
    "title": "Convolutional Neural Networks",
    "section": "103 Initializing hT with hS",
    "text": "103 Initializing hT with hS\n\n\n\n\nSlide 125\n\n\n\n\nif you pertained your NN in ImgNet and now you want to do Satalite classification then it may be usefull to find tune even those layers the bottom ones"
  },
  {
    "objectID": "blog/2023-11-20_convolutional-neural-networks/index.html#solution-ii-use-hs-as-a-feature-extractor-for-ht",
    "href": "blog/2023-11-20_convolutional-neural-networks/index.html#solution-ii-use-hs-as-a-feature-extractor-for-ht",
    "title": "Convolutional Neural Networks",
    "section": "105 Solution II: Use hS, as a feature extractor for hT",
    "text": "105 Solution II: Use hS, as a feature extractor for hT\n\n\n\n\nSlide 127"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html",
    "title": "Lexical semantics and word embeddings",
    "section": "",
    "text": "Description of this Post\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                NLP\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                NLP\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          November 22, 2023"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#title",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#title",
    "title": "Lexical semantics and word embeddings",
    "section": "1 Title",
    "text": "1 Title\n\n\n\n\nSlide 1"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#outline.",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#outline.",
    "title": "Lexical semantics and word embeddings",
    "section": "2 Outline.",
    "text": "2 Outline.\n\n\n\n\nSlide 2"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#semantics",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#semantics",
    "title": "Lexical semantics and word embeddings",
    "section": "3 Semantics",
    "text": "3 Semantics\n\n\n\n\nSlide 3"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#what-is-lexical-meaning",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#what-is-lexical-meaning",
    "title": "Lexical semantics and word embeddings",
    "section": "4 What is lexical meaning?",
    "text": "4 What is lexical meaning?\n\n\n\n\nSlide 4"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#how-to-approach-lexical-meaning",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#how-to-approach-lexical-meaning",
    "title": "Lexical semantics and word embeddings",
    "section": "5 How to approach lexical meaning?",
    "text": "5 How to approach lexical meaning?\n\n\n\n\nSlide 5"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#how-to-approach-lexical-meaning-1",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#how-to-approach-lexical-meaning-1",
    "title": "Lexical semantics and word embeddings",
    "section": "6 How to approach lexical meaning?",
    "text": "6 How to approach lexical meaning?\n\n\n\n\nSlide 6"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#prototype-theory",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#prototype-theory",
    "title": "Lexical semantics and word embeddings",
    "section": "7 Prototype theory",
    "text": "7 Prototype theory\n\n\n\n\nSlide 7"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#semantic-relations",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#semantic-relations",
    "title": "Lexical semantics and word embeddings",
    "section": "8 Semantic relations",
    "text": "8 Semantic relations\n\n\n\n\nSlide 8"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#other-semantic-relations",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#other-semantic-relations",
    "title": "Lexical semantics and word embeddings",
    "section": "9 Other semantic relations",
    "text": "9 Other semantic relations\n\n\n\n\nSlide 9"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#polysemy-and-word-senses",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#polysemy-and-word-senses",
    "title": "Lexical semantics and word embeddings",
    "section": "10 Polysemy and word senses",
    "text": "10 Polysemy and word senses\n\n\n\n\nSlide 10"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#polysemy",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#polysemy",
    "title": "Lexical semantics and word embeddings",
    "section": "11 Polysemy",
    "text": "11 Polysemy\n\n\n\n\nSlide 11"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#outline.-1",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#outline.-1",
    "title": "Lexical semantics and word embeddings",
    "section": "12 Outline.",
    "text": "12 Outline.\n\n\n\n\nSlide 12"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distributional-hypothesis",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distributional-hypothesis",
    "title": "Lexical semantics and word embeddings",
    "section": "13 Distributional hypothesis",
    "text": "13 Distributional hypothesis\n\n\n\n\nSlide 13"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distributional-hypothesis-1",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distributional-hypothesis-1",
    "title": "Lexical semantics and word embeddings",
    "section": "14 Distributional hypothesis",
    "text": "14 Distributional hypothesis\n\n\n\n\nSlide 14"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distributional-hypothesis-2",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distributional-hypothesis-2",
    "title": "Lexical semantics and word embeddings",
    "section": "15 Distributional hypothesis",
    "text": "15 Distributional hypothesis\n\n\n\n\nSlide 15"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distributional-hypothesis-3",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distributional-hypothesis-3",
    "title": "Lexical semantics and word embeddings",
    "section": "16 Distributional hypothesis",
    "text": "16 Distributional hypothesis\n\n\n\n\nSlide 16"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distributional-hypothesis-4",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distributional-hypothesis-4",
    "title": "Lexical semantics and word embeddings",
    "section": "17 Distributional hypothesis",
    "text": "17 Distributional hypothesis\n\n\n\n\nSlide 17"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#scrumpy",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#scrumpy",
    "title": "Lexical semantics and word embeddings",
    "section": "18 Scrumpy",
    "text": "18 Scrumpy\n\n\n\n\nSlide 18"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distributional-hypothesis-5",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distributional-hypothesis-5",
    "title": "Lexical semantics and word embeddings",
    "section": "19 Distributional hypothesis",
    "text": "19 Distributional hypothesis\n\n\n\n\nSlide 19"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#the-general-intuition",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#the-general-intuition",
    "title": "Lexical semantics and word embeddings",
    "section": "20 The general intuition",
    "text": "20 The general intuition\n\n\n\n\nSlide 20"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#vectors",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#vectors",
    "title": "Lexical semantics and word embeddings",
    "section": "21 Vectors",
    "text": "21 Vectors\n\n\n\n\nSlide 21"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#the-notion-of-context",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#the-notion-of-context",
    "title": "Lexical semantics and word embeddings",
    "section": "22 The notion of context",
    "text": "22 The notion of context\n\n\n\n\nSlide 22"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#context",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#context",
    "title": "Lexical semantics and word embeddings",
    "section": "23 Context",
    "text": "23 Context\n\n\n\n\nSlide 23"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#context-1",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#context-1",
    "title": "Lexical semantics and word embeddings",
    "section": "24 Context",
    "text": "24 Context\n\n\n\n\nSlide 24"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#context-2",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#context-2",
    "title": "Lexical semantics and word embeddings",
    "section": "25 Context",
    "text": "25 Context\n\n\n\n\nSlide 25"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#context-weighting",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#context-weighting",
    "title": "Lexical semantics and word embeddings",
    "section": "26 Context weighting",
    "text": "26 Context weighting\n\n\n\n\nSlide 26"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#characteristic-model",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#characteristic-model",
    "title": "Lexical semantics and word embeddings",
    "section": "27 Characteristic model",
    "text": "27 Characteristic model\n\n\n\n\nSlide 27"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#what-semantic-space",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#what-semantic-space",
    "title": "Lexical semantics and word embeddings",
    "section": "28 What semantic space?",
    "text": "28 What semantic space?\n\n\n\n\nSlide 28"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#word-frequency-zipfian-distribution",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#word-frequency-zipfian-distribution",
    "title": "Lexical semantics and word embeddings",
    "section": "29 Word frequency: Zipfian distribution",
    "text": "29 Word frequency: Zipfian distribution\n\n\n\n\nSlide 29"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#what-semantic-space-1",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#what-semantic-space-1",
    "title": "Lexical semantics and word embeddings",
    "section": "30 What semantic space?",
    "text": "30 What semantic space?\n\n\n\n\nSlide 30"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#an-example-noun",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#an-example-noun",
    "title": "Lexical semantics and word embeddings",
    "section": "31 An example noun",
    "text": "31 An example noun\n\n\n\n\nSlide 31"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#an-example-adjective",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#an-example-adjective",
    "title": "Lexical semantics and word embeddings",
    "section": "32 An example adjective",
    "text": "32 An example adjective\n\n\n\n\nSlide 32"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#polysemy-1",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#polysemy-1",
    "title": "Lexical semantics and word embeddings",
    "section": "33 Polysemy",
    "text": "33 Polysemy\n\n\n\n\nSlide 33"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#calculating-similarity-in-a-distributional-space",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#calculating-similarity-in-a-distributional-space",
    "title": "Lexical semantics and word embeddings",
    "section": "34 Calculating similarity in a distributional space",
    "text": "34 Calculating similarity in a distributional space\n\n\n\n\nSlide 34"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#measuring-similarity",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#measuring-similarity",
    "title": "Lexical semantics and word embeddings",
    "section": "35 Measuring similarity",
    "text": "35 Measuring similarity\n\n\n\n\nSlide 35"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#the-scale-of-similarity-some-examples",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#the-scale-of-similarity-some-examples",
    "title": "Lexical semantics and word embeddings",
    "section": "36 The scale of similarity: some examples",
    "text": "36 The scale of similarity: some examples\n\n\n\n\nSlide 36"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#words-most-similar-to-cat",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#words-most-similar-to-cat",
    "title": "Lexical semantics and word embeddings",
    "section": "37 Words most similar to cat",
    "text": "37 Words most similar to cat\n\n\n\n\nSlide 37"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#but-what-is-similarity",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#but-what-is-similarity",
    "title": "Lexical semantics and word embeddings",
    "section": "38 But what is similarity?",
    "text": "38 But what is similarity?\n\n\n\n\nSlide 38"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distributional-methods-are-a-usage-representation",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distributional-methods-are-a-usage-representation",
    "title": "Lexical semantics and word embeddings",
    "section": "39 Distributional methods are a usage representation",
    "text": "39 Distributional methods are a usage representation\n\n\n\n\nSlide 39"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distribution-for-policeman",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distribution-for-policeman",
    "title": "Lexical semantics and word embeddings",
    "section": "40 Distribution for policeman",
    "text": "40 Distribution for policeman\n\n\n\n\nSlide 40"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distribution-for-cop",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distribution-for-cop",
    "title": "Lexical semantics and word embeddings",
    "section": "41 Distribution for cop",
    "text": "41 Distribution for cop\n\n\n\n\nSlide 41"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#clustering-nouns",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#clustering-nouns",
    "title": "Lexical semantics and word embeddings",
    "section": "42 Clustering nouns",
    "text": "42 Clustering nouns\n\n\n\n\nSlide 42"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#clustering-nouns-1",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#clustering-nouns-1",
    "title": "Lexical semantics and word embeddings",
    "section": "43 Clustering nouns",
    "text": "43 Clustering nouns\n\n\n\n\nSlide 43"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#outline.-2",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#outline.-2",
    "title": "Lexical semantics and word embeddings",
    "section": "44 Outline.",
    "text": "44 Outline.\n\n\n\n\nSlide 44"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distributional-semantic-models",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#distributional-semantic-models",
    "title": "Lexical semantics and word embeddings",
    "section": "45 Distributional semantic models",
    "text": "45 Distributional semantic models\n\n\n\n\nSlide 45"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#sparse-vs.-dense-vectors",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#sparse-vs.-dense-vectors",
    "title": "Lexical semantics and word embeddings",
    "section": "46 Sparse vs. dense vectors",
    "text": "46 Sparse vs. dense vectors\n\n\n\n\nSlide 46"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#prediction-based-distributional-models",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#prediction-based-distributional-models",
    "title": "Lexical semantics and word embeddings",
    "section": "47 Prediction-based distributional models",
    "text": "47 Prediction-based distributional models\n\n\n\n\nSlide 47"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram",
    "title": "Lexical semantics and word embeddings",
    "section": "48 Skip-gram",
    "text": "48 Skip-gram\n\n\n\n\nSlide 48"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-1",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-1",
    "title": "Lexical semantics and word embeddings",
    "section": "49 Skip-gram",
    "text": "49 Skip-gram\n\n\n\n\nSlide 49"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-parameter-matrices",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-parameter-matrices",
    "title": "Lexical semantics and word embeddings",
    "section": "50 Skip-gram: Parameter matrices",
    "text": "50 Skip-gram: Parameter matrices\n\n\n\n\nSlide 50"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-setup",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-setup",
    "title": "Lexical semantics and word embeddings",
    "section": "51 Skip-gram: Setup",
    "text": "51 Skip-gram: Setup\n\n\n\n\nSlide 51"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-computing-similarity",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-computing-similarity",
    "title": "Lexical semantics and word embeddings",
    "section": "52 Skip-gram: Computing similarity",
    "text": "52 Skip-gram: Computing similarity\n\n\n\n\nSlide 52"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-similarity-as-dot-product",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-similarity-as-dot-product",
    "title": "Lexical semantics and word embeddings",
    "section": "53 Skip-gram: Similarity as dot product",
    "text": "53 Skip-gram: Similarity as dot product\n\n\n\n\nSlide 53"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-compute-probabilities",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-compute-probabilities",
    "title": "Lexical semantics and word embeddings",
    "section": "54 Skip-gram: Compute probabilities",
    "text": "54 Skip-gram: Compute probabilities\n\n\n\n\nSlide 54"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-learning",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-learning",
    "title": "Lexical semantics and word embeddings",
    "section": "55 Skip-gram: Learning",
    "text": "55 Skip-gram: Learning\n\n\n\n\nSlide 55"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-objective",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-objective",
    "title": "Lexical semantics and word embeddings",
    "section": "56 Skip-gram: Objective",
    "text": "56 Skip-gram: Objective\n\n\n\n\nSlide 56"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#visualising-skip-gram-as-a-network",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#visualising-skip-gram-as-a-network",
    "title": "Lexical semantics and word embeddings",
    "section": "57 Visualising skip-gram as a network",
    "text": "57 Visualising skip-gram as a network\n\n\n\n\nSlide 57"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#one-hot-vectors",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#one-hot-vectors",
    "title": "Lexical semantics and word embeddings",
    "section": "58 One hot vectors",
    "text": "58 One hot vectors\n\n\n\n\nSlide 58"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#visualising-skip-gram-as-a-network-1",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#visualising-skip-gram-as-a-network-1",
    "title": "Lexical semantics and word embeddings",
    "section": "59 Visualising skip-gram as a network",
    "text": "59 Visualising skip-gram as a network\n\n\n\n\nSlide 59"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling",
    "title": "Lexical semantics and word embeddings",
    "section": "60 Skip-gram with negative sampling",
    "text": "60 Skip-gram with negative sampling\n\n\n\n\nSlide 60"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling-1",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling-1",
    "title": "Lexical semantics and word embeddings",
    "section": "61 Skip-gram with negative sampling",
    "text": "61 Skip-gram with negative sampling\n\n\n\n\nSlide 61"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling-training-examples",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling-training-examples",
    "title": "Lexical semantics and word embeddings",
    "section": "62 Skip-gram with negative sampling: Training examples",
    "text": "62 Skip-gram with negative sampling: Training examples\n\n\n\n\nSlide 62"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling-2",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling-2",
    "title": "Lexical semantics and word embeddings",
    "section": "63 Skip-gram with negative sampling",
    "text": "63 Skip-gram with negative sampling\n\n\n\n\nSlide 63"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling-3",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling-3",
    "title": "Lexical semantics and word embeddings",
    "section": "64 Skip-gram with negative sampling",
    "text": "64 Skip-gram with negative sampling\n\n\n\n\nSlide 64"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling-4",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling-4",
    "title": "Lexical semantics and word embeddings",
    "section": "65 Skip-gram with negative sampling",
    "text": "65 Skip-gram with negative sampling\n\n\n\n\nSlide 65"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling-objective",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling-objective",
    "title": "Lexical semantics and word embeddings",
    "section": "66 Skip-gram with negative sampling: Objective",
    "text": "66 Skip-gram with negative sampling: Objective\n\n\n\n\nSlide 66"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling-objective-1",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling-objective-1",
    "title": "Lexical semantics and word embeddings",
    "section": "67 Skip-gram with negative sampling: Objective",
    "text": "67 Skip-gram with negative sampling: Objective\n\n\n\n\nSlide 67"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling-objective-2",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#skip-gram-with-negative-sampling-objective-2",
    "title": "Lexical semantics and word embeddings",
    "section": "68 Skip-gram with negative sampling: Objective",
    "text": "68 Skip-gram with negative sampling: Objective\n\n\n\n\nSlide 68"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#properties-of-embeddings",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#properties-of-embeddings",
    "title": "Lexical semantics and word embeddings",
    "section": "69 Properties of embeddings",
    "text": "69 Properties of embeddings\n\n\n\n\nSlide 69"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#properties-of-embeddings-1",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#properties-of-embeddings-1",
    "title": "Lexical semantics and word embeddings",
    "section": "70 Properties of embeddings",
    "text": "70 Properties of embeddings\n\n\n\n\nSlide 70"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#properties-of-embeddings-2",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#properties-of-embeddings-2",
    "title": "Lexical semantics and word embeddings",
    "section": "71 Properties of embeddings",
    "text": "71 Properties of embeddings\n\n\n\n\nSlide 71"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#properties-of-embeddings-3",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#properties-of-embeddings-3",
    "title": "Lexical semantics and word embeddings",
    "section": "72 Properties of embeddings",
    "text": "72 Properties of embeddings\n\n\n\n\nSlide 72"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#properties-of-embeddings-4",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#properties-of-embeddings-4",
    "title": "Lexical semantics and word embeddings",
    "section": "73 Properties of embeddings",
    "text": "73 Properties of embeddings\n\n\n\n\nSlide 73"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#word-embeddings-in-practice",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#word-embeddings-in-practice",
    "title": "Lexical semantics and word embeddings",
    "section": "74 Word embeddings in practice",
    "text": "74 Word embeddings in practice\n\n\n\n\nSlide 74"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#count-based-models-vs.-skip-gram-word-embeddings",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#count-based-models-vs.-skip-gram-word-embeddings",
    "title": "Lexical semantics and word embeddings",
    "section": "75 Count-based models vs. skip-gram word embeddings",
    "text": "75 Count-based models vs. skip-gram word embeddings\n\n\n\n\nSlide 75"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#count-based-models-vs.-skip-gram-word-embeddings-1",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#count-based-models-vs.-skip-gram-word-embeddings-1",
    "title": "Lexical semantics and word embeddings",
    "section": "76 Count-based models vs. skip-gram word embeddings",
    "text": "76 Count-based models vs. skip-gram word embeddings\n\n\n\n\nSlide 76"
  },
  {
    "objectID": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#acknowledgement",
    "href": "blog/2023-11-22_lexical-semantics-and-word-embeddings/index.html#acknowledgement",
    "title": "Lexical semantics and word embeddings",
    "section": "77 Acknowledgement",
    "text": "77 Acknowledgement\n\n\n\n\nSlide 77"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html",
    "title": "Compositional semantics and sentence representations",
    "section": "",
    "text": "Description of this Post\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                NLP\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                NLP\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          November 22, 2023"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title",
    "title": "Compositional semantics and sentence representations",
    "section": "1 Title",
    "text": "1 Title\n\n\n\n\nSlide 2"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#compositional-semantics",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#compositional-semantics",
    "title": "Compositional semantics and sentence representations",
    "section": "2 Compositional semantics",
    "text": "2 Compositional semantics\n\n\n\n\nSlide 3"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#compositional-semantics-alongside-syntax",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#compositional-semantics-alongside-syntax",
    "title": "Compositional semantics and sentence representations",
    "section": "3 Compositional semantics alongside syntax",
    "text": "3 Compositional semantics alongside syntax\n\n\n\n\nSlide 4"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#non-trivial-issues-with-semantic-composition",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#non-trivial-issues-with-semantic-composition",
    "title": "Compositional semantics and sentence representations",
    "section": "4 Non-trivial issues with semantic composition",
    "text": "4 Non-trivial issues with semantic composition\n\n\n\n\nSlide 5"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#non-trivial-issues-with-semantic-composition-1",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#non-trivial-issues-with-semantic-composition-1",
    "title": "Compositional semantics and sentence representations",
    "section": "5 Non-trivial issues with semantic composition",
    "text": "5 Non-trivial issues with semantic composition\n\n\n\n\nSlide 6"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#issues-with-semantic-composition",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#issues-with-semantic-composition",
    "title": "Compositional semantics and sentence representations",
    "section": "6 Issues with semantic composition",
    "text": "6 Issues with semantic composition\n\n\n\n\nSlide 7"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#modelling-comvositional-semantics",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#modelling-comvositional-semantics",
    "title": "Compositional semantics and sentence representations",
    "section": "7 Modelling comvositional semantics",
    "text": "7 Modelling comvositional semantics\n\n\n\n\nSlide 8"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-1",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-1",
    "title": "Compositional semantics and sentence representations",
    "section": "8 Title",
    "text": "8 Title\n\n\n\n\nSlide 9"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#compositional-distributional-semantics",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#compositional-distributional-semantics",
    "title": "Compositional semantics and sentence representations",
    "section": "9 Compositional distributional semantics",
    "text": "9 Compositional distributional semantics\n\n\n\n\nSlide 10"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#vector-mixture-models",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#vector-mixture-models",
    "title": "Compositional semantics and sentence representations",
    "section": "10 Vector mixture models",
    "text": "10 Vector mixture models\n\n\n\n\nSlide 11"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#additive-and-multiplicative-models",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#additive-and-multiplicative-models",
    "title": "Compositional semantics and sentence representations",
    "section": "11 Additive and multiplicative models",
    "text": "11 Additive and multiplicative models\n\n\n\n\nSlide 12"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lexical-function-models",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lexical-function-models",
    "title": "Compositional semantics and sentence representations",
    "section": "12 Lexical function models",
    "text": "12 Lexical function models\n\n\n\n\nSlide 13"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lexical-function-models-1",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lexical-function-models-1",
    "title": "Compositional semantics and sentence representations",
    "section": "13 Lexical function models",
    "text": "13 Lexical function models\n\n\n\n\nSlide 14"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#learning-adjective-matrices",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#learning-adjective-matrices",
    "title": "Compositional semantics and sentence representations",
    "section": "14 Learning adjective matrices",
    "text": "14 Learning adjective matrices\n\n\n\n\nSlide 15"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#learning-adjective-matrices-1",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#learning-adjective-matrices-1",
    "title": "Compositional semantics and sentence representations",
    "section": "15 Learning adjective matrices",
    "text": "15 Learning adjective matrices\n\n\n\n\nSlide 16"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-2",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-2",
    "title": "Compositional semantics and sentence representations",
    "section": "16 Title",
    "text": "16 Title\n\n\n\n\nSlide 17"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-3",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-3",
    "title": "Compositional semantics and sentence representations",
    "section": "17 Title",
    "text": "17 Title\n\n\n\n\nSlide 17"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-4",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-4",
    "title": "Compositional semantics and sentence representations",
    "section": "18 Title",
    "text": "18 Title\n\n\n\n\nSlide 18"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-5",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-5",
    "title": "Compositional semantics and sentence representations",
    "section": "19 Title",
    "text": "19 Title\n\n\n\n\nSlide 19"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#task-sentiment-classification-of-movie-reviews",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#task-sentiment-classification-of-movie-reviews",
    "title": "Compositional semantics and sentence representations",
    "section": "20 Task: Sentiment classification of movie reviews",
    "text": "20 Task: Sentiment classification of movie reviews\n\n\n\n\nSlide 20"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#words-and-sentences-into-vectors",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#words-and-sentences-into-vectors",
    "title": "Compositional semantics and sentence representations",
    "section": "21 Words (and sentences) into vectors",
    "text": "21 Words (and sentences) into vectors\n\n\n\n\nSlide 21"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#sentence-representation-a-very-simplified-picture",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#sentence-representation-a-very-simplified-picture",
    "title": "Compositional semantics and sentence representations",
    "section": "22 Sentence representation: A (very) simplified picture",
    "text": "22 Sentence representation: A (very) simplified picture\n\n\n\n\nSlide 22"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-6",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-6",
    "title": "Compositional semantics and sentence representations",
    "section": "23 Title",
    "text": "23 Title\n\n\n\n\nSlide 23"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#dataset-stanford-sentiment-treebank-sst",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#dataset-stanford-sentiment-treebank-sst",
    "title": "Compositional semantics and sentence representations",
    "section": "24 Dataset: Stanford Sentiment Treebank (SST)",
    "text": "24 Dataset: Stanford Sentiment Treebank (SST)\n\n\n\n\nSlide 24"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#binary-parse-tree-one-example",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#binary-parse-tree-one-example",
    "title": "Compositional semantics and sentence representations",
    "section": "25 Binary parse tree: One example",
    "text": "25 Binary parse tree: One example\n\n\n\n\nSlide 25"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-7",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-7",
    "title": "Compositional semantics and sentence representations",
    "section": "26 Title",
    "text": "26 Title\n\n\n\n\nSlide 26"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#models",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#models",
    "title": "Compositional semantics and sentence representations",
    "section": "27 Models",
    "text": "27 Models\n\n\n\n\nSlide 27"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#first-approach-sentence-sentiment",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#first-approach-sentence-sentiment",
    "title": "Compositional semantics and sentence representations",
    "section": "28 First approach: Sentence + Sentiment",
    "text": "28 First approach: Sentence + Sentiment\n\n\n\n\nSlide 28"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-8",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-8",
    "title": "Compositional semantics and sentence representations",
    "section": "29 Title",
    "text": "29 Title\n\n\n\n\nSlide 29"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-9",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-9",
    "title": "Compositional semantics and sentence representations",
    "section": "30 Title",
    "text": "30 Title\n\n\n\n\nSlide 30"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#bag-of-words",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#bag-of-words",
    "title": "Compositional semantics and sentence representations",
    "section": "31 Bag of Words",
    "text": "31 Bag of Words\n\n\n\n\nSlide 31"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#bag-of-words-1",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#bag-of-words-1",
    "title": "Compositional semantics and sentence representations",
    "section": "32 Bag of Words",
    "text": "32 Bag of Words\n\n\n\n\nSlide 32"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#turning-words-into-numbers",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#turning-words-into-numbers",
    "title": "Compositional semantics and sentence representations",
    "section": "33 Turning words into numbers",
    "text": "33 Turning words into numbers\n\n\n\n\nSlide 33"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#one-hot-vectors-select-word-embeddings",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#one-hot-vectors-select-word-embeddings",
    "title": "Compositional semantics and sentence representations",
    "section": "34 One-hot vectors select word embeddings",
    "text": "34 One-hot vectors select word embeddings\n\n\n\n\nSlide 34"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-10",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-10",
    "title": "Compositional semantics and sentence representations",
    "section": "35 Title",
    "text": "35 Title\n\n\n\n\nSlide 35"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-11",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-11",
    "title": "Compositional semantics and sentence representations",
    "section": "36 Title",
    "text": "36 Title\n\n\n\n\nSlide 36"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#continuous-bag-of-words-cbow",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#continuous-bag-of-words-cbow",
    "title": "Compositional semantics and sentence representations",
    "section": "37 Continuous Bag of Words (CBOW)",
    "text": "37 Continuous Bag of Words (CBOW)\n\n\n\n\nSlide 37"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#recall-matrix-multiplication",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#recall-matrix-multiplication",
    "title": "Compositional semantics and sentence representations",
    "section": "38 Recall: Matrix Multiplication",
    "text": "38 Recall: Matrix Multiplication\n\n\n\n\nSlide 38"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#what-about-this",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#what-about-this",
    "title": "Compositional semantics and sentence representations",
    "section": "39 What about this?",
    "text": "39 What about this?\n\n\n\n\nSlide 39"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#what-about-this-1",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#what-about-this-1",
    "title": "Compositional semantics and sentence representations",
    "section": "40 What about this?",
    "text": "40 What about this?\n\n\n\n\nSlide 40"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-12",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-12",
    "title": "Compositional semantics and sentence representations",
    "section": "41 Title",
    "text": "41 Title\n\n\n\n\nSlide 41"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-13",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-13",
    "title": "Compositional semantics and sentence representations",
    "section": "42 Title",
    "text": "42 Title\n\n\n\n\nSlide 42"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#mn.-prl-at",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#mn.-prl-at",
    "title": "Compositional semantics and sentence representations",
    "section": "43 mn. PRL AT",
    "text": "43 mn. PRL AT\n\n\n\n\nSlide 43"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#what-about-this-2",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#what-about-this-2",
    "title": "Compositional semantics and sentence representations",
    "section": "44 What about this?",
    "text": "44 What about this?\n\n\n\n\nSlide 44"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#question",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#question",
    "title": "Compositional semantics and sentence representations",
    "section": "45 Question",
    "text": "45 Question\n\n\n\n\nSlide 45"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-14",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-14",
    "title": "Compositional semantics and sentence representations",
    "section": "46 Title",
    "text": "46 Title\n\n\n\n\nSlide 46"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#deep-cbow-with-pretrained-embeddings",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#deep-cbow-with-pretrained-embeddings",
    "title": "Compositional semantics and sentence representations",
    "section": "47 Deep CBOW with pretrained embeddings",
    "text": "47 Deep CBOW with pretrained embeddings\n\n\n\n\nSlide 47"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-15",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-15",
    "title": "Compositional semantics and sentence representations",
    "section": "48 Title",
    "text": "48 Title\n\n\n\n\nSlide 48"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#recap-training-a-neural-network",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#recap-training-a-neural-network",
    "title": "Compositional semantics and sentence representations",
    "section": "49 Recap: Training a neural network",
    "text": "49 Recap: Training a neural network\n\n\n\n\nSlide 49"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#cross-entropy-loss",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#cross-entropy-loss",
    "title": "Compositional semantics and sentence representations",
    "section": "50 Cross Entropy Loss",
    "text": "50 Cross Entropy Loss\n\n\n\n\nSlide 50"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#softmax",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#softmax",
    "title": "Compositional semantics and sentence representations",
    "section": "51 Softmax",
    "text": "51 Softmax\n\n\n\n\nSlide 51"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-16",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-16",
    "title": "Compositional semantics and sentence representations",
    "section": "52 Title",
    "text": "52 Title\n\n\n\n\nSlide 52"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-recurrent-neural-network-rnn",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-recurrent-neural-network-rnn",
    "title": "Compositional semantics and sentence representations",
    "section": "53 Introduction: Recurrent Neural Network (RNN)",
    "text": "53 Introduction: Recurrent Neural Network (RNN)\n\n\n\n\nSlide 53"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-recurrent-neural-network-rnn-1",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-recurrent-neural-network-rnn-1",
    "title": "Compositional semantics and sentence representations",
    "section": "54 Introduction: Recurrent Neural Network (RNN)",
    "text": "54 Introduction: Recurrent Neural Network (RNN)\n\n\n\n\nSlide 54"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-recurrent-neural-network-rnn-2",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-recurrent-neural-network-rnn-2",
    "title": "Compositional semantics and sentence representations",
    "section": "55 Introduction: Recurrent Neural Network (RNN)",
    "text": "55 Introduction: Recurrent Neural Network (RNN)\n\n\n\n\nSlide 55"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-unfolding-the-rnn",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-unfolding-the-rnn",
    "title": "Compositional semantics and sentence representations",
    "section": "56 Introduction: Unfolding the RNN",
    "text": "56 Introduction: Unfolding the RNN\n\n\n\n\nSlide 56"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-making-a-prediction",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-making-a-prediction",
    "title": "Compositional semantics and sentence representations",
    "section": "57 Introduction: Making a prediction",
    "text": "57 Introduction: Making a prediction\n\n\n\n\nSlide 57"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-the-vanishing-gradient-problem",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-the-vanishing-gradient-problem",
    "title": "Compositional semantics and sentence representations",
    "section": "58 Introduction: The vanishing gradient problem",
    "text": "58 Introduction: The vanishing gradient problem\n\n\n\n\nSlide 58"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-the-vanishing-gradient-problem-1",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-the-vanishing-gradient-problem-1",
    "title": "Compositional semantics and sentence representations",
    "section": "59 Introduction: The vanishing gradient problem",
    "text": "59 Introduction: The vanishing gradient problem\n\n\n\n\nSlide 59"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#what-about-this-3",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#what-about-this-3",
    "title": "Compositional semantics and sentence representations",
    "section": "60 What about this?",
    "text": "60 What about this?\n\n\n\n\nSlide 60"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#rnn-vs-ann",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#rnn-vs-ann",
    "title": "Compositional semantics and sentence representations",
    "section": "61 RNN vs ANN",
    "text": "61 RNN vs ANN\n\n\n\n\nSlide 61"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-17",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-17",
    "title": "Compositional semantics and sentence representations",
    "section": "62 Title",
    "text": "62 Title\n\n\n\n\nSlide 62"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#long-short-term-memory-lstm",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#long-short-term-memory-lstm",
    "title": "Compositional semantics and sentence representations",
    "section": "63 Long Short-Term Memory (LSTM)",
    "text": "63 Long Short-Term Memory (LSTM)\n\n\n\n\nSlide 63"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstm-core-idea",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstm-core-idea",
    "title": "Compositional semantics and sentence representations",
    "section": "64 LSTM: Core idea",
    "text": "64 LSTM: Core idea\n\n\n\n\nSlide 64"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstms",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstms",
    "title": "Compositional semantics and sentence representations",
    "section": "65 LSTMs",
    "text": "65 LSTMs\n\n\n\n\nSlide 65"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstm-cell",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstm-cell",
    "title": "Compositional semantics and sentence representations",
    "section": "66 LSTM cell",
    "text": "66 LSTM cell\n\n\n\n\nSlide 66"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstm-cell-state",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstm-cell-state",
    "title": "Compositional semantics and sentence representations",
    "section": "67 LSTM: Cell state",
    "text": "67 LSTM: Cell state\n\n\n\n\nSlide 67"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstm-forget-gate",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstm-forget-gate",
    "title": "Compositional semantics and sentence representations",
    "section": "68 LSTM: Forget gate",
    "text": "68 LSTM: Forget gate\n\n\n\n\nSlide 68"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstm-candidate-cell",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstm-candidate-cell",
    "title": "Compositional semantics and sentence representations",
    "section": "69 LSTM: Candidate cell",
    "text": "69 LSTM: Candidate cell\n\n\n\n\nSlide 69"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstm-input-gate",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstm-input-gate",
    "title": "Compositional semantics and sentence representations",
    "section": "70 LSTM: Input gate",
    "text": "70 LSTM: Input gate\n\n\n\n\nSlide 70"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstm",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstm",
    "title": "Compositional semantics and sentence representations",
    "section": "71 LSTM",
    "text": "71 LSTM\n\n\n\n\nSlide 71"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstm-output-gate",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstm-output-gate",
    "title": "Compositional semantics and sentence representations",
    "section": "72 LSTM: Output gate",
    "text": "72 LSTM: Output gate\n\n\n\n\nSlide 72"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#long-short-term-memory-lstm-1",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#long-short-term-memory-lstm-1",
    "title": "Compositional semantics and sentence representations",
    "section": "73 Long Short-Term Memory (LSTM)",
    "text": "73 Long Short-Term Memory (LSTM)\n\n\n\n\nSlide 73"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstms-applications-success-in-nlp",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstms-applications-success-in-nlp",
    "title": "Compositional semantics and sentence representations",
    "section": "74 LSTMs: Applications & Success in NLP",
    "text": "74 LSTMs: Applications & Success in NLP\n\n\n\n\nSlide 74"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-18",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-18",
    "title": "Compositional semantics and sentence representations",
    "section": "75 Title",
    "text": "75 Title\n\n\n\n\nSlide 75"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#qa-rfar-arr-pparnppaaanantatiannaiasnthkh-aiaila",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#qa-rfar-arr-pparnppaaanantatiannaiasnthkh-aiaila",
    "title": "Compositional semantics and sentence representations",
    "section": "76 QA RFAR ARR PpARnPpaAanantatiannaiasnthkh AIAILA",
    "text": "76 QA RFAR ARR PpARnPpaAanantatiannaiasnthkh AIAILA\n\n\n\n\nSlide 76"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#second-approach-sentence-sentiment-syntax",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#second-approach-sentence-sentiment-syntax",
    "title": "Compositional semantics and sentence representations",
    "section": "77 Second approach: Sentence + Sentiment + Syntax",
    "text": "77 Second approach: Sentence + Sentiment + Syntax\n\n\n\n\nSlide 77"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#exploiting-tree-structure",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#exploiting-tree-structure",
    "title": "Compositional semantics and sentence representations",
    "section": "78 Exploiting tree structure",
    "text": "78 Exploiting tree structure\n\n\n\n\nSlide 78"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#why-would-it-be-useful",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#why-would-it-be-useful",
    "title": "Compositional semantics and sentence representations",
    "section": "79 Why would it be useful?",
    "text": "79 Why would it be useful?\n\n\n\n\nSlide 79"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#constituency-parse",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#constituency-parse",
    "title": "Compositional semantics and sentence representations",
    "section": "80 Constituency Parse",
    "text": "80 Constituency Parse\n\n\n\n\nSlide 80"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#recurrent-vs-tree-recursive-nn",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#recurrent-vs-tree-recursive-nn",
    "title": "Compositional semantics and sentence representations",
    "section": "81 Recurrent vs Tree Recursive NN",
    "text": "81 Recurrent vs Tree Recursive NN\n\n\n\n\nSlide 81"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#tree-recursive-nn",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#tree-recursive-nn",
    "title": "Compositional semantics and sentence representations",
    "section": "82 Tree Recursive NN",
    "text": "82 Tree Recursive NN\n\n\n\n\nSlide 82"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#practical-ii-data-set-stanford-sentiment-treebank-sst",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#practical-ii-data-set-stanford-sentiment-treebank-sst",
    "title": "Compositional semantics and sentence representations",
    "section": "83 Practical II data set: Stanford Sentiment Treebank (SST)",
    "text": "83 Practical II data set: Stanford Sentiment Treebank (SST)\n\n\n\n\nSlide 83"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#tree-lstms-generalize-lstm-to-tree-structure",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#tree-lstms-generalize-lstm-to-tree-structure",
    "title": "Compositional semantics and sentence representations",
    "section": "84 Tree LSTMs: Generalize LSTM to tree structure",
    "text": "84 Tree LSTMs: Generalize LSTM to tree structure\n\n\n\n\nSlide 84"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#tree-lstms",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#tree-lstms",
    "title": "Compositional semantics and sentence representations",
    "section": "85 Tree LSTMs",
    "text": "85 Tree LSTMs\n\n\n\n\nSlide 85"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#child-sum-tree-lstm",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#child-sum-tree-lstm",
    "title": "Compositional semantics and sentence representations",
    "section": "86 Child-Sum Tree LSTM",
    "text": "86 Child-Sum Tree LSTM\n\n\n\n\nSlide 86"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#child-sum-tree-lstm-1",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#child-sum-tree-lstm-1",
    "title": "Compositional semantics and sentence representations",
    "section": "87 Child-Sum Tree LSTM",
    "text": "87 Child-Sum Tree LSTM\n\n\n\n\nSlide 87"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#n-ary-tree-lstm",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#n-ary-tree-lstm",
    "title": "Compositional semantics and sentence representations",
    "section": "88 N-ary Tree LSTM",
    "text": "88 N-ary Tree LSTM\n\n\n\n\nSlide 88"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#n-ary-tree-lstm-1",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#n-ary-tree-lstm-1",
    "title": "Compositional semantics and sentence representations",
    "section": "89 N-ary Tree LSTM",
    "text": "89 N-ary Tree LSTM\n\n\n\n\nSlide 89"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#n-ary-tree-lstm-2",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#n-ary-tree-lstm-2",
    "title": "Compositional semantics and sentence representations",
    "section": "90 N-ary Tree LSTM",
    "text": "90 N-ary Tree LSTM\n\n\n\n\nSlide 90"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstms-vs-tree-lstms",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#lstms-vs-tree-lstms",
    "title": "Compositional semantics and sentence representations",
    "section": "91 LSTMs vs Tree-LSTMs",
    "text": "91 LSTMs vs Tree-LSTMs\n\n\n\n\nSlide 91"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-19",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-19",
    "title": "Compositional semantics and sentence representations",
    "section": "92 Title",
    "text": "92 Title\n\n\n\n\nSlide 92"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-20",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-20",
    "title": "Compositional semantics and sentence representations",
    "section": "93 Title",
    "text": "93 Title\n\n\n\n\nSlide 93"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#building-a-tree-with-a-transition-sequence",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#building-a-tree-with-a-transition-sequence",
    "title": "Compositional semantics and sentence representations",
    "section": "94 Building a tree with a transition sequence",
    "text": "94 Building a tree with a transition sequence\n\n\n\n\nSlide 94"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example",
    "title": "Compositional semantics and sentence representations",
    "section": "95 Transition sequence example",
    "text": "95 Transition sequence example\n\n\n\n\nSlide 95"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-1",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-1",
    "title": "Compositional semantics and sentence representations",
    "section": "96 Transition sequence example",
    "text": "96 Transition sequence example\n\n\n\n\nSlide 96"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-2",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-2",
    "title": "Compositional semantics and sentence representations",
    "section": "97 Transition sequence example",
    "text": "97 Transition sequence example\n\n\n\n\nSlide 97"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-3",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-3",
    "title": "Compositional semantics and sentence representations",
    "section": "98 Transition sequence example",
    "text": "98 Transition sequence example\n\n\n\n\nSlide 98"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-4",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-4",
    "title": "Compositional semantics and sentence representations",
    "section": "99 Transition sequence example",
    "text": "99 Transition sequence example\n\n\n\n\nSlide 99"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-5",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-5",
    "title": "Compositional semantics and sentence representations",
    "section": "100 Transition sequence example",
    "text": "100 Transition sequence example\n\n\n\n\nSlide 100"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-6",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-6",
    "title": "Compositional semantics and sentence representations",
    "section": "101 Transition sequence example",
    "text": "101 Transition sequence example\n\n\n\n\nSlide 101"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-7",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-7",
    "title": "Compositional semantics and sentence representations",
    "section": "102 Transition sequence example",
    "text": "102 Transition sequence example\n\n\n\n\nSlide 102"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-21",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-21",
    "title": "Compositional semantics and sentence representations",
    "section": "103 Title",
    "text": "103 Title\n\n\n\n\nSlide 103"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-mini-batched",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-mini-batched",
    "title": "Compositional semantics and sentence representations",
    "section": "104 Transition sequence example (mini-batched)",
    "text": "104 Transition sequence example (mini-batched)\n\n\n\n\nSlide 104"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-mini-batched-1",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-mini-batched-1",
    "title": "Compositional semantics and sentence representations",
    "section": "105 Transition sequence example (mini-batched)",
    "text": "105 Transition sequence example (mini-batched)\n\n\n\n\nSlide 105"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-mini-batched-2",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-mini-batched-2",
    "title": "Compositional semantics and sentence representations",
    "section": "106 Transition sequence example (mini-batched)",
    "text": "106 Transition sequence example (mini-batched)\n\n\n\n\nSlide 106"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-mini-batched-3",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-mini-batched-3",
    "title": "Compositional semantics and sentence representations",
    "section": "107 Transition sequence example (mini-batched)",
    "text": "107 Transition sequence example (mini-batched)\n\n\n\n\nSlide 107"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-mini-batched-4",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-mini-batched-4",
    "title": "Compositional semantics and sentence representations",
    "section": "108 Transition sequence example (mini-batched)",
    "text": "108 Transition sequence example (mini-batched)\n\n\n\n\nSlide 108"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-mini-batched-5",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#transition-sequence-example-mini-batched-5",
    "title": "Compositional semantics and sentence representations",
    "section": "109 Transition sequence example (mini-batched)",
    "text": "109 Transition sequence example (mini-batched)\n\n\n\n\nSlide 109"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#optional-approach-sentence-sentiment-syntax-node-level-sentiment",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#optional-approach-sentence-sentiment-syntax-node-level-sentiment",
    "title": "Compositional semantics and sentence representations",
    "section": "110 Optional approach: Sentence + Sentiment + Syntax + Node-level sentiment",
    "text": "110 Optional approach: Sentence + Sentiment + Syntax + Node-level sentiment\n\n\n\n\nSlide 110"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-22",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-22",
    "title": "Compositional semantics and sentence representations",
    "section": "111 Title",
    "text": "111 Title\n\n\n\n\nSlide 111"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#recap",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#recap",
    "title": "Compositional semantics and sentence representations",
    "section": "112 Recap",
    "text": "112 Recap\n\n\n\n\nSlide 112"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-23",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#title-23",
    "title": "Compositional semantics and sentence representations",
    "section": "113 Title",
    "text": "113 Title\n\n\n\n\nSlide 113"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#input",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#input",
    "title": "Compositional semantics and sentence representations",
    "section": "114 Input",
    "text": "114 Input\n\n\n\n\nSlide 114"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#recap-activation-functions",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#recap-activation-functions",
    "title": "Compositional semantics and sentence representations",
    "section": "115 Recap: Activation functions",
    "text": "115 Recap: Activation functions\n\n\n\n\nSlide 115"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-intuition-to-solving-the-vanishing-gradient",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-intuition-to-solving-the-vanishing-gradient",
    "title": "Compositional semantics and sentence representations",
    "section": "116 Introduction: Intuition to solving the vanishing gradient",
    "text": "116 Introduction: Intuition to solving the vanishing gradient\n\n\n\n\nSlide 116"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-a-small-improvement",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#introduction-a-small-improvement",
    "title": "Compositional semantics and sentence representations",
    "section": "117 Introduction: A small improvement",
    "text": "117 Introduction: A small improvement\n\n\n\n\nSlide 117"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#child-sum-tree-lstm-2",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#child-sum-tree-lstm-2",
    "title": "Compositional semantics and sentence representations",
    "section": "118 Child-Sum Tree LSTM",
    "text": "118 Child-Sum Tree LSTM\n\n\n\n\nSlide 118"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#a-naive-recursive-nn",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#a-naive-recursive-nn",
    "title": "Compositional semantics and sentence representations",
    "section": "119 A naive recursive NN",
    "text": "119 A naive recursive NN\n\n\n\n\nSlide 119"
  },
  {
    "objectID": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#sgd-vs-gd",
    "href": "blog/2023-11-22_compositional-semantics-and-sentence-representations/index.html#sgd-vs-gd",
    "title": "Compositional semantics and sentence representations",
    "section": "120 SGD vs GD",
    "text": "120 SGD vs GD\n\n\n\n\nSlide 120"
  }
]