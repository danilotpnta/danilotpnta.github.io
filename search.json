[
  {
    "objectID": "dev/index.html",
    "href": "dev/index.html",
    "title": "Danilo Toapanta",
    "section": "",
    "text": "In this section I have recompiled the sources, links and all the material that were more helpfull during the creation of this website."
  },
  {
    "objectID": "notes/2023-09-03_commands-terminal/index.html",
    "href": "notes/2023-09-03_commands-terminal/index.html",
    "title": "Commands Terminal",
    "section": "",
    "text": "Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 3, 2023"
  },
  {
    "objectID": "notes/2023-09-03_commands-terminal/index.html#terminal",
    "href": "notes/2023-09-03_commands-terminal/index.html#terminal",
    "title": "Commands Terminal",
    "section": "1 Terminal",
    "text": "1 Terminal\ncd -    # one folder back\ncd ..   # one up\ncd ../  # two up\ncd      # home directory \ncd /    # root directory\npwd         # print working directory\nopen &lt;PATH&gt;\nopen .     # open current folder you're in\ntouch &lt;file.txt&gt; # to create a file"
  },
  {
    "objectID": "notes/2023-09-03_commands-terminal/index.html#git-hub",
    "href": "notes/2023-09-03_commands-terminal/index.html#git-hub",
    "title": "Commands Terminal",
    "section": "2 Git Hub",
    "text": "2 Git Hub\ngit clone &lt;HTTPS&gt;    # copy repo from the HTTPS of the GitHub repository \ngit status                      # to check whether the tree line has been updated\ngit add .                       # add all new folders and files to git repo\ngit add &lt;name&gt;       # add specific folder for the git repo\n                                         # this is only to tell git taht there has been changes, we still need to commit\ngit commit -m \"&lt;message&gt;\"   # this save the files to git repo\ngit commit -m \"&lt;message&gt;\" -m \"&lt;message for the description box&gt;\"   # this save the files to git repo\nSo the way it works\n\nYou change the code\nYou need to save to the git file –&gt; git add .\nYou need to commit –&gt; git commit - m “message”\nYou push it to the repo –&gt; git push main\n\n\n2.1 Working with branches\n\nhttps://youtu.be/QV0kVNvkMxc\n\n\n\n2.2 Key Generation\nssh-keygen -t rsa -b 4096 -C \"danilotpnta@gmail.com\"   # to generate a key SSH\nls | grep git-key   # to check the keys available\n                    # key.pub pub stands for public \ncat &lt;example_key.pub&gt;                     # to print the key\n\n\n2.3 Generating a new SSH key\nssh-keygen -t ed25519 -C \"danilotpnta@gmail.com\" \n\n\n2.4 Adding your SSH key to the ssh-agent\neval \"$(ssh-agent -s)\"\nopen ~/.ssh/config\nvim ~/.ssh/config\nssh-add ~/.ssh/id_ed25519   # to add the key with name \"id_ed25519\"\ncat ~/.ssh/id_ed25519.pub   # to print the key that we created"
  },
  {
    "objectID": "notes/2023-09-03_commands-terminal/index.html#vim",
    "href": "notes/2023-09-03_commands-terminal/index.html#vim",
    "title": "Commands Terminal",
    "section": "3 Vim",
    "text": "3 Vim\n:wq     # to write/save and quit\nESC     # to scape from __INSERT__\n\n3.1 Prompt Message\nhe Bash command prompt looks like this by default:\n[USERNAME]@[HOSTNAME]:[PATH][SYMBOL]\n\n[USERNAME] is the username of the currently operating user. normally this is your user, but when you run sudo su or similar commands, you get a “root shell”, that means the user is “root”.\n[HOSTNAME] is your hostname. It’s the name of your computer. You had to enter that during the system installation.\n[PATH] is your current working directory, the directory you’re currently operating on. When you open a new terminal, the default directory is your current user’s home directory. A synonym for /home/YOURUSERNAME is ~.\n[SYMBOL] is usually either $ if you’re operating as any normal user, or # if you’re operating as “root” user.\n\nSo your Bash prompt looks like this:\nganesh@ganesh:~$\nThat means you’re logged in as user ganesh on a computer called ganesh as well, currently operating in your own home directory (~). Of course you’re not “root”, therefore the $."
  },
  {
    "objectID": "notes/2023-08-22_commands-for-quarto/index.html",
    "href": "notes/2023-08-22_commands-for-quarto/index.html",
    "title": "Commands Quarto",
    "section": "",
    "text": "Commands Quarto\n        \n        \n                    \n                \n                    A useful list of Quarto commands\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Quarto\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Quarto\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 22, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\n# Creates website in folder 'mysite'\nquarto create-project /Users/datoapanta/Desktop/mysite --type website  \n\n# To render it and preview in local host\nquarto preview mysite\n\n# Creates blog in folder 'blog'\nquarto create-project /Users/datoapanta/Desktop/blog --type website:blog\n\n# To render it and preview in local host\nquarto preview blog"
  },
  {
    "objectID": "notes/2023-09-04_how-to-create-a-jupyther-kernel/index.html",
    "href": "notes/2023-09-04_how-to-create-a-jupyther-kernel/index.html",
    "title": "How to Create a Jupyther Kernel",
    "section": "",
    "text": "How to Create a Jupyther Kernel\n        \n        \n                    \n                \n                    Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 4, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\npython3 -m pip install tensorflow\nconda install -c anaconda ipykernel\npython -m ipykernel install --user --name=firstEnv"
  },
  {
    "objectID": "notes/2023-08-22_commands-for-jupyter/index.html",
    "href": "notes/2023-08-22_commands-for-jupyter/index.html",
    "title": "Commands Jupyter",
    "section": "",
    "text": "Commands Jupyter\n        \n        \n                    \n                \n                    Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 22, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\njupyter kernelspec list              \npython -m ipykernel install --user --name=git-pages"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html",
    "title": "Features, tools & improvements website",
    "section": "",
    "text": "Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 27, 2023"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#change-directories",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#change-directories",
    "title": "Features, tools & improvements website",
    "section": "1 Change directories:",
    "text": "1 Change directories:\n_quarto.yml http://localhost:4200/dev/ include_footer.js: http://localhost:4200/links.js"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#include-a-page-on-how-to-use-the-command-line",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#include-a-page-on-how-to-use-the-command-line",
    "title": "Features, tools & improvements website",
    "section": "2 Include a page on how to use the command line:",
    "text": "2 Include a page on how to use the command line:\nhttps://www.taniarascia.com/how-to-use-the-command-line-for-apple-macos-and-linux/"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#read-how-to-use-node.js",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#read-how-to-use-node.js",
    "title": "Features, tools & improvements website",
    "section": "3 Read how to use Node.js:",
    "text": "3 Read how to use Node.js:\nhttps://www.taniarascia.com/how-to-install-and-use-node-js-and-npm-mac-and-windows/"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#firebase-real-time-database-for-my-static-website",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#firebase-real-time-database-for-my-static-website",
    "title": "Features, tools & improvements website",
    "section": "4 FIREBASE REAL TIME DATABASE FOR MY STATIC WEBSITE",
    "text": "4 FIREBASE REAL TIME DATABASE FOR MY STATIC WEBSITE\nhttps://xyzcoder.github.io/firebase/2019/03/17/firebase-real-time-database.html https://stackoverflow.com/questions/46574537/how-to-set-up-cloud-firestore-for-static-hosted-website https://maxbarry.medium.com/how-i-used-google-drive-and-firebase-to-give-my-static-site-a-cms-7226e01a51b5\n[To create a like button]- https://mazipan.space/en/create-simple-like-button-using-firebase-rtdb"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#copy-the-about-page-of",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#copy-the-about-page-of",
    "title": "Features, tools & improvements website",
    "section": "5 Copy the about page of:",
    "text": "5 Copy the about page of:\nhttps://beamilz.com/about.html"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#copy-his-cv",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#copy-his-cv",
    "title": "Features, tools & improvements website",
    "section": "6 Copy his CV:",
    "text": "6 Copy his CV:\nhttps://slama.dev/cv.pdf"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#review-the-subscribe-letter",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#review-the-subscribe-letter",
    "title": "Features, tools & improvements website",
    "section": "7 Review the Subscribe letter:",
    "text": "7 Review the Subscribe letter:\nhttps://taniarascia.substack.com/archive"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#html-js-css-container",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#html-js-css-container",
    "title": "Features, tools & improvements website",
    "section": "8 HTML, JS, CSS container",
    "text": "8 HTML, JS, CSS container\nhttps://jsbin.com/zusihologo/edit?html,css,output"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#select-sizes",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#select-sizes",
    "title": "Features, tools & improvements website",
    "section": "9 Select sizes:",
    "text": "9 Select sizes:\nhttps://jsbin.com/zusihologo/edit?html,css,"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#this-is-how-you-create-small-slides",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#this-is-how-you-create-small-slides",
    "title": "Features, tools & improvements website",
    "section": "10 This is how you create small slides:",
    "text": "10 This is how you create small slides:\nSLIDES FORMAT: RMD!!! https://github.com/djnavarro/slides-arrow-latinr-2022/blob/main/index.qmd\n\nSlides: https://slides.com/danilotoapanta\nCheck Codebox Sandbox and also embeeding html with Stackbitz\n\n\n\n\nLook into Google SEO to make page appear\nI like this blog: https://blog.meain.io/2023/releasing-scopeline-el/\nfix the content bar make it like her: https://ellakaye.co.uk/"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#javacript-to-counter",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#javacript-to-counter",
    "title": "Features, tools & improvements website",
    "section": "11 Javacript to counter:",
    "text": "11 Javacript to counter:\n/Users/datoapanta/Desktop/garrickadenbuie-com/_quarto.yml\nhttps://counter.dev/dashboard.html?demo=1\n– Fix the monospace"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#make-related-posts-like-this",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#make-related-posts-like-this",
    "title": "Features, tools & improvements website",
    "section": "12 Make related posts like this:",
    "text": "12 Make related posts like this:\n\nhttps://mattorb.com/swift-conciseness-and-trade-offs/\nhttps://github.blog/2023-08-04-a-checklist-and-guide-to-get-your-repository-collaboration-ready/#:~:text=about%20other%C2%A0plans%3F-,Related%20posts,-Engineering"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#add-tree-boxes-projects",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#add-tree-boxes-projects",
    "title": "Features, tools & improvements website",
    "section": "13 Add tree boxes projects:",
    "text": "13 Add tree boxes projects:\n\nViews\nTotal Projects\nMost clicked category"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#install-analytics",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#install-analytics",
    "title": "Features, tools & improvements website",
    "section": "14 Install Analytics:",
    "text": "14 Install Analytics:\n\nhttps://stats.arp242.net/?hl-period=year&period-start=2022-08-08&period-end=2023-08-08&filter=&daily=off"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#create-this-website",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#create-this-website",
    "title": "Features, tools & improvements website",
    "section": "15 Create this website",
    "text": "15 Create this website\nhttps://note.nkmk.me/en/python-os-mkdir-makedirs/"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#make-use-of-jupyter-widgets",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#make-use-of-jupyter-widgets",
    "title": "Features, tools & improvements website",
    "section": "16 Make use of jupyter widgets",
    "text": "16 Make use of jupyter widgets"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#copy-this-for-the-button-of-widgets",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#copy-this-for-the-button-of-widgets",
    "title": "Features, tools & improvements website",
    "section": "17 Copy this for the button of widgets:",
    "text": "17 Copy this for the button of widgets:\nhttps://wiki.manjaro.org/index.php?title=Main_Page/nl&action=history"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#encrypt-pages-with-password",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#encrypt-pages-with-password",
    "title": "Features, tools & improvements website",
    "section": "18 Encrypt pages with password",
    "text": "18 Encrypt pages with password\nhttps://robinmoisson.github.io/staticrypt/"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#implement-further-reading-like-this",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#implement-further-reading-like-this",
    "title": "Features, tools & improvements website",
    "section": "19 Implement further reading like this:",
    "text": "19 Implement further reading like this:\nhttps://engineeringfordatascience.com/posts/how_to_use_allure_pytest_bdd_and_allure_pytest_in_the_same_project/#further-reading"
  },
  {
    "objectID": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#make-use-of-ai-voice-to-read-my-poems",
    "href": "notes/2023-08-27_features,-tools-&-improvements-website-/index.html#make-use-of-ai-voice-to-read-my-poems",
    "title": "Features, tools & improvements website",
    "section": "20 Make use of AI voice to read my poems",
    "text": "20 Make use of AI voice to read my poems"
  },
  {
    "objectID": "notes/index.html",
    "href": "notes/index.html",
    "title": "\nPython\n",
    "section": "",
    "text": "Showing All Notes\n\n \n\nShow All Notes \n\n\n\n\n\n\n\nBlog\n\n\n\n\n\n\n\n\n\n #   published: \n\n\nPython\n\n\n\n\n\n\n\n\n\n     \n    \n        \n        \n        \n            \n        \n        \n            \n            1\n        \n            \n                \n                1\n        \n        \n        \n            \n        \n        \n        \n            \n        \n        \n        \n            \n        \n        \n            \n            2\n        \n            \n        \n        \n        \n            \n        \n        \n        \n            \n        \n        \n        \n            \n        \n        \n            \n            3\n            \n            4\n        \n            \n                \n                2\n                \n                3\n        \n        \n            \n            5\n        \n            \n        \n        \n        \n            \n                \n                4\n        \n        \n            \n            6\n        \n            \n                \n                5\n        \n        \n            \n            7\n        \n            \n\nNotes\n    \n    \n                \n                        \n                            \n                                Oct 06\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        How to embed ML application? NEW\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Oct 06\n                        \n                \n                \n                        \n                            \n                                Sep 11\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        How to create Conda environment using YML file?\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 11\n                        \n                \n                \n                        \n                            \n                                Sep 04\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        How to Create a Jupyther Kernel\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 04\n                        \n                \n                \n                        \n                            \n                                Sep 03\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Create Website using Local\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 03\n                        \n                \n                \n                        \n                            \n                                Sep 03\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Commands Terminal\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 03\n                        \n                \n                \n                        \n                            \n                                Aug 30\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        MSc AI Resources\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Aug 30\n                        \n                \n                \n                        \n                            \n                                Aug 27\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Changes to Vanilla Quarto\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Aug 27\n                        \n                \n                \n                        \n                            \n                                Aug 27\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Features, tools & improvements website\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Aug 27\n                        \n                \n                \n                        \n                            \n                                Aug 26\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        How to highlight lines of code in Github\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Aug 26\n                        \n                \n                \n                        \n                            \n                                Aug 22\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Commands Shells\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Aug 22\n                        \n                \n                \n                        \n                            \n                                Aug 22\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Commands GitHub\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Aug 22\n                        \n                \n                \n                        \n                            \n                                Aug 22\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Commands Jupyter\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Aug 22\n                        \n                \n                \n                        \n                            \n                                Aug 22\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Command Environments\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Aug 22\n                        \n                \n                \n                        \n                            \n                                Aug 22\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Commands Quarto\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Aug 22\n                        \n                \n    \n\n\n         \n            Environment\n        \n         \n            UvA\n        \n         \n            Shells\n        \n         \n            Scripting\n        \n         \n            GitHub\n        \n         \n            Environments\n        \n         \n            Quarto\n        \n         \n            Conda\n        \n         \n            Bash\n        \n         \n            Zsh\n        \n         \n            Python\n        \n         \n            Conda\n        \n         \n            Notes-table\n        \n\n\nNo matching items\n\n\n\n\n\n  \n  \n    \n    CATEGORIES\n      \n    \n      \n  \n  \n  \n    \n      TAGS"
  },
  {
    "objectID": "notes/2023-09-03_create-website-using-local/index.html",
    "href": "notes/2023-09-03_create-website-using-local/index.html",
    "title": "Create Website using Local",
    "section": "",
    "text": "Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 3, 2023"
  },
  {
    "objectID": "notes/2023-09-03_create-website-using-local/index.html#setting-up-the-terminal",
    "href": "notes/2023-09-03_create-website-using-local/index.html#setting-up-the-terminal",
    "title": "Create Website using Local",
    "section": "1 Setting up the Terminal",
    "text": "1 Setting up the Terminal\nFirst you need to have an idea to control the terminal. Look at the following link\n\nEnvironments\n\n\nCreate an environment called web with python\nconda create -n web python=3.7\nTo activate the new environment\nconda activate web\nTo move terminal to website folder in Desktop:\ncd /Users/datoapanta/Desktop/website"
  },
  {
    "objectID": "notes/2023-09-03_create-website-using-local/index.html#setting-up-next.js",
    "href": "notes/2023-09-03_create-website-using-local/index.html#setting-up-next.js",
    "title": "Create Website using Local",
    "section": "2 Setting up Next.js",
    "text": "2 Setting up Next.js\n\nInstallation Guide\n\nTo kills a port\nnpx kill-port 3000"
  },
  {
    "objectID": "blog/2023-09-24_color-rosa/index.html",
    "href": "blog/2023-09-24_color-rosa/index.html",
    "title": "Una rosa color morada",
    "section": "",
    "text": "Una rosa color morada\n        \n        \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Poems\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Spanish\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Poems\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Spanish\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 24, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\nby Danilo Toapanta \n\nBlog  &gt; Poems\n\n\nVida mia te escribo esta carta\nno una, ni dos, las veces que sea\nporque el de querer querer\nya no es color rosa morado\npero azul-amarillo\naveces rojo apaciguado.\n\nEs por eso vida mia,\ntemo que el color rosado\nte parezca morado\ncuando caiga la noche\ny no estes a mi lado.\n\nTe miro de reojo\ntu piensas infinito\nno palpitas ni titubeas\nestas firme como el hierro.\n\nPero asi tan altiva,\ndelicada es tu otra esquina\nEn la noche aqui te respondo,\ny con certeza a mi lado\ntus manos encuentran las mias\n\nLa noche fria afuera palpita\nel viento resumba la ventana\ntu soñando profundo y yo aqui\nescribiendo porque el rosado\nya no es morado."
  },
  {
    "objectID": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html",
    "href": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html",
    "title": "Automating the creation of Blog posts",
    "section": "",
    "text": "A Python solution to create blog posts from the command line\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Extension\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Quarto\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Extension\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Quarto\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 21, 2023\n        \n      \n      \n        \n      \n      \n\n    \n        Quick Links\n    \n         Quick Links:\n                                    \n                 Code\n                        \n                                    \n                 Repository\nVideo"
  },
  {
    "objectID": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html#motivation",
    "href": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html#motivation",
    "title": "Automating the creation of Blog posts",
    "section": "1 Motivation",
    "text": "1 Motivation\nWhen putting together a blog post, there are several steps that are time consuming. For instance, creating a directory with the date for the slug, then a title name and followed a YAML header that suits the format of the article. All this can be time consuming and hence in this post I will show how I have automated the creation of template posts to write code right away rather that setting this up\n\nGoal: from a simple command line i.e. mkblog notebook 'How to rock' a folder with the current date and the title-name i.e. 2023-08-21_how-to-rock will be created. Then the script should copy a pre-build post model that will modify the header’s date, title, href (for downloable Jupyter Notebooks) i.e:\n\ntitle: \"How to create Dynamic plots\"\ndate: \"2023-08-21\""
  },
  {
    "objectID": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html#creating-the-script",
    "href": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html#creating-the-script",
    "title": "Automating the creation of Blog posts",
    "section": "2 Creating the script",
    "text": "2 Creating the script\nThe first thing that came to my mind when creating the script was to the type of post. On a general level I have classify them in three categories\n\npost: this is a normal qmd file that can hold articles and is capable to run R, Python, JavaScript and so on.\npoems: this is a qmd modified version that enables the formatting that you see in my poems.\nnotebook: this is a ipynb file that can be executed using my conda environments\n\nThe question is now how to set all this up. Reviewing at scripting languages and ways on how to create extension for html files I realised all this could be done with python.\nHere down below the script that makes all this possible\n\n2.1 Make a Directory\n\n\ncreate_dir.py\n\n\nimport os \nimport sys\nfrom datetime import datetime\nimport shutil\n\ndef create_post(type_file, post_name):\n\n    # Save a copy only name\n    raw_post_name = post_name\n\n    # Example: \"how-to-rock\"\n    post_name = post_name.lower().replace(\" \", \"-\")\n\n    # Current Date: \"2023-08-21\"\n    current_date = datetime.today().strftime('%Y-%m-%d')\n\n    # Folder name: \"2023-08-21_how-to-rock\"\n    folder_name = current_date + '_' + post_name\n\n    # Current Directory path\n    current_dir = os.getcwd()\n    \n    # Output Directory\n    output_path = current_dir + \"/out\"\n\n    # Folder Path: \"../out/2023-08-21_how-to-rock\"\n    path_folder = os.path.join(output_path, folder_name)\n\n    # Make a Directory\n    os.mkdir(path_folder)\n    print(\"Directory '% s' created!\" % folder_name)\n\n# Name of Post\n# 0 is the name of the py file\n# 1 is the first argument\n\ntype_file = \"notebook\" # sys.argv[1]\npost_name = \"how to rock\" # sys.argv[2]             \n\ncreate_post(type_file, post_name)\n\nDirectory '2023-08-21_how-to-rock' created!\n\n\n\n\n2.2 Copy, move & edit a Blog’s Template\nAfter we have created a folder, we can proceed to make a copy of a user-defined template with settings that we may want to use for that specific type of post. For instance for my notebook posts I want to modify the date of the header, its title name and the ref link to download the output of the Jupyter notebook.\nFor this to scale and be able to fire the script from any directory I will point to a specific folder where I will make all this changes and then move those modified files to my ../blog section.\nThe structure of my files where the script is stored is as follows:\n\n\nTerminal\n\n_extensions\n└── mkpost\n    ├── create_dir.py\n    ├── out\n    ├── splitWin.app\n    └── templates\n        ├── notebook\n        │   └── index.ipynb\n        ├── poems\n        │   └── index.qmd\n        └── post\n            └── index.qmd\n\n\n\n\n\n\n\nNote\n\n\n\nTo print the tree structure you see above I have used: brew install tree and then tree &lt;path&gt;\n\n\nIn the folder view you find mkpost as the folder that holds the script previously shown. There is also out folder which contains the folder just created 2023-08-21_how-to-rock. There is also splitWin.app which will talk in section  and lastly a folder called templates where you can see index.* files that will be copied to our newly created folder.\nFollowing the continuation of the python script that does all the moving, copying and editing.\n\n\ncreate_dir.py\n\n\ndef create_file(type_file):\n    # -------------- CREATE FILE --------------\n    # Holds available extensions\n    dic = {'post': 'qmd', 'poems':'qmd', 'notebook':'ipynb'}\n    file_extension = dic[type_file]\n    \n    # Source path: \"../template/file_type/index.ext\"\n    source_file = f\"templates/{type_file}/index.{file_extension}\"\n    \n    # File name \"index.ext\"\n    file_name = f\"index.{file_extension}\"\n\n    # Destination path: \"../out/2023-08-21_how-to-rock/index.ext\"\n    destination_file = os.path.join(path_folder, file_name)\n\n    # Creating a Copy from Template folder\n    shutil.copy(source_file, destination_file)\n\n    # -------------- UPDATE HEADER --------------\n    lines = open(destination_file, 'r').readlines()\n    \n    if (type_file == \"notebook\"):\n        title_row = 9\n        lines[title_row] = f'    \\\"title: \\\\\"{raw_post_name.capitalize()}\\\\\"\\\\n\\\",'\n\n        date_row = 11\n        lines[date_row] = f'    \\\"date: \\\\\"{current_date}\\\\\"\\\\n\\\",'\n\n        code_name_row = 16\n        post_code_name = post_name + '.out.ipynb'\n        lines[code_name_row] = f'    \\\"      file-name: {post_code_name}\\\\n\\\",'\n\n    else:\n        title_row = 1\n        lines[title_row] = f'title: \"{raw_post_name.capitalize()}\"\\n'\n\n        date_row = 3\n        lines[date_row] = f'date: \"{current_date}\"\\n'\n\n    file = open(destination_file, 'w')\n    file.writelines(lines)\n    file.close()\n    \n    # -------------- MOVE FILE --------------\n    # Folder Path: \"../out/2023-08-21_how-to-rock\"\n    src = path_folder\n\n    # Path to Blog\n    dst = \"../../blog\"\n    shutil.move(src, dst)       \n    \n\nif (type_file == \"post\"):\n    create_file(\"post\")\nelif (type_file == \"notebook\"):\n    create_file(\"notebook\")\nelif (type_file == \"poems\"):\n    create_file(\"poems\")\nelse:\n    print(f\"Wrong type_file: {type_file}. Available: 'post', 'poems' or 'notebook'\")\n    sys.exit()\n    \n\nThe code above does the following:\n\nWhen the user inputs the name and the type_file it looks at the template folder with the specified extension and does the copying\nUpdates the header changing date to the current date at the moment of creating the directory, title with the name we input in the terminal and, lastly if is a notebook it changes the href to enable the user download the notebook.\nOnce all changes are done, the folder with the index.* file are move to the blog section."
  },
  {
    "objectID": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html#fire-it-up-from-terminal",
    "href": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html#fire-it-up-from-terminal",
    "title": "Automating the creation of Blog posts",
    "section": "3 Fire it up from terminal",
    "text": "3 Fire it up from terminal\nFor convenience, no matter in which directory of your computer you are in, this section cover how to fire it up the script that we have created. For starters, if you are running macOS or Linux most likely you will be using bash, zsh or fish shells. These shells, as it comes to not surprise, can launch scripts with user-defined strings defined.\nFor my liking I have decided to proceed with:\n\n\nTerminal\n\nmkblog [type_file] [\"name_post\"]\n\nTo enable this, you have to cd to your .bash_profile or .zshrc in my case. Then we will define the alias mkblog and will do the following:\n\ncd to the path where we have stored our python script. That is _extensions\nExecute the script using python\nOpen my workspace in Visual Studio\nOpen the index.* we just created i.e. in the dir \"2023-08-21_how-to-rock\"\nMake quarto render that file. Voila start coding!\n\n\n\n.zshrc\n\n# Creates script to open blog post\nmkblog() {\n  cd ../path/more_path/_extensions/mkpost\n  python create_dir.py $1 $2\n  cd ..\n  cd ..\n  code website.code-workspace\n  BACKUPDIR=$(ls -td blog/*/ | head -1)\n  cd $BACKUPDIR\n  FILENAME=$(ls | sort -f)\n  code $FILENAME\n  quarto preview $FILENAME \n}"
  },
  {
    "objectID": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html#bonus---create-an-script-to-split-views",
    "href": "blog/2023-08-18_how-to-automate-the-creation-of-blog-posts/index.html#bonus---create-an-script-to-split-views",
    "title": "Automating the creation of Blog posts",
    "section": "Bonus - Create an script to split views",
    "text": "Bonus - Create an script to split views\n\nWhen working with large screen I would like to place in the left side the file I created and in the right side my browser to preview the changes I made while editing my file. If you are familiar with AppleScript then you will be at home with the following lines.\n\n\nsplitWin.app\n\nactivate application \"Visual Studio Code\"\nrepeat 1 times\n    tell application \"System Events\" to key code 123 using {command down}\nend repeat\n\nactivate application \"Microsoft Edge\"\nrepeat 1 times\n    tell application \"System Events\" to key code 124 using {command down}\nend repeat\n\nLong story short, the script will send the keystrokes cmd + ←, cmd + → to each application and thus split the windows to left and right. How to accomplished this behavior? Glad you asked, I invite your to read this post where I go through how I made my life easier using Lua Shortcuts."
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html",
    "href": "blog/2023-10-04_logistic-regression/index.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "Lecture Notes UvA on 25-9-2023\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          October 4, 2023\nThe downside with the Perceptron is that there is no probabilistic interpretation. We want to link the linear model to class conditional probabilities\ni.e we would like to say there is 50% that this belongs to class K \\[\n\\begin{align}\np(C|x)\n\\end{align}\n\\]\nNow, lets talk about Logistic Regression"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#plotting-pc_kx-2nd-plot",
    "href": "blog/2023-10-04_logistic-regression/index.html#plotting-pc_kx-2nd-plot",
    "title": "Logistic Regression",
    "section": "1 Plotting \\(p(C_k|x)\\) (2nd plot)",
    "text": "1 Plotting \\(p(C_k|x)\\) (2nd plot)\n\n\nCode\n# Generate a grid of x and y coordinates\nx_range = np.linspace(-10, 10, 400)\ny_range = np.linspace(-10, 10, 400)\nxx, yy = np.meshgrid(x_range, y_range)\n\n# Calculate p(C_A | x) and p(C_B | x) for each point on the grid\n# Note: This is a simplified approach and doesn't use the actual Naive Bayes model\np_C_A_given_x = norm.pdf(np.linalg.norm([xx - np.cos(theta) * (2 * theta + np.pi), yy - np.sin(theta) * (2 * theta + np.pi)], axis=0))\np_C_B_given_x = norm.pdf(np.linalg.norm([xx - np.cos(theta) * (-2 * theta - np.pi), yy - np.sin(theta) * (-2 * theta - np.pi)], axis=0))\n\n# Plot the contour plots\nplt.figure(figsize=(7, 3))\nplt.subplot(121)\nplt.contourf(xx, yy, p_C_A_given_x, cmap='Blues', levels=20)\nplt.title('p(C_A | x)')\nplt.colorbar()\n\nplt.subplot(122)\nplt.contourf(xx, yy, p_C_B_given_x, cmap='Oranges', levels=20)\nplt.title('p(C_B | x)')\nplt.colorbar()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nThe contour plots show the probability values over the grid of x and y coordinates, with color indicating probability levels. The higher the probability, the darker the color.\nSince the data is not generated according to a real statistical model, the visualized distributions are more conceptual than precise.\nIn a real Naive Bayes model, you would estimate p(C_k | x) using the actual data and the independence assumption. The visualization would depend on the data, features, and model parameters."
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#concentric-circles-distribution",
    "href": "blog/2023-10-04_logistic-regression/index.html#concentric-circles-distribution",
    "title": "Logistic Regression",
    "section": "2 Concentric circles Distribution",
    "text": "2 Concentric circles Distribution\n\n\nCode\nfrom sklearn.datasets import make_circles\n\nX, y = make_circles(n_samples=1000, random_state=123, \n                    noise=0.1, factor=0.2)\n\nplt.figure(figsize=(8,6))\n\nplt.scatter(X[y==0, 0], X[y==0, 1], color='red', alpha=0.5)\nplt.scatter(X[y==1, 0], X[y==1, 1], color='blue', alpha=0.5)\nplt.title('Concentric circles')\nplt.ylabel('y coordinate')\nplt.xlabel('x coordinate')\nplt.show()"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#deriving-logistic-regression",
    "href": "blog/2023-10-04_logistic-regression/index.html#deriving-logistic-regression",
    "title": "Logistic Regression",
    "section": "3 Deriving Logistic Regression",
    "text": "3 Deriving Logistic Regression\n\nNote: We would be talking about Binary Classification\n\nHere the want to link linear model to probabilities to get Logistic Regression\n\nWhen we set up Bayes Classifiers, We look at the ratio of probabilities.\n\n\n\n\nHere we are saying that this ratio would not work because i.e if we would predict a negative value for this ratio that would mean that either the denominator or denominator would be negative. But negative probables cannot happen.\nThe solution, make compute the \\(\\ln\\)\n\n\n\nNote that at the decision boundary meaning when \\(p(C_1|x)=p(C_2|x)\\) we would have that the ratio is zero.\nNow, rearranging the expression above:\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Sigmoid"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#logistic-regression-making-predictions",
    "href": "blog/2023-10-04_logistic-regression/index.html#logistic-regression-making-predictions",
    "title": "Logistic Regression",
    "section": "4 Logistic Regression: Making Predictions",
    "text": "4 Logistic Regression: Making Predictions"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#counting-parameters",
    "href": "blog/2023-10-04_logistic-regression/index.html#counting-parameters",
    "title": "Logistic Regression",
    "section": "5 Counting Parameters",
    "text": "5 Counting Parameters\nHow much more parameter efficient is logistic regression vs a Gaussian classifier? (assume the feature vector has D dimensions)\nLogistic regression\n\nNum of parameters: \\(D+1\\) one weight for each feature value and then you have the bias weight.\n\nLinear Discriminant Analysis\n\nHere we defined the Gaussian likelihoods\n\n\nNum of parameters: \\((2D)+[D(D - 1)2 + D]\\)\n\n\nHow many parameters do the means of these gaussian likelihood have?\n\\(2D\\): because D dimensions per each mean and we have 2 likelihoods because we are doing binary classifier\nHow many parameters the covariance matrix have? Assume we are doing LDA, so the covariance matrix are shared.\n\\(D^2\\) Naively but in this case, the covariance matrix has this symmetry structure so \\(D*D - D/2\\) is the off diagonal matrix and we add \\(D\\) more for the diagonal\nThe last term, we have means, we have covariances. We need the bias because maybe we can have unbalance data so we also want this to balance the data.\nIn a bayes classifier we fixed our unbalance data with the prior. So we have one parameter for the prior\n\nTo understand more: link\nThat means for the LDA we need around \\(D^2\\) as compared to Logistic Regression \\(D+1\\) to get a classification example."
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#learning-via-log-likelihood",
    "href": "blog/2023-10-04_logistic-regression/index.html#learning-via-log-likelihood",
    "title": "Logistic Regression",
    "section": "6 Learning via Log-Likelihood",
    "text": "6 Learning via Log-Likelihood\nWe talked about our Logistic Regression model, now lets see how do we fit into our data."
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#learning-via-log-likelihood-1",
    "href": "blog/2023-10-04_logistic-regression/index.html#learning-via-log-likelihood-1",
    "title": "Logistic Regression",
    "section": "7 Learning via Log-likelihood",
    "text": "7 Learning via Log-likelihood\nWe assume our data are ID.\nNow that we have our labels which are binary we could use a Bernouli distribution to model this.\n\n\n\nWhere, \\(\\pi\\) represents the probability of sucess and \\(t\\) represents our possible outcomes. In this case our outcomes would be to belong to class \\(0\\) if \\(C_0\\) or \\(1\\) if \\(C_1\\)\n\n\n\nWhere, \\(\\sigma(\\textbf{w}^T\\textbf{x}_n)^{t_n}\\) is equal to \\(p(C1|x)\\). See the graph of the sigmoid Figure 1\nNow lets take the log of this Likelihood\n\n\n\nTo compute the Error we have:\n\n\n\nThis is equation is also called cross-entropy loss\nif the label \\(t_n=1\\) then second term will go away. Because we want to have the error to go to zero, then we need to make the log to go to zero. This happens when \\(log(1)\\) thus the \\(\\sigma(\\textbf{w}^T\\textbf{x}_n)\\) needs to equal one. This will only happen when the value of \\(\\textbf{w}^T\\textbf{x}_n\\) is large enough so that the \\(\\sigma()\\) computes it to one, meaning that \\(p(C_1|x)=1\\) which means we have predicted the correct label. Recall \\(t_n=1\\).\nThe other way around, the truth label is \\(t_n=1\\) but the output of \\(\\sigma(\\textbf{w}^T\\textbf{x}_n)~0\\) so close to zero which means the \\(\\ln(0.00001)=-11\\) would be negative which then recall we have a \\(-\\) minus sign which means we would be making a big error of \\(11\\).\n\\(E(w)\\) is convex in \\(\\textbf{w}\\) but unlike linear regression there is no analytical solution [1]. Which means if we take the derivative and solve for \\(w\\) we would get stuck.\n\nWhat is convex decision boundaries?\n\n\n\n\nif you take any two points within the boundary, the line segment connecting those points lies entirely within the boundary as well"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#class-entropy-loss",
    "href": "blog/2023-10-04_logistic-regression/index.html#class-entropy-loss",
    "title": "Logistic Regression",
    "section": "8 Class-Entropy Loss",
    "text": "8 Class-Entropy Loss\n\n\n\n\n8.1 Comparing Logistic Regression and Square Regression\n\n\n\nLogistic Regression is on the green line, Least Square Regression the purple.\n\nIf you have outliers, LEast Square changes its boundary so its sensible to outliers\nLogistic Regression is not, it kept the original boundary"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#gradient-descent-variants",
    "href": "blog/2023-10-04_logistic-regression/index.html#gradient-descent-variants",
    "title": "Logistic Regression",
    "section": "9 Gradient Descent: Variants",
    "text": "9 Gradient Descent: Variants\n\nNote, because we saw that the Error of the Log-likelihood of Logistic Regression cannot be solved analytically then we turn into gradient descent\n\n\n\n\n\nBecause the above summation is expensive then we got variants.\n\nBatch: Use all N data points\nStochastic: Use one data point to approximate sum\nHere we pick a random point \\(i\\) and we multiply by \\(N\\) to replicate the magnitude of learning rate. This is to keep same scale as the full gradient descent formula we see above. In other words this is just to conserve the magnitude of the \\(\\eta\\) value\n\n\n\n\n\nMini-Batch: Use B data points where 1 &lt; B &lt; N. Usually B much less than N (B &lt;&lt; N)\n\n\n\n\n\n9.1 Gradient Descent: Variants Performance"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#gradient-calculation",
    "href": "blog/2023-10-04_logistic-regression/index.html#gradient-calculation",
    "title": "Logistic Regression",
    "section": "10 Gradient Calculation",
    "text": "10 Gradient Calculation\n\n\n\n\n\n\n\n\n\n\n\n\nThe answer look identical to the one proposed for the perceptron in our prev post\n\n\n\n\nThe difference with the perceptron its that the update for the weights its softer.\nThe Gradient descent with logistic regresion will keep updating until \\(t_i-\\sigma(\\textbf{w}_t^T\\textbf{x}_i)\\) is close to zero, whereas the perceptron because of this \\(f(w^T\\phi)&gt;0\\) condition will be: \\(t_i-\\sigma(\\textbf{w}_t^T\\textbf{x}_i)\\) this is close enough (review the inequality post) to zero then we do not update the weight."
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#stochastic-gradient-descent",
    "href": "blog/2023-10-04_logistic-regression/index.html#stochastic-gradient-descent",
    "title": "Logistic Regression",
    "section": "11 Stochastic Gradient Descent",
    "text": "11 Stochastic Gradient Descent\nHere the perceptron choose only misclassified, here in Stochastic Gradient Descent we would pick any point randomly. Even if it’s well classified already.\n\n\n\nNow the question is: how do I set this parameter \\(\\eta\\) the learning rate. The answer to that is a method that help us find that. It’s called Newton-Raphson"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#setting-learning-rate",
    "href": "blog/2023-10-04_logistic-regression/index.html#setting-learning-rate",
    "title": "Logistic Regression",
    "section": "12 Setting learning rate",
    "text": "12 Setting learning rate\nIt is a difficult task:\n\ntoo small —&gt; long time to reach minimum\ntoo big —&gt; bounce around and never converge"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#idea-use-2nd-derivative",
    "href": "blog/2023-10-04_logistic-regression/index.html#idea-use-2nd-derivative",
    "title": "Logistic Regression",
    "section": "13 Idea: Use 2nd Derivative",
    "text": "13 Idea: Use 2nd Derivative\nThe second derivative corresponds to the curvature of the loss function, thus\nThis captures the notion of curvature\n\n\n\n\nSmall second derivative –&gt; large learning rate\nSo if these two purple arrows are pointing in the same direction it means there their second derivative is small because there is no much change which then means we can increase the learning rate because there is still a curvature meaning we have not reach to global minimum\nLarge second derivative –&gt; small learning rate\nIn the second case with the green arrows, this time the second derivative is large because there is a substantial change from pointing down to now pointing in almost horizontal direction. Then that means that we are getting closer to a deep and this we want to make the learning rate small\n\n\n13.1 Computing 2nd Derivative (for scalar)\n\n\n\nHere the second derivative \\(\\frac{\\partial^2}{\\partial w_t^2}\\) represents the curvature of the loss function so the answer that we will show below is just the graph of how this curvature would look like.\n\n\n\n\nThe error curvature would be maximized when the model is uncertain. The intuition is that if you have a lot of points next to the decision boundary then\nIt is small when the model is certain.\n\n\n\n\nWhere we have introduce the normalization term"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#steepest-descent-vs-newton-raphson",
    "href": "blog/2023-10-04_logistic-regression/index.html#steepest-descent-vs-newton-raphson",
    "title": "Logistic Regression",
    "section": "14 Steepest DEscent vs Newton-Raphson",
    "text": "14 Steepest DEscent vs Newton-Raphson\n\n\n\n\nThus, we see tha the Newton-Raphson takes a more direct path because it considers the curvature of the error loss.\n\n\n\n\n\n\nDerivative of vector^T with respect to vector\n\n\n\n\n\nThe notation \\(\\partial (x^T) / \\partial x\\) represents the derivative of a row vector \\(x^T\\) with respect to a column vector \\(x\\). In this context, the derivative is a Jacobian matrix.\nIf \\(x\\) is an \\(n\\)-dimensional column vector and \\(x^T\\) is the corresponding \\(n\\)-dimensional row vector, then the derivative \\(\\partial (x^T) / \\partial x\\) is a \\(n \\times n\\) Jacobian matrix.\nEach element \\((\\partial (x^T)_i / \\partial x_j)\\) of this Jacobian matrix is the partial derivative of the \\(i\\)-th element of \\(x^T\\) with respect to the \\(j\\)-th element of \\(x\\). Since each element of \\(x^T\\) is just a scalar, this derivative is straightforward to calculate:\n\\((\\partial (x^T)_i / \\partial x_j) = \\delta_{ij}\\)\nwhere \\(\\delta_{ij}\\) is the Kronecker delta, which is equal to 1 when \\(i = j\\) and 0 otherwise.\nTherefore, the Jacobian matrix \\(\\partial (x^T) / \\partial x\\) is a diagonal matrix with 1s on the diagonal and 0s off the diagonal. It’s an identity matrix of size \\(n \\times n\\)."
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#newton-raphson-iterative-optimization",
    "href": "blog/2023-10-04_logistic-regression/index.html#newton-raphson-iterative-optimization",
    "title": "Logistic Regression",
    "section": "15 Newton-Raphson Iterative Optimization",
    "text": "15 Newton-Raphson Iterative Optimization\n\n\n\n\n\n\n\n15.1 What is the H?\n\n\n\n\nThe blue highlighted section means that we have taken the second derivative over the error of the log-likelihood which has a minus hence why the blue hihglited parts vary in order."
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#newton-rpahson-iterative-optimization",
    "href": "blog/2023-10-04_logistic-regression/index.html#newton-rpahson-iterative-optimization",
    "title": "Logistic Regression",
    "section": "16 Newton-Rpahson Iterative Optimization",
    "text": "16 Newton-Rpahson Iterative Optimization"
  },
  {
    "objectID": "blog/2023-10-04_logistic-regression/index.html#faq",
    "href": "blog/2023-10-04_logistic-regression/index.html#faq",
    "title": "Logistic Regression",
    "section": "17 FAQ",
    "text": "17 FAQ\n\n\n\n\n\n\nWhat are linear features in binary classification?\n\n\n\n\n\nIn binary classification, linear features refer to features that can be effectively separated by a straight line (or a hyperplane in higher dimensions) when plotting them on a graph. These features are sometimes called linearly separable features because you can draw a line that cleanly separates the two classes, making it easy for a linear classifier like logistic regression or a linear support vector machine (SVM) to classify the data accurately.\nHere’s an example to illustrate linear features in binary classification:\nSuppose you are working on a binary classification problem to predict whether an email is spam (class 1) or not spam (class 0) based on two features: the number of words in the email and the number of times the word “free” appears in the email.\nYou collect data on various emails, and when you plot this data on a graph with the number of words on the x-axis and the frequency of the word “free” on the y-axis, you notice that spam emails tend to have fewer words and a higher frequency of the word “free,” while non-spam emails tend to have more words and a lower frequency of the word “free.”\nHere’s a simplified example:\n\nSpam Email A: 10 words, “free” appears 8 times\nSpam Email B: 12 words, “free” appears 10 times\nNon-Spam Email X: 20 words, “free” appears 2 times\nNon-Spam Email Y: 18 words, “free” appears 1 time\n\nIf you plot these data points on a graph, you might observe that you can draw a straight line that effectively separates the spam emails (class 1) from the non-spam emails (class 0). In this case, the number of words and the frequency of the word “free” are linear features, as they allow for a linear separation of the two classes.\nHere’s what the separation might look like (though in reality, the data might be more complex):\n\n\nCode\nimport matplotlib.pyplot as plt\n\n# Data points\nspam_emails = [(10, 8), (12, 10)]\nnon_spam_emails = [(20, 2), (18, 1)]\n\n# Unpack the data into separate lists\nspam_x, spam_y = zip(*spam_emails)\nnon_spam_x, non_spam_y = zip(*non_spam_emails)\n\n# Create the scatter plot\nplt.scatter(spam_x, spam_y, label='Spam Emails', marker='*')\nplt.scatter(non_spam_x, non_spam_y, label='Non-Spam Emails', marker='o')\n\n# Add labels and legend\nplt.xlabel('Number of Words')\nplt.ylabel('Frequency of \"free\"')\nplt.legend()\n\n# Add a straight line for separation (in this case, manually defined)\nplt.plot([15, 15], [0, 12], linestyle='--', color='gray')\n\n# Set plot limits and display\nplt.xlim(0, 25)\nplt.ylim(0, 12)\nplt.title('Linearly Separable Data for Binary Classification')\nplt.grid(True)\nplt.show()\n\n\n\n\n\nIn this example, you can see that a straight line can be drawn to separate the two classes, making the features (number of words and frequency of “free”) linear features for this binary classification problem."
  },
  {
    "objectID": "blog/2022-11-05_welcome/index.html",
    "href": "blog/2022-11-05_welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Welcome To My Blog\n        \n        \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                News\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                News\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          November 5, 2022\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\nThis is the first post in my blog. Welcome!"
  },
  {
    "objectID": "blog/2023-09-03_when-you-get-older/index.html",
    "href": "blog/2023-09-03_when-you-get-older/index.html",
    "title": "When you get older",
    "section": "",
    "text": "When you get older\n        \n        \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Poems\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Spanish\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Poems\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Spanish\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 3, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\nby Danilo Toapanta \n\nBlog  &gt; Poems\n\n\nWhen you get older my son\nYour hands start to become like raisins\nYour heart beats like one of those boats\nbut not like those new ones.\n\nWhen you get older son\nYour memories start to fade\nAs with your energy every day\nYou wonder son, how are my children doing\nAnd in a cozy chair your find yourself\nlost navigating in your memories\nthose years where your hands were not raisins.\n\nFor that reason my son\nif you see me agitated\nfragile like a leaf of autumn\nremember son\nyour father is just\nlike a brand new boat\nbut not like those new ones\nit is just a boat,\na boat that continues navigating\nwith more wisdom and firm pace.\n\nOh son, do not panic. If one day this boat\nhas decided to take its last ship\nThat day my son you will know this ship\nhas found the most valuable and precious secret\nAnd that day my son\nI will pass on you\nbefore my wood sinks and\nmy sails float in the sea of life.\n\nBe certain son,\nthat day you will then be armoured for a war\nand from the depth seas\nI will command you and guide your way\nexactly like my father did it\na couple of decades ago.\n\nWith love to Marcelo and Valerio Saico"
  },
  {
    "objectID": "blog/2023-01-29_displaying-jupyter-notebooks/index.html",
    "href": "blog/2023-01-29_displaying-jupyter-notebooks/index.html",
    "title": "Displaying jupyter notebooks",
    "section": "",
    "text": "Example of a simple blog post using Jupyter Notebooks\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Analysis\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Testing\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Analysis\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Testing\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          January 29, 2023"
  },
  {
    "objectID": "blog/2023-01-29_displaying-jupyter-notebooks/index.html#polar-demo",
    "href": "blog/2023-01-29_displaying-jupyter-notebooks/index.html#polar-demo",
    "title": "Displaying jupyter notebooks",
    "section": "Polar Demo",
    "text": "Polar Demo\nFor a demonstration of a line plot on a polar axis, see Figure 1.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 1 * np.pi * r\nfig, ax = plt.subplots(\n    subplot_kw = {'projection': 'polar'}\n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\nFigure 1: A line plot on a polar axis\n\n\n\n\n\nHow to transform into a plot\n\nplt.figure(figsize=(4, 2))\n_ = plt.plot([3, 4, 2, 5])\n\n\n\n\n\nThis is gonna be a normal plot. The figure above\nWhen people think about using artificial intelligence (AI) for writing, they immediately jump to 1500-word articles and lengthy social media posts. And yes, these are use cases that AI writing assistants can help with.\nBut it’s only a fraction of what this technology can do.\nA high-quality paragraph generator transforms everyone on your team into a robust and well-rounded writer. Now anyone can create informative, engaging, and persuasive content one paragraph at a time – whether responding to a lead via email or creating a thought leadership piece to go viral.\nThat’s why, in a moment, we’ll show you how to use Cop.aiI’s paragraph generator to build any text-based asset you need.\nBefore diving in, though, let’s cover the basics and answer the following: what’s a paragraph generator, how do they work, and why would you want to use one?\n\n\n\nAnother Big boy\nWhen people think about using artificial intelligence (AI) for writing, they immediately jump to 1500-word articles and lengthy social media posts. And yes, these are use cases that AI writing assistants can help with.\nBut it’s only a fraction of what this technology can do.\nA high-quality paragraph generator transforms everyone on your team into a robust and well-rounded writer. Now anyone can create informative, engaging, and persuasive content one paragraph at a time – whether responding to a lead via email or creating a thought leadership piece to go viral.\nThat’s why, in a moment, we’ll show you how to use Cop.aiI’s paragraph generator to build any text-based asset you need.\nBefore diving in, though, let’s cover the basics and answer the following: what’s a paragraph generator, how do they work, and why would you want to use one?\n\n\n2.1 My template for you"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "\nPython\n",
    "section": "",
    "text": "In this section Danilo writes down his notes, the things he has figured out about his computer, and ocasionally when feeling inspired he writes poems.\n\n\n\n\n\n\nShowing All Posts\n\n \n\nShow All Posts \n\n\n\n\n\n\n\nNotes\n\n\n\n\n\n\n\n\n #   published: \n\n\nPython\n\n\n\n\n\n\n\n\n\n     \n    \n        \n        \n            \n            1\n            \n            2\n        \n            \n                \n                1\n        \n        \n            \n            3\n            \n            4\n        \n            \n                \n                2\n        \n        \n            \n            5\n            \n            6\n        \n            \n                \n                3\n        \n        \n            \n            7\n            \n            8\n        \n            \n                \n                4\n        \n        \n            \n            9\n        \n            \n                \n                5\n        \n        \n        \n            \n        \n        \n            \n            10\n            \n            11\n        \n            \n                \n                6\n        \n        \n            \n            12\n        \n            \n                \n                7\n        \n        \n            \n            13\n            \n            14\n        \n            \n                \n                8\n        \n        \n            \n            15\n        \n            \n                \n                9\n        \n        \n            \n            16\n        \n            \n                \n                10\n        \n        \n            \n            17\n        \n            \n                \n                11\n                \n                12\n        \n        \n        \n            \n                \n                13\n        \n        \n            \n            18\n        \n            \n                \n                14\n        \n        \n            \n            19\n        \n            \n                \n                15\n                \n                16\n        \n        \n            \n            20\n        \n            \n                \n                17\n                \n                18\n        \n        \n            \n            21\n        \n            \n                \n                19\n        \n        \n            \n            22\n        \n            \n                \n                20\n        \n        \n            \n            23\n        \n            \n                \n                21\n        \n        \n            \n            24\n        \n            \n                \n                22\n                \n                23\n        \n        \n            \n            25\n        \n\n2023\n    \n    \n                \n                        \n                            \n                                Oct 07\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Latent Variable Models & K-Means Clustering NEW\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Oct 07\n                        \n                \n                \n                        \n                            \n                                Oct 04\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Neural networks\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Oct 04\n                        \n                \n                \n                        \n                            \n                                Oct 04\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Logistic Regression\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Oct 04\n                        \n                \n                \n                        \n                            \n                                Oct 03\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        The Perceptron\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Oct 03\n                        \n                \n                \n                        \n                            \n                                Sep 26\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Matrix Calculus\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 26\n                        \n                \n                \n                        \n                            \n                                Sep 26\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Maximum Likelihood vs Maximum a Posteriori Estimation\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 26\n                        \n                \n                \n                        \n                            \n                                Sep 25\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Classification and Decision Theory\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 25\n                        \n                \n                \n                        \n                            \n                                Sep 24\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Una rosa color morada\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 24\n                        \n                \n                \n                        \n                            \n                                Sep 05\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Probability Theory in Machine Learning\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 05\n                        \n                \n                \n                        \n                            \n                                Sep 04\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        MNIST Classification\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 04\n                        \n                \n                \n                        \n                            \n                                Sep 03\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        When you get older\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Sep 03\n                        \n                \n                \n                        \n                            \n                                Aug 21\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Automating the creation of Blog posts\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Aug 21\n                        \n                \n                \n                        \n                            \n                                Aug 18\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        How to use widgets in jupyter notebooks\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Aug 18\n                        \n                \n                \n                        \n                            \n                                Jul 29\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Cafe Negro color Miel\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Jul 29\n                        \n                \n                \n                        \n                            \n                                Jul 24\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Picking the right tool to show your Machine Learning project\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Jul 24\n                        \n                \n                \n                        \n                            \n                                Jun 20\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Running my first Marathon\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Jun 20\n                        \n                \n                \n                        \n                            \n                                Jun 09\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        On the topic of Optimization\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Jun 09\n                        \n                \n                \n                        \n                            \n                                Jun 05\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        How PCY Algorithm works\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Jun 05\n                        \n                \n                \n                        \n                            \n                                May 29\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Markdown structure, titles and CSS\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                May 29\n                        \n                \n                \n                        \n                            \n                                Jan 29\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Displaying jupyter notebooks\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Jan 29\n                        \n                \n                \n                        \n                            \n                                Jan 12\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        2022 into 2023\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Jan 12\n                        \n                \n    \n\n\n         \n            Education\n        \n         \n            Machine Learning\n        \n         \n            Education\n        \n         \n            Machine Learning\n        \n         \n            Education\n        \n         \n            Machine Learning\n        \n         \n            Education\n        \n         \n            Machine Learning\n        \n         \n            Education\n        \n         \n            Education\n        \n         \n            Machine Learning\n        \n         \n            Poems\n        \n         \n            Education\n        \n         \n            Machine Learning\n        \n         \n            Machine Learning\n        \n         \n            Poems\n        \n         \n            Extension\n        \n         \n            Poems\n        \n         \n            DevOps\n        \n         \n            Life\n        \n         \n            Workflow\n        \n         \n            Data Mining\n        \n         \n            Markdown\n        \n         \n            Analysis\n        \n         \n            News\n        \n         \n            Python\n        \n         \n            Python\n        \n         \n            Python\n        \n         \n            AI\n        \n         \n            Vector Calculus\n        \n         \n            Classification\n        \n         \n            Spanish\n        \n         \n            Probability Theory\n        \n         \n            Python\n        \n         \n            Spanish\n        \n         \n            Quarto\n        \n         \n            Python\n        \n         \n            Python\n        \n         \n            Spanish\n        \n         \n            Python\n        \n         \n            Shiny\n        \n         \n            Amsterdam\n        \n         \n            Running\n        \n         \n            Lua\n        \n         \n            Python\n        \n         \n            Testing\n        \n         \n            Testing\n        \n         \n            Python\n        \n         \n            2023-table\n        \n\n\nNo matching items\n\n\n\n\n\n\n\n     \n    \n        \n        \n            \n            1\n        \n            \n                \n                1\n        \n        \n            \n            2\n        \n\n2022\n    \n    \n                \n                        \n                            \n                                Dec 29\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Cuando miras al cielo NEW\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Dec 29\n                        \n                \n                \n                        \n                            \n                                Nov 05\n                            \n                            \n                            \n                        \n                        \n                            \n                            \n                                \n                                        Welcome To My Blog\n                                \n                            \n                            \n                        \n                        \n                            \n                            \n                            \n                                    \n                                    \n                                            \n                                                All\n                                            \n                                                                        \n                            \n                        \n                        \n                            \n                            \n                            \n                            \n                                Nov 05\n                        \n                \n    \n\n\n         \n            Poems\n        \n         \n            News\n        \n         \n            Spanish\n        \n         \n            2022-table\n        \n\n\nNo matching items\n\n\n\n\n\n  \n  \n    \n    CATEGORIES\n      \n    \n      \n  \n  \n  \n    \n      TAGS"
  },
  {
    "objectID": "blog/2023-06-05_how-hash-table-works/index.html",
    "href": "blog/2023-06-05_how-hash-table-works/index.html",
    "title": "How PCY Algorithm works",
    "section": "",
    "text": "An Effective Hash-Based Algorithm for Mining Association Rules.\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Data Mining\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Data Mining\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          June 5, 2023\n        \n      \n      \n        \n      \n      \n\n    \n        Quick Links\n    \n         Quick Links:\n                                    \n                 Code\n                        \n                                     See Article"
  },
  {
    "objectID": "blog/2023-06-05_how-hash-table-works/index.html#initializing-the-transaction-baskets",
    "href": "blog/2023-06-05_how-hash-table-works/index.html#initializing-the-transaction-baskets",
    "title": "How PCY Algorithm works",
    "section": "Initializing the transaction baskets",
    "text": "Initializing the transaction baskets\n\nimport numpy as np\nimport pandas as pd\nimport itertools\n\n\n# initialize lists\ndata = [[1,2,5], [2,3,5], [4,5], [1,6,7], [2,3,5,7], [1,2,7]]\npairs = [list(itertools.combinations(i, 2)) for i in data]\nmydict = {'Items':data, 'Pairs': pairs}\n\n# Create the pandas DataFrame with column name is provided explicitly\ndf = pd.DataFrame(mydict)\n\n# Print dataframe\ndisplay(df)\n\n\n\n\n\n\n\n\nItems\nPairs\n\n\n\n\n0\n[1, 2, 5]\n[(1, 2), (1, 5), (2, 5)]\n\n\n1\n[2, 3, 5]\n[(2, 3), (2, 5), (3, 5)]\n\n\n2\n[4, 5]\n[(4, 5)]\n\n\n3\n[1, 6, 7]\n[(1, 6), (1, 7), (6, 7)]\n\n\n4\n[2, 3, 5, 7]\n[(2, 3), (2, 5), (2, 7), (3, 5), (3, 7), (5, 7)]\n\n\n5\n[1, 2, 7]\n[(1, 2), (1, 7), (2, 7)]"
  },
  {
    "objectID": "blog/2023-06-05_how-hash-table-works/index.html#calculating-the-supports",
    "href": "blog/2023-06-05_how-hash-table-works/index.html#calculating-the-supports",
    "title": "How PCY Algorithm works",
    "section": "Calculating the supports",
    "text": "Calculating the supports\n\nprint(data)\n\n[[1, 2, 5], [2, 3, 5], [4, 5], [1, 6, 7], [2, 3, 5, 7], [1, 2, 7]]\n\n\n\nsupports = {}\nfor row in data:\n    for e in row:\n        if e not in supports:\n            supports[e] = 0\n\n# Sorting dictionary\nsorted_dict = supports.keys()\nsuppports = sorted(sorted_dict)\nprint(supports)\n\n{1: 0, 2: 0, 5: 0, 3: 0, 4: 0, 6: 0, 7: 0}\n\n\n\nfor row in data:\n    for e in row:\n        supports[e] += 1\n\nprint(supports)\n\n{1: 3, 2: 4, 5: 4, 3: 2, 4: 1, 6: 1, 7: 3}\n\n\n\nitem = [ key for key, value in supports.items()]\nsupp = [ value for key, value in supports.items()]\nunique_items_count = {'Itemset': item, 'Sup': supp}\n\ndf_item_sup = pd.DataFrame(unique_items_count)\ndisplay(df_item_sup)\n\n\n\n\n\n\nTable 1: Support\n\n\n\nItemset\nSup\n\n\n\n\n0\n1\n3\n\n\n1\n2\n4\n\n\n2\n5\n4\n\n\n3\n3\n2\n\n\n4\n4\n1\n\n\n5\n6\n1\n\n\n6\n7\n3\n\n\n\n\n\n\n\n\n\nPass 1\n\ndef hash_f_pair(i,j):\n    return (i*j) % 7\n\n\nunique_items = []\nfor row in pairs:\n    for e in row:\n        if e not in unique_items:\n            unique_items.append(e)\nprint(unique_items)\n\n[(1, 2), (1, 5), (2, 5), (2, 3), (3, 5), (4, 5), (1, 6), (1, 7), (6, 7), (2, 7), (3, 7), (5, 7)]\n\n\n\nunique_items[0][1]\n\n2\n\n\n\nhash_value_pairs = []\nfor e in unique_items:\n        hash_value_pairs.append(hash_f_pair(e[0],e[1]))\nprint(hash_value_pairs)\n\n[2, 5, 3, 6, 1, 6, 6, 0, 0, 0, 0, 0]\n\n\n\nmy_dict2 = {}\nfor pair in unique_items:\n    my_dict2[str(pair)] = 0\nprint(my_dict2)\n\n{'(1, 2)': 0, '(1, 5)': 0, '(2, 5)': 0, '(2, 3)': 0, '(3, 5)': 0, '(4, 5)': 0, '(1, 6)': 0, '(1, 7)': 0, '(6, 7)': 0, '(2, 7)': 0, '(3, 7)': 0, '(5, 7)': 0}\n\n\n\nfor row in pairs:\n    for e in row:\n        my_dict2[str(e)] +=1\n\nprint(my_dict2)\n\n{'(1, 2)': 2, '(1, 5)': 1, '(2, 5)': 3, '(2, 3)': 2, '(3, 5)': 2, '(4, 5)': 1, '(1, 6)': 1, '(1, 7)': 2, '(6, 7)': 1, '(2, 7)': 2, '(3, 7)': 1, '(5, 7)': 1}\n\n\n\ncounts = [ value for key, value in my_dict2.items()]\nprint(counts)\n# df_counts = pd.DataFrame()\n\n[2, 1, 3, 2, 2, 1, 1, 2, 1, 2, 1, 1]\n\n\n\nunique_items_count = {'Pairs': unique_items, 'Count': counts, 'Hash': hash_value_pairs}\nprint(unique_items_count)\n\n{'Pairs': [(1, 2), (1, 5), (2, 5), (2, 3), (3, 5), (4, 5), (1, 6), (1, 7), (6, 7), (2, 7), (3, 7), (5, 7)], 'Count': [2, 1, 3, 2, 2, 1, 1, 2, 1, 2, 1, 1], 'Hash': [2, 5, 3, 6, 1, 6, 6, 0, 0, 0, 0, 0]}\n\n\n\ndf_counts = pd.DataFrame(unique_items_count)\ndisplay(df_counts)\n\n\n\n\n\n\nTable 2: Hash Pair Table\n\n\n\nPairs\nCount\nHash\n\n\n\n\n0\n(1, 2)\n2\n2\n\n\n1\n(1, 5)\n1\n5\n\n\n2\n(2, 5)\n3\n3\n\n\n3\n(2, 3)\n2\n6\n\n\n4\n(3, 5)\n2\n1\n\n\n5\n(4, 5)\n1\n6\n\n\n6\n(1, 6)\n1\n6\n\n\n7\n(1, 7)\n2\n0\n\n\n8\n(6, 7)\n1\n0\n\n\n9\n(2, 7)\n2\n0\n\n\n10\n(3, 7)\n1\n0\n\n\n11\n(5, 7)\n1\n0\n\n\n\n\n\n\n\n\nMinium support count is 2 so we eliminate from the Pair list the items that have less than 2 from Table 1. The resulting table is called the Candidate Pairs.\n\ndf_counts_after = df_counts.drop([5, 6, 8])\ndisplay(df_counts_after)\n\n\n\n\n\n\nTable 3: Hash Pair Table after Pass 1\n\n\n\nPairs\nCount\nHash\n\n\n\n\n0\n(1, 2)\n2\n2\n\n\n1\n(1, 5)\n1\n5\n\n\n2\n(2, 5)\n3\n3\n\n\n3\n(2, 3)\n2\n6\n\n\n4\n(3, 5)\n2\n1\n\n\n7\n(1, 7)\n2\n0\n\n\n9\n(2, 7)\n2\n0\n\n\n10\n(3, 7)\n1\n0\n\n\n11\n(5, 7)\n1\n0\n\n\n\n\n\n\n\n\n\n\nPass 2\nThe final step is to build a table from Table 2 that counts the number of ocurrences per hash value.\n\nhash_values = [x for x in range(max(hash_value_pairs)+1)]\nmy_dict3 = {}\nfor e in hash_values:\n    my_dict3[e] = 0\n\nfor i, hash_value in enumerate(df_counts[\"Hash\"]):\n    my_dict3[hash_value] += df_counts[\"Count\"][i]\nprint(my_dict3)\n\ndata_bucket = {\"Bucket\": hash_values, \"Count\": my_dict3.values()}\ndf_bucket_count = pd.DataFrame(data_bucket)\ndisplay(df_bucket_count)\n\n{0: 7, 1: 2, 2: 2, 3: 3, 4: 0, 5: 1, 6: 4}\n\n\n\n\n\n\n\n\n\nBucket\nCount\n\n\n\n\n0\n0\n7\n\n\n1\n1\n2\n\n\n2\n2\n2\n\n\n3\n3\n3\n\n\n4\n4\n0\n\n\n5\n5\n1\n\n\n6\n6\n4\n\n\n\n\n\n\n\nWith the result above we can look back to table Table 3 and see which hash values, have a value lower than the minimum support count. That is hash value 4 and 5. With this result we look at table Table 3 and delete those corresponding hash values. The final result is teh Final Candidates\n\ndf_counts_after_pass2 = df_counts_after.drop([1])\ndisplay(df_counts_after_pass2)\n\n\n\n\n\n\n\n\nPairs\nCount\nHash\n\n\n\n\n0\n(1, 2)\n2\n2\n\n\n2\n(2, 5)\n3\n3\n\n\n3\n(2, 3)\n2\n6\n\n\n4\n(3, 5)\n2\n1\n\n\n7\n(1, 7)\n2\n0\n\n\n9\n(2, 7)\n2\n0\n\n\n10\n(3, 7)\n1\n0\n\n\n11\n(5, 7)\n1\n0"
  },
  {
    "objectID": "blog/2023-07-24_the-right-tool/index.html",
    "href": "blog/2023-07-24_the-right-tool/index.html",
    "title": "Picking the right tool to show your Machine Learning project",
    "section": "",
    "text": "Picking the right tool to show your Machine Learning project\n        \n        \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                DevOps\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                            \n                            \n                                Shiny\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                DevOps\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                                            \n                            \n                               \n                                Shiny\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          July 24, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\n\n\n\n\n\n\nDisclaimer\n\n\n\nFor sake of keeping my thoughts run smoothly this page may contain typos. Bear with Danilo.\n\n\n\n\nThe reason\nI have come across the question on where to host the models that I have trained and display its outputs in an interactive way.\nWhile doing some googling I came across different technologies which much of which have been recently launched, provided the pletora of machine learning application these days. So here a couple of things that I have learnt:\n\n\nStatic websites just got better!\nFor static websites, there is pretty much not too many available options. Statics sites like this one make use of javascript as the backbone to run expensive tasks and usually data science tools these days operate with Python, Julia or R.\nBeing said that, pyscript seems to pose a first steps on how to run python in HTML. Found this was a relief because then I discovered that Python code is able to be written in a portable binary-code format WASM, which in turn means you can write Python and run it at the server side. For a more thorugh explanation about this you can check this video explanation.\n\n\nIf Python available which technology to use?\nHere gets tricky, if you want to have a fast and easy to deployment usually there is no much customization, and by that I mean curky ads and logos like: made by.. not to much fan of those. Following a simple chart that I have found really usefull to solve my enquires, I am attaching the source link here for reference.\n Source: 1\n\n\nThe decision\nAll set and stone, I have only some requirements to jump into learning a new technology and those are\n\nScalable: I want to be able to not just use it for my blog but for future work as well\nOn the look: if it has not been used for the last couple of years then something new is on the look\nBalance-learning-curve: I have learnt Haskell and let me tell you, prototyping and designing code is another world in functional language. So I want be a eager learning while still discovering more tools next couple of months in the road.\n\nConsidering these facts: I am planing to stick with Shiny for the time being."
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html",
    "title": "Classification and Decision Theory",
    "section": "",
    "text": "Notes for the course at UvA: Machine Learning 1\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Classification\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Classification\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 25, 2023\nThis section focus on third week of the course. For Regression continue to this post."
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#classification-through-decision-regions",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#classification-through-decision-regions",
    "title": "Classification and Decision Theory",
    "section": "1 Classification through decision regions",
    "text": "1 Classification through decision regions\n\nHere the targets can take only discrete values. In Linear Regression the targets were continuous\n\n\\[\n\\begin{align}\n\\underline{x} &\\in \\mathbb{R}^{Dx1}, \\text{ $D$ Dimensional Space}\\\\\n&= [x_1, .., x_D]^T \\nonumber\n\\end{align}\n\\]\n\nFor instance when \\(D=2\\) we can think of \\(x_1\\) as the amount of black pixels in the image, and \\(x_2\\) as the white pixels. Then I can clasify one image into this 2-D dimensional space. So in the xy-plane one image has \\((x1,x2)\\) coordinates\nWe dive \\(\\underline{x}\\) into \\(K\\) Decision Regions \\(R_k\\).\nFor each Decision Region \\(R_k\\) we assign it to a class \\(C_k\\).\nThe target \\(\\underline{t} \\in \\{C_1,...,C_k\\}\\) meaning the target can be classified either \\(C_1\\) or the target can be classified as \\(C_2\\)"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#linear-classification",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#linear-classification",
    "title": "Classification and Decision Theory",
    "section": "2 Linear Classification",
    "text": "2 Linear Classification\n\nNote: do not confuse \\(D\\) the amount of data points with this new \\(D\\) where we talk about the dimensionality of how each data point is represented (the coordinates)\n\n\nThe classification is done by only linear decision boundaries\n\nFor \\(D\\)-dimensional input space: \\(\\underline{x}\\in\\mathbb{R}^{D}\\). The decision surface is a \\(D-1\\) dimensional hyperplane. For instance:\n\nThe decision boundaries can take a form of a line, i.e when \\(\\underline{x}\\in\\mathbb{R}^{D=2x1}\\) meaning the dots are drawn in the \\(x,y\\) coordinates\nThe decision boundaries can take a form of a plane, i.e when \\(\\underline{x}\\in\\mathbb{R}^{D=3x1}\\) meaning the dots are drawn in the \\(x,y,z\\) coordinates\n\nLinear Classifiers have however some constraints: one-versus-one, or one-vs-rest cannot classified in one specific region when majority vote its applied. There is class of decisions"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#decision-theory",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#decision-theory",
    "title": "Classification and Decision Theory",
    "section": "3 Decision Theory",
    "text": "3 Decision Theory\nHere we talked about when we consider a classifier (a model) a good classifier.\n\nWe talk about the Bayes Error Rate\nHow to minimize the misclassification rate\n\nModel that you start with:\n\nClass-conditional densities: \\(p(\\underline{x}|C_k)\\) aka (Likelihood)\nPrior class probabilities: \\(p(C_k)\\)\n\nFrom these two you can derive:\n\nThe Joint distribution \\(p(\\underline{x}, C_k)\\)\n\n\\[\n\\begin{align}\np(\\underline{x}, C_k)=p(\\underline{x}|C_k)p(C_k)\n\\end{align}\n\\]\n\nThe Posterior \\(p(C_k|\\underline{x})\\).\n\n\\[\n\\begin{align}\np(C_k|\\underline{x}) = \\frac{p(\\underline{x}| C_k)p(C_k)}{p(\\underline{x})}\n\\end{align}\n\\]\n\nDecision Theory tell us that the best prediction for input \\(\\underline{x}\\) is to choose the class with highest joint \\(p(\\underline{x}, C_k)\\)\nOr equivalently: choose class with the highest posterior \\(p(C_k|\\underline{x})\\)\nDecision boundary between \\(C_k\\) and \\(C_j\\) are at \\(p(C_k | \\underline{x})=p(C_j | \\underline{x})\\)"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#from-bayes-rule-to-bayes-classifiers",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#from-bayes-rule-to-bayes-classifiers",
    "title": "Classification and Decision Theory",
    "section": "4 From Bayes Rule to Bayes Classifiers",
    "text": "4 From Bayes Rule to Bayes Classifiers\n\\[\n\\begin{align}\np(C|X) = \\frac{P(X|C)P(C)}{P(X)} \\\\\n\\end{align}\n\\]\nWhere:\n\n\\(P(C|X)\\) is the Posterior (Given the data what is the prob of being class C_k)\n\\(P(X|C)\\) is the Likelihood (How the data is distributed given C)\n\\(P(C)\\) is the Prior\n\\(P(X)\\) is the Evidence/ Marginal likelihood\n\nThe evidence \\(P(X)\\) can also be decomposed in:\n\\[\n\\begin{align}\nP(X) &= \\sum_{j}{}P(X,C_j)\\\\\n     &= \\sum_{j}{}P(X|C_j)P(C_j) \\\\\n\\end{align}\n\\]\nUnlike regression, I will have one likelihood per each class, mainly:\n\\[\n\\begin{align}\np(X|C_0) \\quad \\text{and} \\quad p(X|C_1) \\\\\n\\end{align}\n\\]\nFor instance for \\(K=2\\) two classes. This means per each class we are going to have our own model\nThe decicion boundary then becomes equal when both likelihoods are equal:\n\\[\n\\begin{align}\np(C_0|X) &= p(C_1|X) \\quad \\text{Decision Boundary}\\\\\n% P(X, C_0) &= p(X, C_1) \\nonumber\n\\end{align}\n\\]\nHere:\n\n\\(P(C_0|X)\\) is the Posterior probability"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#types-of-classification",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#types-of-classification",
    "title": "Classification and Decision Theory",
    "section": "5 Types of Classification",
    "text": "5 Types of Classification\n\nDecision Trees\nLogistic Regressions\nBayes Classifiers (Generative): first fit P(x|C) and then use Bayes Rule to flip it and tell which type of class correspond \\(x\\)\n\nNaive Bayes: you put an x and it gives you to which class \\(K\\) correponds\nGaussian Likelihood: here \\(p(x|C_k) = N(\\mu_k, \\Sigma_k)\\)\nQDA: Quadratic discriminant analysis\n\nShared Parameters\nLDA: Linear Discriminant Analysis\n\n\n\n\n5.1 Gaussian Generative Classifiers\nHere we assume arbitrary covariance matrices for each class\n\\[\n\\begin{align}\np(x|C_k) = N(\\mu_k, \\Sigma_k)\n\\end{align}\n\\]\n\nEach class \\(K\\) is going to have its normal distribution. And each of these distributions would be completely different from the others.\n\n\nQuadratic Discriminant Analysis\nHere the decision boundary would be quadratic.\nHere the covariances would different for each class, like so:\n\\[\n\\begin{align}\n1&=\\frac{p(x, C_2)}{p(x, C_1)} \\\\\n&=\\frac{p(x| C_2)p(C_2)}{p(x| C_1)p(C_1)} \\nonumber\n\\end{align}\n\\]\nTaking the log at both sides\n\\[\n\\begin{align}\n0 &= log N(\\mu_2, \\Sigma_2) - log N(\\mu_1, \\Sigma_1) + log \\frac{p(C_2)}{p(C_1)}\n\\end{align}\n\\]\nIf you solve the equation above then you end up with quadratic terms.\nThis tell us that now we can handle non-linear separate cases now the data can needs to be quadratic separable.\n\n\n5.1.1 Shared Parameters\n\n\nLinear Discriminant Analysis\nHere the decision boundary would be linear.\nHere the covariances would be the same: 1 covariance matrix like so:\n\\[\n\\begin{align}\n0 &= log N(\\mu_2, \\Sigma) - log N(\\mu_1, \\Sigma) + log \\frac{p(C_2)}{p(C_1)}\n\\end{align}\n\\]\nHere we do not impose \\(diag\\{\\Sigma_k\\}\\), we can have Naive Bayes approach here. The latter meaning we can indeeed if we want have the covariance matrices to be \\(diag\\{\\Sigma_k\\}\\). In this called we called. Naive Bayes applied to LDA.\n\nNaive Bayes applied to LDA: same/shared parameters for \\(\\Sigma_k\\) and \\(diag\\{\\Sigma_k\\}\\)\n\n\n\n\nUnderstanding Covariance and Variance\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import multivariate_normal\nimport matplotlib.colorbar as cbar\n\n# Define the mean and covariance matrix for the original case\nmean = [0, 0]\ncovariance_matrix = [[2, 1], [1, 2]]  # Example covariance matrix\n\n# Create a grid of points\nx, y = np.meshgrid(np.linspace(-5, 5, 100), np.linspace(-5, 5, 100))\npos = np.dstack((x, y))\n\n# Create a multivariate Gaussian distribution for the original case\nrv = multivariate_normal(mean, covariance_matrix)\n\n# Calculate the probability density at each point in the grid for the original case\npdf = rv.pdf(pos)\n\n# Calculate eigenvalues and eigenvectors for the original case\neigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n\n# Define the scale factor for the arrows\nscale_factor = 2.0\n\n# Create the first subplot for the original case\nplt.subplot(1, 2, 1)\nplt.contourf(x, y, pdf, cmap='viridis')\nfor i in range(2):\n    plt.arrow(\n        mean[0],\n        mean[1],\n        eigenvectors[i, 0] * np.sqrt(eigenvalues[i]) * scale_factor,\n        eigenvectors[i, 1] * np.sqrt(eigenvalues[i]) * scale_factor,\n        head_width=0.2,\n        head_length=0.2,\n        fc='r',\n        ec='r',\n    )\nplt.annotate(f'Var(X) = {eigenvalues[0]:.2f}', xy=(-3, 3), color='white')\nplt.annotate(f'Var(Y) = {eigenvalues[1]:.2f}', xy=(-3, 2), color='white')\nplt.annotate(f'Cov(X, Y) = {covariance_matrix[0][1]:.2f}', xy=(-3, 1), color='white')\nplt.title('Original Case (Covariance ≠ 0)')\n\n# Define the mean and covariance matrix for the equal variance case\nequal_variance_cov_matrix = np.diag([2, 2])  # Equal variance along both dimensions\n\n# Create a multivariate Gaussian distribution for the equal variance case\nrv_equal_variance = multivariate_normal(mean, equal_variance_cov_matrix)\n\n# Calculate the probability density at each point in the grid for the equal variance case\npdf_equal_variance = rv_equal_variance.pdf(pos)\n\n# Create the second subplot for the equal variance case\nplt.subplot(1, 2, 2)\nplt.contourf(x, y, pdf_equal_variance, cmap='viridis')\nplt.annotate(f'Var(X) = {equal_variance_cov_matrix[0, 0]:.2f}', xy=(-3, 3), color='white')\nplt.annotate(f'Var(Y) = {equal_variance_cov_matrix[1, 1]:.2f}', xy=(-3, 2), color='white')\nplt.title('Equal Variance Case (Covariance = 0)')\n\n# Set common labels\nfor ax in plt.gcf().axes:\n    ax.set_xlabel('X')\n    ax.set_ylabel('Y')\n\n# Ensure equal aspect ratio for both subplots\nfor ax in plt.gcf().axes:\n    ax.set_aspect('equal', adjustable='box')\n\n# Create a new axes for the legend with adjusted width\ncax = plt.gcf().add_axes([0.96, 0.3, 0.02, 0.4])  # Adjust the width and position as needed\n\n# Plot vertical colorbar for the legend\ncbar.ColorbarBase(cax, cmap='viridis', orientation='vertical', label='Probability Density')\n\n# Adjust the overall layout\nplt.subplots_adjust(wspace=0.3)\n\nplt.show()\n\n\n\n\n\nThis plot visually illustrates how variance represents the spread along each dimension, and the arrows depict how the covariance matrix encodes the relationships between the dimensions in a Gaussian distribution.\n\nOriginal Case (Covariance ≠ 0):\n\n\nIn the first plot (Original Case), the color yellow represents regions where the probability density is higher. In a Gaussian distribution, the probability density is highest at the mean (center) of the distribution and decreases as you move away from the mean. The color yellow typically corresponds to higher probability values in this context.\n\n\nEqual Variance Case (Covariance = 0):\n\n\nIn the second plot (Equal Variance Case), the color yellow also represents regions of higher probability density. Even though the covariance is zero, meaning there is no linear relationship between the X and Y dimensions, the multivariate Gaussian distribution still has a peak at the mean (center) in each dimension. The color yellow again corresponds to higher probability values in this context.\n\n\n\n\n\nQDA: they have separate Covariances\nLDA: they share a non-zero covariance\nHere the shared variances mean for example 3 in the y-direction and 1 in the x-direction, they however contain a non-zero covariance\nHere the shared variances mean for example 1 in the y-direction and 1 in the x-direction, they however contain a zero covariance."
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#probabilistic-generative-models-k2",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#probabilistic-generative-models-k2",
    "title": "Classification and Decision Theory",
    "section": "6 Probabilistic Generative Models \\(K=2\\)",
    "text": "6 Probabilistic Generative Models \\(K=2\\)\n\\[\n\\begin{align}\nP(C_1|x) &= \\frac{p(x|C_1)p(C_1)}{p(x|C_1)p(C_1)p(x|C_2)p(C_2)}\\\\\n&= \\frac{1}{1+e^-a}\\nonumber\\\\\n\\end{align}\n\\]\nWhere \\(a\\) is the log odds:\n\\[\n\\begin{align}\na &= \\ln\\frac{p(x|C_1)p(C_1)}{p(x|C_2)p(C_2)}\\label{log_odds}\\\\\n\\end{align}\n\\]\nThis can be expressed as the Sigmoid Function:\n\\[\n\\begin{align}\n\\sigma &= \\frac{1}{1+e^{(-a)}}\\\\\n\\end{align}\n\\]\n\nWhen the log odds its possitive in the sigmud function it will converge to 1. This means I am certain it will be class \\(C_1\\)\nIf the log odds is equal meaning not clue which class to assign. The probability of classifing the target to either class is 0.5.\n\nFor \\(a\\) to be equal to zero. I need \\(a=\\ln(1)\\). This 1 means \\(p(x|C_1)p(C_1)=p(x|C_2)p(C_2)\\)\n\nWhen the log odds its negative, the sigmoid function will go to zero. This means I am certain it will be class \\(C_2\\)"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#probabilistic-generative-models-generalk",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#probabilistic-generative-models-generalk",
    "title": "Classification and Decision Theory",
    "section": "7 Probabilistic Generative Models, general:\\(K\\)",
    "text": "7 Probabilistic Generative Models, general:\\(K\\)\n\n\n\n\n\n\nRemember\n\n\n\nYou are given:\n\nClass-conditional densities: \\(p(x|C_k)\\) aka Likelihood\nPrior class probabilities: \\(p(Ck)\\)\n\nWith these two guys you can get:\n\nJoint Distribution: \\(p(x,C_k) = p(x|C_k)p(C_k)\\) the numerator\nThe Posterior \\(p(C_k|x)=\\frac{p(x|C_k)p(C_k)}{p(x)}\\)\n\nGoal:\n\nFind \\(p(C_k|x)\\) so that you can determine the class of \\(x\\) by knowing the Decision boundaries\n\n\n\n\n\\[\n\\begin{align}\nP(C_k|x) &= \\frac{p(x|C_k)p(C_k)}{\\sum_{j=1}^{K}p(x|C_j)p(C_j)}\\\\\n&= \\frac{e^{a_k}}{\\sum_{j=1}^{K}e^{a_j}}\\label{softmax}\\\\\na_k &= \\ln(p(x|C_k)p(C_k)) \\nonumber\n\\end{align}\n\\]\nWhere \\(\\ref{softmax}\\) is called the Softmax:\n\nif \\(a_k&gt;&gt;a_j\\) for all \\(j \\neq k\\) then \\(p(C_k|x)=1\\) and \\(p(C_j|x)=0\\)\nThe Softmax reduces to the Simoid function when \\(K=2\\)\n\n\n7.0.1 How to parametrize Class Conditional Densities (aka The Likelihood)?\nWith Gaussians!\n\\[\n\\begin{align}\np(x|C_k)&=\\mathcal{N}(x|\\mu_k , \\Sigma_k ) \\\\\n        &= \\frac{1}{(2 \\pi)^{D/2}} \\frac{1}{|\\Sigma_k|^{1/2}} \\exp^{\\{-\\frac{1}{2}(x-\\mu_k)^T \\Sigma_k^-1 (x-\\mu_k)\\}} \\label{gaussian_lda}\\\\\n\\end{align}\n\\]\n\nWhere the Gaussian is going to be multivariate and it will be \\(D\\)-dimensional due to the input being \\(x \\in \\mathbb{R}^{D}\\)\n\nThis means for each \\(\\mu_k\\) and \\(\\Sigma_k\\) I would have a different Gaussian distribution\n\n\\(\\Sigma_k\\) determines the shape of my distribution. Like in the python plot above in the left graph\n\nWhen we assume each of these Gaussian share the same the Covariance matrix: \\(\\Sigma_k\\) then we are talking about LDA\nTo determine the decision boundary we have that:\n\\[\n\\begin{align}\np(C_1|X) &= \\frac{1}{1+e^(-a)} = \\sigma(a)\\\\\n\\end{align}\n\\]\nWhere \\(a\\) is defined was defined as the log odds. So replacing \\(p(x|C_k)\\) so replacing \\(\\ref{gaussian_lda}\\) (the Gaussians) in the log odds \\(\\ref{log_odds}\\) give us The Generalized Linear Model:\n\\[\n\\begin{align}\np(C_1|x) &= \\sigma(\\underline{w}^T\\underline{x}+w_o)\\\\\n\\end{align}\n\\]\nAnd now recall that the decision boundary happens when \\(p(C_1|x) = p(C_2|x)\\).\n\nThis all means if we want to make decisions based on the posterior distributions, then \\(a=0\\) meaning the prob/prob is 1 or the \\(\\sigma(a) = \\frac{1}{2}\\)"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#lda-maximum-likelihood-for-k2",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#lda-maximum-likelihood-for-k2",
    "title": "Classification and Decision Theory",
    "section": "8 LDA: Maximum Likelihood for K=2",
    "text": "8 LDA: Maximum Likelihood for K=2\n\nGoal: recover the Gaussian distributions (the join distribution = p(X, C_k)) that have generated the data. To accomplished that we need to take the MLE over the the Gaussian conditional densities aka the likelihood and solve for \\(u_k\\), \\(\\Sigma\\) and priors \\(p(C_k)\\)\n\n\n\n\n\n\n\nIsometric Covariance definition\n\n\n\n\n\nIt is a special case of a covariance matrix where all off-diagonal elements are zero, and the diagonal elements are equal, representing a constant variance or dispersion in all dimensions.\nMathematically, an isometric covariance matrix Σ can be represented as:\n\nΣ = σ² * I\n\nWhere:\n\nΣ is the covariance matrix.\nσ² is the common variance or dispersion parameter.\nI is the identity matrix, which has ones on the diagonal and zeros elsewhere.\n\nIn this form, each element along the diagonal of the covariance matrix Σ is equal to σ², and all off-diagonal elements are zero. This implies that the variables in a multivariate distribution with an isometric covariance matrix have equal variances and are uncorrelated with each other.\n\n\n\nGiven:\n\nGaussian conditional densities aka Likelihoods:\n\n\\[\n\\begin{align}\np(x|C_k) = \\frac{1}{(2 \\pi)^{D/2}} \\frac{1}{|\\Sigma_k|^{1/2}} \\exp^{\\{-\\frac{1}{2}(x-\\mu_k)^T \\Sigma_k^-1 (x-\\mu_k)\\}} \\nonumber\\\\\n\\end{align}\n\\]\n\nPrior \\(p(C_k)\\)\nBecause we have \\(k=2\\) then we can assign \\(p(C_1) = q\\) and \\(p(C_2) = 1-q\\)\n\nWith 1. and 2. we can solve for the Joint distributions:\nFor \\(x_n\\) with \\(t_n =1\\): \\[\n\\begin{align}\np(x_n, C_1) &= p(x_n|C_1)p(C_1) = q \\, N(x_n|\\mu_1,\\Sigma) \\\\\n\\end{align}\n\\]\nFor \\(x_n\\) with \\(t_n =0\\): \\[\n\\begin{align}\np(x_n, C_2) &= p(x_n|C_2)p(C_2) = (1-q) \\, N(x_n|\\mu_2, \\Sigma)\\\\\n\\end{align}\n\\]\n\n\\(t_n\\) is binary if I do \\(\\sum t_n\\) here I am counting the number of times \\(t_n\\) is equals to 1.\n\n\n8.1 Deriving \\(q_{ML}\\)\n\\[\n\\begin{align}\nq_{ML} &= \\frac{1}{N} \\sum_{n=1}^{N} t_n = \\frac{N_1}{N}\\\\\n\\end{align}\n\\]\n\n\\(q\\) is the prior probability of observing class \\(K=1\\). The result above means the total number of observations that I have observed \\(t_n=1\\)\n\n\n\n8.2 Deriving \\(\\mu{ML}\\)\n\\[\n\\begin{align}\n\\mu_{1,ML} &= \\frac{1}{N_1} \\sum_{n=1}^{N} t_n \\, x_n\\\\\n\\end{align}\n\\]\n\n\\(\\mu_{1,Ml}\\) is the sample mean of all my observations where \\(x_n\\) belongs to class \\(K=1\\). Here $t_n =1 $ when the class is 1.\n\n\\[\n\\begin{align}\n\\mu_{2,ML} &= \\frac{1}{N_2} \\sum_{n=1}^{N} (1-t_n) \\, x_n\\\\\n\\end{align}\n\\]\n\n\\(\\mu_{2,Ml}\\) is the sample mean of all my observations where \\(x_n\\) belongs to class \\(K=2\\)\n\n\n\n8.3 Covariance for discrete Random Variables\nFor class \\(i\\) the covariance matrix can be calculated as: \\[\n\\begin{align}\n\\Sigma_i &= \\frac{1}{N_i}\\sum_{n=1}^{N_i}(x_n-\\mu_i)(x_n-\\mu_i)^T \\\\\n\\end{align}\n\\]\nWhere:\n\n\\(N_i\\) ​is the number of data points in class \\(i\\)\n\\(x_n\\) is a data point in class \\(i\\)\n\\(\\mu_i\\) is the mean vector of class \\(i\\)\n\n\n\n\n\n\n\nHow to classify a new data point?\n\n\n\n\n\n\nGaussian Classifier: Once you have the covariance matrices for each class, you can use them to build a Gaussian classifier. The Gaussian classifier estimates the likelihood of a given data point belonging to each class based on the probability density function of a multivariate Gaussian distribution with the class’s mean and covariance matrix.\nClassification: When you receive a new data point, you calculate the likelihood of it belonging to each class using the Gaussian distribution parameters (mean and covariance matrix) for each class. You can then assign the data point to the class with the highest likelihood.\n\n\n\n\nThe whole point of LDA was explained at: here\n\n\n8.4 Disadvantages of LDA\n\nSensitive to outliers. Meaning if I have a point really far from \\(\\mu_1\\) then it induces a large shift to the actual \\(\\mu_1\\)\nRelies in handcrafted features, if I go to high dimensional spaces I need to make choices and complicates things\nThe same as regression, here in clarification with LDA the MLE MAximum Likelihood are prone to overfilling. The latter because any regularization has been applied\n\nSo far:"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#probabilistic-generative-models-discrete",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#probabilistic-generative-models-discrete",
    "title": "Classification and Decision Theory",
    "section": "9 Probabilistic Generative Models: Discrete",
    "text": "9 Probabilistic Generative Models: Discrete\nIn this section we parametrize the class-conditional density with other distributions\n\nSo far we parametrize the Class conditional distributions with Gaussians. We can use however different ones. This is necessary when ie. the data it is not continuous and for instance its discrete.\nIn the Continuous space the number of parameters does not scales as much as in the discrete where then we have for i.e a binary classification to \\(2^D\\) parameters. The reasons is that we cannot fit anymore a Gaussains distribution to the discrete variables\n\nTo contrast the huge num. of parameters then we are going to make a model assumption that is:\n\nNaive Bayes assumption: feature value are treated as independent when conditioned on class \\(C_k\\).\n\nThe above means that we are going to model each feature value with its own distribution. This in turn means that to model \\(p(x|C_k, \\lambda_1,...,\\lambda_D)\\) we will have \\(D\\) number of parameters. The following equation accounts for that using the product symbol.\nGiven:\n\nClass-conditional probabilities: \\[\n\\begin{align}\np(x|C_k) &= \\prod_{i=1}^{D} \\, p(x_i|C_k) \\\\\n&= \\prod_{i=1}^{D} \\,  \\pi_{k_i}^{x_i}(1- \\pi_{k_i}^{x_i})^{1-x_i} \\nonumber\n\\end{align}\n\\]\n\nHere:\n\n\\(x_i\\) takes the value \\(0\\) or \\(1\\) given my class \\(C_k\\)\n\nThe above equation was modeled using the bernoulli equation\n\n\n\n\n\n\nEffect of changing parameters in Bernoulli distribution\n\n\n\n\n\nThe Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes, often referred to as “success” and “failure.” It is named after Swiss mathematician Jacob Bernoulli. The Bernoulli distribution is used to represent situations where an event can result in one of two possible outcomes, typically denoted as 1 (success) or 0 (failure).\nHere are the key characteristics and properties of the Bernoulli distribution:\n\nParameters: The Bernoulli distribution has a single parameter, denoted as “p,” which represents the probability of success (or the probability of the outcome being 1). The parameter “q” represents the probability of failure (q = 1 - p).\nProbability Mass Function (PMF): The probability mass function of the Bernoulli distribution is defined as follows:\nP(X = x) = p^x * q^(1-x)\nWhere:\n\nP(X = x) is the probability of the random variable X taking the value x (either 0 or 1).\np is the probability of success (X = 1).\nq is the probability of failure (X = 0).\n\nMean and Variance:\n\nThe mean (expected value) of a Bernoulli random variable is E(X) = p.\nThe variance of a Bernoulli random variable is Var(X) = p(1-p).\n\nSupport: The Bernoulli distribution is defined over the set of values {0, 1}.\n\nApplications of the Bernoulli distribution: - Modeling coin flips (heads or tails). - Modeling success/failure outcomes, such as whether a product is defective (failure) or non-defective (success). - Modeling binary decisions, such as whether a customer makes a purchase (success) or does not make a purchase (failure).\nExample Scenario: Suppose you have a coin that is not fair; it is biased. When you flip this biased coin, it does not have an equal chance of landing on heads (H) or tails (T). Instead, it has a higher probability of landing on heads.\nProbability of Success (Heads): In this example, we have a probability of success (getting heads) denoted as “p.” Let’s say that “p” is equal to 0.6. This means that when you flip the coin, there is a 60% chance of getting heads (H) and a 40% chance of getting tails (T).\nUsing the Bernoulli Distribution: To model this coin-flipping scenario, you can use a Bernoulli distribution. In this context:\n\nThe outcome “1” can represent success (getting heads).\nThe outcome “0” can represent failure (getting tails).\n\nThe Bernoulli distribution allows you to calculate the probability of success (1) or failure (0) for each coin flip.\nBernoulli Distribution Parameters: - Parameter “p” is the probability of success (1), which is 0.6 in this case. - Parameter “q” is the probability of failure (0), which is 1 - p, or 0.4 in this case.\nUsing the Bernoulli PMF: The Bernoulli probability mass function (PMF) allows you to calculate the probability of each outcome:\n\nP(X = 1) represents the probability of getting heads (success), which is equal to “p” or 0.6.\nP(X = 0) represents the probability of getting tails (failure), which is equal to “q” or 0.4.\n\nInterpreting the Results: When you flip this biased coin multiple times, the Bernoulli distribution helps you understand the likelihood of getting heads (success) or tails (failure) for each individual flip. For example:\n\nIf you flip the coin 10 times, you would expect to get heads approximately 6 times (0.6 * 10) on average.\nHowever, the actual outcomes in any given sequence of 10 flips may vary around this expected value due to randomness.\n\nThe Bernoulli distribution provides a mathematical framework to model and analyze such binary outcomes in scenarios like coin flipping, where there are two possible results with different probabilities of occurrence.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import bernoulli\n\n# Define the probability of success (getting heads)\np = 0.6\n\n# Number of coin flips\nnum_flips = 10\n\n# Simulate the outcomes of flipping the biased coin 10 times\noutcomes = bernoulli.rvs(p, size=num_flips)\n\n# Calculate the PMF of the Bernoulli distribution\nx = [0, 1]\npmf = bernoulli.pmf(x, p)\n\n# Create a bar plot to visualize the PMF\nplt.figure()\n\nplt.subplot(1, 2, 1)\nplt.bar(x, pmf, align='center', alpha=0.7)\nplt.xticks(x)\nplt.xlabel('Outcome')\nplt.ylabel('Probability')\nplt.title(f'Bernoulli Distribution PMF (p={p})')\n\nplt.subplot(1, 2, 2)\nplt.bar(range(num_flips), outcomes, align='center', alpha=0.7)\nplt.xticks(range(num_flips))\nplt.xlabel('Coin Flip')\nplt.ylabel('Outcome (0 or 1)')\nplt.title(f'Outcomes of {num_flips} Coin Flips (p={p})')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\\(\\pi_{k_i}=p(x_i=1|C_k)\\)\n\nNow the number of parameters per class is \\(D\\)\n\nWith this parametrization we can calculate the posterior probability: \\(p(C_k|x)\\) where we can compute it with our recently parametrized-bernouli like class density aka the likelihood. Here modeling the prior follows the same as how we did it with the class-density akak Likelihood, With these two we can get the joint aka the evidence evidence.\nRemember the evidence is the marginalization (sumation) over the joint (\\(p(x,C_k)\\)).\n\\[\n\\begin{align}\np(x) = \\sum_{k=1}^{K}p(x,C_k) = \\sum_{k=1}^{K}p(x|C_k)p(C_k)\n\\end{align}\n\\]"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#discriminative-linear-models",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#discriminative-linear-models",
    "title": "Classification and Decision Theory",
    "section": "10 Discriminative Linear Models",
    "text": "10 Discriminative Linear Models\nWe go away momentarily from the prob view and try model the discriminant function without describing first a prob model.\nWe will do the following. Given input \\(x \\in \\mathbb{R}^{Dx1}\\) and targets \\(t \\in {C1, C2}={-1,1}\\)\n\\[\n\\begin{align}\ny(x,\\overline{w})&=f(\\overline{w}^t \\boldsymbol{\\phi}) \\\\\n\\boldsymbol{\\phi} &= (\\phi_{0}(x),\\phi_{1}(x),...,\\phi_{M-1}(x))^T\n\\end{align}\n\\]\nThis model is linear with respect to \\(w\\)"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#least-squares-for-classification",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#least-squares-for-classification",
    "title": "Classification and Decision Theory",
    "section": "11 Least Squares for Classification",
    "text": "11 Least Squares for Classification\nWe are gonna have for each \\(K\\) a linear model (discriminant function)\n\\[\n\\begin{align}\ny_k = (\\textbf{x}) = \\textbf{w}_{k}^{T}\\textbf{x} + w_{k0}\n\\end{align}\n\\]\nWhere:\n\nInputs: \\(\\textbf{x} \\in \\mathbb{R}^{Dx1}\\), \\(D\\)-Dimensional feature vector (data points that describe each vector)\ni.e for \\(D=10\\) we have \\(\\textbf{x}_n = (x1, x2, ...,x_D)^T = (0,1,0,...0)\\)\nFor instance in the document classifier form the practicals, we have that each word from the document will add up to form a \\(D\\) vector. Each element in this vector correspond \\(0\\) or \\(1\\) indicating whether a word belongs or not to the document.\n\\(\\textbf{w}_k^T \\in \\mathbb{R}^{1xD}\\) is the weight vector for class \\(k\\)\n\\(w_{k0}\\) is the bias term.\n\nWe can generalize this not only for one \\(y_k\\) but for all \\(K\\text{s}\\) like so:\n\\[\n\\begin{align}\n\\textbf{y} =  \\mathbf{\\widetilde W}^T \\mathbf{\\tilde x}\n\\end{align}\n\\]\nWhere:\n\nMatrix \\(\\mathbf{\\widetilde W} \\in \\mathbb{R}^{MxK}\\): has in the kth column \\(\\mathbf{\\tilde w}_k = (w_{k0}, \\textbf{w})^T \\in \\mathbb{R}^{(D+1)x1} \\in \\mathbb{R}^{Mx1}\\)\nMatrix \\(\\mathbf{\\widetilde W}^T \\in \\mathbb{R}^{KxM}\\)\n\\(\\mathbf{\\tilde{x}} = (1, \\textbf{w})^T \\in \\mathbb{R}^{(D+1)x1}\\in \\mathbb{R}^{Mx1}\\)\nVector: \\(\\textbf{y(x)} \\in \\mathbb{R}^{Kx1}\\)\n\nRemember at the end \\(y_k\\) is just a number (you can think of a number that tells you how far \\(x\\) is from the decision surface)so we are going to assign \\(\\textbf{x}\\) to class \\(C_k\\) if: \\[\n\\DeclareMathOperator*{\\argmax}{argmax}\n\\begin{align}\nk = \\argmax_{j} \\, y_j(\\textbf{x})\\\\\n\\end{align}\n\\]\nNow, for this to work we need target values so that we can minimize our error function:\n\\[\n\\begin{align}\nE_D(\\mathbf{\\widetilde W})=\\frac{1}{2}Tr[(\\mathbf{\\widetilde X}\\mathbf{\\widetilde W} - \\mathbf{\\widetilde T})^T(\\mathbf{\\widetilde X}\\mathbf{\\widetilde W} - \\mathbf{\\widetilde T})]\n\\end{align}\n\\]\n\n\n\n\n\n\nRemember: What was Linear Regresion & Do we get the target values?\n\n\n\n\n\nIn simple linear regression, there is one target value, whereas in multiple linear regression, there can be multiple target values.\nIn a typical linear regression problem, you are given the input features (independent variables) and the corresponding target values (dependent variables) as training data. The goal of linear regression is to learn a linear relationship between the input features and the target values\nInput Features (Independent Variables): These are the variables that you use to make predictions. Each data point in the dataset has a set of input features.\nTarget Values (Dependent Variables): These are the values you are trying to predict or estimate based on the input features. Each data point in the dataset has a corresponding target value.\nThe linear regression model is trained using this dataset to find the coefficients (weights) for the input features that minimize the mean squared error between the predicted values and the actual target values. Once the model is trained, you can use it to make predictions on new or unseen data.\n\n\n\nIn the above equation \\(E_D\\):\n\n\\(X \\in \\mathbb{R}^{Nx(D+1)} \\in \\mathbb{R}^{NxM}\\), where each row is a different observation (a different number of document like in the practicals) represented by the vector \\(\\mathbf{\\tilde{x}}_n\\)\nTarget: \\(T \\in \\mathbb{R}^{NxK}\\), where each row is a different one-hot encoded vector that is trying to predict what is the class that \\(\\mathbf{\\tilde{x}}_n\\) belongs to. The one-hot enconding means that for that particular kth value is 1 meaning it belongs to the kth class and for the rest is zero.\n\\(t \\in \\mathbb{R}^{Kx1}\\) where \\(t \\in \\{C_1, C_2, ..., C_k\\}\\) and \\(K\\) classes\ni.e for \\(K=4\\) for binary classification we have we have \\(t = (0, 0, 0, 1)^T\\). The latter would be the one-hot encoding for \\(K=4\\) documents\ni.e if \\(k=5\\) my one-hot encoding when it is predicting for class k=3 would be. \\(t_n=(0,0,1,0,0)^T\\)\n\n\\(Tr\\): Sum of the diagonal matrix\n\n\nGoal: Now that we have defined our error we want to minimize it as a function of \\(W\\) so that when we new values for \\(x\\) come, then we multiply with our computed \\(W\\) and finally get our predicted \\(y(x)\\).\n\nSolution:\n\\[\n\\begin{align}\n\\mathbf{\\widetilde W}_{LS} = (\\mathbf{\\widetilde X}^T\\mathbf{\\widetilde X})^{-1}\\mathbf{\\widetilde X}^T\\textbf{T} = \\mathbf{\\widetilde X}^\\dagger\\textbf{T}\n\\end{align}\n\\]\nFinally to predict the label for \\(\\mathbf{\\tilde{x}}\\) we use our discriminant function: \\[\n\\begin{align}\n\\textbf{y}_{LS}(\\textbf{x})&=\\mathbf{\\widetilde W}_{LS}^T\\mathbf{\\tilde{x}}\\\\\n& \\in \\mathbb{R}^{KxM} \\, \\in \\mathbb{R}^{Mx1} \\nonumber\\\\\n&\\in \\mathbb{R}^{Kx1}\\nonumber\n\\end{align}\n\\]\nSo one number per each class. We get a vector with dimensions \\(K\\) because this vector was one-hot encoded so that means we have to look at the value that contains \\(1\\) and that \\(k_{th}\\) element would be our class \\(C_k\\)\n\nDiscriminant functions are used to classify data points into different classes based on the values of the discriminant function\n\n\n11.1 Why Linear Regresion for Classification is not a good idea?\n\nThe decision boundaries are sensitive to outliers. Our Linear Regresion wants our distance to be as close to \\(y(x)=1\\) if the target value is also \\(1\\), but if there is outliers then these points will influence the decision boundary skewing it.\nFor \\(k&gt;2\\) some decision regions can become very small or are even completely ignored\nThe components of the \\(\\textbf{y}_{LS}(\\textbf{x})\\) are not real probabilities"
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#multi-class-logistic-regression",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#multi-class-logistic-regression",
    "title": "Classification and Decision Theory",
    "section": "12 Multi-class Logistic Regression",
    "text": "12 Multi-class Logistic Regression\nConsider logistic regresion for \\(K\\) classes with \\(N\\) training vectors \\(\\{x_n\\}_{n=1}^{N}\\). Each of these vectors is mapped to a different feature vector.\n\\[\n\\begin{align}\n\\phi_n = \\phi(x_n) = (\\phi_0(x_n), \\phi_1(x_n), ..., \\phi_{M-1}(x_n))^T\n\\end{align}\n\\]\n\nEach vector \\(x_n\\) has a target vector \\(t_n\\) of size \\(K\\)\n\n\\[\n\\begin{align}\nt_n = (t_{n1}, t_{n2}, ..., t_{nK})^T\n\\end{align}\n\\]\nWhere, \\(t_{nk} = 1\\) if \\(x_n \\in C_k\\), \\(0\\) otherwise.\n\nThe input data can be collected in a matrix \\(X\\) such that the n-th row is given by \\(\\textbf{x}_{n}^{T}\\). The targets can also be collected in a matrix \\(T\\) where each n-th row is given by \\(\\textbf{t}_{n}^{T}\\)\n\nWe have:\n\\[\n\\begin{align}\ny_k(\\phi) = p(C_k|\\phi(x), \\textbf{w}_1,...,\\textbf{w}_K) = \\frac{exp(a_k)}{\\sum_{j=1}^{K}exp(a_j)}\n\\end{align}\n\\]\nWhere we have \\(a_k = \\textbf{w}_{k}^{T}\\phi\\)\nDimensions:\n\\[\n\\begin{align}\n\\textbf{y(x)} &= (y_1(x),...,y_k(x) )^T &\\in \\mathbb{R}^{Kx1} \\nonumber\\\\\n\\phi &= \\phi(x) = (\\phi_0(x), ..., \\phi_{M-1}(x))^T &\\in \\mathbb{R}^{Mx1}\\nonumber\\\\\n\\mathbf{\\phi}_n &= \\phi(x_n) = (\\phi_0(x_n), ..., \\phi_{M-1}(x_n))^T\\nonumber\\\\\n\\Phi &= (\\phi_1, \\phi_2, ..., \\phi_{N})^T &\\in \\mathbb{R}^{NxM}\\nonumber\\\\\n\\mathbf{w}_k &= (w_{k0},...,w_{k(M-1)})^T \\in \\mathbb{R}^{(D+1)x1} &\\in \\mathbb{R}^{Mx1}\\nonumber\\\\\nX &= (\\textbf{x}_1,...,\\textbf{x}_N)^T \\in \\mathbb{R}^{Nx(D+1)} &\\in \\mathbb{R}^{NxM}\\nonumber\\\\\n\\textbf{t}_n &= (t_{n1}, ...,t_{nK})^T  &\\in \\mathbb{R}^{1xK}\\nonumber\\\\\nT &= (\\textbf{t}_1,...,\\textbf{t}_N)^T &\\in \\mathbb{R}^{NxK}\\nonumber\\\\\n\\end{align}\n\\]\n\n12.1 Multivariate Gaussian Distribution\nThe PDF: \\[\n\\begin{align}\nf(\\mathbf{x} | \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}) = \\frac{1}{(2\\pi)^{\\frac{n}{2}} |\\boldsymbol{\\Sigma}|^{\\frac{1}{2}}} \\exp\\left(-\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu})^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu})\\right)\\\\\n\\end{align}\n\\]\nWhere:\n\n\\(\\mathbf{x}\\) represents the vector of random variables (n-dimensional).\n\\(\\boldsymbol{\\mu}\\) is the mean vector, which is also an n-dimensional vector.\n\\(\\boldsymbol{\\Sigma}\\) is the covariance matrix, which is an n x n symmetric positive-definite matrix.\n\\(|\\boldsymbol{\\Sigma}|\\) represents the determinant of the covariance matrix.\n\\((\\mathbf{x} - \\boldsymbol{\\mu})^T\\) represents the transpose of the vector \\((\\mathbf{x} - \\boldsymbol{\\mu}\\)).\n\\(\\boldsymbol{\\Sigma}^{-1}\\) is the inverse of the covariance matrix."
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#fixed-bssis-functions",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#fixed-bssis-functions",
    "title": "Classification and Decision Theory",
    "section": "13 Fixed Bssis Functions",
    "text": "13 Fixed Bssis Functions\nIn the context of basis functions, the statement “Easy way to define nonlinear models (wrt the original features) via linear models (in the parameters)” means that you can represent complex, nonlinear relationships between your input features and the output variable by using a linear model in terms of transformed or “basis” functions. Let’s break down what this statement implies:\n\nNonlinear Models: Nonlinear models are those that cannot be expressed as simple linear relationships between the input features and the output. In many real-world problems, the relationships between variables are not linear, which makes modeling them directly with linear models (like linear regression) challenging.\nOriginal Features: These are the raw input features of your data. For example, if you’re working with a dataset of house prices, the original features might include the number of bedrooms, square footage, and location.\nBasis Functions: Basis functions are mathematical functions that transform the original features into a new set of features. These new features are designed to capture the underlying nonlinear relationships in the data. Common basis functions include polynomial functions (e.g., squaring a feature to capture quadratic relationships) and radial basis functions (used in radial basis function networks).\nLinear Models (in the Parameters): Despite the use of basis functions to transform the input features, the model’s structure is still linear in terms of its parameters. This means that you can express the output variable as a linear combination of the transformed features, where the coefficients of this linear combination are the parameters of the model. For example, you might have a model like:\ny = w0 + w1 * basis_function1(x) + w2 * basis_function2(x) + ... + wn * basis_functionn(x)\nHere, w0, w1, w2, ..., wn are the model parameters, and basis_function1(x), basis_function2(x), ... are the transformed features created by the basis functions.\n\nSo, the statement is highlighting that by using basis functions to transform the original features, you can still use a linear model in terms of its parameters to capture complex, nonlinear relationships in the data. This approach makes it easier to model nonlinear data patterns while benefiting from the simplicity and interpretability of linear models when it comes to parameter estimation and inference."
  },
  {
    "objectID": "blog/2023-09-25_classification-and-decision-theory/index.html#faq",
    "href": "blog/2023-09-25_classification-and-decision-theory/index.html#faq",
    "title": "Classification and Decision Theory",
    "section": "14 FAQ",
    "text": "14 FAQ\n\n\n\n\n\n\n1. Why if correlated features are treated independently, the evidence for a class will be overcounted?\n\n\n\n\n\nI apologize for any confusion. Let me break down that fragment for better clarity:\n\nEvidence for a Class: When we talk about “evidence for a class” in a classification problem, we’re referring to the information or characteristics of a data point’s features that suggest or indicate which class that data point should belong to. This evidence is essentially the input data that the classification algorithm uses to make predictions.\nCorrelated Features: Correlated features are features that have some degree of statistical relationship or similarity between them. In the context of a classification problem, correlated features might provide similar or redundant information about the data.\nRedundant or Overlapping Information: When features are correlated, it means that some of the information they provide is redundant or overlapping. In other words, these features may convey the same or very similar details about the data point. For example, if you have two highly correlated features, knowing the value of one feature might give you a good idea about the value of the other.\nTreating Features Independently: In some classification algorithms, especially simple ones like Naive Bayes, each feature is treated as if it is completely independent of the others. This assumption simplifies the modeling process but can be problematic when features are correlated.\nCounting Shared Information Multiple Times: When you treat correlated features independently, you essentially consider the shared or overlapping information multiple times. For example, if two features are highly correlated and you treat them independently, you might effectively count the same information twice, once for each correlated feature. This can lead to an overestimation of the importance of that shared information.\n\nTo illustrate this concept, consider a classification task where you’re trying to predict whether an email is spam (class 1) or not spam (class 0) based on two features: the number of times the word “money” appears in the email and the number of times the word “cash” appears. If these two features are highly correlated (i.e., they tend to occur together), treating them independently might lead to double-counting the evidence related to financial terms, which could skew the classification result. Therefore, it’s important to handle correlated features appropriately in order to make accurate predictions.\n\n\n\n\n\n\n\n\n\n2. What is the Köppen climate classification system?\n\n\n\n\n\nIt consists of five primary climate groups, which are further subdivided into various climate types. Here’s a breakdown of the primary climate groups and their associated climate types:\n\nGroup A: Tropical Climates:\n\nAf: Tropical rainforest climate\nAm: Tropical monsoon climate\nAw: Tropical wet and dry or savanna climate\n\nGroup B: Dry Climates:\n\nBWh: Hot desert climate\nBWk: Cold desert climate\nBSh: Hot semi-arid climate\nBSk: Cold semi-arid climate\n\nGroup C: Temperate Climates:\n\nCfa: Humid subtropical climate\nCwa: Monsoon-influenced humid subtropical climate\nCfb: Oceanic or maritime climate\nCfc: Subpolar oceanic climate\nCsa: Mediterranean climate\nCsb: Mediterranean climate with dry summer\nCwa: Monsoon-influenced humid subtropical climate\nCwc: Cold subtropical highland climate\n\nGroup D: Continental Climates:\n\nDfa: Hot-summer humid continental climate\nDfb: Warm-summer humid continental climate\nDfc: Subarctic or boreal climate\nDwa: Hot-summer subarctic climate\nDwb: Warm-summer subarctic climate\n\nGroup E: Polar Climates:\n\nET: Tundra climate\nEF: Ice cap climate\n\n\nAdditionally, there is a Group H: Highland Climates category for high-altitude regions with their own unique climate characteristics.\nSo, there are a total of 12 primary climate types within the Köppen climate classification system, and each of these primary types can be further refined with additional letters and numbers to provide more specific details about temperature and precipitation patterns.\n\n\n\n\n\n\n\n\n\n3. What are Generative Models?\n\n\n\n\n\nIn machine learning, generative models are a class of models used to learn the underlying probability distribution of the data. These models are called “generative” because they can generate new data samples that resemble the training data. In other words, they capture the structure and patterns within the data and can be used to create synthetic data points that are statistically similar to the real data.\n\nHow NB is a generative model?\n\nIn generative models we model two things: 1. the class-conditional densities p(x|C_k) 2. the class priors p(C_k). With these two we can compute the join distribution.\nFurthermore, one can use Bayes Theorem to compute the posterior p(C_k|x). Looking at the equation above we see that we have defined the numerator as the joint distribution obtained from our generative model. For the denominator part, we have computed the evidence by marginalising over the k classes.\nHaving done this, (we have used Naive Bayes to model the distribution of our features values as independent to decrease the number of parameters) we have obtain the posterior probability which can be used to determine class membership for each new input x.\nAs referred in Bishop, approaches that explicit or implicitly model the distribution of input as well as the outputs are known as generative models. They called generative models because by sampling from them it is possible to generate synthetic data points in the input space.\n\nWhat does it mean by Generative models?\n\nIn Bishop we have:\n\nApproaches that explicitly or implicitly model the distribution of inputs as well as outputs are known as generative models, because by sampling from them it is possible to generate synthetic data points in the input space.\n\nThe statement you provided highlights a key characteristic of generative models and explains why they are called “generative.” Let’s break down the meaning of this statement:\n\nApproaches that explicitly or implicitly model the distribution of inputs as well as outputs: This part of the statement refers to machine learning models that are designed to not only capture the relationship between inputs and outputs but also to learn the underlying probability distribution of the inputs. In other words, these models aim to understand how the input data is generated probabilistically.\nKnown as generative models: These models are commonly referred to as “generative models” because they have the capability to generate synthetic data points that resemble the real data. This is achieved by sampling from the learned distribution of inputs. In essence, generative models can create new data instances that are statistically similar to the training data.\nBy sampling from them it is possible to generate synthetic data points in the input space: This part of the statement explains the practical significance of generative models. Once a generative model has learned the data distribution, you can use it to create new data points. These new data points are generated by sampling from the probability distribution of inputs that the model has learned during training.\n\nHere’s a simple example to illustrate this concept: Consider a generative model trained on a dataset of images of cats. The model learns not only to recognize cats but also the underlying distribution of features that define what a cat looks like. Once trained, you can sample from this model, and it will generate new images of cats that resemble those in the training data. These generated images are synthetic data points in the input space because they represent new, artificial cat images that the model has “generated” based on what it has learned about cats.\n\n\n\n\n\n\n\n\n\n4. Convex regions\n\n\n\n\n\nLet’s consider a 2D space, and we have a convex region “C1.” We’ll choose two points within this region, x0 and x1. Then, we’ll create a line segment by varying λ between 0 and 1 and plot the points on the line segment. If all points on the line segment remain within C1, it indicates that C1 is convex.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define the convex region C1 (a circle for this example)\nradius = 2\ncenter = (0, 0)\n\n# Generate random points within C1\ntheta = np.linspace(0, 2 * np.pi, 100)\nx0 = center[0] + radius * np.cos(theta)\ny0 = center[1] + radius * np.sin(theta)\n\n# Choose two points x0 and x1 within C1\nx0_point = (1, 1)\nx1_point = (-1, 1)\n\n# Create a figure and axis\nfig, ax = plt.subplots()\n\n# Plot C1 as a filled circle\nax.fill(x0, y0, 'b', alpha=0.5)\n\n# Plot the two chosen points x0 and x1\nax.plot(x0_point[0], x0_point[1], 'ro', label='x0')\nax.plot(x1_point[0], x1_point[1], 'go', label='x1')\n\n# Generate points along the line segment defined by x0 and x1\nlambdas = np.linspace(0, 1, 50)\nline_points = [(1 - l) * np.array(x0_point) + l * np.array(x1_point) for l in lambdas]\n\n# Check if all points on the line segment are within C1\nall_inside_c1 = all(np.linalg.norm(p - center) &lt;= radius for p in line_points)\n\n# Highlight the line segment\nif all_inside_c1:\n    ax.plot([p[0] for p in line_points], [p[1] for p in line_points], 'k-', label='Line Segment (Convex)')\nelse:\n    ax.plot([p[0] for p in line_points], [p[1] for p in line_points], 'r-', label='Line Segment (Not Convex)')\n\n# Set axis limits\nax.set_xlim(-3, 3)\nax.set_ylim(-3, 3)\n\n# Add labels and legend\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Convex Region and Line Segment')\nax.legend()\n\n# Show the plot\nplt.grid(True)\nplt.show()\n\n\n\n\n\nIn this example, we define a convex region “C1” as a circle. We choose two points, x0 and x1, within C1 and create a line segment by interpolating between them using λ values. If all points on the line segment remain within the circle (C1), it indicates that C1 is convex. The plot will show the circle, the two chosen points, and the line segment along with labels and a legend."
  },
  {
    "objectID": "blog/2023-06-09_on-the-topic/index.html",
    "href": "blog/2023-06-09_on-the-topic/index.html",
    "title": "On the topic of Optimization",
    "section": "",
    "text": "Below the apps I use in a daily basis to make my life easier\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Workflow\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Lua\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Workflow\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Lua\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          June 9, 2023\n        \n      \n      \n        \n      \n      \n\n    \n        Quick Links\n    \n         Quick Links:\n                                     Microsoft Edge\n                        \n                                     Hammerspoon Code"
  },
  {
    "objectID": "blog/2023-06-09_on-the-topic/index.html#microsoft-edge",
    "href": "blog/2023-06-09_on-the-topic/index.html#microsoft-edge",
    "title": "On the topic of Optimization",
    "section": "1 Microsoft Edge",
    "text": "1 Microsoft Edge\n\nPrefer this over Safari because of add-ons. Chrome is the same\n\nI used it to install apps like YouTube or Google Translator so that when I hit a shortcut command, it opens that app. Here it’s an example."
  },
  {
    "objectID": "blog/2023-06-09_on-the-topic/index.html#hammerspoon",
    "href": "blog/2023-06-09_on-the-topic/index.html#hammerspoon",
    "title": "On the topic of Optimization",
    "section": "2 Hammerspoon",
    "text": "2 Hammerspoon\n\nI use this application to create global shortcuts. Donwload App\n\nUses Lua programming language to assign keybindings to certain actions. Here a sneak peek of what can you do.\n--- Open App\nfunction open(name)\n    return function()\n        hs.application.launchOrFocus(name)\n        if name == 'Finder' then\n            hs.appfinder.appFromName(name):activate()\n        end\n    end\nend\nFor complete implementation visit this repo.\nThe above function can be called to open an app: Google Maps by an i.e. the shortcut: ⌘ + M\n--- Binding Keys\nhs.hotkey.bind({ \"cmd\" }, \"M\", open(\"Google Maps\"))\n\n2.1 Windows Approach\nFor Windows alternative see the code below:\n\n\nCode\n\n#MaxHotkeysPerInterval 200\n!WheelUp::Volume_Up\n!WheelDown::Volume_Down\n!MButton::Volume_Mute\n&lt;#!e::\nRun, %WINDIR%\\explorer.exe\nreturn\n!q::Send !{F4}\nreturn\n&lt;#!x::\nRun, msedge.exe\nreturn\n!y::\nRun, C:\\Users\\datoapnta\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\YouTube.lnk\nreturn"
  },
  {
    "objectID": "blog/2023-06-09_on-the-topic/index.html#honourable-mentions",
    "href": "blog/2023-06-09_on-the-topic/index.html#honourable-mentions",
    "title": "On the topic of Optimization",
    "section": "3 Honourable Mentions",
    "text": "3 Honourable Mentions\n\nThe apps above can do the same, but I like the UX interface.\n\n\n\n\nApp\nDescription\n\n\n\n\nBetterTouchTool\nEnables trackpad new gestures shortcuts\n\n\nAutoHotkey\nSame as Hammerspoon but for Windows\n\n\nTiles\nWindows manager (allows keybindings)"
  },
  {
    "objectID": "blog/2023-07-29_cafe-negro-color-miel/index.html",
    "href": "blog/2023-07-29_cafe-negro-color-miel/index.html",
    "title": "Cafe Negro color Miel",
    "section": "",
    "text": "Cafe Negro color Miel\n        \n        \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Poems\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Spanish\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Poems\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Spanish\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          July 29, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\nby Danilo Toapanta \n\nBlog  &gt; Poems\n\n\nTus ojos son misterio\ncafes negros\nmi reflejo en ti\ncuando estoy alegre\ntus ojos sonrien\ncuando estoy triste\nellos suspiran\naveces nos quedamos quietos\nno hay palabras\npero nuestros ojos\noh vida, te lo aseguro\nellos estan\nplaticando como tortolos"
  },
  {
    "objectID": "blog/2023-09-04_mnist-classification/index.html",
    "href": "blog/2023-09-04_mnist-classification/index.html",
    "title": "MNIST Classification",
    "section": "",
    "text": "Classification example using Tensorflow\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 4, 2023\n        \n      \n      \n        \n      \n      \n\n    \n        Quick Links\n    \n         Quick Links:\n                                    \n                 Notebook\n                        \n                                    \n                 requirements.txt"
  },
  {
    "objectID": "blog/2023-09-04_mnist-classification/index.html#how-to-run-locally",
    "href": "blog/2023-09-04_mnist-classification/index.html#how-to-run-locally",
    "title": "MNIST Classification",
    "section": "1 How to run locally",
    "text": "1 How to run locally\n$ pip install -r requirements.txt"
  },
  {
    "objectID": "blog/2023-09-04_mnist-classification/index.html#importing-all-libraries",
    "href": "blog/2023-09-04_mnist-classification/index.html#importing-all-libraries",
    "title": "MNIST Classification",
    "section": "2 Importing all libraries",
    "text": "2 Importing all libraries\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nimport cv2\nnp.random.seed(42)                          # This allows us to reproduce the results from our script\nfrom keras.models import Sequential             \nfrom keras.layers import Dense, Activation\nfrom keras.optimizers import Adam, SGD\nfrom keras.utils import to_categorical \n\n\n(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\nprint('Total no of Images: ',X_train.shape[0]) \nprint('Size of Image:', X_train.shape[1:])\nprint('Total no of labels:', y_train.shape)\n\nTotal no of Images:  60000\nSize of Image: (28, 28)\nTotal no of labels: (60000,)\n\n\n\n# Look input data\nnum = 10\nnum_row = 2\nnum_col = 5\nimages = X_train[:num]\nlabels = y_train[:num]\n\n# Ploting images\nfig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\nfor i in range(num):\n    ax = axes[i//num_col, i%num_col]\n    ax.imshow(images[i], cmap='gray')\n    ax.set_title('Label: {}'.format(labels[i]))\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "blog/2023-09-04_mnist-classification/index.html#prepare-input-data",
    "href": "blog/2023-09-04_mnist-classification/index.html#prepare-input-data",
    "title": "MNIST Classification",
    "section": "3 Prepare input data",
    "text": "3 Prepare input data\n\nX_train = X_train.reshape((X_train.shape[0],-1))\nX_test = X_test.reshape((X_test.shape[0], -1))\n\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\nprint(X_train.shape, X_test.shape)\n\n(60000, 784) (10000, 784)\n\n\n\n# Normalize data\nX_train = X_train/255\nX_test = X_test/255\n\n# print(X_train[0])\nX_train.shape\n\n(60000, 784)\n\n\n\n# Perfom one encoding\n\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\nprint(y_train.shape)\n\n(60000, 10)\n\n\n\nnum_classes = y_test.shape[1]\nnum_pixels = 784"
  },
  {
    "objectID": "blog/2023-09-04_mnist-classification/index.html#defining-the-model",
    "href": "blog/2023-09-04_mnist-classification/index.html#defining-the-model",
    "title": "MNIST Classification",
    "section": "4 Defining the model",
    "text": "4 Defining the model\n\n# Define baseline model\n\ndef baseline_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(256, input_dim=num_pixels, activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    \n    return model\n\n\n# Build the model\nmodel = baseline_model()\nmodel.summary()\n\nModel: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_6 (Dense)             (None, 256)               200960    \n                                                                 \n dense_7 (Dense)             (None, 64)                16448     \n                                                                 \n dense_8 (Dense)             (None, 10)                650       \n                                                                 \n=================================================================\nTotal params: 218058 (851.79 KB)\nTrainable params: 218058 (851.79 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\nopt = SGD(lr = 0.001)\nmodel.compile(loss='categorical_crossentropy', optimizer= opt, metrics=['accuracy'])\n\nWARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD."
  },
  {
    "objectID": "blog/2023-09-04_mnist-classification/index.html#train-model",
    "href": "blog/2023-09-04_mnist-classification/index.html#train-model",
    "title": "MNIST Classification",
    "section": "5 Train model",
    "text": "5 Train model\n\nmodel.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n\nEpoch 1/5\n1875/1875 [==============================] - 9s 4ms/step - loss: 0.6029 - accuracy: 0.8422\nEpoch 2/5\n1875/1875 [==============================] - 7s 4ms/step - loss: 0.2849 - accuracy: 0.9181\nEpoch 3/5\n1875/1875 [==============================] - 7s 4ms/step - loss: 0.2314 - accuracy: 0.9346\nEpoch 4/5\n1875/1875 [==============================] - 8s 4ms/step - loss: 0.1962 - accuracy: 0.9440\nEpoch 5/5\n1875/1875 [==============================] - 8s 4ms/step - loss: 0.1701 - accuracy: 0.9510\n\n\n&lt;keras.src.callbacks.History at 0x13e2b0b50&gt;"
  },
  {
    "objectID": "blog/2023-09-04_mnist-classification/index.html#test-model",
    "href": "blog/2023-09-04_mnist-classification/index.html#test-model",
    "title": "MNIST Classification",
    "section": "6 Test model",
    "text": "6 Test model\n\nscores = model.evaluate(X_test, y_test, verbose=1)\nprint(\"Error: %.2f%%\" % (100-scores[1]*100))\n\n313/313 [==============================] - 1s 3ms/step - loss: 0.1672 - accuracy: 0.9516\nError: 4.84%"
  },
  {
    "objectID": "blog/2023-09-04_mnist-classification/index.html#predicting",
    "href": "blog/2023-09-04_mnist-classification/index.html#predicting",
    "title": "MNIST Classification",
    "section": "7 Predicting",
    "text": "7 Predicting\n\nimg_width, img_height = 28, 28\ngray_image = X_test[0]\nplt.imshow(gray_image,cmap='Greys')\nplt.show()\n# gray_image.shape\nx = np.expand_dims(gray_image, axis=0)\nx = x.reshape((1, -1))\n\n\n\n\n\npreds = model.predict(x)\nprob = np.argmax(preds, axis=1)\n\nprint('Predicted value is ', prob)\nprint('Probability across all numbers :', preds[0])\n\n1/1 [==============================] - 0s 30ms/step\nPredicted value is  [7]\nProbability across all numbers : [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]"
  },
  {
    "objectID": "books/index.html",
    "href": "books/index.html",
    "title": "Books",
    "section": "",
    "text": "Books\n\n\nThis section covers various books that I have read and think are worth recommending.\n\n\n\n\n\n\nGoal of this section\n\n\n\n\n\n\nRefer to this page when my friends ask me what I read\nKeep a colection of books including the author’s name\n\n\n\n\n\n\n\n\n\n        \n            \n                \n                Atomic Habits\n                James Clear\n            \n        \n\n\n        \n            \n                \n                Unclutter Your Life in One Week\n                Erin Rooney Doland\n            \n        \n\n\n\n         \n            \n                \n                \n                    The Tipping Point\n                    Malcolm Gladwell\n                \n            \n        \n\n\n\n        \n            \n                \n                Mindset\n                Carol S. Dweck\n            \n        \n\n\n\n        \n            \n                \n                The Four-Hour Workweek\n                Tim Ferriss\n            \n        \n\n\n\n        \n            \n                \n                Blink\n                Malcolm Gladwell\n            \n        \n\n\n\n        \n            \n                \n                The Tipping Point\n                Malcolm Gladwell\n            \n        \n\n\n\n        \n            \n                \n                The Information\n                James Gleick\n            \n        \n\n\n\n        \n            \n                \n                The Practice\n                Seth Godin\n            \n        \n\n\n\n        \n            \n                \n                All Marketers are Liars\n                Seth Godin\n            \n        \n\n\n\n        \n            \n                \n                Emotional Intelligence\n                Daniel Goleman\n            \n        \n\n\n\n        \n            \n                \n                Originals\n                Adam Grant\n            \n        \n\n\n\n        \n            \n                \n                You Can't Make This Stuff Up\n                Lee Gutkind\n            \n        \n\n\n\n        \n            \n                \n                Mindfulness in Plain English\n                Bhante Henepola Gunaratana\n            \n        \n\n\n\n        \n            \n                \n                The Joy of Less\n                Francine Jay\n            \n        \n\n\n\n        \n            \n                \n                Farsighted\n                Steven Johnson\n            \n        \n\n\n\n        \n            \n                \n                Where Good Ideas Come From\n                Steven Johnson"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Published",
    "section": "",
    "text": "# \n        \n        \n          projects:\n        \n      \n      Published\n    \n  \n\n  \n    \n      \n        \n          Show All Projects  \n        \n      \n    \n  \n  \n\n \n\n\n\n\n     \n        \n        \n            \n            1\n            \n            2\n            \n            3\n            \n            4\n        \n            \n                \n                1\n                \n                2\n        \n        \n            \n            5\n            \n            6\n            \n            7\n        \n            \n                \n                3\n        \n        \n            \n            8\n            \n            9\n            \n            10\n        \n            \n                \n                4\n        \n        \n            \n            11\n            \n            12\n            \n            13\n            \n            14\n        \n            \n                \n                5\n                \n                6\n        \n        \n            \n            15\n            \n            16\n            \n            17\n        \n            \n                \n                7\n                \n                8\n        \n        \n            \n            18\n            \n            19\n            \n            20\n            \n            21\n        \n            \n                \n                9\n        \n        \n            \n            22\n            \n            23\n        \n            \n                \n                10\n        \n        \n            \n            24\n            \n            25\n        \n            \n                \n                11\n\n\n        \n        \n            \n            \n                \n                    \n                        \n                            Website\n                            \n                            ×\n                            \n                        \n                        \n                            \n                                \n                                \n                                    \n                                    \n                                        \n                                    \n                                    \n                                    \n                                        \n                                                \n                                                    In this project I have created a website to hold my notes, show my projects, share my contact details. If you are interested in the project make sure to click on the source icon to take a look at the complete source. Cheers \n                                                \n                                            \n                                            \n                                                About\n                                             \n                                                \n                                                    Source\n                                                    \n                                                 \n                                                \n                                             \n                                                 \n                                                        \n                                                            \n                                                            \n                                                                HTML\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                Javascript\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                SCSS\n                                                               \n                                                        \n                                             \n                                            \n                                            \n                                                \n                                                \n                                                    \n                                                    \n                                                    Tags:\n                                                    \n                                                \n                                                 \n                                                        \n                                                            \n                                                                \n                                                                    Blog\n                                                                   \n                                                        \n                                                        \n                                                            \n                                                                \n                                                                    Research\n                                                                   \n                                                        \n                                             \n                                        \n                                     \n                                 \n                            \n                         \n                     \n                  \n             \n            \n            \n            \n                \n                    Website\n                \n                \n            \n            \n                \n                \n                    About\n                 \n                    \n                        Source\n                        \n                        \n                     \n                    \n                 \n                     \n                            \n                                \n                                    HTML\n                                   \n                            \n                            \n                                \n                                    Javascript\n                                   \n                            \n                            \n                                \n                                    SCSS\n                                   \n                            \n                 \n                \n                \n                    \n                    \n                        \n                        \n                        \n                        Tags:\n                        \n                    \n                     \n                            \n                                \n                                    \n                                        Blog\n                                       \n                            \n                            \n                                \n                                    \n                                        Research\n                                       \n                            \n                 \n            \n        \n        \n        \n            \n            \n                \n                    \n                        \n                            ML Project\n                            \n                            ×\n                            \n                        \n                        \n                            \n                                \n                                \n                                    \n                                    \n                                        \n                                    \n                                    \n                                    \n                                        \n                                                \n                                                    \n                                                \n                                            \n                                            \n                                                About\n                                             \n                                                \n                                                    Source\n                                                    \n                                                 \n                                                \n                                             \n                                                 \n                                                        \n                                                            \n                                                            \n                                                                Python\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                OpenSpiel\n                                                               \n                                                        \n                                             \n                                            \n                                            \n                                                \n                                                \n                                                    \n                                                    \n                                                    Tags:\n                                                    \n                                                \n                                                 \n                                                        \n                                                            \n                                                                \n                                                                    Machine Learning\n                                                                   \n                                                        \n                                             \n                                        \n                                     \n                                 \n                            \n                         \n                     \n                  \n             \n            \n            \n            \n                \n                    ML Project\n                \n                \n            \n            \n                \n                \n                    About\n                 \n                    \n                        Source\n                        \n                        \n                     \n                    \n                 \n                     \n                            \n                                \n                                    Python\n                                   \n                            \n                            \n                                \n                                    OpenSpiel\n                                   \n                            \n                 \n                \n                \n                    \n                    \n                        \n                        \n                        \n                        Tags:\n                        \n                    \n                     \n                            \n                                \n                                    \n                                        Machine Learning\n                                       \n                            \n                 \n            \n        \n        \n        \n            \n            \n                \n                    \n                        \n                            EA Project\n                            \n                            ×\n                            \n                        \n                        \n                            \n                                \n                                \n                                    \n                                    \n                                        \n                                    \n                                    \n                                    \n                                        \n                                                \n                                                    \n                                                \n                                            \n                                            \n                                                About\n                                             \n                                                \n                                                    Source\n                                                    \n                                                 \n                                                \n                                             \n                                                 \n                                                        \n                                                            \n                                                            \n                                                                Python\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                Numba\n                                                               \n                                                        \n                                             \n                                            \n                                            \n                                                \n                                                \n                                                    \n                                                    \n                                                    Tags:\n                                                    \n                                                \n                                                 \n                                                        \n                                                            \n                                                                \n                                                                    Optimization\n                                                                   \n                                                        \n                                             \n                                        \n                                     \n                                 \n                            \n                         \n                     \n                  \n             \n            \n            \n            \n                \n                    EA Project\n                \n                \n            \n            \n                \n                \n                    About\n                 \n                    \n                        Source\n                        \n                        \n                     \n                    \n                 \n                     \n                            \n                                \n                                    Python\n                                   \n                            \n                            \n                                \n                                    Numba\n                                   \n                            \n                 \n                \n                \n                    \n                    \n                        \n                        \n                        \n                        Tags:\n                        \n                    \n                     \n                            \n                                \n                                    \n                                        Optimization\n                                       \n                            \n                 \n            \n        \n        \n        \n            \n            \n                \n                    \n                        \n                            CV Project\n                            \n                            ×\n                            \n                        \n                        \n                            \n                                \n                                \n                                    \n                                    \n                                        \n                                    \n                                    \n                                    \n                                        \n                                                \n                                                    \n                                                \n                                            \n                                            \n                                                About\n                                             \n                                                \n                                                    Source\n                                                    \n                                                 \n                                                \n                                             \n                                                 \n                                                        \n                                                            \n                                                            \n                                                                Python\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                Kaggle\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                Tensorflow\n                                                               \n                                                        \n                                             \n                                            \n                                            \n                                                \n                                                \n                                                    \n                                                    \n                                                    Tags:\n                                                    \n                                                \n                                                 \n                                                        \n                                                            \n                                                                \n                                                                    Computer Vision\n                                                                   \n                                                        \n                                                        \n                                                            \n                                                                \n                                                                    Control Systems\n                                                                   \n                                                        \n                                             \n                                        \n                                     \n                                 \n                            \n                         \n                     \n                  \n             \n            \n            \n            \n                \n                    CV Project\n                \n                \n            \n            \n                \n                \n                    About\n                 \n                    \n                        Source\n                        \n                        \n                     \n                    \n                 \n                     \n                            \n                                \n                                    Python\n                                   \n                            \n                            \n                                \n                                    Kaggle\n                                   \n                            \n                            \n                                \n                                    Tensorflow\n                                   \n                            \n                 \n                \n                \n                    \n                    \n                        \n                        \n                        \n                        Tags:\n                        \n                    \n                     \n                            \n                                \n                                    \n                                        Computer Vision\n                                       \n                            \n                            \n                                \n                                    \n                                        Control Systems\n                                       \n                            \n                 \n            \n        \n        \n        \n            \n            \n                \n                    \n                        \n                            AI Project\n                            \n                            ×\n                            \n                        \n                        \n                            \n                                \n                                \n                                    \n                                    \n                                        \n                                    \n                                    \n                                    \n                                        \n                                                \n                                                    \n                                                \n                                            \n                                            \n                                                About\n                                             \n                                                \n                                                    Source\n                                                    \n                                                 \n                                                \n                                             \n                                                 \n                                                        \n                                                            \n                                                            \n                                                                Python\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                LateX\n                                                               \n                                                        \n                                             \n                                            \n                                            \n                                                \n                                                \n                                                    \n                                                    \n                                                    Tags:\n                                                    \n                                                \n                                                 \n                                                        \n                                                            \n                                                                \n                                                                    Machine Learning\n                                                                   \n                                                        \n                                                        \n                                                            \n                                                                \n                                                                    Algorithms\n                                                                   \n                                                        \n                                             \n                                        \n                                     \n                                 \n                            \n                         \n                     \n                  \n             \n            \n            \n            \n                \n                    AI Project\n                \n                \n            \n            \n                \n                \n                    About\n                 \n                    \n                        Source\n                        \n                        \n                     \n                    \n                 \n                     \n                            \n                                \n                                    Python\n                                   \n                            \n                            \n                                \n                                    LateX\n                                   \n                            \n                 \n                \n                \n                    \n                    \n                        \n                        \n                        \n                        Tags:\n                        \n                    \n                     \n                            \n                                \n                                    \n                                        Machine Learning\n                                       \n                            \n                            \n                                \n                                    \n                                        Algorithms\n                                       \n                            \n                 \n            \n        \n        \n        \n            \n            \n                \n                    \n                        \n                            BSc Thesis\n                            \n                            ×\n                            \n                        \n                        \n                            \n                                \n                                \n                                    \n                                    \n                                        \n                                    \n                                    \n                                    \n                                        \n                                                \n                                                    \n                                                \n                                            \n                                            \n                                                About\n                                             \n                                                \n                                                    Paper\n                                                    \n                                                 \n                                                \n                                             \n                                                 \n                                                        \n                                                            \n                                                            \n                                                                C++\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                LateX\n                                                               \n                                                        \n                                                        \n                                                            \n                                                            \n                                                                Arduino\n                                                               \n                                                        \n                                             \n                                            \n                                            \n                                                \n                                                \n                                                    \n                                                    \n                                                    Tags:\n                                                    \n                                                \n                                                 \n                                                        \n                                                            \n                                                                \n                                                                    Electrical Engineering\n                                                                   \n                                                        \n                                             \n                                        \n                                     \n                                 \n                            \n                         \n                     \n                  \n             \n            \n            \n            \n                \n                    BSc Thesis\n                \n                \n            \n            \n                \n                \n                    About\n                 \n                    \n                        Paper\n                        \n                     \n                    \n                 \n                     \n                            \n                                \n                                    C++\n                                   \n                            \n                            \n                                \n                                    LateX\n                                   \n                            \n                            \n                                \n                                    Arduino\n                                   \n                            \n                 \n                \n                \n                    \n                    \n                        \n                        \n                        \n                        Tags:\n                        \n                    \n                     \n                            \n                                \n                                    \n                                        Electrical Engineering\n                                       \n                            \n                 \n            \n        \n        \n        \n            \n            \n                \n                    \n                        \n                            C++ Project\n                            \n                            ×\n                            \n                        \n                        \n                            \n                                \n                                \n                                    \n                                    \n                                        \n                                    \n                                    \n                                    \n                                        \n                                                \n                                                    \n                                                \n                                            \n                                            \n                                                About\n                                             \n                                                \n                                                    Source\n                                                    \n                                                 \n                                                \n                                             \n                                                 \n                                                        \n                                                            \n                                                            \n                                                                C++\n                                                               \n                                                        \n                                             \n                                            \n                                            \n                                                \n                                                \n                                                    \n                                                    \n                                                    Tags:\n                                                    \n                                                \n                                                 \n                                                        \n                                                            \n                                                                \n                                                                    Software Engineering\n                                                                   \n                                                        \n                                             \n                                        \n                                     \n                                 \n                            \n                         \n                     \n                  \n             \n            \n            \n            \n                \n                    C++ Project\n                \n                \n            \n            \n                \n                \n                    About\n                 \n                    \n                        Source\n                        \n                        \n                     \n                    \n                 \n                     \n                            \n                                \n                                    C++\n                                   \n                            \n                 \n                \n                \n                    \n                    \n                        \n                        \n                        \n                        Tags:\n                        \n                    \n                     \n                            \n                                \n                                    \n                                        Software Engineering\n                                       \n                            \n                 \n            \n        \n        \n        \n            \n            \n                \n                    \n                        \n                            Control Systems Project\n                            \n                            ×\n                            \n                        \n                        \n                            \n                                \n                                \n                                    \n                                    \n                                        \n                                    \n                                    \n                                    \n                                        \n                                                \n                                                    \n                                                \n                                            \n                                            \n                                                About\n                                             \n                                                \n                                                    Source\n                                                    \n                                                 \n                                                \n                                             \n                                                 \n                                                        \n                                                            \n                                                            \n                                                                20-sim\n                                                               \n                                                        \n                                             \n                                            \n                                            \n                                                \n                                                \n                                                    \n                                                    \n                                                    Tags:\n                                                    \n                                                \n                                                 \n                                                        \n                                                            \n                                                                \n                                                                    Electrical Engineering\n                                                                   \n                                                        \n                                             \n                                        \n                                     \n                                 \n                            \n                         \n                     \n                  \n             \n            \n            \n            \n                \n                    Control Systems Project\n                \n                \n            \n            \n                \n                \n                    About\n                 \n                    \n                        Source\n                        \n                        \n                     \n                    \n                 \n                     \n                            \n                                \n                                    20-sim\n                                   \n                            \n                 \n                \n                \n                    \n                    \n                        \n                        \n                        \n                        Tags:\n                        \n                    \n                     \n                            \n                                \n                                    \n                                        Electrical Engineering\n                                       \n                            \n                 \n            \n        \n\n\n         \n            All\n        \n         \n            HTML\n        \n         \n            Javascript\n        \n         \n            SCSS\n        \n         \n            All\n        \n         \n            Python\n        \n         \n            OpenSpiel\n        \n         \n            All\n        \n         \n            Python\n        \n         \n            Numba\n        \n         \n            All\n        \n         \n            Python\n        \n         \n            Kaggle\n        \n         \n            Tensorflow\n        \n         \n            All\n        \n         \n            Python\n        \n         \n            LateX\n        \n         \n            All\n        \n         \n            C++\n        \n         \n            LateX\n        \n         \n            Arduino\n        \n         \n            All\n        \n         \n            C++\n        \n         \n            All\n        \n         \n            20-sim\n        \n         \n            Blog\n        \n         \n            Research\n        \n         \n            Machine Learning\n        \n         \n            Optimization\n        \n         \n            Computer Vision\n        \n         \n            Control Systems\n        \n         \n            Machine Learning\n        \n         \n            Algorithms\n        \n         \n            Electrical Engineering\n        \n         \n            Software Engineering\n        \n         \n            Electrical Engineering\n        \n         \n            website\n        \n         \n            ml_project\n        \n         \n            ea_project\n        \n         \n            cv_project\n        \n         \n            ai_project\n        \n         \n            bsc_thesis\n        \n         \n            c_project\n        \n         \n            control_systems_project\n        \n\n\nNo matching items"
  },
  {
    "objectID": "coming-soon.html",
    "href": "coming-soon.html",
    "title": "Coming Soon",
    "section": "",
    "text": "Coming Soon\n        \n    \n    \n        \n            The page you requested is under construction."
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "Danilo Toapanta",
    "section": "",
    "text": "Hi, there! This is Danilo.\n                    \n                    I’m an AI researcher based in the Netherlands.\n                    I studied Computer Science in my undergraduate programme and now I am doing my master in Artificial Intelligence.\n                    When I am not trying to figure out how my computer works, I like to read books, run, go for a swim, and spend some quality time with my family.\n                    \n                    \n                        You can look me up on Github↗. \n                        Check out my LinkedIn↗. \n                        Read my lastest post. \n                        \n                        Or send me an\n                            email↗."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Danilo Toapanta",
    "section": "",
    "text": "Quick links:  Slides  |  Projects  | Books  | What I’m doing now\n\nNews\n\n\n    \n        \n            Sep 2023 - I am attending, OpenAI: AI and the Future of Humanity\n            Jun 2023 - I will do an intership at IMEC\n            May 2023 - Have been accepted to the M.Sc. in AI at UvA\n            Feb 2023 - Now the website has a Blog section\n            Nov 2023 - Have completed AI Berkeley Course\n        \n    \n\n\n\n\n\n\n\nNote\n\n\n\nThis website is under construction. To review changes visit DEV page of this site."
  },
  {
    "objectID": "blog/2022-12-29_cuando-miras-al-cielo/index.html",
    "href": "blog/2022-12-29_cuando-miras-al-cielo/index.html",
    "title": "Cuando miras al cielo",
    "section": "",
    "text": "Cuando miras al cielo\n        \n        \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Poems\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Spanish\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Poems\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Spanish\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          December 29, 2022\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\nby Danilo Toapanta \n\nBlog  &gt; Poems\n\n\nEn el cesped yace tu cuerpo\ndonde tus ideas viajan por las nubes\ntus manos tratan de alcanzar el cielo\ntu mente siente la textura de algodón\npero tu cuerpo sabe que yace en el cesped."
  },
  {
    "objectID": "blog/2023-01-12_2022-into-2023/index.html",
    "href": "blog/2023-01-12_2022-into-2023/index.html",
    "title": "2022 into 2023",
    "section": "",
    "text": "2022 into 2023\n        \n        \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                News\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                News\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          January 12, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\nHappy New Year! Time to write another year in review. This will be the first time I’ve done this. Here are all the previous ones:\n\n2022 into 2023\n\nI have really high hopes for 2023! It’s only a few days in and so far so good. I’ve really had a chance to relax, rest, and reset."
  },
  {
    "objectID": "blog/2023-09-26_matrix-calculus/index.html",
    "href": "blog/2023-09-26_matrix-calculus/index.html",
    "title": "Matrix Calculus",
    "section": "",
    "text": "Derivatives of vectors, matrix and other utils\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Vector Calculus\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Vector Calculus\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 26, 2023"
  },
  {
    "objectID": "blog/2023-09-26_matrix-calculus/index.html#transpose-properties",
    "href": "blog/2023-09-26_matrix-calculus/index.html#transpose-properties",
    "title": "Matrix Calculus",
    "section": "Transpose Properties",
    "text": "Transpose Properties\nIf \\(\\Sigma\\) is symmetric:\n\\[\n\\begin{align}\n\\Sigma = \\Sigma^T\\\\\n\\end{align}\n\\]\nThe inverse of a symmetric matrix is also symmetric\n\\[\n\\begin{align}\n(\\Sigma^{-1})^T = (\\Sigma^T)^{-1} = \\Sigma^{-1} \\label{cov_trans_inv} \\\\\n\\end{align}\n\\]\n\n\n\n\n\n\nProof Eq. \\(\\ref{cov_trans_inv}\\)\n\n\n\n\n\n\n\nCode\nimport numpy as np\n\n# Create a symmetric matrix\nA = np.array([[4, 1, 2],\n              [1, 5, 3],\n              [2, 3, 6]])\n\n# Check if A is symmetric\nis_symmetric = np.allclose(A, A.T)\n\nif is_symmetric:\n    # Calculate the inverse of the symmetric matrix\n    A_inv = np.linalg.inv(A)\n\n    print(\"Original symmetric matrix A:\")\n    print(A)\n\n    print(\"\\nInverse of A:\")\n    print(A_inv)\nelse:\n    print(\"The matrix A is not symmetric.\")\n\n\nOriginal symmetric matrix A:\n[[4 1 2]\n [1 5 3]\n [2 3 6]]\n\nInverse of A:\n[[ 0.3         0.         -0.1       ]\n [ 0.          0.28571429 -0.14285714]\n [-0.1        -0.14285714  0.27142857]]\n\n\nHere we have shown that the inverse of a symmetric matrix its also a symmetric matrix. It is not the same because doing the inverse you do other calculations but is symmetric around the diagonal"
  },
  {
    "objectID": "blog/2023-09-26_matrix-calculus/index.html#partial-derivatives",
    "href": "blog/2023-09-26_matrix-calculus/index.html#partial-derivatives",
    "title": "Matrix Calculus",
    "section": "Partial Derivatives",
    "text": "Partial Derivatives\n\\[\n\\begin{align}\n\\frac{\\partial \\textbf{a}^T\\textbf{X}\\textbf{b}}{\\partial\\textbf{X}} &= \\textbf{a}\\textbf{b}^T\\\\\n\\frac{\\partial \\textbf{a}^T\\textbf{X}^{-1}\\textbf{b}}{\\partial\\textbf{X}} &= -(\\textbf{X}^{-1})^T\\textbf{a}\\textbf{b}^T(\\textbf{X}^{-1})^T\\\\\n& = - (\\textbf{X}^{-1})\\textbf{a}\\textbf{b}^T(\\textbf{X}^{-1})\\quad &\\text{If $\\textbf{X}$ is symmetric} \\nonumber \\\\\n\\frac{\\partial (\\textbf{x}-\\textbf{A}\\textbf{s})^T\\textbf{W}(\\textbf{x}-\\textbf{A}\\textbf{s})}{\\partial\\textbf{A}} &= -2\\textbf{W}(\\textbf{x}-\\textbf{A}\\textbf{s})\\textbf{s}^T \\quad &\\text{If $\\textbf{W}$ is symmetric} \\\\\n\\frac{\\partial (\\textbf{x}-\\textbf{A}\\textbf{s})^T\\textbf{W}(\\textbf{x}-\\textbf{A}\\textbf{s})}{\\partial\\textbf{s}} &= -2(\\textbf{x}-\\textbf{A}\\textbf{s})\\textbf{W}^T\\textbf{A} \\quad &\\text{If $\\textbf{W}$ is symmetric} \\\\\n\\frac{\\partial (\\textbf{x}-\\textbf{s})^T\\textbf{W}(\\textbf{x}-\\textbf{s})}{\\partial\\textbf{s}} &= -2(\\textbf{x}-\\textbf{s})\\textbf{W}^T \\quad &\\text{If $\\textbf{W}$ is symmetric}\n\\end{align}\n\\]"
  },
  {
    "objectID": "blog/2023-10-03_the-perceptron/index.html",
    "href": "blog/2023-10-03_the-perceptron/index.html",
    "title": "The Perceptron",
    "section": "",
    "text": "Lecture Notes UvA on 19-9-2023\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                AI\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                AI\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          October 3, 2023"
  },
  {
    "objectID": "blog/2023-10-03_the-perceptron/index.html#the-perceptron-model",
    "href": "blog/2023-10-03_the-perceptron/index.html#the-perceptron-model",
    "title": "The Perceptron",
    "section": "1 The Perceptron Model",
    "text": "1 The Perceptron Model\nit just a linear model where:\n\n\n\nHere \\(\\phi(x)=x\\) for instance.\n\n1.1 Error function\n\n\n\n\n\n1.2 The Perceptron: Learning\n\n\n\nHere \\(&lt;1\\) we can also have \\(\\gamma\\)\n\n\n\n\n\n1.3 Perceptron Learning as Gradient Descent\n\n\n\n\n\n1.4 Pros with the Perceptron\n\nThe algorithm guarantees to converge if the data is linear separable\n\n\n\n1.5 Problems with the Perceptron\n\nPerceptron only works for 2 classes\nCycling theorem: many solutions if data is not linearly separable\nBased on linear combination of fixed basis functions."
  },
  {
    "objectID": "blog/2023-09-05_equation-for-ml1/index.html",
    "href": "blog/2023-09-05_equation-for-ml1/index.html",
    "title": "Probability Theory in Machine Learning",
    "section": "",
    "text": "Formulas for the course at UvA: Machine Learning 1\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Probability Theory\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Probability Theory\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 5, 2023\nThis section focus on two weeks of the course. For Classification continue to this post."
  },
  {
    "objectID": "blog/2023-09-05_equation-for-ml1/index.html#rules-of-probability-theory",
    "href": "blog/2023-09-05_equation-for-ml1/index.html#rules-of-probability-theory",
    "title": "Probability Theory in Machine Learning",
    "section": "1 Rules of Probability Theory",
    "text": "1 Rules of Probability Theory\nSum Rule used in Marginalization \\[\n\\begin{align}\np(x) &= \\sum_{y \\in Y }^{} p(x,y) \\\\\n     &= \\sum_{y \\in Y }^{} p(x|y)p(y) \\nonumber\n\\end{align}\n\\]\nProduct Rule used in the Join Probability \\[\n\\begin{align}\np(x,y) = p(x|y)p(y)\n\\end{align}\n\\]"
  },
  {
    "objectID": "blog/2023-09-05_equation-for-ml1/index.html#expectation-rules",
    "href": "blog/2023-09-05_equation-for-ml1/index.html#expectation-rules",
    "title": "Probability Theory in Machine Learning",
    "section": "2 Expectation Rules",
    "text": "2 Expectation Rules\n\\[\n\\begin{align}\n    \\mathbb{E}[f(x)+g(x)] &= \\mathbb{E}[f(x)] + \\mathbb{E}[g(x)]\\\\\n    \\mathbb{E}[cf(x)] &= c\\mathbb{E}[f(x)]\\\\\n    \\mathbb{E}[c] &= c\\\\\n    \\mathbb{E}[\\mathbb{E}[f(x)]] &= \\mathbb{E}[f(x)]^2\\\\\n\\end{align}\n\\]"
  },
  {
    "objectID": "blog/2023-09-05_equation-for-ml1/index.html#probability-theory-equations",
    "href": "blog/2023-09-05_equation-for-ml1/index.html#probability-theory-equations",
    "title": "Probability Theory in Machine Learning",
    "section": "3 Probability Theory Equations",
    "text": "3 Probability Theory Equations\n\\[\n\\begin{align}\n    \\mathbb{E}[x] &= \\int_{x}x \\, p(x) \\, dx\\\\\n    var[x] &= \\mathbb{E}[(x-\\mathbb{E}[x])^2] \\nonumber\\\\\n    &=\\mathbb{E}[f(x)^2] - \\mathbb{E}[f(x)]^2\\\\\n    cov[x,y] &= \\mathbb{E}[xy]-\\mathbb{E}[x]\\mathbb{E}[y]\\\\  \n    \\mathcal{N}(x|\\mu , \\sigma^2) &= \\frac{1}{\\sqrt{2 \\pi  \\sigma^2}} \\exp^{\\{-\\frac{1}{2 \\sigma^2}(x-\\mu)^2\\}}\\\\\n    \\mathcal{N}(x|\\mu , \\Sigma ) &= (2 \\pi)^{-k/2} |\\Sigma|^{-1/2} \\exp^{\\{-\\frac{1}{2}(x-\\mu)^T \\Sigma^-1 (x-\\mu)\\}}\\\\\n\\end{align}\n\\]\nThis is our model. This is what we estimate: \\[\n\\begin{align}\ny(\\underline{x})\n\\end{align}\n\\]\nThe observations can be sampled from (signal + noise): \\[\n\\begin{align}\nt = sin(\\underline{x}) + \\varepsilon\n\\end{align}\n\\]\nData Pair: For a given \\(x\\), I can get a target value \\(t\\) (the observation) \\[\n\\begin{align}\n(t, x)  \n\\end{align}\n\\]\nFor instance, we have a sampled data D, and for each \\(x\\) we have seen \\(t\\) and that is our excel file we can work with"
  },
  {
    "objectID": "blog/2023-09-05_equation-for-ml1/index.html#bayessian-linear-regression",
    "href": "blog/2023-09-05_equation-for-ml1/index.html#bayessian-linear-regression",
    "title": "Probability Theory in Machine Learning",
    "section": "4 Bayessian Linear Regression",
    "text": "4 Bayessian Linear Regression\nWe do not want to average over models but this time we want to find the best parameters over only one Data set (without splitting it) and change only our parameters.\nFor this we would consider the posterior. So what is the probability that this parameters \\(w\\) represent the actual data.\nGoal recover the probability distribution that may have generated this data (the posterior)\n\n4.1 Dimensions\n\\[\n\\begin{align}\n\\underline{t} &\\in \\mathbb{R}^{Nx1}, \\text{ $N$ amount of linear regressions}\\\\\n\\underline{w} &\\in \\mathbb{R}^{Mx1}, \\text{ $M$ amount of parameters}\\\\\nX &\\in \\mathbb{R}^{NxD}, \\text{ $N$ amount of observ, $D$ amount of models}\\\\\n% \\underline{x_i} &\\in \\mathbb{R}^{Dx1}, \\text{ $i$ the $i_{th}$ experiment} \\\\\n&= [\\underline{x_{1}}, \\underline{x_{2}}, ... ,\\underline{x_{N}}] \\nonumber \\\\\n\\underline{x_{1}} &\\in \\mathbb{R}^{Nx1} = [x_1, x_2,...,x_N]\\\\\n\\underline{\\phi}(\\underline{x}) &\\in \\mathbb{R}^{Dx1} \\to \\mathbb{R}^{Mx1}\\\\\n\\phi_{1}(\\underline{x}) &\\in \\mathbb{R}^{Nx1} \\to \\mathbb{R}^{1x1}\\\\\n\\Phi &\\in \\mathbb{R}^{NxM}\n\\end{align}\n\\]"
  },
  {
    "objectID": "blog/2023-09-05_equation-for-ml1/index.html#sequential-bayesian-learning",
    "href": "blog/2023-09-05_equation-for-ml1/index.html#sequential-bayesian-learning",
    "title": "Probability Theory in Machine Learning",
    "section": "5 Sequential Bayesian Learning",
    "text": "5 Sequential Bayesian Learning\nHere our goal is to find the parameters of w. So we want to find the values w that discribe best the distribution of our data points meaning we want to find the posterior described as:\n\\(p(w|x_1,t_1, \\alpha, \\beta)\\)\n\nWe have a prior, we assume initial values\nWe sample one data point and apply Gaussian distribution to obtain a likelihood\nWith the prior and likelihood we get the posterior (what we want)"
  },
  {
    "objectID": "blog/2023-09-05_equation-for-ml1/index.html#predictive-distribution",
    "href": "blog/2023-09-05_equation-for-ml1/index.html#predictive-distribution",
    "title": "Probability Theory in Machine Learning",
    "section": "6 Predictive Distribution",
    "text": "6 Predictive Distribution\nIf we are given a new input x’, then we want to be able to compute its new distribution meaning we want to compute the new likelihood that looks as follows:\n\\(p(t'|x', X, \\underline{t}, \\alpha, \\beta) = \\int p(t'|x', \\underline{w}, \\beta) p(\\underline{w}|X, \\underline{t}, \\alpha, \\beta)dw\\)\nThe above equation uses Marginalization over w. That does not mean that it depends on w. It’s just a dummy variable it can be another variable thus the predictive distribution does not depend on w.\nThe second term is the posterior.\n\nHere we are given all data points and we get the parameters for w. With that we can get a prior. Those are the assumptions of how the weigths should be.\nThe predictive probability does not depend on w anymore. It depends on the data, so on the experience gained so far. If a new data point comes in then we would update our predictive distribution\nFor each new point x’ we want to fins the new distribution probability for t’"
  },
  {
    "objectID": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html",
    "href": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html",
    "title": "Maximum Likelihood vs Maximum a Posteriori Estimation",
    "section": "",
    "text": "MLE vs MAP in the context of parameter estimation\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 26, 2023"
  },
  {
    "objectID": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#definition",
    "href": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#definition",
    "title": "Maximum Likelihood vs Maximum a Posteriori Estimation",
    "section": "Definition",
    "text": "Definition\nMaximum Likelihood Estimation (MLE) and Maximum A Posteriori Estimation (MAP) are two common statistical methods used for parameter estimation in various fields, including machine learning and statistics. They are often used in the context of estimating parameters of a statistical model or distribution. Here are the key differences between MLE and MAP:"
  },
  {
    "objectID": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#objective",
    "href": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#objective",
    "title": "Maximum Likelihood vs Maximum a Posteriori Estimation",
    "section": "Objective:",
    "text": "Objective:\n\nMLE (Maximum Likelihood Estimation): MLE aims to find the parameter values that maximize the likelihood function, which measures how well the observed data fits the model. In other words, it seeks the parameter values that make the observed data most probable under the assumed model.\nBasically, I have prob density ie a Gaussian. I take its log and then compute the derivate of it w/ rspect to some variable of interest i.e \\(\\mu\\), or \\(\\underline{w}\\)\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generate random data from a Gaussian distribution\nmean = 0  # Mean of the Gaussian distribution\nstd_dev = 1  # Standard deviation of the Gaussian distribution\nsample_size = 10000  # Number of data points\n\ndata = np.random.normal(mean, std_dev, sample_size)\n\n# Create a figure with two subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3))\n\n# Plot the Gaussian distribution on the left subplot\nax1.hist(data, bins=50, density=True, color='blue', alpha=0.7, label='Gaussian Data')\nax1.set_xlabel('x')\nax1.set_ylabel('PDF')\nax1.set_title('Gaussian Distribution')\nax1.grid(True)\n\n# Calculate the PDF of the Gaussian distribution for plotting\nx = np.linspace(mean - 4 * std_dev, mean + 4 * std_dev, 1000)\npdf = norm.pdf(x, mean, std_dev)\n\n# Plot the log PDF on the right subplot\nlog_pdf = np.log(pdf)\nax2.plot(x, log_pdf, 'r-', label='Log PDF of Gaussian')\nax2.set_xlabel('x')\nax2.set_ylabel('Log PDF')\nax2.set_title('Log PDF of Gaussian Distribution')\nax2.grid(True)\n\n# Show legends\nax1.legend()\nax2.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nMAP (Maximum A Posteriori Estimation): MAP, on the other hand, incorporates prior information about the parameters into the estimation process. It seeks the parameter values that maximize the posterior probability, which combines the likelihood of the data and the prior probability of the parameters.\n\n\n\n\n\n\n\nWant to know more?\n\n\n\n\n\n\nIncorporation of Prior Information:\nMLE: MLE does not consider any prior information or beliefs about the parameters. It solely relies on the likelihood of the observed data. MAP: MAP explicitly incorporates prior beliefs or information about the parameters through the prior probability distribution. This makes MAP especially useful when you have some prior knowledge about the parameters.\n\n\nFormulation:\nMLE: The MLE estimate for a parameter is obtained by maximizing the likelihood function, typically by taking the derivative of the likelihood function with respect to the parameter and setting it to zero. MAP: The MAP estimate for a parameter is obtained by maximizing the posterior probability, which is proportional to the product of the likelihood and the prior probability. Mathematically, it involves finding the mode of the posterior distribution.\n\n\nRobustness to Small Sample Sizes:\nMLE: MLE can be sensitive to small sample sizes because it tends to overfit the data when the sample size is small. MAP: MAP can provide more stable estimates in situations with limited data because it incorporates prior information, which can act as regularization.\n\n\nInterpretability:\nMLE: MLE estimates tend to be more data-driven and may not incorporate external knowledge. They are often considered more objective. MAP: MAP estimates can be influenced by prior information, which can introduce subjectivity into the estimation process. The choice of the prior distribution can significantly impact the MAP estimates.\nIn summary, the main difference between MLE and MAP is the incorporation of prior information. MLE seeks the parameter values that maximize the likelihood of the data, while MAP combines the likelihood with prior information to find parameter values that maximize the posterior probability. The choice between MLE and MAP depends on the specific problem and the availability of prior knowledge about the parameters."
  },
  {
    "objectID": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#incorporation-of-prior-information",
    "href": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#incorporation-of-prior-information",
    "title": "Maximum Likelihood vs Maximum a Posteriori Estimation",
    "section": "Incorporation of Prior Information:",
    "text": "Incorporation of Prior Information:\nMLE: MLE does not consider any prior information or beliefs about the parameters. It solely relies on the likelihood of the observed data. MAP: MAP explicitly incorporates prior beliefs or information about the parameters through the prior probability distribution. This makes MAP especially useful when you have some prior knowledge about the parameters."
  },
  {
    "objectID": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#formulation",
    "href": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#formulation",
    "title": "Maximum Likelihood vs Maximum a Posteriori Estimation",
    "section": "Formulation:",
    "text": "Formulation:\nMLE: The MLE estimate for a parameter is obtained by maximizing the likelihood function, typically by taking the derivative of the likelihood function with respect to the parameter and setting it to zero. MAP: The MAP estimate for a parameter is obtained by maximizing the posterior probability, which is proportional to the product of the likelihood and the prior probability. Mathematically, it involves finding the mode of the posterior distribution."
  },
  {
    "objectID": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#robustness-to-small-sample-sizes",
    "href": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#robustness-to-small-sample-sizes",
    "title": "Maximum Likelihood vs Maximum a Posteriori Estimation",
    "section": "Robustness to Small Sample Sizes:",
    "text": "Robustness to Small Sample Sizes:\nMLE: MLE can be sensitive to small sample sizes because it tends to overfit the data when the sample size is small. MAP: MAP can provide more stable estimates in situations with limited data because it incorporates prior information, which can act as regularization."
  },
  {
    "objectID": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#interpretability",
    "href": "blog/2023-09-26_maximum-likelihood-estimation-(mle)-vs-maximum-a-posteriori-estimation-(map)/index.html#interpretability",
    "title": "Maximum Likelihood vs Maximum a Posteriori Estimation",
    "section": "Interpretability:",
    "text": "Interpretability:\nMLE: MLE estimates tend to be more data-driven and may not incorporate external knowledge. They are often considered more objective. MAP: MAP estimates can be influenced by prior information, which can introduce subjectivity into the estimation process. The choice of the prior distribution can significantly impact the MAP estimates.\nIn summary, the main difference between MLE and MAP is the incorporation of prior information. MLE seeks the parameter values that maximize the likelihood of the data, while MAP combines the likelihood with prior information to find parameter values that maximize the posterior probability. The choice between MLE and MAP depends on the specific problem and the availability of prior knowledge about the parameters."
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html",
    "href": "blog/2023-10-04_neural-networks/index.html",
    "title": "Neural networks",
    "section": "",
    "text": "Lecture Notes UvA on 26-9-2023\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          October 4, 2023\nThe only difference between the normal perceptron and the logistic regression its how we compute the activation function the f(x)\nThe perceptron cannot solve the XOR problem also the logistic regression. To get around this problem, we stack perceptron like in a layer fashion model. This is called Multilayer Perceptron\nBut because people start to use the logistic regression instead of the actual hardcore perceptron output (so \\(+1\\) or \\(-1\\)) then we now call it. Multilayer Logistic Regression\nSo instead of that we are gonna have different activation functions\nWe also talked about QDA this is a non linear model classifier\nWe call the computation from going to the input to the ouput as forward propagation\nThe number of parameters for Logistic Regression is \\(D+1\\) vs Gaussian Classifier contains \\(D^2\\). all these computation.\nSo when you get scared about the number of layers then you just remember the previous layers they were just a type of basis funtions and the last layer is a linear model like so:\nThe difference between linear models with adaptive basis is that the Neural Networks learn the basis functions.\nWith Neural Networks we do not have to have heuristics for this basis functions but they learn by themselves.\nWe see that to separate our data from above we can use one hidden layer with tree units:\nRecall from the previous lecture that with our Logistic Regression we neede to have some radial functions, the difference here its that we can now gotten learnt this basis functions with our Neural Network.\nNN start with low level features and keeps increasing until it calculates the features it find relevant to take a decision.\nIt is spacial invariant because you are moving your kernel along all dimensions."
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#universal-approximators",
    "href": "blog/2023-10-04_neural-networks/index.html#universal-approximators",
    "title": "Neural networks",
    "section": "1 Universal Approximators",
    "text": "1 Universal Approximators\nWe can find a number M and for the weights \\(\\textbf{w}^(2)\\) so the weights in the second layer. Here \\(M\\) represents the units aka the circles in a layer. See the green highlighted circles below\n\n\n\n\nIf we want the error to be to zero then we want the value of \\(M\\) to be larger and larger. This is because we fixed our NN to have only 2 layers so the only thing that can grow its the widht so \\(M\\) so the number of neurons (units). So with M its hard if you compute plenty of them because then you need a lot of GPUs.\nThe summary of the Universal Approximator is that width \\(M\\) is the one that matter. It is just one hidden layer and if you can make it big enough, so if you can increase \\(M\\) enough then you can fit approximate almost anything\n\n\n\n\nHere \\(\\textbf{w}^2 \\in \\mathbb{R}^{Mx1}\\) because if we want to compute only one single value at the end of the NN we need the dimensions of the vector to align see figure above"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#deep-neural-nets-and-shallow-neural-nets",
    "href": "blog/2023-10-04_neural-networks/index.html#deep-neural-nets-and-shallow-neural-nets",
    "title": "Neural networks",
    "section": "2 Deep Neural Nets and Shallow Neural Nets",
    "text": "2 Deep Neural Nets and Shallow Neural Nets\n\n\n\nHere we are saying that if we want to conserve the error lower as much as a Deep Neural Net, so that we can have a Shallow Neural Net then we need to increase the number of \\(M\\) or number of weights. But by doing so this scales exponentially.\nTo growth complexity you have to increase the width, but instead of this you can do it in the depth. As we will see in the slide below, Depth gives you more complexity so its preferable to increase depth instead of width\n\nWidth: \\(M\\) number of weights\nIf you want the error small then increase this number. However if you go this route the number \\(M(\\varepsilon)\\) grows exponentially\nDepth: \\(l\\) number of hidden layers.\nHere it gives you more complexity, so its recommended, End result have deeper NNs.\n\n\nThe point of the image above is to show that with the same model (3 hidden units and 1 linesr ouput unit) which is the Neural Network we can approximate these 4 functions."
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#expressive-power-relu-networks",
    "href": "blog/2023-10-04_neural-networks/index.html#expressive-power-relu-networks",
    "title": "Neural networks",
    "section": "3 Expressive power ReLU networks",
    "text": "3 Expressive power ReLU networks"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#network-training-regression",
    "href": "blog/2023-10-04_neural-networks/index.html#network-training-regression",
    "title": "Neural networks",
    "section": "4 Network Training: Regression",
    "text": "4 Network Training: Regression\nRemember computing the Maximum Likelihood is the same as the minimum of the negative log likelihood, that is why there is a minus on front the \\(\\ln p(\\textbf{t}|\\textbf{W},\\textbf{w})\\)"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#network-training",
    "href": "blog/2023-10-04_neural-networks/index.html#network-training",
    "title": "Neural networks",
    "section": "5 Network Training",
    "text": "5 Network Training\n\n5.1 Regression: Network Training\n\n\n\n\n\n5.2 Binary Classification: Network Training\n\n\n\n5.3 Classification with K classes: Network Training\n\n\n\nFor further explanation in class distribution take a look at here"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#losses-overview",
    "href": "blog/2023-10-04_neural-networks/index.html#losses-overview",
    "title": "Neural networks",
    "section": "6 Losses overview",
    "text": "6 Losses overview"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#training-neural-networks",
    "href": "blog/2023-10-04_neural-networks/index.html#training-neural-networks",
    "title": "Neural networks",
    "section": "7 Training Neural Networks",
    "text": "7 Training Neural Networks\nBecause we cannot find easily the mathematically solutions for training the NN, we use Gradient Descent\n\n\n\n\nResult of forward propagation. Depends on all the NN weights —&gt; Lots of local minima! It results in lots of local minima because we are updating simultaneously all the weights\nThat means that the loss function depends on all the parameters (all the weights in the NN) thus we have a lot of parameters to update.\n\n\n\n\nHere for instance we have 2 local minima and one unique global minima"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#neural-network-optimization-surface",
    "href": "blog/2023-10-04_neural-networks/index.html#neural-network-optimization-surface",
    "title": "Neural networks",
    "section": "8 Neural Network Optimization Surface",
    "text": "8 Neural Network Optimization Surface\n\n\n\n\nDespite these crazy optimization landscapes, gradient descent works amazingly well!\nFor large networks, many of the critical points are saddle-points, not local minima.\n\nAs our dimensionality increases, the saddle points will grow with respect to the minimum, but the minimam will also grow\n\n\n\nBecause of all these variation we want to always report uncertainties on performance. This uncertainties comes from randomness in initialization and Stochastic Gradient Descend SGD.\nThe idea is to report error by averaging over all these models in the same column.\nNow, we talked about making the learning rate higher at start and then slowly decreased it at training. This what we talk in the next topic:"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#cyclic-learning-rates",
    "href": "blog/2023-10-04_neural-networks/index.html#cyclic-learning-rates",
    "title": "Neural networks",
    "section": "9 Cyclic Learning Rates",
    "text": "9 Cyclic Learning Rates\nIt may seem crazy making the learning rate cyclic, so increase it again then lower it then increase it again. But this results in exploration so that you don’t end up in a local minima.\n\n\n\n\n\n\nWith cyclic learning rate we could explore three local minima\n\nNote: We used to compute Logistic Regression with Gradient Descent, here its the same with NN. More mathematically we cannot compute a closed form of the weights hence we use GD."
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#chain-rule-through-layers",
    "href": "blog/2023-10-04_neural-networks/index.html#chain-rule-through-layers",
    "title": "Neural networks",
    "section": "10 Chain Rule through Layers",
    "text": "10 Chain Rule through Layers\n\nForward Propagation: is to evaluate the full network from inputs to ouputs\nBackward Propagation: is to send error signals back though the network\n\n\n\n\nRemember \\(h_l = \\sigma(a)\\). Meaning the ouput of the sigmoid is the new \\(h_l\\). With this in mind because we want to tune the parameters aka weights we send the error back to the inputs, this as we said before it’s called backpropagation.\nNow, because we want to send the error back so that we can reduce it, we would compute the derivative. Here is the same, we will compute the derivatives and because the NN its like a chain of multiplication due to the chain rule, here we can make use of optimization techniques. That is:\n\nBackpropagation is simply the chain rule implemented with cached values of intermediate computations.\nWe have the tradeoff between computational complexity for memory. In other words we have saved in computation complexity (carry out many derivatives) because we have cached these \\(h_{l,j}\\) which is exactly the result of computing the derivatives to reduce the error and thus carry out backpropagation.\n\nIn summary when we do backprogation due to the symmetry of the hidden layers, we can save in computing all the times the derivatives and instead trade it for memory to cache these \\(h_{l,j}\\)\nThe above is what distinguishes the chain rule from backpropagation. Backpropagation uses the notion of reusing information."
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#downside-numerical-issues",
    "href": "blog/2023-10-04_neural-networks/index.html#downside-numerical-issues",
    "title": "Neural networks",
    "section": "11 Downside: Numerical Issues",
    "text": "11 Downside: Numerical Issues\n\n\n\nTwo things can go wrong with this approach:\n\nExploding gradients:\n\nProblem: The multiplication of an intermediate derivate value could be large so then wehn you continue multiplying with the rest of the layers then it will become a huge number.\n\nSolution: can usually be handled by ‘clipping’ values or regularizing weights to be small.\n\nVanishing gradients:\n\nProblem: When the ouput of the sigmoid is close to \\(1\\) or \\(0\\) we would have that the derivative \\(h_{l,j}*(1-h_{l,j})\\) where recall that \\(\\textbf{h}_l=\\sigma(\\textbf{a})\\) meaning when sigmoid evaluates to this extremes then the derivative would become zero. In other words, if zero because \\(h_{l,j}\\) can be \\(1\\) or \\(0\\) then all derivatives to earlier layers will be zero. See figure below:\n\n\n\n\nThe figure above then means that if one derivative becomes zero then learning cannot happen.\n\nPossible Solution1: there is no proper solution because if you say you want to clip this derivative not to yield \\(1\\) or \\(0\\) then your next question its to how much close to these extremes I should set the derivative. (In practice however the sigmoid will not evaluate to perfect \\(1\\) or \\(0\\) but it will be small enough to make the multiplication of the other derivatives in the chain rule significantly deleterious to proceed training).\n\nPossible Solution2: In the neural networks we add a line that connect the current output layer \\(h_l\\) with the previous outout layer \\(h_{l-1}\\)"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#scalar-neural-network",
    "href": "blog/2023-10-04_neural-networks/index.html#scalar-neural-network",
    "title": "Neural networks",
    "section": "12 Scalar Neural Network",
    "text": "12 Scalar Neural Network\n\n\n\n\nRecall that when we do linear regression we do not need to have an activation function \\(f\\) like softmax or logistic, we just have the identity which means \\(f(w_2 \\cdot h)\\) becomes just \\(w_2 \\cdot h\\).\n\n\n\n\n\n12.1 Computing the Error loss on \\(w_1\\)\n\n\n\nIf we would compute the error but now with activation function \\(a\\) equals Relu\n\n\n\nThis could be a bad idea because if \\(w_1 \\cdot x\\) is lower than \\(0\\) then the whole error loss would be evaluated to zero and thus cannot train the network because you keep getting derivatives of zero. This is called the Dead Relu problem. In practice people initialize the input to a positive value. Also people use Leaky Relu depicted below"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#vector-neural-network",
    "href": "blog/2023-10-04_neural-networks/index.html#vector-neural-network",
    "title": "Neural networks",
    "section": "13 Vector Neural Network",
    "text": "13 Vector Neural Network\n\nWe will have a scalar input and scalar ouput but with hidden layers as vectors.\n\n\n\n\n\n\n\nNote\n\n\n\n\nDerivative is a row vector: \\[\n\\begin{align}\n\\frac{\\partial f}{\\partial \\textbf{x}} = \\left[\\frac{\\partial f}{\\partial x_1},...,\\frac{\\partial f}{\\partial x_D} \\right]\n\\end{align}\n\\]\nGradient is the transpose of the Derivative vector: \\[\n\\begin{align}\n\\nabla_{w_1}f = \\left[\\frac{\\partial f}{\\partial \\textbf{w}_1} \\right]^T\n\\end{align}\n\\] We do the transpose because we are tryng to get the same shape as our paramter \\(\\textbf{W}\\). So in this case if \\(W\\) would have been a two-row vector then with the transpose we ensure that."
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#computations-in-2d",
    "href": "blog/2023-10-04_neural-networks/index.html#computations-in-2d",
    "title": "Neural networks",
    "section": "14 Computations in 2D",
    "text": "14 Computations in 2D\n\n\n\nA rule of thumb is:\n\nOutput linear operator Rows\nThe model parameters as Columns"
  },
  {
    "objectID": "blog/2023-10-04_neural-networks/index.html#two-modes-forward-and-reverse",
    "href": "blog/2023-10-04_neural-networks/index.html#two-modes-forward-and-reverse",
    "title": "Neural networks",
    "section": "15 Two Modes: Forward and Reverse",
    "text": "15 Two Modes: Forward and Reverse\nIn Pytorch, you can compute the forward or reverse computation we saw before. The only difference is which direction you cache from.\n\nForward mode: you start with the partial derivatives at the beginning of the NN. For instance in the image below, from dh1/dw1 (the first layer) to df/dh2 (the last layer).\n\nBetter when ouput dim &gt;&gt; input dim\n\n\n\n\n\n\nReverse mode: you start from the ouput to the input.\n\nBetter when ouput dim &lt;&lt; input dim\n\n\n\n\n\n\nThis is telling us that i.e to be more efficient in an image classifier then you would prefer the Reverse mode because you have that your input would be a huge array of numbers whereas your ouput would be a few classes. So here it applies: dim ouput &lt;&lt; dim input.\nThe reason for ie in forward mode is that you would compute small derivatives because your input is small so then you delay to compute much more multiplication to the end\nAnother examples why is more efficient, say your outputs &gt;&gt; inputs, then if you start by computing the ouput derivatives then you are going to accumulate and carry all those dimensions due to the large ouput derivatives. Then you carry all these computations to the input layer that has fewer computations but you already have a hug baggage and its not efficient. Summary: you want to do the large multiplication until the end so that you do not carry unnecessary derivation."
  },
  {
    "objectID": "blog/2023-08-18_how_to_use_widgets_in_jupyter_notebooks/index.html",
    "href": "blog/2023-08-18_how_to_use_widgets_in_jupyter_notebooks/index.html",
    "title": "How to use widgets in jupyter notebooks",
    "section": "",
    "text": "How to use widgets in jupyter notebooks\n                \n            \n                        \n                \n                    Description of this Notebook\n                \n            \n                        \n            \n                                            \n\n                    \n                                            \n                            \n                                All\n                            \n                         \n                                            \n                            \n                                TAGS\n                            \n                         \n                                            \n                            \n                                Python\n                            \n                         \n                    \n                    \n                                    \n                            \n        \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 18, 2023\n        \n      \n      \n        \n      \n      \n\n        \n                 Code\n            \n    \n\n\n\n\n\n\n    \n        How to use widgets in jupyter notebooks\n        \n        \n                    \n                \n                    Description of this Notebook\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 18, 2023\n        \n      \n      \n        \n      \n      \n\n    \n        Quick Links\n    \n         Quick Links:\n                                    \n                 Code"
  },
  {
    "objectID": "blog/2023-06-20_running-my-first-marathon/index.html",
    "href": "blog/2023-06-20_running-my-first-marathon/index.html",
    "title": "Running my first Marathon",
    "section": "",
    "text": "I will be running at the 42km TCS Amsterdam 2023, 15th October\n                \n            \n                        \n            \n                                            \n\n                    \n                                            \n                            \n                                All\n                            \n                         \n                                            \n                            \n                                Life\n                            \n                         \n                                            \n                            \n                                TAGS\n                            \n                         \n                                            \n                            \n                                Amsterdam\n                            \n                         \n                                            \n                            \n                                Running\n                            \n                         \n                    \n                    \n                                    \n                            \n        \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          June 20, 2023\n        \n      \n      \n        \n      \n      \n\n        \n                 Slides\n                 Code\n                 Video\nThe idea of running a marathon its exiting. Specially when I did a half-marathon and reach the goal feeling a champ."
  },
  {
    "objectID": "blog/2023-06-20_running-my-first-marathon/index.html#during-the-training",
    "href": "blog/2023-06-20_running-my-first-marathon/index.html#during-the-training",
    "title": "Running my first Marathon",
    "section": "During the training",
    "text": "During the training\nTo prepare runnign at be acustomed during the competition after looking at some post and blogs I have decided to come up with my own plan, the idea is to prepare it by my own because I will be still be bussy during the month of October\nFor that reason, I have compelled the following traning plan, after looking analysis how other do it."
  },
  {
    "objectID": "blog/2023-06-20_running-my-first-marathon/index.html#during-the-marathon",
    "href": "blog/2023-06-20_running-my-first-marathon/index.html#during-the-marathon",
    "title": "Running my first Marathon",
    "section": "During the marathon",
    "text": "During the marathon\n\nThe pace\nFrom experience I know it can be tricky to fall into the tramp or going as fast as other people will do it. I have made this mistake and I find myself not sticking to my goals. The whole purpose of training its to test how capable I am and compare myself with myself. Thus, to avoid ‘hittin the wall’ I would like to analalize…"
  },
  {
    "objectID": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html",
    "href": "blog/2023-10-07_latent-variable-models-&-k-means-clustering/index.html",
    "title": "Latent Variable Models & K-Means Clustering",
    "section": "",
    "text": "Latent Variable Models & K-Means Clustering\n        \n        \n                    \n                \n                    Lecture Notes UvA on 2-10-2023\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Education\n                            \n                        \n                                            \n                            \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Python\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Education\n                            \n                        \n                                            \n                            \n                               \n                                Machine Learning\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Python\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          October 7, 2023"
  },
  {
    "objectID": "blog/2023-05-29_markdown-structure/index.html",
    "href": "blog/2023-05-29_markdown-structure/index.html",
    "title": "Markdown structure, titles and CSS",
    "section": "",
    "text": "Showing how titles and sections will be displayed in all posts\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Markdown\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Testing\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Markdown\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Testing\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          May 29, 2023"
  },
  {
    "objectID": "blog/2023-05-29_markdown-structure/index.html#posts",
    "href": "blog/2023-05-29_markdown-structure/index.html#posts",
    "title": "Markdown structure, titles and CSS",
    "section": "1. Posts",
    "text": "1. Posts\ndate-modified: last-modified\n\n# Bootstrap Icons\ncategories: [ &lt;i class='bi bi-archive'&gt;&lt;/i&gt; DevOps, TAGS, Python]                    \n\n# Material Icons\ncategories: [ \"&lt;i class='material-icons'&gt;account_circle&lt;/i&gt;\",  DevOps, TAGS, Python] \n\n# Hides post\ncoming-soon: true\n\n# Make numbered the sections\nnumber-sections: true\n\n# Until what numebr to show in TOC\ntoc-depth: 4"
  },
  {
    "objectID": "blog/2023-05-29_markdown-structure/index.html#notebook",
    "href": "blog/2023-05-29_markdown-structure/index.html#notebook",
    "title": "Markdown structure, titles and CSS",
    "section": "2. Notebook",
    "text": "2. Notebook\n# Uses Bootstrap icons\nlinks:\n  - icon: download\n    name: Code\n    href: index.out.ipynb\n  - icon: file-earmark-pdf\n    name: See Article \n    url: https://www.researchgate.net/\n  - icon: file-slides-fill\n    name: Slides\n    url: https://www.google.com/\n  - icon: play-btn-fill\n    name: Video\n    url: https://www.google.com/\n\n# Creates downloadable icon below TOC\nformat:\n  ipynb: default"
  },
  {
    "objectID": "blog/2023-05-29_markdown-structure/index.html#this-is-an-h2-title",
    "href": "blog/2023-05-29_markdown-structure/index.html#this-is-an-h2-title",
    "title": "Markdown structure, titles and CSS",
    "section": "1.1 This is an H2 title",
    "text": "1.1 This is an H2 title\n\n1.1.1 This is an H3 title\n\n1.1.1.1 This is an H4 title\nAbove we use the left option to specify items for the left side of the navigation bar. You can also use the right option to specify items for the right side.\nThe text for navigation bar items will be taken from the underlying target document’s title. Note that in the above example we provide a custom text: “Home” value for index.qmd.\nYou can also create a navigation bar menu by including a menu (which is a list of items much like left and right). For example:\nleft: - text: “More” menu: - talks.qmd - about.qmd\nHere are all of the options available for top navigation:\nOption Description title Navbar title (uses the site: title if none is specified). Use title: false to suppress the display of the title on the navbar. logo Logo image to be displayed left of the title. logo-alt Alternate text for the logo image. logo-href Target href from navbar logo / title. By default, the logo and title link to the root page of the site (/index.html). background Background color (“primary”, “secondary”, “success”, “danger”, “warning”, “info”, “light”, “dark”, or hex color) foreground Foreground color (“primary”, “secondary”, “success”, “danger”, “warning”, “info”, “light”, “dark”, or hex color). The foreground color will be used to color navigation elements, text and links that appear in the navbar. search Include a search box (true or false) tools List of navbar tools (e.g. link to github or twitter, etc.). See Navbar Tools for details. left / right Lists of navigation items for left and right side of navbar pinned Always show the navbar (true or false). Defaults to false, and uses headroom.js to automatically show the navbar when the user scrolls up on the page. collapse Collapse the navbar items into a hamburger menu when the display gets narrow (defaults to true) collapse-below Responsive breakpoint at which to collapse navbar items to a hamburger menu (“sm”, “md”, “lg”, “xl”, or “xxl”, defaults to “lg”) Here are the options available for individual navigation items:\nOption Description href Link to file contained with the project or external URL. text Text to display for navigation item (defaults to the document title if not provided). icon Name of one of the standard Bootstrap 5 icons (e.g. “github”, “twitter”, “share”, etc.). aria-label Accessible label for the navigation item. rel Value for rel attribute. Multiple space-separated values are permitted. menu List of navigation items to populate a drop-down menu.\n\n\n\n1.1.2 This is a title\nAbove we use the left option to specify items for the left side of the navigation bar. You can also use the right option to specify items for the right side.\nThe text for navigation bar items will be taken from the underlying target document’s title. Note that in the above example we provide a custom text: “Home” value for index.qmd.\nYou can also create a navigation bar menu by including a menu (which is a list of items much like left and right). For example:\nleft: - text: “More” menu:\n- talks.qmd\n\n- about.qmd\n\n1.1.2.1 This is a title\nHere are all of the options available for top navigation:\nOption Description\ntitle Navbar title (uses the site: title if none is specified). Use title: false to suppress the display of the title on the navbar. logo Logo image to be displayed left of the title. logo-alt Alternate text for the logo image. logo-href Target href from navbar logo / title. By default, the logo and title link to the root page of the site (/index.html). background Background color (“primary”, “secondary”, “success”, “danger”, “warning”, “info”, “light”, “dark”, or hex color) foreground Foreground color (“primary”, “secondary”, “success”, “danger”, “warning”, “info”, “light”, “dark”, or hex color). The foreground color will be used to color navigation elements, text and links that appear in the navbar. search Include a search box (true or false) tools List of navbar tools (e.g. link to github or twitter, etc.). See Navbar Tools for details. left / right Lists of navigation items for left and right side of navbar pinned Always show the navbar (true or false). Defaults to false, and uses headroom.js to automatically show the navbar when the user scrolls up on the page. collapse Collapse the navbar items into a hamburger menu when the display gets narrow (defaults to true) collapse-below Responsive breakpoint at which to collapse navbar items to a hamburger menu (“sm”, “md”, “lg”, “xl”, or “xxl”, defaults to “lg”) Here are the options available for individual navigation items:\nOption Description href Link to file contained with the project or external URL. text Text to display for navigation item (defaults to the document title if not provided). icon Name of one of the standard Bootstrap 5 icons (e.g. “github”, “twitter”, “share”, etc.). aria-label Accessible label for the navigation item. rel Value for rel attribute. Multiple space-separated values are permitted. menu List of navigation items to populate a drop-down menu."
  },
  {
    "objectID": "blog/2023-05-29_markdown-structure/index.html#this-is-a-title-2",
    "href": "blog/2023-05-29_markdown-structure/index.html#this-is-a-title-2",
    "title": "Markdown structure, titles and CSS",
    "section": "1.2 This is a title",
    "text": "1.2 This is a title\nOption Description title Navbar title (uses the site: title if none is specified). Use title: false to suppress the display of the title on the navbar. logo Logo image to be displayed left of the title. logo-alt Alternate text for the logo image. logo-href Target href from navbar logo / title. By default, the logo and title link to the root page of the site (/index.html). background Background color (“primary”, “secondary”, “success”, “danger”, “warning”, “info”, “light”, “dark”, or hex color) foreground Foreground color (“primary”, “secondary”, “success”, “danger”, “warning”, “info”, “light”, “dark”, or hex color). The foreground color will be used to color navigation elements, text and links that appear in the navbar. search Include a search box (true or false) tools List of navbar tools (e.g. link to github or twitter, etc.). See Navbar Tools for details. left / right Lists of navigation items for left and right side of navbar pinned Always show the navbar (true or false). Defaults to false, and uses headroom.js to automatically show the navbar when the user scrolls up on the page. collapse Collapse the navbar items into a hamburger menu when the display gets narrow (defaults to true) collapse-below Responsive breakpoint at which to collapse navbar items to a hamburger menu (“sm”, “md”, “lg”, “xl”, or “xxl”, defaults to “lg”) Here are the options available for individual navigation items:\nOption Description href Link to file contained with the project or external URL. text Text to display for navigation item (defaults to the document title if not provided). icon Name of one of the standard Bootstrap 5 icons (e.g. “github”, “twitter”, “share”, etc.). aria-label Accessible label for the navigation item. rel Value for rel attribute. Multiple space-separated values are permitted. menu List of navigation items to populate a drop-down menu."
  },
  {
    "objectID": "blog/2023-05-29_markdown-structure/index.html#this-is-a-title-5",
    "href": "blog/2023-05-29_markdown-structure/index.html#this-is-a-title-5",
    "title": "Markdown structure, titles and CSS",
    "section": "2.1 This is a title",
    "text": "2.1 This is a title\nAbove we use the left option to specify items for the left side of the navigation bar. You can also use the right option to specify items for the right side.\nThe text for navigation bar items will be taken from the underlying target document’s title. Note that in the above example we provide a custom text: “Home” value for index.qmd.\nYou can also create a navigation bar menu by including a menu (which is a list of items much like left and right). For example:\nleft: - text: “More” menu: - talks.qmd - about.qmd\nHere are all of the options available for top navigation:"
  },
  {
    "objectID": "blog/2023-05-29_markdown-structure/index.html#this-is-a-title-6",
    "href": "blog/2023-05-29_markdown-structure/index.html#this-is-a-title-6",
    "title": "Markdown structure, titles and CSS",
    "section": "2.2 This is a title",
    "text": "2.2 This is a title\n\n2.2.1 This is a title\nOption Description title Navbar title (uses the site: title if none is specified). Use title: false to suppress the display of the title on the navbar. logo Logo image to be displayed left of the title. logo-alt Alternate text for the logo image. logo-href Target href from navbar logo / title. By default, the logo and title link to the root page of the site (/index.html). background Background color (“primary”, “secondary”, “success”, “danger”, “warning”, “info”, “light”, “dark”, or hex color) foreground Foreground color (“primary”, “secondary”, “success”, “danger”, “warning”, “info”, “light”, “dark”, or hex color). The foreground color will be used to color navigation elements, text and links that appear in the navbar. search Include a search box (true or false) tools List of navbar tools (e.g. link to github or twitter, etc.). See Navbar Tools for details. left / right Lists of navigation items for left and right side of navbar pinned Always show the navbar (true or false). Defaults to false, and uses headroom.js to automatically show the navbar when the user scrolls up on the page. collapse Collapse the navbar items into a hamburger menu when the display gets narrow (defaults to true) collapse-below Responsive breakpoint at which to collapse navbar items to a hamburger menu (“sm”, “md”, “lg”, “xl”, or “xxl”, defaults to “lg”) Here are the options available for individual navigation items:"
  },
  {
    "objectID": "sites/index.html",
    "href": "sites/index.html",
    "title": "My Sites",
    "section": "",
    "text": "My Sites\n\n\n\n\n\n\nMain section where I keep track of important news about my professional carrier.\n\n\nHOME\n\n\n\n\n\n\n\n\nAbout me, my interests and experience, and my work as a AI Research Engineer.\n\n\nABOUT\n\n\n\n\n\n\n\n\nI sometimes write about what I’m doing and learning, mostly about CS and building websites.\n\n\nBLOG\n\n\n\n\n\n\n\n\nI have worked on big-scale projects. Here are links to their repos, websites and any other resources.\n\n\nPROJECTS\n\n\n\n\n\n\n\n\nSlides and resources from talks I’ve given for educational purposes or conferences.\n\n\nSLIDES\n\n\n\n\n\n\n\n\n\nWhat I have read and I am reading at the moment. Recomendations? I’d love to hear from you!\n\n\nBOOKS"
  },
  {
    "objectID": "notes/2023-08-26_how-to-highlight-lines-of-code-in-github/index.html",
    "href": "notes/2023-08-26_how-to-highlight-lines-of-code-in-github/index.html",
    "title": "How to highlight lines of code in Github",
    "section": "",
    "text": "How to highlight lines of code in Github\n        \n        \n                    \n                \n                    Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 26, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\nYou use at the end of an html:\n#L5-L6\n\n[Demo](https://github.com/danilotpnta/hammerspoon-config/blob/master/init.lua#L5-L6)\nDemo"
  },
  {
    "objectID": "notes/2023-08-27_changes-to-vanilla-quarto/index.html",
    "href": "notes/2023-08-27_changes-to-vanilla-quarto/index.html",
    "title": "Changes to Vanilla Quarto",
    "section": "",
    "text": "Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 27, 2023"
  },
  {
    "objectID": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#find-styles-code-highlighting",
    "href": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#find-styles-code-highlighting",
    "title": "Changes to Vanilla Quarto",
    "section": "1 Find Styles Code Highlighting",
    "text": "1 Find Styles Code Highlighting\n\nPandoc highlight styles: /Applications/quarto/share/pandoc/highlight-styles"
  },
  {
    "objectID": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#changes-the-moon-icon",
    "href": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#changes-the-moon-icon",
    "title": "Changes to Vanilla Quarto",
    "section": "2 Changes the moon icon",
    "text": "2 Changes the moon icon\n\nChange toggle-icons: /Applications/quarto/share/formats/html/bootstrap/\\_bootstrap-rules.scss\n/Users/datoapanta/Desktop/danilotpnta.github.io/docs/site_libs/bootstrap/bootstrap-dark.min.css\nI change the SVG from this site: https://icons.getbootstrap.com/icons/moon/\n\n\n\nCopy this\n\n// .navbar .quarto-color-scheme-toggle:not(.alternate) .bi::before {\n//   background-image: url('data:image/svg+xml,&lt;svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" fill=\"#{colorToRGBA($navbar-light-color)}\" class=\"bi bi-toggle-off\" viewBox=\"0 0 16 16\"&gt;&lt;path d=\"M11 4a4 4 0 0 1 0 8H8a4.992 4.992 0 0 0 2-4 4.992 4.992 0 0 0-2-4h3zm-6 8a4 4 0 1 1 0-8 4 4 0 0 1 0 8zM0 8a5 5 0 0 0 5 5h6a5 5 0 0 0 0-10H5a5 5 0 0 0-5 5z\"/&gt;&lt;/svg&gt;');\n// }\n\n// Toggle MOON\n.navbar .quarto-color-scheme-toggle:not(.alternate) .bi::before {\n  background-image: url('data:image/svg+xml,&lt;svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" fill=\"#{colorToRGBA($navbar-light-color)}\" class=\"bi bi-toggle-off\" viewBox=\"0 0 16 16\"&gt;&lt;path d=\"M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278zM4.858 1.311A7.269 7.269 0 0 0 1.025 7.71c0 4.02 3.279 7.276 7.319 7.276a7.316 7.316 0 0 0 5.205-2.162c-.337.042-.68.063-1.029.063-4.61 0-8.343-3.714-8.343-8.29 0-1.167.242-2.278.681-3.286z\"/&gt;&lt;/svg&gt;');\n}\n\n// Toggle MOON filled\n// .navbar .quarto-color-scheme-toggle.alternate .bi::before {\n//   background-image: url('data:image/svg+xml,&lt;svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" fill=\"#{colorToRGBA($navbar-light-color)}\" class=\"bi bi-toggle-on\" viewBox=\"0 0 16 16\"&gt;&lt;path d=\"M5 3a5 5 0 0 0 0 10h6a5 5 0 0 0 0-10H5zm6 9a4 4 0 1 1 0-8 4 4 0 0 1 0 8z\"/&gt;&lt;/svg&gt;');\n// }\n\n.navbar .quarto-color-scheme-toggle.alternate .bi::before {\n  background-image: url('data:image/svg+xml,&lt;svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" fill=\"#{colorToRGBA($navbar-light-color)}\" class=\"bi bi-toggle-on\" viewBox=\"0 0 16 16\"&gt;&lt;path d=\"M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z\"/&gt;&lt;/svg&gt;');\n}"
  },
  {
    "objectID": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#changes-title-of-categories-to-all-categories",
    "href": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#changes-title-of-categories-to-all-categories",
    "title": "Changes to Vanilla Quarto",
    "section": "3 Changes title of “Categories” to “All Categories”",
    "text": "3 Changes title of “Categories” to “All Categories”\n\n/Applications/quarto/bin/quarto.js\n\nCopy this:\n// headingEl.innerText = localizedString(format, kListingPageFieldCategories);\nheadingEl.innerText = \"All Categories\";"
  },
  {
    "objectID": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#remove-the-all-from-categories-sidebar",
    "href": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#remove-the-all-from-categories-sidebar",
    "title": "Changes to Vanilla Quarto",
    "section": "4 Remove the “All” from “Categories” Sidebar",
    "text": "4 Remove the “All” from “Categories” Sidebar\n\n/Applications/quarto/bin/quarto.js\n\nCopy this:\nconst allCategory = localizedString(format, kListingPageCategoryAll);\n// const allEl = categoryElement(doc, allCategory, formatFn(allCategory, totalCategories), \"\");"
  },
  {
    "objectID": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#adds-extra-feature-to-the-headeroffset-function",
    "href": "notes/2023-08-27_changes-to-vanilla-quarto/index.html#adds-extra-feature-to-the-headeroffset-function",
    "title": "Changes to Vanilla Quarto",
    "section": "5 Adds extra feature to the headerOffset function",
    "text": "5 Adds extra feature to the headerOffset function\n\nIf the header is absolute then the header.height will be zero to fix the TOC\n/Applications/quarto/share/projects/website/navigation/quarto-nav.js\n\n\n\nCopy this\n\n// function headerOffset() {\n//   // Set an offset if there is are fixed top navbar\n//   const headerEl = window.document.querySelector(\"header.fixed-top\");\n//   if (headerEl) {\n//     return headerEl.clientHeight;\n//   } else {\n//     return 0;\n//   }\n// }\n\nfunction headerOffset() {\n  // Set an offset if there is are fixed top navbar\n  const headerEl = window.document.querySelector(\"header.fixed-top\");\n  if (headerEl) {\n    // If the page is a blog post then return the height as 0\n    const blogSection = window.document.querySelector(\"header.blog-page\");\n    if (blogSection) {\n      // Add extra padding to display well the navbar\n      document.getElementById(\n        \"quarto-content\"\n      ).style.paddingTop = `${headerEl.clientHeight}px`;\n      // returns 0 to fix the TOC where it displays the section\n      return 0;\n    } else {\n      return headerEl.clientHeight;\n    }\n  } else {\n    return 0;\n  }\n}"
  },
  {
    "objectID": "notes/2023-08-22_commands-for-shells/index.html",
    "href": "notes/2023-08-22_commands-for-shells/index.html",
    "title": "Commands Shells",
    "section": "",
    "text": "Commands Shells\n        \n        \n                    \n                \n                    A useful list of Shell commands\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Shells\n                            \n                        \n                                            \n                            \n                                Scripting\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Bash\n                            \n                        \n                                            \n                            \n                                Zsh\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Shells\n                            \n                        \n                                            \n                            \n                               \n                                Scripting\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Bash\n                            \n                        \n                                            \n                            \n                               \n                                Zsh\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 22, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\n\nBash\n# Creates an alias function that can be called from terminal\nfunction(){\n    \n    # $1 first argument passed from terminal\n    FOLDER=$(python create_dir.py $1 $2) \n\n    # To print a variable\n    echo $FOLDER\n\n    # Use var inside another var uses ${}\n    BACKUPDIR=$(ls -td ${FOLDER}/*/ | head -1)\n\n}\n\n\nZsh\n\n# Eliminate the last line of history\ncd\ncode .zsh_history\nreload_shell\n\n# Makes reload the page\nreload_shell(){\n  cd \n  source .zshrc   \n}\n\n# Folder for plugin's\nopen ~/.oh-my-zsh/plugins\n\n# Show all including empty files\nls -a            \n\n\nSyntax\n# Valid naming\n_ALI\nTOKEN_A\n\n# Invalid naming\n2_VAR\n-VARIABLE\nVAR1-VAR2"
  },
  {
    "objectID": "notes/2023-10-06_how-to-embed-ml-application/index.html",
    "href": "notes/2023-10-06_how-to-embed-ml-application/index.html",
    "title": "How to embed ML application?",
    "section": "",
    "text": "Example how to add ml application from gradio.app\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          October 6, 2023"
  },
  {
    "objectID": "notes/2023-10-06_how-to-embed-ml-application/index.html#adding-the-script",
    "href": "notes/2023-10-06_how-to-embed-ml-application/index.html#adding-the-script",
    "title": "How to embed ML application?",
    "section": "1 Adding the script",
    "text": "1 Adding the script\n&lt;script type=\"module\"\nsrc=\"https://gradio.s3-us-west-2.amazonaws.com/3.36.1/gradio.js\"&gt;\n&lt;/script&gt;\n&lt;gradio-app space=\"ForBo7/FloodDetector\"&gt;&lt;/gradio-app&gt;"
  },
  {
    "objectID": "notes/2023-10-06_how-to-embed-ml-application/index.html#styling",
    "href": "notes/2023-10-06_how-to-embed-ml-application/index.html#styling",
    "title": "How to embed ML application?",
    "section": "2 Styling",
    "text": "2 Styling\nTo avoid lines surrounding, add to theme-light.scss\n.info.svelte-1kyws56.svelte-1kyws56 {\n    display: none !important;\n}\n\n.embed-container.svelte-1kyws56.svelte-1kyws56 {\n    border: none !important;\n}"
  },
  {
    "objectID": "notes/2023-08-22_commands-for-github/index.html",
    "href": "notes/2023-08-22_commands-for-github/index.html",
    "title": "Commands GitHub",
    "section": "",
    "text": "Commands GitHub\n        \n        \n                    \n                \n                    A useful list of Github commands\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                GitHub\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                GitHub\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 22, 2023\n        \n      \n      \n        \n      \n      \n\n    \n    \n\n\n\nGithub\ngh repo create\ngit add . && git commit - 'update'\ngit push origin master \n\nmkdir repo-name\ncd repo-name\ntouch file.js\ngit init\ngit add . && git commit -m 'update'\ngh repo create &gt; existing\n\ngit push origin master\n\ngit pull origin master\n\n# To remove files from terminal\ngit rm -r fil\n\n# To change of branch\n\n\ngh\ngh repo delete name-repo\ngh repo create\ngh browse         # Open the repo in a browser Tab\n\n# To update changes to the website\ncd danilotpnta.github.io/\ngit checkout main   # Make sure you are in main branch \nquarto publish gh-pages"
  },
  {
    "objectID": "notes/2023-08-30_repos-uva-assigments/index.html",
    "href": "notes/2023-08-30_repos-uva-assigments/index.html",
    "title": "MSc AI Resources",
    "section": "",
    "text": "Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                UvA\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                UvA\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 30, 2023"
  },
  {
    "objectID": "notes/2023-08-30_repos-uva-assigments/index.html#general-information",
    "href": "notes/2023-08-30_repos-uva-assigments/index.html#general-information",
    "title": "MSc AI Resources",
    "section": "General Information",
    "text": "General Information\n\n\nSummaries: https://github.com/phlippe/UvA_Summaries\nMaths Site: https://www.math4.ai/docs/essentials/eigen_systems.html"
  },
  {
    "objectID": "notes/2023-08-30_repos-uva-assigments/index.html#machine-learning-1",
    "href": "notes/2023-08-30_repos-uva-assigments/index.html#machine-learning-1",
    "title": "MSc AI Resources",
    "section": "Machine Learning 1",
    "text": "Machine Learning 1\n\n\nVideos: https://www.youtube.com/@erikbekkers6398/\n\n\n\n2022-2023\n\nhttps://github.com/QiaoRenOreo/UvA_MachineLearning1\n\n\n\n2018-2019\n\nhttps://github.com/jamie0725/Machine-Learning-1\n\n\n\n2017-2018\n\nhttps://github.com/mhashas/ml1-assignments\nhttps://github.com/Lukx19/UvA-ML1\nhttps://github.com/askliar/machine-learning\nhttps://github.com/FC-31/machine_learning\n\n\n\n2016-2017\n\nhttps://github.com/VincentRoest/machinelearning/tree/master\n\n\n\n2015-2016\n\nhttps://github.com/Ignotus/uva-machine-learning"
  },
  {
    "objectID": "notes/2023-08-30_repos-uva-assigments/index.html#cv-1",
    "href": "notes/2023-08-30_repos-uva-assigments/index.html#cv-1",
    "title": "MSc AI Resources",
    "section": "CV 1",
    "text": "CV 1\n\n2021-2022\n\nhttps://github.com/din0s/uva-cv1\n\n\n\n2019-2020\n\nhttps://github.com/jamie0725/Computer-Vision-1/\nhttps://github.com/dbtmpl/Computer-Vision-1\nhttps://github.com/ktodorov/uva-cv1-19\n\n\n\n2018-2019\n\nhttps://github.com/KrishnaTarun/Computer-Vision-1/\n\n\n\n2017-2018\n\nhttps://github.com/danakianfar/computer_vision_1"
  },
  {
    "objectID": "notes/2023-08-30_repos-uva-assigments/index.html#deep-learning",
    "href": "notes/2023-08-30_repos-uva-assigments/index.html#deep-learning",
    "title": "MSc AI Resources",
    "section": "Deep Learning",
    "text": "Deep Learning\n\n2022-2023\n\nhttps://github.com/QiaoRenOreo/UvA_DeepLearning\n\n\n\n2018-2019\n\nhttps://github.com/davidmrau/deep_learning\nhttps://github.com/MathieuBartels/deep-learning1-uva-2019\nhttps://uvadlc.github.io/\nhttps://github.com/uvadlc\nhttps://github.com/danakianfar/deep_learning"
  },
  {
    "objectID": "notes/2023-08-30_repos-uva-assigments/index.html#nlp",
    "href": "notes/2023-08-30_repos-uva-assigments/index.html#nlp",
    "title": "MSc AI Resources",
    "section": "NLP",
    "text": "NLP\n\n2022-2023\n\nhttps://github.com/gerardPlanella/NLP1_UvA_2022"
  },
  {
    "objectID": "notes/2023-08-30_repos-uva-assigments/index.html#machine-learning-2",
    "href": "notes/2023-08-30_repos-uva-assigments/index.html#machine-learning-2",
    "title": "MSc AI Resources",
    "section": "Machine Learning 2",
    "text": "Machine Learning 2\n\nhttps://github.com/morris-frank/uva-machine-learning-2\n\n\n2017-2018\n\nhttps://github.com/davide-belli/machine-learning-2-labs-hws"
  },
  {
    "objectID": "notes/2023-08-22_command_for_environments/index.html",
    "href": "notes/2023-08-22_command_for_environments/index.html",
    "title": "Command Environments",
    "section": "",
    "text": "A useful list of conda commands\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Environments\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Conda\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Environments\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Conda\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          August 22, 2023"
  },
  {
    "objectID": "notes/2023-08-22_command_for_environments/index.html#conda",
    "href": "notes/2023-08-22_command_for_environments/index.html#conda",
    "title": "Command Environments",
    "section": "Conda",
    "text": "Conda\n\nA conda environment is a directory that contains a specific collection of conda packages that you have installed. For example, you may have one environment with NumPy 1.7 and its dependencies, and another environment with NumPy 1.6 for legacy testing."
  },
  {
    "objectID": "notes/2023-08-22_command_for_environments/index.html#anaconda",
    "href": "notes/2023-08-22_command_for_environments/index.html#anaconda",
    "title": "Command Environments",
    "section": "Anaconda",
    "text": "Anaconda\n\nIt gives you all the standard packages used in scientific computing in a convenient package without having to worry about installing them all individually with their dependencies."
  },
  {
    "objectID": "notes/2023-08-22_command_for_environments/index.html#in-short-conda-anaconda",
    "href": "notes/2023-08-22_command_for_environments/index.html#in-short-conda-anaconda",
    "title": "Command Environments",
    "section": "In short Conda + Anaconda",
    "text": "In short Conda + Anaconda\nConda is a package manager. It helps you take care of your different packages by handling installing, updating and removing them. Anaconda contains all of the most common packages (tools) a data scientist needs and can be considered the hardware store of data science tools.\nconda install anaconda"
  },
  {
    "objectID": "notes/2023-08-22_command_for_environments/index.html#how-to-erase-an-environment",
    "href": "notes/2023-08-22_command_for_environments/index.html#how-to-erase-an-environment",
    "title": "Command Environments",
    "section": "How to erase an environment",
    "text": "How to erase an environment\nconda remove --name ml1labs --all"
  },
  {
    "objectID": "notes/2023-08-22_command_for_environments/index.html#echo-path",
    "href": "notes/2023-08-22_command_for_environments/index.html#echo-path",
    "title": "Command Environments",
    "section": "echo $PATH",
    "text": "echo $PATH\n\n$PATH (or the search path) is the list of directories that will be searched for anything that you type on the command line\nWe use sometimes ls or pwd or echo this is because there is a $PATH where this was. This list of pre-designated directories is stored in a special variable called “PATH”\nThis is a colon-delimited list of all the directories the command line looks in by default for programs on the particular computer.\nExample\n$ (progLab) datoapanta@Danilos-MacBook-Pro ~ % echo $PATH\n/Users/datoapanta/opt/anaconda3/envs/progLab/bin:/Users/datoapanta/opt/anaconda3/condabin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/usr/local/share/dotnet:~/.dotnet/tools:/Library/Frameworks/Mono.framework/Versions/Current/Commands:/Users/datoapanta/.local/bin:/Users/datoapanta/.local/bin\necho $PATH | tr \":\" \"\\n\"\n/Users/datoapanta/opt/anaconda3/envs/progLab/bin /Users/datoapanta/opt/anaconda3/condabin /usr/local/bin /usr/bin /bin /usr/sbin /sbin /Library/TeX/texbin /usr/local/share/dotnet ~/.dotnet/tools /Library/Frameworks/Mono.framework/Versions/Current/Commands /Users/datoapanta/.local/bin /Users/datoapanta/.local/bin\n\nWe can now more clearly see this is a list of directories. All of these places, stored in the variable called “PATH”, are searched whenever we are typing a command in the terminal window.\nIf the command we are trying to use is present in any of the directories listed in our PATH, we don’t need to point at its specific location in full (its path, lowercase) when we are trying to use it – which is of course nice for things we use often."
  },
  {
    "objectID": "notes/2023-09-11_how-to-create-conda-environment-using-yml-file/index.html",
    "href": "notes/2023-09-11_how-to-create-conda-environment-using-yml-file/index.html",
    "title": "How to create Conda environment using YML file?",
    "section": "",
    "text": "Description of this Note\n                \n            \n        \n        \n                    \n                \n                \n                    \n\n                                            \n                            \n                                All\n                            \n                        \n                                            \n                            \n                                Environment\n                            \n                        \n                                            \n                            \n                                TAGS\n                            \n                        \n                                            \n                            \n                                Conda\n                            \n                        \n                                    \n                \n\n\n                \n                    \n                    \n                    \n                        \n                        \n                        \n                        \n                    \n\n                    \n                                            \n                            \n                               \n                                All\n                            \n                        \n                                            \n                            \n                               \n                                Environment\n                            \n                        \n                                            \n                            \n                               \n                                TAGS\n                            \n                        \n                                            \n                            \n                               \n                                Conda\n                            \n                        \n                    \n                    \n                \n\n                    \n    \n\n\n    \n    \n\n        \n        Author\n        \n                 Danilo Toapanta \n              \n      \n        \n        \n        Published\n        \n          September 11, 2023"
  },
  {
    "objectID": "notes/2023-09-11_how-to-create-conda-environment-using-yml-file/index.html#define-yml-requirements",
    "href": "notes/2023-09-11_how-to-create-conda-environment-using-yml-file/index.html#define-yml-requirements",
    "title": "How to create Conda environment using YML file?",
    "section": "1 Define YML requirements",
    "text": "1 Define YML requirements\nFor instance the following file: environment.yml\nname: cv1\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  - python=3.7\n  - pip=21.3.1\n  - pip:\n    - numpy==1.19.5\n    - opencv-contrib-python==3.4.2.17\n    - matplotlib==3.3.4\n    - jupyter==1.0.0\n    - scikit-learn==0.23.0\n    - scipy==1.5.4"
  },
  {
    "objectID": "notes/2023-09-11_how-to-create-conda-environment-using-yml-file/index.html#create-conda-env-from-terminal",
    "href": "notes/2023-09-11_how-to-create-conda-environment-using-yml-file/index.html#create-conda-env-from-terminal",
    "title": "How to create Conda environment using YML file?",
    "section": "2 Create Conda ENV from terminal",
    "text": "2 Create Conda ENV from terminal\nconda env create -f path/to/environment.yml"
  },
  {
    "objectID": "now/index.html",
    "href": "now/index.html",
    "title": "Danilo Toapanta",
    "section": "",
    "text": "What I’m working on right now\n\n\nUpdated on August 16th, 2023.\n\n\n    \n\n\nCore Habits\n\nRead ≧ 20 min\nExercise ≧ 1 hour\nMeditate ≧ 10 minutes\nRun weekly ≧ 18km\n\n\n\nInternship\n\nConnect Hugging Face ML application to repo\nYAML automation for downloading JPEG\n\n\n\nWebsite\n\nFinishing up the project page.\nFuture features can be found at DEV\n\n\n\nR Studio\n\nLearning file management\n\n\n\nReading\n\nAtomic Habits by James Clear\n\n—\n\nBooks I’ve enjoy reading\n\n\n\nArchive \n\n\n\n\n\n\n\nWhat I’m working on right now\n\n\nUpdated on July 24th, 2023.\n\n\n    \n\n\nCore habits\n\nRead ≧ 20 min\nExercise ≧ 1 hour\nMeditate ≧ 10 minutes\n\n\n\nWebsite\n\nGet a domain to publish this site\nFuture features can be found at DEV\n\n\n\nReading\n\n12 Rules for Life by Jordan Peterson\n\n\n\n\n\n\n\nWhat I’m working on right now\n\n\nUpdated on June 28th, 2023\n\n\n    \n\n\n\nWebsite\n\nStart coding from scracth this site"
  }
]